# @package _global_
defaults:
  - ../defaults

learning_rate: 0.001
warmup_steps: 80
weight_decay: 0.001
ranking_loss_coeff: 0.005

select_hidden_layers: null

token_emb: 2
sentence_emb: 1
dropout: 0.1

# from durations cut equivalent to the median time
classification_event_time_thr: 83.6666641235

transformer_hidden_size: 32
transformer_num_hidden_layers: 4
transformer_num_attention_heads: 2
transformer_intermediate_size: 4
transformer_attention_probs_dropout_prob: ${dropout}
transformer_hidden_probs_dropout: ${dropout}

shared_intermediate_size: 4
shared_batch_norm: true
shared_hidden_dropout_prob: 0.05
shared_bias: true
shared_num_hidden_layers: 1
shared_num_labels: 16

survival_max_time: 400
