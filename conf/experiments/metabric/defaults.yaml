# @package _global_
defaults:
  - ../defaults

learning_rate: 0.001
warmup_steps: 80
weight_decay: 0.00001

select_hidden_layers: null

sentence_emb: 3
token_emb: 2
dropout: 0.05

transformer_hidden_size: 8
transformer_num_hidden_layers: 1
transformer_num_attention_heads: 2
transformer_intermediate_size: 8
transformer_attention_probs_dropout_prob: ${dropout}
transformer_hidden_probs_dropout: ${dropout}

shared_intermediate_size: 16
shared_batch_norm: true
shared_hidden_dropout_prob: 0.05
shared_bias: true
shared_num_hidden_layers: 0
shared_num_labels: 8

likelihood_loss_coeff: 0.5
ranking_loss_coeff: 0.3
ranking_loss_sigma: 0.1
calibration_loss_coeff: 0.2
