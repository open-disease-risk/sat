# @package _global_


label_transform_scheme: equidistant
label_transform_cuts: 4

one_calibration_bins: 10

likelihood_loss_coeff: 0.5

event_ranking_loss_coeff: 0.1
event_ranking_loss_sigma: 0.1
event_ranking_loss_margin: 0.05

ranking_loss_coeff: 0.2
ranking_loss_sigma: 0.1
ranking_loss_margin: 0.05

calibration_loss_coeff: 0.2

focal_loss_coeff: 0.1
focal_loss_gamma: [2.0]

observation_ranking_loss_coeff: 0.3
observation_ranking_loss_sigma: 0.1

listmle_epsilon: 1e-10
listmle_temperature: 1.0

# SurvRNC specific parameters
survrnc_margin: 0.5
survrnc_temperature: 0.1
survrnc_hard_mining: True
survrnc_mining_ratio: 0.3

# SOAP specific parameters
soap_margin: 0.1
soap_sigma: 1.0
soap_num_pairs: null  # Auto-calculate based on batch size (n log n pairs)
soap_sampling_strategy: "importance"  # uniform, importance, hard
soap_adaptive_margin: true

# RankNet specific parameters
ranknet_sigma: 1.0  # Controls the steepness of the sigmoid
ranknet_sampling_ratio: 0.3  # Ratio of pairs to sample (0.0-1.0)
ranknet_adaptive_sampling: true  # Adaptively sample more from difficult regions

# DSM specific parameters
dsm_intermediate_size: 64
dsm_num_hidden_layers: 1
dsm_num_mixtures: 4
dsm_distribution: weibull
dsm_temp: 1000.0
dsm_discount: 1.0
dsm_bias: true
dsm_batch_norm: true
dsm_hidden_dropout_prob: 0.2
dsm_elbo: true

# MENSA specific parameters
mensa_intermediate_size: 64
mensa_num_hidden_layers: 1
mensa_num_mixtures: 4
mensa_distribution: weibull
mensa_temp: 1000.0
mensa_discount: 1.0
mensa_bias: true
mensa_batch_norm: true
mensa_hidden_dropout_prob: 0.2
mensa_elbo: true
mensa_event_distribution: true
mensa_dependency_regularization: 0.01

loss_balancing_scale_alpha: 0.9
loss_balancing_scale_eps: 1.0e-8
loss_balancing_grad_alpha: 0.9
loss_balancing_grad_eps: 1.0e-8
loss_balancing_uncertainty_sigma: 1.0
loss_balancing_adaptive_alpha: 0.9
loss_balancing_adaptive_eps: 1.0e-8
loss_balancing_adaptive_window_size: 100
loss_balancing_adaptive_adaptation_rate: 0.005


detect_anomalies: true

brier_per_horizon: false
nllpch_per_event: false
l1_per_event: false
mse_per_event: false
ce_per_event: false

learning_rate: 0.0001
weight_decay: 0.01
token_emb: 2
sentence_emb: 2

mtl_initializer_range: 0.02
mtl_initializer: kaiming_normal

transformer_layer_norm: false
transformer_initializer_range: 0.01
transformer_hidden_size: 24
transformer_intermediate_size: 96
transformer_num_attention_heads: 4
transformer_num_hidden_layers: 2

survival_initializer_range: 0.02
survival_initializer: kaiming_normal
survival_shared_intermediate_size: 4
survival_shared_num_hidden_layers: 0
survival_batch_norm: false
survival_hidden_dropout_prob: false
survival_bias: true
survival_num_hidden_layers: 1
survival_loss_weight: 1.0

classification_initializer_range: 0.02
classification_initializer: xavier_normal
classification_shared_intermediate_size: 4
classification_shared_num_hidden_layers: 0
classification_event_time_thr: 0.5 # not tuned yet
classification_intermediate_size: 64
classification_batch_norm: false
classification_hidden_dropout_prob: false
classification_bias: true
classification_num_hidden_layers: 0
classification_loss_weight: 1.0

regression_initializer_range: 0.02
regression_initializer: kaiming_normal
regression_shared_intermediate_size: 4
regression_shared_num_hidden_layers: 0
regression_intermediate_size: 32
regression_batch_norm: false
regression_hidden_dropout_prob: false
regression_bias: true
regression_num_hidden_layers: 0
regression_num_labels: 1
regression_loss_weight: 1.0
