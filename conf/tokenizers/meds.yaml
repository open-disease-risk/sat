_target_: sat.utils.tokenizing.create_tokenizer
out_dir: ${modelhub}/tokenizer/${dataset}
vocab_size: 30000
tokens:
  - pad
  - unk