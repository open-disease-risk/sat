name: optuna
solutions:
- params:
    learning_rate: 0.0061137121048044875
    weight_decay: 3.330582807440702e-05
    transformer_hidden_size: 16
    transformer_intermediate_size: 32
    transformer_num_attention_heads: 2
    transformer_num_hidden_layers: 4
    survival_intermediate_size: 8
    token_emb: 4
    sentence_emb: 2
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 0.00042246423592538226
    weight_decay: 0.005008187391233939
    transformer_hidden_size: 32
    transformer_intermediate_size: 96
    transformer_num_attention_heads: 2
    transformer_num_hidden_layers: 1
    survival_intermediate_size: 8
    token_emb: 4
    sentence_emb: 3
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 0.009289024403020499
    weight_decay: 0.0039026059380269287
    transformer_hidden_size: 32
    transformer_intermediate_size: 32
    transformer_num_attention_heads: 2
    transformer_num_hidden_layers: 2
    survival_intermediate_size: 16
    token_emb: 5
    sentence_emb: 2
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 0.0039605179868854815
    weight_decay: 0.0001221474711152454
    transformer_hidden_size: 32
    transformer_intermediate_size: 96
    transformer_num_attention_heads: 4
    transformer_num_hidden_layers: 4
    survival_intermediate_size: 24
    token_emb: 2
    sentence_emb: 1
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 0.004832867855096106
    weight_decay: 0.06601474405077805
    transformer_hidden_size: 32
    transformer_intermediate_size: 96
    transformer_num_attention_heads: 2
    transformer_num_hidden_layers: 2
    survival_intermediate_size: 8
    token_emb: 3
    sentence_emb: 1
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 5.393534995190827e-05
    weight_decay: 2.455433858523167e-05
    transformer_hidden_size: 32
    transformer_intermediate_size: 32
    transformer_num_attention_heads: 4
    transformer_num_hidden_layers: 4
    survival_intermediate_size: 8
    token_emb: 2
    sentence_emb: 2
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 0.008116605998602625
    weight_decay: 0.022823036597030538
    transformer_hidden_size: 32
    transformer_intermediate_size: 96
    transformer_num_attention_heads: 2
    transformer_num_hidden_layers: 2
    survival_intermediate_size: 24
    token_emb: 2
    sentence_emb: 2
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 2.229911535434348e-05
    weight_decay: 0.001307250737331016
    transformer_hidden_size: 8
    transformer_intermediate_size: 64
    transformer_num_attention_heads: 2
    transformer_num_hidden_layers: 2
    survival_intermediate_size: 24
    token_emb: 4
    sentence_emb: 3
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 0.002256924383027078
    weight_decay: 2.661594045830411e-05
    transformer_hidden_size: 8
    transformer_intermediate_size: 32
    transformer_num_attention_heads: 2
    transformer_num_hidden_layers: 2
    survival_intermediate_size: 8
    token_emb: 3
    sentence_emb: 2
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 0.00020878308162909816
    weight_decay: 2.7097805678432808e-05
    transformer_hidden_size: 8
    transformer_intermediate_size: 32
    transformer_num_attention_heads: 4
    transformer_num_hidden_layers: 4
    survival_intermediate_size: 24
    token_emb: 3
    sentence_emb: 1
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 0.00040278980476250937
    weight_decay: 3.606966016732677e-05
    transformer_hidden_size: 8
    transformer_intermediate_size: 64
    transformer_num_attention_heads: 2
    transformer_num_hidden_layers: 2
    survival_intermediate_size: 8
    token_emb: 3
    sentence_emb: 1
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 1.3552297831123055e-05
    weight_decay: 0.07732917746089271
    transformer_hidden_size: 16
    transformer_intermediate_size: 64
    transformer_num_attention_heads: 4
    transformer_num_hidden_layers: 1
    survival_intermediate_size: 24
    token_emb: 4
    sentence_emb: 2
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 0.0012022868661430894
    weight_decay: 2.379171324746947e-05
    transformer_hidden_size: 32
    transformer_intermediate_size: 32
    transformer_num_attention_heads: 2
    transformer_num_hidden_layers: 2
    survival_intermediate_size: 16
    token_emb: 2
    sentence_emb: 3
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 1.8982529812689684e-05
    weight_decay: 0.00813878424171078
    transformer_hidden_size: 16
    transformer_intermediate_size: 96
    transformer_num_attention_heads: 4
    transformer_num_hidden_layers: 1
    survival_intermediate_size: 24
    token_emb: 3
    sentence_emb: 2
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 5.2698841682225425e-05
    weight_decay: 0.03864403689527847
    transformer_hidden_size: 32
    transformer_intermediate_size: 64
    transformer_num_attention_heads: 2
    transformer_num_hidden_layers: 2
    survival_intermediate_size: 16
    token_emb: 5
    sentence_emb: 3
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 0.0014652750990073898
    weight_decay: 5.4350394734202735e-05
    transformer_hidden_size: 32
    transformer_intermediate_size: 64
    transformer_num_attention_heads: 4
    transformer_num_hidden_layers: 1
    survival_intermediate_size: 8
    token_emb: 5
    sentence_emb: 1
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 0.0010823348557257727
    weight_decay: 0.0029260870570705566
    transformer_hidden_size: 16
    transformer_intermediate_size: 32
    transformer_num_attention_heads: 2
    transformer_num_hidden_layers: 1
    survival_intermediate_size: 16
    token_emb: 2
    sentence_emb: 3
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 1.0615718252222271e-05
    weight_decay: 0.0006611988376590907
    transformer_hidden_size: 8
    transformer_intermediate_size: 64
    transformer_num_attention_heads: 4
    transformer_num_hidden_layers: 4
    survival_intermediate_size: 16
    token_emb: 3
    sentence_emb: 2
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 1.542591637353615e-05
    weight_decay: 2.0697748051904995e-05
    transformer_hidden_size: 8
    transformer_intermediate_size: 96
    transformer_num_attention_heads: 2
    transformer_num_hidden_layers: 1
    survival_intermediate_size: 8
    token_emb: 5
    sentence_emb: 2
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 0.0005967041986315213
    weight_decay: 0.007137804866402637
    transformer_hidden_size: 16
    transformer_intermediate_size: 32
    transformer_num_attention_heads: 4
    transformer_num_hidden_layers: 1
    survival_intermediate_size: 8
    token_emb: 3
    sentence_emb: 1
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 0.0014652750990073898
    weight_decay: 0.03864403689527847
    transformer_hidden_size: 16
    transformer_intermediate_size: 32
    transformer_num_attention_heads: 4
    transformer_num_hidden_layers: 1
    survival_intermediate_size: 16
    token_emb: 5
    sentence_emb: 1
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 2.229911535434348e-05
    weight_decay: 0.001307250737331016
    transformer_hidden_size: 8
    transformer_intermediate_size: 64
    transformer_num_attention_heads: 2
    transformer_num_hidden_layers: 4
    survival_intermediate_size: 16
    token_emb: 2
    sentence_emb: 3
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 0.00040278980476250937
    weight_decay: 0.03864403689527847
    transformer_hidden_size: 8
    transformer_intermediate_size: 96
    transformer_num_attention_heads: 2
    transformer_num_hidden_layers: 2
    survival_intermediate_size: 8
    token_emb: 3
    sentence_emb: 3
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 0.00040278980476250937
    weight_decay: 0.04240734380564835
    transformer_hidden_size: 8
    transformer_intermediate_size: 32
    transformer_num_attention_heads: 2
    transformer_num_hidden_layers: 1
    survival_intermediate_size: 8
    token_emb: 2
    sentence_emb: 1
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 0.004672613931887468
    weight_decay: 0.005008187391233939
    transformer_hidden_size: 32
    transformer_intermediate_size: 96
    transformer_num_attention_heads: 2
    transformer_num_hidden_layers: 1
    survival_intermediate_size: 8
    token_emb: 4
    sentence_emb: 2
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 0.0061137121048044875
    weight_decay: 0.00813878424171078
    transformer_hidden_size: 16
    transformer_intermediate_size: 96
    transformer_num_attention_heads: 4
    transformer_num_hidden_layers: 1
    survival_intermediate_size: 24
    token_emb: 4
    sentence_emb: 2
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 1.542591637353615e-05
    weight_decay: 2.0697748051904995e-05
    transformer_hidden_size: 8
    transformer_intermediate_size: 64
    transformer_num_attention_heads: 2
    transformer_num_hidden_layers: 2
    survival_intermediate_size: 24
    token_emb: 4
    sentence_emb: 3
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 0.0039605179868854815
    weight_decay: 0.0001221474711152454
    transformer_hidden_size: 32
    transformer_intermediate_size: 64
    transformer_num_attention_heads: 2
    transformer_num_hidden_layers: 4
    survival_intermediate_size: 24
    token_emb: 4
    sentence_emb: 1
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 0.00042246423592538226
    weight_decay: 0.005008187391233939
    transformer_hidden_size: 8
    transformer_intermediate_size: 32
    transformer_num_attention_heads: 2
    transformer_num_hidden_layers: 1
    survival_intermediate_size: 24
    token_emb: 4
    sentence_emb: 3
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 8.361461861194367e-05
    weight_decay: 0.005008187391233939
    transformer_hidden_size: 32
    transformer_intermediate_size: 96
    transformer_num_attention_heads: 2
    transformer_num_hidden_layers: 4
    survival_intermediate_size: 24
    token_emb: 2
    sentence_emb: 1
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 0.0014652750990073898
    weight_decay: 0.015819078485415385
    transformer_hidden_size: 32
    transformer_intermediate_size: 32
    transformer_num_attention_heads: 2
    transformer_num_hidden_layers: 1
    survival_intermediate_size: 8
    token_emb: 5
    sentence_emb: 3
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 0.009289024403020499
    weight_decay: 0.0039026059380269287
    transformer_hidden_size: 32
    transformer_intermediate_size: 32
    transformer_num_attention_heads: 2
    transformer_num_hidden_layers: 2
    survival_intermediate_size: 16
    token_emb: 5
    sentence_emb: 2
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 0.00042246423592538226
    weight_decay: 0.0013905491582833402
    transformer_hidden_size: 16
    transformer_intermediate_size: 96
    transformer_num_attention_heads: 2
    transformer_num_hidden_layers: 1
    survival_intermediate_size: 8
    token_emb: 2
    sentence_emb: 3
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 0.00017342015221900742
    weight_decay: 0.0029260870570705566
    transformer_hidden_size: 16
    transformer_intermediate_size: 32
    transformer_num_attention_heads: 2
    transformer_num_hidden_layers: 1
    survival_intermediate_size: 16
    token_emb: 5
    sentence_emb: 1
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 1.8982529812689684e-05
    weight_decay: 0.00813878424171078
    transformer_hidden_size: 16
    transformer_intermediate_size: 64
    transformer_num_attention_heads: 4
    transformer_num_hidden_layers: 2
    survival_intermediate_size: 24
    token_emb: 4
    sentence_emb: 3
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 0.0004929160836785712
    weight_decay: 0.03864403689527847
    transformer_hidden_size: 32
    transformer_intermediate_size: 64
    transformer_num_attention_heads: 2
    transformer_num_hidden_layers: 2
    survival_intermediate_size: 8
    token_emb: 4
    sentence_emb: 3
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 1.3552297831123055e-05
    weight_decay: 0.07732917746089271
    transformer_hidden_size: 32
    transformer_intermediate_size: 96
    transformer_num_attention_heads: 4
    transformer_num_hidden_layers: 4
    survival_intermediate_size: 24
    token_emb: 2
    sentence_emb: 2
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 0.0014652750990073898
    weight_decay: 5.4350394734202735e-05
    transformer_hidden_size: 8
    transformer_intermediate_size: 64
    transformer_num_attention_heads: 4
    transformer_num_hidden_layers: 1
    survival_intermediate_size: 8
    token_emb: 5
    sentence_emb: 1
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 0.00040278980476250937
    weight_decay: 0.0029260870570705566
    transformer_hidden_size: 16
    transformer_intermediate_size: 32
    transformer_num_attention_heads: 2
    transformer_num_hidden_layers: 2
    survival_intermediate_size: 8
    token_emb: 3
    sentence_emb: 1
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 0.00339221852893789
    weight_decay: 2.661594045830411e-05
    transformer_hidden_size: 8
    transformer_intermediate_size: 32
    transformer_num_attention_heads: 2
    transformer_num_hidden_layers: 2
    survival_intermediate_size: 8
    token_emb: 3
    sentence_emb: 2
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 0.0004929160836785712
    weight_decay: 0.03864403689527847
    transformer_hidden_size: 32
    transformer_intermediate_size: 32
    transformer_num_attention_heads: 2
    transformer_num_hidden_layers: 1
    survival_intermediate_size: 8
    token_emb: 4
    sentence_emb: 3
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 0.00339221852893789
    weight_decay: 0.0031367353545389874
    transformer_hidden_size: 8
    transformer_intermediate_size: 64
    transformer_num_attention_heads: 4
    transformer_num_hidden_layers: 2
    survival_intermediate_size: 8
    token_emb: 4
    sentence_emb: 2
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 0.006222736398722538
    weight_decay: 0.03864403689527847
    transformer_hidden_size: 16
    transformer_intermediate_size: 96
    transformer_num_attention_heads: 2
    transformer_num_hidden_layers: 1
    survival_intermediate_size: 8
    token_emb: 2
    sentence_emb: 2
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 0.00339221852893789
    weight_decay: 2.661594045830411e-05
    transformer_hidden_size: 16
    transformer_intermediate_size: 96
    transformer_num_attention_heads: 2
    transformer_num_hidden_layers: 2
    survival_intermediate_size: 8
    token_emb: 3
    sentence_emb: 2
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 0.0039605179868854815
    weight_decay: 0.010866395574403536
    transformer_hidden_size: 32
    transformer_intermediate_size: 64
    transformer_num_attention_heads: 2
    transformer_num_hidden_layers: 4
    survival_intermediate_size: 16
    token_emb: 2
    sentence_emb: 1
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 8.361461861194367e-05
    weight_decay: 0.07732917746089271
    transformer_hidden_size: 32
    transformer_intermediate_size: 96
    transformer_num_attention_heads: 4
    transformer_num_hidden_layers: 4
    survival_intermediate_size: 24
    token_emb: 2
    sentence_emb: 1
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 2.229911535434348e-05
    weight_decay: 0.07732917746089271
    transformer_hidden_size: 8
    transformer_intermediate_size: 96
    transformer_num_attention_heads: 2
    transformer_num_hidden_layers: 4
    survival_intermediate_size: 24
    token_emb: 2
    sentence_emb: 2
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 0.0061137121048044875
    weight_decay: 5.4350394734202735e-05
    transformer_hidden_size: 16
    transformer_intermediate_size: 96
    transformer_num_attention_heads: 4
    transformer_num_hidden_layers: 1
    survival_intermediate_size: 24
    token_emb: 5
    sentence_emb: 1
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 1.556465839519243e-05
    weight_decay: 2.0697748051904995e-05
    transformer_hidden_size: 8
    transformer_intermediate_size: 32
    transformer_num_attention_heads: 2
    transformer_num_hidden_layers: 1
    survival_intermediate_size: 8
    token_emb: 4
    sentence_emb: 1
  values:
  - -.inf
  - .inf
- params:
    learning_rate: 0.003554605052751381
    weight_decay: 0.005008187391233939
    transformer_hidden_size: 32
    transformer_intermediate_size: 64
    transformer_num_attention_heads: 2
    transformer_num_hidden_layers: 1
    survival_intermediate_size: 24
    token_emb: 5
    sentence_emb: 1
  values:
  - -.inf
  - .inf
