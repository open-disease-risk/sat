task: optuna_sweep
do_sweep: false
do_data_parse: true
do_data_transform: true
do_tokenize: true
do_pretrain: false
do_finetune: true
fold: ''
run_id: ${oc.env:AZUREML_RUN_ID, ""}
parent_run_id: ${oc.env:AZUREML_ROOT_RUN_ID, "."}
base_dir: .
model_dir: ${parent_run_id}/${run_id}
data_dir: ${base_dir}/data
log_dir: ${base_dir}/logs
output_dir: ${hydra:runtime.output_dir}
work_dir: ${hydra:runtime.cwd}
modelhub: ${data_dir}/model-hub
data:
  parse:
    _target_: sat.data.dataset.parse_hsa_synthetic.hsa
    source: ${data_source}
    processed_dir: ${modelhub}
    train_ratio: 0.7
    validation_ratio: 0.1
    test_ratio: 0.2
    scale_method: standard
    scale_numerics: true
    min_scale_numerics: 1.0
    name: ${dataset}
    kfold: ${cv.kfold}
  preprocess_data: false
  perform_split: true
  split_col: split
  duration_col: durations
  event_col: events
  id_col: id
  num_events: 2
  transformed_duration_cols:
  - t
  - f
  splits:
  - train
  - valid
  - test
  load:
    _target_: datasets.load_dataset
    path: json
    data_files:
    - ${modelhub}/${dataset}/${fold}${dataset}.json
    streaming: false
  label_transform:
    buffer_size: 20000
    cuts: ${label_transform_cuts}
    scheme: ${label_transform_scheme}
    save_dir: ${modelhub}/${dataset}
    event_type: null
data_source: ${base_dir}/data/hsa-synthetic/simulated_data.csv
tokenizers:
  tokenizer_dir: ${modelhub}/${dataset}/tokenizer
  tokenize_column: x
  is_split_into_words: false
  do_padding: true
  padding_args:
    direction: right
    pad_to_multiple_of: 1
    padding: max_length
    length: ${tokenizers.max_seq_length}
  do_truncation: true
  truncation_args:
    direction: left
    max_length: ${tokenizers.max_seq_length}
  pad_token: '[PAD]'
  mask_token: '[MASK]'
  unk_token: '[UNK]'
  cls_token: '[CLS]'
  sep_token: '[SEP]'
  tokenizer:
    _target_: tokenizers.Tokenizer
    model:
      _target_: tokenizers.models.WordLevel
      unk_token: ${tokenizers.unk_token}
  pre_tokenizer:
    _target_: tokenizers.pre_tokenizers.WhitespaceSplit
  trainer:
    _target_: tokenizers.trainers.WordLevelTrainer
  special_tokens:
    unk_token: ${tokenizers.unk_token}
    sep_token: ${tokenizers.sep_token}
    pad_token: ${tokenizers.pad_token}
    cls_token: ${tokenizers.cls_token}
    mask_token: ${tokenizers.mask_token}
  num_proc: 4
  cls_model_type: BERT
  max_seq_length: 15
transformers:
  config:
    _target_: sat.models.bert.configuration_bert.NumericBertConfig
    hidden_size: ${transformer_hidden_size}
    num_hidden_layers: ${transformer_num_hidden_layers}
    num_attention_heads: ${transformer_num_attention_heads}
    intermediate_size: ${transformer_intermediate_size}
    attention_probs_dropout_prob: ${transformer_attention_probs_dropout_prob}
    hidden_act: gelu
    hidden_dropout_prob: ${transformer_hidden_probs_dropout}
    output_attentions: false
    output_hidden_states: true
    initializer_range: ${transformer_initializer_range}
    layer_norm: ${transformer_layer_norm}
    return_dict: true
    vocab_size: 1000
tasks:
  losses:
    survival:
      _target_: sat.loss.momentum_buffer.AdaptiveMoCoLoss
      base_loss:
        _target_: sat.loss.SATNLLPCHazardLoss
        importance_sample_weights: ${data.label_transform.save_dir}/imp_sample.csv
        num_events: ${data.num_events}
      buffer_size: ${moco_buffer_size}
      num_events: ${data.num_events}
      embedding_dim: ${data.label_transform.cuts}
      use_buffer: ${moco_use_buffer}
      current_batch_weight: ${moco_batch_weight}
      buffer_weight: ${moco_buffer_weight}
      dynamic_buffer: ${moco_dynamic_buffer}
      initial_buffer_size: ${moco_initial_buffer_size}
      variance_window: ${moco_variance_window}
      variance_threshold: ${moco_variance_threshold}
      min_buffer_ratio: ${moco_min_buffer_ratio}
      max_buffer_ratio: ${moco_max_buffer_ratio}
  metrics:
  - _target_: sat.evaluate.eval_modules.ComputeBrier
    cfg: ${data}
    survival_train_path: ${data.label_transform.save_dir}/transformed_train_labels.csv
    duration_cuts: ${data.label_transform.save_dir}/duration_cuts.csv
    per_horizon: ${brier_per_horizon}
  - _target_: sat.evaluate.eval_modules.ComputeCIndex
    cfg: ${data}
    survival_train_path: ${data.label_transform.save_dir}/transformed_train_labels.csv
    duration_cuts: ${data.label_transform.save_dir}/duration_cuts.csv
  eval_metric: eval_ipcw_avg
  eval_metric_greater_is_better: true
  config:
    _target_: sat.models.heads.MTLConfig
    _convert_: partial
    freeze_transformer: false
    initializer_range: ${mtl_initializer_range}
    initializer: ${mtl_initializer}
    pretrained_params: ${transformers}
    sentence_emb: ${sentence_emb}
    token_emb: ${token_emb}
    hidden_size: ${transformer_hidden_size}
    num_features: ${tokenizers.max_seq_length}
    intermediate_size: ${shared_intermediate_size}
    num_labels: ${shared_num_labels}
    batch_norm: ${shared_batch_norm}
    hidden_dropout_prob: ${shared_hidden_dropout_prob}
    bias: ${shared_bias}
    num_hidden_layers: ${shared_num_hidden_layers}
    select_hidden_layers: ${select_hidden_layers}
    return_dict: true
    task_heads:
    - _target_: sat.models.heads.SurvivalConfig
      _recursive_: false
      initializer_range: ${survival_initializer_range}
      initializer: ${survival_initializer}
      num_features: ${shared_num_labels}
      intermediate_size: ${survival_shared_intermediate_size}
      num_hidden_layers: ${survival_shared_num_hidden_layers}
      indiv_intermediate_size: ${survival_intermediate_size}
      indiv_num_hidden_layers: ${survival_num_hidden_layers}
      num_labels: ${data.label_transform.cuts}
      batch_norm: ${survival_batch_norm}
      hidden_dropout_prob: ${survival_hidden_dropout_prob}
      bias: ${survival_bias}
      loss: ${tasks.losses}
      loss_weight: ${survival_loss_weight}
      num_events: ${data.num_events}
trainer:
  custom: false
  training_arguments:
    _target_: transformers.TrainingArguments
    report_to: tensorboard
    optim: adamw_torch
    overwrite_output_dir: true
    num_train_epochs: 200
    per_device_train_batch_size: 256
    per_device_eval_batch_size: 512
    load_best_model_at_end: true
    greater_is_better: ${tasks.eval_metric_greater_is_better}
    eval_strategy: steps
    eval_steps: 10
    logging_strategy: steps
    logging_steps: 10
    save_strategy: steps
    save_steps: 10
    eval_delay: ${warmup_steps}
    weight_decay: ${weight_decay}
    metric_for_best_model: ${tasks.eval_metric}
    learning_rate: ${learning_rate}
    lr_scheduler_type: cosine
    gradient_accumulation_steps: 2
    warmup_steps: ${warmup_steps}
    save_total_limit: 2
    output_dir: ${modelhub}/${dataset}/${modelname}
    save_safetensors: false
    gradient_checkpointing: false
    dataloader_pin_memory: true
    remove_unused_columns: false
callbacks:
- _target_: transformers.EarlyStoppingCallback
  early_stopping_patience: 10
label_transform_scheme: equidistant
label_transform_cuts: 4
one_calibration_bins: 10
likelihood_loss_coeff: 0.5
event_ranking_loss_coeff: 0.1
event_ranking_loss_sigma: 0.1
event_ranking_loss_margin: 0.05
ranking_loss_coeff: 0.2
ranking_loss_sigma: 0.1
ranking_loss_margin: 0.05
calibration_loss_coeff: 0.2
focal_loss_coeff: 0.1
focal_loss_gamma:
- 2.0
observation_ranking_loss_coeff: 0.3
observation_ranking_loss_sigma: 0.1
listmle_epsilon: 1.0e-10
listmle_temperature: 1.0
survrnc_margin: 0.5
survrnc_temperature: 0.1
survrnc_hard_mining: true
survrnc_mining_ratio: 0.3
soap_margin: 0.1
soap_sigma: 1.0
soap_num_pairs: null
soap_sampling_strategy: importance
soap_adaptive_margin: true
ranknet_sigma: 1.0
ranknet_sampling_ratio: 0.3
ranknet_adaptive_sampling: true
dsm_intermediate_size: 64
dsm_num_hidden_layers: 1
dsm_num_mixtures: 4
dsm_distribution: weibull
dsm_temp: 1000.0
dsm_discount: 1.0
dsm_bias: true
dsm_batch_norm: true
dsm_hidden_dropout_prob: 0.2
dsm_elbo: true
mensa_intermediate_size: 64
mensa_num_hidden_layers: 1
mensa_num_mixtures: 4
mensa_distribution: weibull
mensa_temp: 1000.0
mensa_discount: 1.0
mensa_bias: true
mensa_batch_norm: true
mensa_hidden_dropout_prob: 0.2
mensa_elbo: true
mensa_event_distribution: true
mensa_dependency_regularization: 0.01
loss_balancing_scale_alpha: 0.9
loss_balancing_scale_eps: 1.0e-08
loss_balancing_grad_alpha: 0.9
loss_balancing_grad_eps: 1.0e-08
loss_balancing_uncertainty_sigma: 1.0
loss_balancing_adaptive_alpha: 0.9
loss_balancing_adaptive_eps: 1.0e-08
loss_balancing_adaptive_window_size: 100
loss_balancing_adaptive_adaptation_rate: 0.005
detect_anomalies: true
brier_per_horizon: false
nllpch_per_event: false
l1_per_event: false
mse_per_event: false
ce_per_event: false
learning_rate: 0.00027730119903939774
weight_decay: 0.02937344466455191
token_emb: 4
sentence_emb: 3
mtl_initializer_range: 0.02
mtl_initializer: kaiming_normal
transformer_layer_norm: true
transformer_initializer_range: 0.01
transformer_hidden_size: 32
transformer_intermediate_size: 32
transformer_num_attention_heads: 4
transformer_num_hidden_layers: 4
survival_initializer_range: 0.02
survival_initializer: kaiming_normal
survival_shared_intermediate_size: 32
survival_shared_num_hidden_layers: 1
survival_batch_norm: false
survival_hidden_dropout_prob: false
survival_bias: true
survival_num_hidden_layers: 1
survival_loss_weight: 1.0
classification_initializer_range: 0.02
classification_initializer: xavier_normal
classification_shared_intermediate_size: 4
classification_shared_num_hidden_layers: 0
classification_event_time_thr: 60.5
classification_intermediate_size: 64
classification_batch_norm: false
classification_hidden_dropout_prob: false
classification_bias: true
classification_num_hidden_layers: 0
classification_loss_weight: 1.0
regression_initializer_range: 0.02
regression_initializer: kaiming_normal
regression_shared_intermediate_size: 4
regression_shared_num_hidden_layers: 0
regression_intermediate_size: 32
regression_batch_norm: false
regression_hidden_dropout_prob: false
regression_bias: true
regression_num_hidden_layers: 0
regression_num_labels: 1
regression_loss_weight: 1.0
moco_buffer_size: 256
moco_use_buffer: true
moco_batch_weight: 1.0
moco_buffer_weight: 1.0
moco_dynamic_buffer: false
moco_initial_buffer_size: 256
moco_initial_batch_weight: 1.0
moco_final_batch_weight: 0.5
moco_initial_buffer_weight: 0.0
moco_final_buffer_weight: 1.0
moco_warmup_steps: 1000
moco_variance_window: 10
moco_variance_threshold: 0.15
moco_min_buffer_ratio: 0.25
moco_max_buffer_ratio: 1.0
warmup_steps: 40
select_hidden_layers: null
dropout: 0.1
transformer_attention_probs_dropout_prob: ${dropout}
transformer_hidden_probs_dropout: ${dropout}
shared_intermediate_size: 64
shared_batch_norm: true
shared_hidden_dropout_prob: 0.05
shared_bias: true
shared_num_hidden_layers: 0
shared_num_labels: 8
survival_max_time: 150
dataset: hsa_synthetic
modelname: survival-moco_trial_1744469387
survival_intermediate_size: 24
moco_adaptive_buffer: true
moco_track_variance: true
job: job
seed: 1978139071
task_name: sat-${task}-${modelname}-${dataset}-${job}
cv:
  kfold: ${oc.select:cv_kfold,0}
pipeline_use_cv: true
pipeline_use_ci: false
multiple_replications: true
cv_kfold: 3
cv_kfold_reuse: true
alpha: 0.05
error: 0.1
'n': 10
use_val: false
less_than_n: 10
optuna:
  metric:
  - ipcw.mean
  - brier.mean
  metric_direction:
  - maximize
  - minimize
  pruner:
    _target_: optuna.pruners.MedianPruner
    interval_steps: 5
    n_startup_trials: 5
    n_warmup_steps: 40
  study_overwrite: true
