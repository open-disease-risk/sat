{
  "best_global_step": 83,
  "best_metric": 0.603160560223612,
  "best_model_checkpoint": "./data/model-hub/metabric/survival_trial_1744203459/checkpoint-83",
  "epoch": 41.5,
  "eval_steps": 1,
  "global_step": 83,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 1.1155611276626587,
      "learning_rate": 4.3263476934784874e-05,
      "loss": 1.5354,
      "step": 1
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.1212260723114014,
      "learning_rate": 8.652695386956975e-05,
      "loss": 1.5967,
      "step": 2
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.0589492321014404,
      "learning_rate": 0.0001297904308043546,
      "loss": 1.5692,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.039379596710205,
      "learning_rate": 0.0001730539077391395,
      "loss": 1.5314,
      "step": 4
    },
    {
      "epoch": 2.5,
      "grad_norm": 1.0860675573349,
      "learning_rate": 0.00021631738467392436,
      "loss": 1.5382,
      "step": 5
    },
    {
      "epoch": 3.0,
      "grad_norm": 1.1731157302856445,
      "learning_rate": 0.0002595808616087092,
      "loss": 1.5317,
      "step": 6
    },
    {
      "epoch": 3.5,
      "grad_norm": 1.2392436265945435,
      "learning_rate": 0.0003028443385434941,
      "loss": 1.5448,
      "step": 7
    },
    {
      "epoch": 4.0,
      "grad_norm": 1.0150425434112549,
      "learning_rate": 0.000346107815478279,
      "loss": 1.5388,
      "step": 8
    },
    {
      "epoch": 4.5,
      "grad_norm": 1.0979880094528198,
      "learning_rate": 0.0003893712924130638,
      "loss": 1.5352,
      "step": 9
    },
    {
      "epoch": 5.0,
      "grad_norm": 1.4221951961517334,
      "learning_rate": 0.0004326347693478487,
      "loss": 1.5573,
      "step": 10
    },
    {
      "epoch": 5.5,
      "grad_norm": 1.2941224575042725,
      "learning_rate": 0.0004758982462826336,
      "loss": 1.5189,
      "step": 11
    },
    {
      "epoch": 6.0,
      "grad_norm": 1.1817152500152588,
      "learning_rate": 0.0005191617232174184,
      "loss": 1.5444,
      "step": 12
    },
    {
      "epoch": 6.5,
      "grad_norm": 1.231406331062317,
      "learning_rate": 0.0005624252001522034,
      "loss": 1.5044,
      "step": 13
    },
    {
      "epoch": 7.0,
      "grad_norm": 1.3857612609863281,
      "learning_rate": 0.0006056886770869882,
      "loss": 1.5485,
      "step": 14
    },
    {
      "epoch": 7.5,
      "grad_norm": 1.1278414726257324,
      "learning_rate": 0.000648952154021773,
      "loss": 1.5303,
      "step": 15
    },
    {
      "epoch": 8.0,
      "grad_norm": 1.4914358854293823,
      "learning_rate": 0.000692215630956558,
      "loss": 1.4991,
      "step": 16
    },
    {
      "epoch": 8.5,
      "grad_norm": 1.4192060232162476,
      "learning_rate": 0.0007354791078913428,
      "loss": 1.541,
      "step": 17
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.9827300310134888,
      "learning_rate": 0.0007787425848261276,
      "loss": 1.4787,
      "step": 18
    },
    {
      "epoch": 9.5,
      "grad_norm": 1.2689143419265747,
      "learning_rate": 0.0008220060617609125,
      "loss": 1.5166,
      "step": 19
    },
    {
      "epoch": 10.0,
      "grad_norm": 1.373030185699463,
      "learning_rate": 0.0008652695386956974,
      "loss": 1.4968,
      "step": 20
    },
    {
      "epoch": 10.5,
      "grad_norm": 1.1912760734558105,
      "learning_rate": 0.0009085330156304824,
      "loss": 1.465,
      "step": 21
    },
    {
      "epoch": 11.0,
      "grad_norm": 1.4433884620666504,
      "learning_rate": 0.0009517964925652672,
      "loss": 1.5213,
      "step": 22
    },
    {
      "epoch": 11.5,
      "grad_norm": 1.195029377937317,
      "learning_rate": 0.000995059969500052,
      "loss": 1.4713,
      "step": 23
    },
    {
      "epoch": 12.0,
      "grad_norm": 1.1606709957122803,
      "learning_rate": 0.0010383234464348369,
      "loss": 1.5004,
      "step": 24
    },
    {
      "epoch": 12.5,
      "grad_norm": 1.333449125289917,
      "learning_rate": 0.0010815869233696217,
      "loss": 1.4997,
      "step": 25
    },
    {
      "epoch": 13.0,
      "grad_norm": 0.989214301109314,
      "learning_rate": 0.0011248504003044067,
      "loss": 1.4254,
      "step": 26
    },
    {
      "epoch": 13.5,
      "grad_norm": 1.2133339643478394,
      "learning_rate": 0.0011681138772391916,
      "loss": 1.4815,
      "step": 27
    },
    {
      "epoch": 14.0,
      "grad_norm": 1.4291212558746338,
      "learning_rate": 0.0012113773541739764,
      "loss": 1.4059,
      "step": 28
    },
    {
      "epoch": 14.5,
      "grad_norm": 1.2799774408340454,
      "learning_rate": 0.0012546408311087612,
      "loss": 1.4595,
      "step": 29
    },
    {
      "epoch": 15.0,
      "grad_norm": 1.1051342487335205,
      "learning_rate": 0.001297904308043546,
      "loss": 1.4407,
      "step": 30
    },
    {
      "epoch": 15.5,
      "grad_norm": 1.1902536153793335,
      "learning_rate": 0.0013411677849783311,
      "loss": 1.4532,
      "step": 31
    },
    {
      "epoch": 16.0,
      "grad_norm": 1.7491897344589233,
      "learning_rate": 0.001384431261913116,
      "loss": 1.4048,
      "step": 32
    },
    {
      "epoch": 16.5,
      "grad_norm": 1.1395597457885742,
      "learning_rate": 0.0014276947388479006,
      "loss": 1.3946,
      "step": 33
    },
    {
      "epoch": 17.0,
      "grad_norm": 1.2093156576156616,
      "learning_rate": 0.0014709582157826856,
      "loss": 1.4349,
      "step": 34
    },
    {
      "epoch": 17.5,
      "grad_norm": 1.1288714408874512,
      "learning_rate": 0.0015142216927174705,
      "loss": 1.4221,
      "step": 35
    },
    {
      "epoch": 18.0,
      "grad_norm": 1.2855687141418457,
      "learning_rate": 0.0015574851696522553,
      "loss": 1.3442,
      "step": 36
    },
    {
      "epoch": 18.5,
      "grad_norm": 1.3959282636642456,
      "learning_rate": 0.0016007486465870403,
      "loss": 1.3763,
      "step": 37
    },
    {
      "epoch": 19.0,
      "grad_norm": 1.487224817276001,
      "learning_rate": 0.001644012123521825,
      "loss": 1.3999,
      "step": 38
    },
    {
      "epoch": 19.5,
      "grad_norm": 1.5651742219924927,
      "learning_rate": 0.00168727560045661,
      "loss": 1.3924,
      "step": 39
    },
    {
      "epoch": 20.0,
      "grad_norm": 2.0245394706726074,
      "learning_rate": 0.0017305390773913948,
      "loss": 1.3517,
      "step": 40
    },
    {
      "epoch": 20.5,
      "grad_norm": 2.092343330383301,
      "learning_rate": 0.0017738025543261795,
      "loss": 1.3191,
      "step": 41
    },
    {
      "epoch": 21.0,
      "grad_norm": 2.5080080032348633,
      "learning_rate": 0.0018170660312609647,
      "loss": 1.4142,
      "step": 42
    },
    {
      "epoch": 21.5,
      "grad_norm": 2.47448468208313,
      "learning_rate": 0.0018603295081957493,
      "loss": 1.3502,
      "step": 43
    },
    {
      "epoch": 22.0,
      "grad_norm": 2.87565279006958,
      "learning_rate": 0.0019035929851305344,
      "loss": 1.3682,
      "step": 44
    },
    {
      "epoch": 22.5,
      "grad_norm": 2.122982978820801,
      "learning_rate": 0.0019468564620653192,
      "loss": 1.3788,
      "step": 45
    },
    {
      "epoch": 23.0,
      "grad_norm": 2.362722396850586,
      "learning_rate": 0.001990119939000104,
      "loss": 1.3116,
      "step": 46
    },
    {
      "epoch": 23.5,
      "grad_norm": 3.6216204166412354,
      "learning_rate": 0.002033383415934889,
      "loss": 1.3474,
      "step": 47
    },
    {
      "epoch": 24.0,
      "grad_norm": 2.174219846725464,
      "learning_rate": 0.0020766468928696737,
      "loss": 1.2829,
      "step": 48
    },
    {
      "epoch": 24.5,
      "grad_norm": 1.5240564346313477,
      "learning_rate": 0.0021199103698044588,
      "loss": 1.3402,
      "step": 49
    },
    {
      "epoch": 25.0,
      "grad_norm": 3.1970646381378174,
      "learning_rate": 0.0021631738467392434,
      "loss": 1.3315,
      "step": 50
    },
    {
      "epoch": 25.5,
      "grad_norm": 1.8267327547073364,
      "learning_rate": 0.0022064373236740284,
      "loss": 1.3142,
      "step": 51
    },
    {
      "epoch": 26.0,
      "grad_norm": 2.7382943630218506,
      "learning_rate": 0.0022497008006088135,
      "loss": 1.2797,
      "step": 52
    },
    {
      "epoch": 26.5,
      "grad_norm": 1.9387470483779907,
      "learning_rate": 0.002292964277543598,
      "loss": 1.3322,
      "step": 53
    },
    {
      "epoch": 27.0,
      "grad_norm": 2.171257972717285,
      "learning_rate": 0.002336227754478383,
      "loss": 1.301,
      "step": 54
    },
    {
      "epoch": 27.5,
      "grad_norm": 1.7596731185913086,
      "learning_rate": 0.0023794912314131678,
      "loss": 1.3439,
      "step": 55
    },
    {
      "epoch": 28.0,
      "grad_norm": 2.408552646636963,
      "learning_rate": 0.002422754708347953,
      "loss": 1.264,
      "step": 56
    },
    {
      "epoch": 28.5,
      "grad_norm": 2.2082362174987793,
      "learning_rate": 0.002466018185282738,
      "loss": 1.2884,
      "step": 57
    },
    {
      "epoch": 29.0,
      "grad_norm": 2.732940673828125,
      "learning_rate": 0.0025092816622175225,
      "loss": 1.3038,
      "step": 58
    },
    {
      "epoch": 29.5,
      "grad_norm": 1.4064621925354004,
      "learning_rate": 0.0025525451391523075,
      "loss": 1.2527,
      "step": 59
    },
    {
      "epoch": 30.0,
      "grad_norm": 1.6950833797454834,
      "learning_rate": 0.002595808616087092,
      "loss": 1.3112,
      "step": 60
    },
    {
      "epoch": 30.5,
      "grad_norm": 1.998311161994934,
      "learning_rate": 0.0026390720930218768,
      "loss": 1.3014,
      "step": 61
    },
    {
      "epoch": 31.0,
      "grad_norm": 3.711310625076294,
      "learning_rate": 0.0026823355699566623,
      "loss": 1.2221,
      "step": 62
    },
    {
      "epoch": 31.5,
      "grad_norm": 1.889614224433899,
      "learning_rate": 0.002725599046891447,
      "loss": 1.2662,
      "step": 63
    },
    {
      "epoch": 32.0,
      "grad_norm": 1.5672856569290161,
      "learning_rate": 0.002768862523826232,
      "loss": 1.257,
      "step": 64
    },
    {
      "epoch": 32.5,
      "grad_norm": 1.873627781867981,
      "learning_rate": 0.0028121260007610165,
      "loss": 1.1991,
      "step": 65
    },
    {
      "epoch": 33.0,
      "grad_norm": 3.7456741333007812,
      "learning_rate": 0.002855389477695801,
      "loss": 1.3319,
      "step": 66
    },
    {
      "epoch": 33.5,
      "grad_norm": 1.2845139503479004,
      "learning_rate": 0.0028986529546305866,
      "loss": 1.226,
      "step": 67
    },
    {
      "epoch": 34.0,
      "grad_norm": 2.393552780151367,
      "learning_rate": 0.0029419164315653713,
      "loss": 1.2563,
      "step": 68
    },
    {
      "epoch": 34.5,
      "grad_norm": 2.403273344039917,
      "learning_rate": 0.0029851799085001563,
      "loss": 1.2034,
      "step": 69
    },
    {
      "epoch": 35.0,
      "grad_norm": 2.8744072914123535,
      "learning_rate": 0.003028443385434941,
      "loss": 1.2856,
      "step": 70
    },
    {
      "epoch": 35.5,
      "grad_norm": 3.2558372020721436,
      "learning_rate": 0.0030717068623697255,
      "loss": 1.2071,
      "step": 71
    },
    {
      "epoch": 36.0,
      "grad_norm": 2.387049674987793,
      "learning_rate": 0.0031149703393045106,
      "loss": 1.2592,
      "step": 72
    },
    {
      "epoch": 36.5,
      "grad_norm": 2.788422107696533,
      "learning_rate": 0.0031582338162392956,
      "loss": 1.2386,
      "step": 73
    },
    {
      "epoch": 37.0,
      "grad_norm": 2.2972607612609863,
      "learning_rate": 0.0032014972931740807,
      "loss": 1.2402,
      "step": 74
    },
    {
      "epoch": 37.5,
      "grad_norm": 2.139279365539551,
      "learning_rate": 0.0032447607701088653,
      "loss": 1.2243,
      "step": 75
    },
    {
      "epoch": 38.0,
      "grad_norm": 2.7219579219818115,
      "learning_rate": 0.00328802424704365,
      "loss": 1.1996,
      "step": 76
    },
    {
      "epoch": 38.5,
      "grad_norm": 2.56857967376709,
      "learning_rate": 0.003331287723978435,
      "loss": 1.229,
      "step": 77
    },
    {
      "epoch": 39.0,
      "grad_norm": 2.4708080291748047,
      "learning_rate": 0.00337455120091322,
      "loss": 1.2046,
      "step": 78
    },
    {
      "epoch": 39.5,
      "grad_norm": 2.5188231468200684,
      "learning_rate": 0.003417814677848005,
      "loss": 1.2091,
      "step": 79
    },
    {
      "epoch": 40.0,
      "grad_norm": 2.6498913764953613,
      "learning_rate": 0.0034610781547827897,
      "loss": 1.2128,
      "step": 80
    },
    {
      "epoch": 40.0,
      "eval_brier_0th_event": 0.20859439118372877,
      "eval_brier_0th_event_n": 258,
      "eval_brier_avg": 0.20859439118372877,
      "eval_brier_weighted_avg": 0.20859439118372877,
      "eval_ipcw": 0.5896849240765337,
      "eval_ipcw_0th_event": 0.5896849240765337,
      "eval_ipcw_0th_event_0.25": 0.6081786130409871,
      "eval_ipcw_0th_event_0.5": 0.6015346975016442,
      "eval_ipcw_0th_event_0.75": 0.5939534943267764,
      "eval_ipcw_0th_event_1.0": 0.5896849240765337,
      "eval_ipcw_0th_event_n": 258,
      "eval_ipcw_avg": 0.5983379322364853,
      "eval_ipcw_avg_0th_event": 0.5983379322364853,
      "eval_ipcw_weighted_avg": 0.5983379322364853,
      "eval_loss": 0.7009133100509644,
      "eval_runtime": 0.0701,
      "eval_samples_per_second": 6335.074,
      "eval_steps_per_second": 14.268,
      "step": 80
    },
    {
      "epoch": 40.5,
      "grad_norm": 2.6733546257019043,
      "learning_rate": 0.003461068065156432,
      "loss": 1.1653,
      "step": 81
    },
    {
      "epoch": 40.5,
      "eval_brier_0th_event": 0.2075636527870733,
      "eval_brier_0th_event_n": 258,
      "eval_brier_avg": 0.2075636527870733,
      "eval_brier_weighted_avg": 0.2075636527870733,
      "eval_ipcw": 0.5873881170587619,
      "eval_ipcw_0th_event": 0.5873881170587619,
      "eval_ipcw_0th_event_0.25": 0.6104163254532338,
      "eval_ipcw_0th_event_0.5": 0.6038352715961381,
      "eval_ipcw_0th_event_0.75": 0.5926350087370844,
      "eval_ipcw_0th_event_1.0": 0.5873881170587619,
      "eval_ipcw_0th_event_n": 258,
      "eval_ipcw_avg": 0.5985686807113045,
      "eval_ipcw_avg_0th_event": 0.5985686807113045,
      "eval_ipcw_weighted_avg": 0.5985686807113045,
      "eval_loss": 0.6989651322364807,
      "eval_runtime": 0.0683,
      "eval_samples_per_second": 6497.034,
      "eval_steps_per_second": 14.633,
      "step": 81
    },
    {
      "epoch": 41.0,
      "grad_norm": 2.3947651386260986,
      "learning_rate": 0.003461037796395012,
      "loss": 1.2723,
      "step": 82
    },
    {
      "epoch": 41.0,
      "eval_brier_0th_event": 0.2063591826346188,
      "eval_brier_0th_event_n": 258,
      "eval_brier_avg": 0.2063591826346188,
      "eval_brier_weighted_avg": 0.2063591826346188,
      "eval_ipcw": 0.587464934245444,
      "eval_ipcw_0th_event": 0.587464934245444,
      "eval_ipcw_0th_event_0.25": 0.6171614782344395,
      "eval_ipcw_0th_event_0.5": 0.6060798798552688,
      "eval_ipcw_0th_event_0.75": 0.593282692730176,
      "eval_ipcw_0th_event_1.0": 0.587464934245444,
      "eval_ipcw_0th_event_n": 258,
      "eval_ipcw_avg": 0.6009972462663321,
      "eval_ipcw_avg_0th_event": 0.6009972462663321,
      "eval_ipcw_weighted_avg": 0.6009972462663321,
      "eval_loss": 0.6957988739013672,
      "eval_runtime": 0.0709,
      "eval_samples_per_second": 6260.134,
      "eval_steps_per_second": 14.099,
      "step": 82
    },
    {
      "epoch": 41.5,
      "grad_norm": 1.4411723613739014,
      "learning_rate": 0.0034609873488514837,
      "loss": 1.2131,
      "step": 83
    },
    {
      "epoch": 41.5,
      "eval_brier_0th_event": 0.20653910928252783,
      "eval_brier_0th_event_n": 258,
      "eval_brier_avg": 0.20653910928252783,
      "eval_brier_weighted_avg": 0.20653910928252783,
      "eval_ipcw": 0.5908931112822445,
      "eval_ipcw_0th_event": 0.5908931112822445,
      "eval_ipcw_0th_event_0.25": 0.6155492522544408,
      "eval_ipcw_0th_event_0.5": 0.609305708586613,
      "eval_ipcw_0th_event_0.75": 0.5968941687711495,
      "eval_ipcw_0th_event_1.0": 0.5908931112822445,
      "eval_ipcw_0th_event_n": 258,
      "eval_ipcw_avg": 0.603160560223612,
      "eval_ipcw_avg_0th_event": 0.603160560223612,
      "eval_ipcw_weighted_avg": 0.603160560223612,
      "eval_loss": 0.6958649754524231,
      "eval_runtime": 0.0676,
      "eval_samples_per_second": 6563.949,
      "eval_steps_per_second": 14.784,
      "step": 83
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 15586147200.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
