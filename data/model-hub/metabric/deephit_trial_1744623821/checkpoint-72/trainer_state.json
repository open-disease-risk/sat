{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 36.0,
  "eval_steps": 1,
  "global_step": 72,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 3.952299118041992,
      "learning_rate": 2.1746093649299786e-05,
      "loss": 6.4086,
      "step": 1
    },
    {
      "epoch": 1.0,
      "grad_norm": 3.9931914806365967,
      "learning_rate": 4.349218729859957e-05,
      "loss": 6.0931,
      "step": 2
    },
    {
      "epoch": 1.5,
      "grad_norm": 3.6309688091278076,
      "learning_rate": 6.523828094789936e-05,
      "loss": 5.3172,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 3.405872106552124,
      "learning_rate": 8.698437459719915e-05,
      "loss": 5.5795,
      "step": 4
    },
    {
      "epoch": 2.5,
      "grad_norm": 3.2920148372650146,
      "learning_rate": 0.00010873046824649893,
      "loss": 5.1982,
      "step": 5
    },
    {
      "epoch": 3.0,
      "grad_norm": 4.5627007484436035,
      "learning_rate": 0.00013047656189579872,
      "loss": 5.0198,
      "step": 6
    },
    {
      "epoch": 3.5,
      "grad_norm": 3.911085367202759,
      "learning_rate": 0.0001522226555450985,
      "loss": 5.0648,
      "step": 7
    },
    {
      "epoch": 4.0,
      "grad_norm": 4.8207502365112305,
      "learning_rate": 0.0001739687491943983,
      "loss": 5.2391,
      "step": 8
    },
    {
      "epoch": 4.5,
      "grad_norm": 3.9686567783355713,
      "learning_rate": 0.0001957148428436981,
      "loss": 5.0888,
      "step": 9
    },
    {
      "epoch": 5.0,
      "grad_norm": 4.741100788116455,
      "learning_rate": 0.00021746093649299786,
      "loss": 5.2932,
      "step": 10
    },
    {
      "epoch": 5.5,
      "grad_norm": 3.9360101222991943,
      "learning_rate": 0.00023920703014229766,
      "loss": 5.3401,
      "step": 11
    },
    {
      "epoch": 6.0,
      "grad_norm": 4.696338653564453,
      "learning_rate": 0.00026095312379159744,
      "loss": 5.242,
      "step": 12
    },
    {
      "epoch": 6.5,
      "grad_norm": 4.484668254852295,
      "learning_rate": 0.00028269921744089724,
      "loss": 5.3952,
      "step": 13
    },
    {
      "epoch": 7.0,
      "grad_norm": 4.489387512207031,
      "learning_rate": 0.000304445311090197,
      "loss": 5.5701,
      "step": 14
    },
    {
      "epoch": 7.5,
      "grad_norm": 4.813650608062744,
      "learning_rate": 0.0003261914047394968,
      "loss": 5.5108,
      "step": 15
    },
    {
      "epoch": 8.0,
      "grad_norm": 5.188435077667236,
      "learning_rate": 0.0003479374983887966,
      "loss": 5.5517,
      "step": 16
    },
    {
      "epoch": 8.5,
      "grad_norm": 5.381478786468506,
      "learning_rate": 0.0003696835920380964,
      "loss": 5.4657,
      "step": 17
    },
    {
      "epoch": 9.0,
      "grad_norm": 5.606817722320557,
      "learning_rate": 0.0003914296856873962,
      "loss": 5.8889,
      "step": 18
    },
    {
      "epoch": 9.5,
      "grad_norm": 5.947476863861084,
      "learning_rate": 0.0004131757793366959,
      "loss": 5.7037,
      "step": 19
    },
    {
      "epoch": 10.0,
      "grad_norm": 6.096377849578857,
      "learning_rate": 0.0004349218729859957,
      "loss": 5.5297,
      "step": 20
    },
    {
      "epoch": 10.5,
      "grad_norm": 5.763323783874512,
      "learning_rate": 0.0004566679666352955,
      "loss": 5.7288,
      "step": 21
    },
    {
      "epoch": 11.0,
      "grad_norm": 6.392601013183594,
      "learning_rate": 0.0004784140602845953,
      "loss": 5.7923,
      "step": 22
    },
    {
      "epoch": 11.5,
      "grad_norm": 6.465663433074951,
      "learning_rate": 0.0005001601539338951,
      "loss": 5.707,
      "step": 23
    },
    {
      "epoch": 12.0,
      "grad_norm": 6.0667195320129395,
      "learning_rate": 0.0005219062475831949,
      "loss": 5.9395,
      "step": 24
    },
    {
      "epoch": 12.5,
      "grad_norm": 6.48118257522583,
      "learning_rate": 0.0005436523412324947,
      "loss": 5.8368,
      "step": 25
    },
    {
      "epoch": 13.0,
      "grad_norm": 6.124824523925781,
      "learning_rate": 0.0005653984348817945,
      "loss": 5.6989,
      "step": 26
    },
    {
      "epoch": 13.5,
      "grad_norm": 7.368044376373291,
      "learning_rate": 0.0005871445285310943,
      "loss": 5.7312,
      "step": 27
    },
    {
      "epoch": 14.0,
      "grad_norm": 5.857226371765137,
      "learning_rate": 0.000608890622180394,
      "loss": 6.0769,
      "step": 28
    },
    {
      "epoch": 14.5,
      "grad_norm": 6.599240779876709,
      "learning_rate": 0.0006306367158296938,
      "loss": 5.8388,
      "step": 29
    },
    {
      "epoch": 15.0,
      "grad_norm": 7.352761268615723,
      "learning_rate": 0.0006523828094789936,
      "loss": 5.7399,
      "step": 30
    },
    {
      "epoch": 15.5,
      "grad_norm": 6.5040483474731445,
      "learning_rate": 0.0006741289031282934,
      "loss": 5.8068,
      "step": 31
    },
    {
      "epoch": 16.0,
      "grad_norm": 6.647873401641846,
      "learning_rate": 0.0006958749967775932,
      "loss": 5.943,
      "step": 32
    },
    {
      "epoch": 16.5,
      "grad_norm": 6.52863883972168,
      "learning_rate": 0.000717621090426893,
      "loss": 5.8124,
      "step": 33
    },
    {
      "epoch": 17.0,
      "grad_norm": 7.825774192810059,
      "learning_rate": 0.0007393671840761928,
      "loss": 5.7282,
      "step": 34
    },
    {
      "epoch": 17.5,
      "grad_norm": 6.220015525817871,
      "learning_rate": 0.0007611132777254926,
      "loss": 5.8068,
      "step": 35
    },
    {
      "epoch": 18.0,
      "grad_norm": 9.148008346557617,
      "learning_rate": 0.0007828593713747924,
      "loss": 5.8845,
      "step": 36
    },
    {
      "epoch": 18.5,
      "grad_norm": 7.703896999359131,
      "learning_rate": 0.0008046054650240922,
      "loss": 5.8752,
      "step": 37
    },
    {
      "epoch": 19.0,
      "grad_norm": 8.401947021484375,
      "learning_rate": 0.0008263515586733919,
      "loss": 5.9111,
      "step": 38
    },
    {
      "epoch": 19.5,
      "grad_norm": 8.554425239562988,
      "learning_rate": 0.0008480976523226917,
      "loss": 5.7919,
      "step": 39
    },
    {
      "epoch": 20.0,
      "grad_norm": 9.96895694732666,
      "learning_rate": 0.0008698437459719915,
      "loss": 6.0219,
      "step": 40
    },
    {
      "epoch": 20.5,
      "grad_norm": 9.078592300415039,
      "learning_rate": 0.0008915898396212911,
      "loss": 5.8999,
      "step": 41
    },
    {
      "epoch": 21.0,
      "grad_norm": 11.497714042663574,
      "learning_rate": 0.000913335933270591,
      "loss": 5.7733,
      "step": 42
    },
    {
      "epoch": 21.5,
      "grad_norm": 7.380097389221191,
      "learning_rate": 0.0009350820269198907,
      "loss": 5.9548,
      "step": 43
    },
    {
      "epoch": 22.0,
      "grad_norm": 11.302881240844727,
      "learning_rate": 0.0009568281205691907,
      "loss": 5.7192,
      "step": 44
    },
    {
      "epoch": 22.5,
      "grad_norm": 8.577980041503906,
      "learning_rate": 0.0009785742142184905,
      "loss": 5.9572,
      "step": 45
    },
    {
      "epoch": 23.0,
      "grad_norm": 12.14664363861084,
      "learning_rate": 0.0010003203078677901,
      "loss": 5.7607,
      "step": 46
    },
    {
      "epoch": 23.5,
      "grad_norm": 8.750062942504883,
      "learning_rate": 0.00102206640151709,
      "loss": 5.956,
      "step": 47
    },
    {
      "epoch": 24.0,
      "grad_norm": 15.624423027038574,
      "learning_rate": 0.0010438124951663897,
      "loss": 6.1673,
      "step": 48
    },
    {
      "epoch": 24.5,
      "grad_norm": 8.98453140258789,
      "learning_rate": 0.0010655585888156897,
      "loss": 6.0384,
      "step": 49
    },
    {
      "epoch": 25.0,
      "grad_norm": 11.540238380432129,
      "learning_rate": 0.0010873046824649893,
      "loss": 5.7869,
      "step": 50
    },
    {
      "epoch": 25.5,
      "grad_norm": 9.942486763000488,
      "learning_rate": 0.001109050776114289,
      "loss": 5.9061,
      "step": 51
    },
    {
      "epoch": 26.0,
      "grad_norm": 12.615607261657715,
      "learning_rate": 0.001130796869763589,
      "loss": 5.9285,
      "step": 52
    },
    {
      "epoch": 26.5,
      "grad_norm": 10.858869552612305,
      "learning_rate": 0.0011525429634128886,
      "loss": 6.0276,
      "step": 53
    },
    {
      "epoch": 27.0,
      "grad_norm": 13.723336219787598,
      "learning_rate": 0.0011742890570621885,
      "loss": 5.8363,
      "step": 54
    },
    {
      "epoch": 27.5,
      "grad_norm": 13.660242080688477,
      "learning_rate": 0.0011960351507114882,
      "loss": 5.8872,
      "step": 55
    },
    {
      "epoch": 28.0,
      "grad_norm": 15.044294357299805,
      "learning_rate": 0.001217781244360788,
      "loss": 6.0859,
      "step": 56
    },
    {
      "epoch": 28.5,
      "grad_norm": 14.679898262023926,
      "learning_rate": 0.0012395273380100878,
      "loss": 5.9494,
      "step": 57
    },
    {
      "epoch": 29.0,
      "grad_norm": 15.433838844299316,
      "learning_rate": 0.0012612734316593875,
      "loss": 6.0432,
      "step": 58
    },
    {
      "epoch": 29.5,
      "grad_norm": 9.623327255249023,
      "learning_rate": 0.0012830195253086874,
      "loss": 5.8379,
      "step": 59
    },
    {
      "epoch": 30.0,
      "grad_norm": 13.869227409362793,
      "learning_rate": 0.0013047656189579871,
      "loss": 6.1243,
      "step": 60
    },
    {
      "epoch": 30.5,
      "grad_norm": 10.623905181884766,
      "learning_rate": 0.0013265117126072868,
      "loss": 5.9011,
      "step": 61
    },
    {
      "epoch": 31.0,
      "grad_norm": 12.543923377990723,
      "learning_rate": 0.0013482578062565867,
      "loss": 6.0463,
      "step": 62
    },
    {
      "epoch": 31.5,
      "grad_norm": 10.751513481140137,
      "learning_rate": 0.0013700038999058864,
      "loss": 5.6777,
      "step": 63
    },
    {
      "epoch": 32.0,
      "grad_norm": 12.48503589630127,
      "learning_rate": 0.0013917499935551863,
      "loss": 6.1477,
      "step": 64
    },
    {
      "epoch": 32.5,
      "grad_norm": 12.59488582611084,
      "learning_rate": 0.001413496087204486,
      "loss": 6.1407,
      "step": 65
    },
    {
      "epoch": 33.0,
      "grad_norm": 18.73713493347168,
      "learning_rate": 0.001435242180853786,
      "loss": 5.5339,
      "step": 66
    },
    {
      "epoch": 33.5,
      "grad_norm": 16.35279083251953,
      "learning_rate": 0.0014569882745030856,
      "loss": 6.0192,
      "step": 67
    },
    {
      "epoch": 34.0,
      "grad_norm": 19.315950393676758,
      "learning_rate": 0.0014787343681523855,
      "loss": 5.8211,
      "step": 68
    },
    {
      "epoch": 34.5,
      "grad_norm": 14.828290939331055,
      "learning_rate": 0.0015004804618016854,
      "loss": 5.861,
      "step": 69
    },
    {
      "epoch": 35.0,
      "grad_norm": 17.823341369628906,
      "learning_rate": 0.0015222265554509851,
      "loss": 6.1543,
      "step": 70
    },
    {
      "epoch": 35.5,
      "grad_norm": 13.986159324645996,
      "learning_rate": 0.0015439726491002848,
      "loss": 5.8414,
      "step": 71
    },
    {
      "epoch": 36.0,
      "grad_norm": 17.415475845336914,
      "learning_rate": 0.0015657187427495847,
      "loss": 6.0722,
      "step": 72
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 84234401280.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
