{
  "best_global_step": 80,
  "best_metric": 0.6442616633174265,
  "best_model_checkpoint": "./data/model-hub/metabric/survival-moco_trial_1744119102/checkpoint-80",
  "epoch": 40.0,
  "eval_steps": 1,
  "global_step": 80,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 0.8843704462051392,
      "learning_rate": 2.4713473525023797e-05,
      "loss": 1.5243,
      "step": 1
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.9942722320556641,
      "learning_rate": 4.9426947050047594e-05,
      "loss": 1.5492,
      "step": 2
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.0538588762283325,
      "learning_rate": 7.414042057507138e-05,
      "loss": 1.5245,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.7370515465736389,
      "learning_rate": 9.885389410009519e-05,
      "loss": 1.5354,
      "step": 4
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.9819793105125427,
      "learning_rate": 0.00012356736762511898,
      "loss": 1.4931,
      "step": 5
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.750946044921875,
      "learning_rate": 0.00014828084115014277,
      "loss": 1.5678,
      "step": 6
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.9000288844108582,
      "learning_rate": 0.00017299431467516656,
      "loss": 1.5151,
      "step": 7
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.6987234950065613,
      "learning_rate": 0.00019770778820019037,
      "loss": 1.5557,
      "step": 8
    },
    {
      "epoch": 4.5,
      "grad_norm": 0.7980020046234131,
      "learning_rate": 0.00022242126172521416,
      "loss": 1.5413,
      "step": 9
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.8213216662406921,
      "learning_rate": 0.00024713473525023795,
      "loss": 1.5038,
      "step": 10
    },
    {
      "epoch": 5.5,
      "grad_norm": 0.6759576201438904,
      "learning_rate": 0.00027184820877526177,
      "loss": 1.5249,
      "step": 11
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.8087756037712097,
      "learning_rate": 0.00029656168230028553,
      "loss": 1.5169,
      "step": 12
    },
    {
      "epoch": 6.5,
      "grad_norm": 0.6746434569358826,
      "learning_rate": 0.00032127515582530935,
      "loss": 1.526,
      "step": 13
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.6408167481422424,
      "learning_rate": 0.0003459886293503331,
      "loss": 1.5158,
      "step": 14
    },
    {
      "epoch": 7.5,
      "grad_norm": 0.7676528096199036,
      "learning_rate": 0.00037070210287535693,
      "loss": 1.5168,
      "step": 15
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.521952211856842,
      "learning_rate": 0.00039541557640038075,
      "loss": 1.5093,
      "step": 16
    },
    {
      "epoch": 8.5,
      "grad_norm": 0.6697426438331604,
      "learning_rate": 0.0004201290499254045,
      "loss": 1.5013,
      "step": 17
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.7753159999847412,
      "learning_rate": 0.00044484252345042833,
      "loss": 1.5298,
      "step": 18
    },
    {
      "epoch": 9.5,
      "grad_norm": 0.7220355868339539,
      "learning_rate": 0.0004695559969754521,
      "loss": 1.5034,
      "step": 19
    },
    {
      "epoch": 10.0,
      "grad_norm": 1.0016452074050903,
      "learning_rate": 0.0004942694705004759,
      "loss": 1.5185,
      "step": 20
    },
    {
      "epoch": 10.5,
      "grad_norm": 0.8868035078048706,
      "learning_rate": 0.0005189829440254998,
      "loss": 1.5093,
      "step": 21
    },
    {
      "epoch": 11.0,
      "grad_norm": 0.7914223074913025,
      "learning_rate": 0.0005436964175505235,
      "loss": 1.502,
      "step": 22
    },
    {
      "epoch": 11.5,
      "grad_norm": 0.9174728393554688,
      "learning_rate": 0.0005684098910755472,
      "loss": 1.4902,
      "step": 23
    },
    {
      "epoch": 12.0,
      "grad_norm": 0.8454249501228333,
      "learning_rate": 0.0005931233646005711,
      "loss": 1.503,
      "step": 24
    },
    {
      "epoch": 12.5,
      "grad_norm": 0.9519098401069641,
      "learning_rate": 0.0006178368381255948,
      "loss": 1.5036,
      "step": 25
    },
    {
      "epoch": 13.0,
      "grad_norm": 0.8168646097183228,
      "learning_rate": 0.0006425503116506187,
      "loss": 1.4882,
      "step": 26
    },
    {
      "epoch": 13.5,
      "grad_norm": 0.9386460185050964,
      "learning_rate": 0.0006672637851756426,
      "loss": 1.4923,
      "step": 27
    },
    {
      "epoch": 14.0,
      "grad_norm": 0.7763116955757141,
      "learning_rate": 0.0006919772587006662,
      "loss": 1.4907,
      "step": 28
    },
    {
      "epoch": 14.5,
      "grad_norm": 0.868179976940155,
      "learning_rate": 0.00071669073222569,
      "loss": 1.4859,
      "step": 29
    },
    {
      "epoch": 15.0,
      "grad_norm": 0.8048661947250366,
      "learning_rate": 0.0007414042057507139,
      "loss": 1.4781,
      "step": 30
    },
    {
      "epoch": 15.5,
      "grad_norm": 0.9053381681442261,
      "learning_rate": 0.0007661176792757377,
      "loss": 1.4765,
      "step": 31
    },
    {
      "epoch": 16.0,
      "grad_norm": 0.7590827941894531,
      "learning_rate": 0.0007908311528007615,
      "loss": 1.4772,
      "step": 32
    },
    {
      "epoch": 16.5,
      "grad_norm": 0.8207481503486633,
      "learning_rate": 0.0008155446263257852,
      "loss": 1.4552,
      "step": 33
    },
    {
      "epoch": 17.0,
      "grad_norm": 0.7835827469825745,
      "learning_rate": 0.000840258099850809,
      "loss": 1.4869,
      "step": 34
    },
    {
      "epoch": 17.5,
      "grad_norm": 0.9169372916221619,
      "learning_rate": 0.0008649715733758329,
      "loss": 1.4662,
      "step": 35
    },
    {
      "epoch": 18.0,
      "grad_norm": 0.6496176719665527,
      "learning_rate": 0.0008896850469008567,
      "loss": 1.45,
      "step": 36
    },
    {
      "epoch": 18.5,
      "grad_norm": 0.91153883934021,
      "learning_rate": 0.0009143985204258805,
      "loss": 1.4419,
      "step": 37
    },
    {
      "epoch": 19.0,
      "grad_norm": 0.6149089932441711,
      "learning_rate": 0.0009391119939509042,
      "loss": 1.4745,
      "step": 38
    },
    {
      "epoch": 19.5,
      "grad_norm": 0.7050217390060425,
      "learning_rate": 0.0009638254674759279,
      "loss": 1.4501,
      "step": 39
    },
    {
      "epoch": 20.0,
      "grad_norm": 0.8761553168296814,
      "learning_rate": 0.0009885389410009518,
      "loss": 1.4278,
      "step": 40
    },
    {
      "epoch": 20.5,
      "grad_norm": 0.676794707775116,
      "learning_rate": 0.0010132524145259755,
      "loss": 1.4284,
      "step": 41
    },
    {
      "epoch": 21.0,
      "grad_norm": 0.744194507598877,
      "learning_rate": 0.0010379658880509996,
      "loss": 1.4561,
      "step": 42
    },
    {
      "epoch": 21.5,
      "grad_norm": 0.8017647862434387,
      "learning_rate": 0.0010626793615760232,
      "loss": 1.4235,
      "step": 43
    },
    {
      "epoch": 22.0,
      "grad_norm": 0.8623948693275452,
      "learning_rate": 0.001087392835101047,
      "loss": 1.4419,
      "step": 44
    },
    {
      "epoch": 22.5,
      "grad_norm": 0.630983829498291,
      "learning_rate": 0.0011121063086260707,
      "loss": 1.4267,
      "step": 45
    },
    {
      "epoch": 23.0,
      "grad_norm": 0.7840437889099121,
      "learning_rate": 0.0011368197821510944,
      "loss": 1.4078,
      "step": 46
    },
    {
      "epoch": 23.5,
      "grad_norm": 0.67996746301651,
      "learning_rate": 0.0011615332556761185,
      "loss": 1.4027,
      "step": 47
    },
    {
      "epoch": 24.0,
      "grad_norm": 0.8235105872154236,
      "learning_rate": 0.0011862467292011421,
      "loss": 1.4043,
      "step": 48
    },
    {
      "epoch": 24.5,
      "grad_norm": 0.8133226037025452,
      "learning_rate": 0.001210960202726166,
      "loss": 1.3912,
      "step": 49
    },
    {
      "epoch": 25.0,
      "grad_norm": 0.6839923858642578,
      "learning_rate": 0.0012356736762511897,
      "loss": 1.3966,
      "step": 50
    },
    {
      "epoch": 25.5,
      "grad_norm": 0.7071340084075928,
      "learning_rate": 0.0012603871497762135,
      "loss": 1.3852,
      "step": 51
    },
    {
      "epoch": 26.0,
      "grad_norm": 0.7367567420005798,
      "learning_rate": 0.0012851006233012374,
      "loss": 1.3915,
      "step": 52
    },
    {
      "epoch": 26.5,
      "grad_norm": 0.8015661835670471,
      "learning_rate": 0.001309814096826261,
      "loss": 1.3796,
      "step": 53
    },
    {
      "epoch": 27.0,
      "grad_norm": 0.7573220133781433,
      "learning_rate": 0.0013345275703512851,
      "loss": 1.3847,
      "step": 54
    },
    {
      "epoch": 27.5,
      "grad_norm": 0.7027292847633362,
      "learning_rate": 0.0013592410438763088,
      "loss": 1.3695,
      "step": 55
    },
    {
      "epoch": 28.0,
      "grad_norm": 1.1184920072555542,
      "learning_rate": 0.0013839545174013325,
      "loss": 1.3644,
      "step": 56
    },
    {
      "epoch": 28.5,
      "grad_norm": 0.7565895318984985,
      "learning_rate": 0.0014086679909263563,
      "loss": 1.3727,
      "step": 57
    },
    {
      "epoch": 29.0,
      "grad_norm": 1.103368878364563,
      "learning_rate": 0.00143338146445138,
      "loss": 1.3496,
      "step": 58
    },
    {
      "epoch": 29.5,
      "grad_norm": 1.0039598941802979,
      "learning_rate": 0.001458094937976404,
      "loss": 1.3375,
      "step": 59
    },
    {
      "epoch": 30.0,
      "grad_norm": 0.8320529460906982,
      "learning_rate": 0.0014828084115014277,
      "loss": 1.3842,
      "step": 60
    },
    {
      "epoch": 30.5,
      "grad_norm": 1.2109037637710571,
      "learning_rate": 0.0015075218850264514,
      "loss": 1.3684,
      "step": 61
    },
    {
      "epoch": 31.0,
      "grad_norm": 1.0120790004730225,
      "learning_rate": 0.0015322353585514755,
      "loss": 1.3079,
      "step": 62
    },
    {
      "epoch": 31.5,
      "grad_norm": 1.3520742654800415,
      "learning_rate": 0.0015569488320764991,
      "loss": 1.3341,
      "step": 63
    },
    {
      "epoch": 32.0,
      "grad_norm": 1.2068310976028442,
      "learning_rate": 0.001581662305601523,
      "loss": 1.3384,
      "step": 64
    },
    {
      "epoch": 32.5,
      "grad_norm": 0.8183436393737793,
      "learning_rate": 0.0016063757791265466,
      "loss": 1.3429,
      "step": 65
    },
    {
      "epoch": 33.0,
      "grad_norm": 1.26426100730896,
      "learning_rate": 0.0016310892526515703,
      "loss": 1.3342,
      "step": 66
    },
    {
      "epoch": 33.5,
      "grad_norm": 0.8658729791641235,
      "learning_rate": 0.0016558027261765944,
      "loss": 1.328,
      "step": 67
    },
    {
      "epoch": 34.0,
      "grad_norm": 1.192837119102478,
      "learning_rate": 0.001680516199701618,
      "loss": 1.3066,
      "step": 68
    },
    {
      "epoch": 34.5,
      "grad_norm": 1.311072826385498,
      "learning_rate": 0.001705229673226642,
      "loss": 1.2994,
      "step": 69
    },
    {
      "epoch": 35.0,
      "grad_norm": 1.5983532667160034,
      "learning_rate": 0.0017299431467516658,
      "loss": 1.3516,
      "step": 70
    },
    {
      "epoch": 35.5,
      "grad_norm": 1.404541015625,
      "learning_rate": 0.0017546566202766894,
      "loss": 1.3021,
      "step": 71
    },
    {
      "epoch": 36.0,
      "grad_norm": 2.379361629486084,
      "learning_rate": 0.0017793700938017133,
      "loss": 1.337,
      "step": 72
    },
    {
      "epoch": 36.5,
      "grad_norm": 2.174344301223755,
      "learning_rate": 0.001804083567326737,
      "loss": 1.3248,
      "step": 73
    },
    {
      "epoch": 37.0,
      "grad_norm": 2.2147228717803955,
      "learning_rate": 0.001828797040851761,
      "loss": 1.2764,
      "step": 74
    },
    {
      "epoch": 37.5,
      "grad_norm": 1.3709748983383179,
      "learning_rate": 0.0018535105143767847,
      "loss": 1.2834,
      "step": 75
    },
    {
      "epoch": 38.0,
      "grad_norm": 1.892385721206665,
      "learning_rate": 0.0018782239879018084,
      "loss": 1.3459,
      "step": 76
    },
    {
      "epoch": 38.5,
      "grad_norm": 0.8517737984657288,
      "learning_rate": 0.0019029374614268322,
      "loss": 1.2957,
      "step": 77
    },
    {
      "epoch": 39.0,
      "grad_norm": 1.8212401866912842,
      "learning_rate": 0.0019276509349518559,
      "loss": 1.3047,
      "step": 78
    },
    {
      "epoch": 39.5,
      "grad_norm": 1.3204087018966675,
      "learning_rate": 0.00195236440847688,
      "loss": 1.3245,
      "step": 79
    },
    {
      "epoch": 40.0,
      "grad_norm": 1.5996030569076538,
      "learning_rate": 0.0019770778820019036,
      "loss": 1.2727,
      "step": 80
    },
    {
      "epoch": 40.0,
      "eval_brier_0th_event": 0.0,
      "eval_brier_0th_event_n": 258,
      "eval_brier_avg": 0.0,
      "eval_brier_weighted_avg": 0.0,
      "eval_ipcw": 0.591353945859479,
      "eval_ipcw_0th_event": 0.591353945859479,
      "eval_ipcw_0th_event_0.25": 0.6966642963981416,
      "eval_ipcw_0th_event_0.5": 0.6530315461140375,
      "eval_ipcw_0th_event_0.75": 0.6359968648980479,
      "eval_ipcw_0th_event_1.0": 0.591353945859479,
      "eval_ipcw_0th_event_n": 258,
      "eval_ipcw_avg": 0.6442616633174265,
      "eval_ipcw_avg_0th_event": 0.6442616633174265,
      "eval_ipcw_weighted_avg": 0.6442616633174265,
      "eval_loss": 0.6686239242553711,
      "eval_runtime": 0.0869,
      "eval_samples_per_second": 5108.971,
      "eval_steps_per_second": 11.507,
      "step": 80
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 8772019200.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
