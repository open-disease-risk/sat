{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 26.0,
  "eval_steps": 1,
  "global_step": 78,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 0.7165073752403259,
      "learning_rate": 8.368667026216322e-06,
      "loss": 1.5989,
      "step": 1
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 0.7598944902420044,
      "learning_rate": 1.6737334052432643e-05,
      "loss": 1.6053,
      "step": 2
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.9151996970176697,
      "learning_rate": 2.510600107864896e-05,
      "loss": 1.5979,
      "step": 3
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 0.7392130494117737,
      "learning_rate": 3.347466810486529e-05,
      "loss": 1.6274,
      "step": 4
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 0.8100014925003052,
      "learning_rate": 4.18433351310816e-05,
      "loss": 1.6056,
      "step": 5
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.839985191822052,
      "learning_rate": 5.021200215729792e-05,
      "loss": 1.4777,
      "step": 6
    },
    {
      "epoch": 2.3333333333333335,
      "grad_norm": 0.7639555931091309,
      "learning_rate": 5.858066918351424e-05,
      "loss": 1.6127,
      "step": 7
    },
    {
      "epoch": 2.6666666666666665,
      "grad_norm": 0.7026931047439575,
      "learning_rate": 6.694933620973057e-05,
      "loss": 1.5861,
      "step": 8
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.9050464034080505,
      "learning_rate": 7.531800323594688e-05,
      "loss": 1.6779,
      "step": 9
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 0.8078798651695251,
      "learning_rate": 8.36866702621632e-05,
      "loss": 1.5828,
      "step": 10
    },
    {
      "epoch": 3.6666666666666665,
      "grad_norm": 0.7979194521903992,
      "learning_rate": 9.205533728837953e-05,
      "loss": 1.5867,
      "step": 11
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.833042323589325,
      "learning_rate": 0.00010042400431459584,
      "loss": 1.6855,
      "step": 12
    },
    {
      "epoch": 4.333333333333333,
      "grad_norm": 0.9362669587135315,
      "learning_rate": 0.00010879267134081218,
      "loss": 1.6006,
      "step": 13
    },
    {
      "epoch": 4.666666666666667,
      "grad_norm": 0.725064754486084,
      "learning_rate": 0.00011716133836702849,
      "loss": 1.5957,
      "step": 14
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.7358248829841614,
      "learning_rate": 0.00012553000539324482,
      "loss": 1.6036,
      "step": 15
    },
    {
      "epoch": 5.333333333333333,
      "grad_norm": 0.9037342071533203,
      "learning_rate": 0.00013389867241946115,
      "loss": 1.5856,
      "step": 16
    },
    {
      "epoch": 5.666666666666667,
      "grad_norm": 0.921017587184906,
      "learning_rate": 0.00014226733944567744,
      "loss": 1.6164,
      "step": 17
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.7553303837776184,
      "learning_rate": 0.00015063600647189377,
      "loss": 1.6263,
      "step": 18
    },
    {
      "epoch": 6.333333333333333,
      "grad_norm": 0.8126881718635559,
      "learning_rate": 0.0001590046734981101,
      "loss": 1.5922,
      "step": 19
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 1.0216199159622192,
      "learning_rate": 0.0001673733405243264,
      "loss": 1.6064,
      "step": 20
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.9423657059669495,
      "learning_rate": 0.00017574200755054274,
      "loss": 1.6216,
      "step": 21
    },
    {
      "epoch": 7.333333333333333,
      "grad_norm": 0.8427488207817078,
      "learning_rate": 0.00018411067457675906,
      "loss": 1.5732,
      "step": 22
    },
    {
      "epoch": 7.666666666666667,
      "grad_norm": 1.1335548162460327,
      "learning_rate": 0.00019247934160297536,
      "loss": 1.6054,
      "step": 23
    },
    {
      "epoch": 8.0,
      "grad_norm": 1.0540720224380493,
      "learning_rate": 0.00020084800862919168,
      "loss": 1.6286,
      "step": 24
    },
    {
      "epoch": 8.333333333333334,
      "grad_norm": 1.0210994482040405,
      "learning_rate": 0.000209216675655408,
      "loss": 1.6081,
      "step": 25
    },
    {
      "epoch": 8.666666666666666,
      "grad_norm": 1.1160658597946167,
      "learning_rate": 0.00021758534268162435,
      "loss": 1.5691,
      "step": 26
    },
    {
      "epoch": 9.0,
      "grad_norm": 1.1327611207962036,
      "learning_rate": 0.00022595400970784068,
      "loss": 1.6357,
      "step": 27
    },
    {
      "epoch": 9.333333333333334,
      "grad_norm": 1.073606252670288,
      "learning_rate": 0.00023432267673405697,
      "loss": 1.5768,
      "step": 28
    },
    {
      "epoch": 9.666666666666666,
      "grad_norm": 1.1641770601272583,
      "learning_rate": 0.0002426913437602733,
      "loss": 1.5937,
      "step": 29
    },
    {
      "epoch": 10.0,
      "grad_norm": 1.2049944400787354,
      "learning_rate": 0.00025106001078648965,
      "loss": 1.5624,
      "step": 30
    },
    {
      "epoch": 10.333333333333334,
      "grad_norm": 1.1784276962280273,
      "learning_rate": 0.00025942867781270594,
      "loss": 1.6143,
      "step": 31
    },
    {
      "epoch": 10.666666666666666,
      "grad_norm": 1.2282520532608032,
      "learning_rate": 0.0002677973448389223,
      "loss": 1.5336,
      "step": 32
    },
    {
      "epoch": 11.0,
      "grad_norm": 1.1214911937713623,
      "learning_rate": 0.0002761660118651386,
      "loss": 1.6168,
      "step": 33
    },
    {
      "epoch": 11.333333333333334,
      "grad_norm": 1.1387189626693726,
      "learning_rate": 0.0002845346788913549,
      "loss": 1.6035,
      "step": 34
    },
    {
      "epoch": 11.666666666666666,
      "grad_norm": 1.247686743736267,
      "learning_rate": 0.00029290334591757124,
      "loss": 1.5739,
      "step": 35
    },
    {
      "epoch": 12.0,
      "grad_norm": 1.8844993114471436,
      "learning_rate": 0.00030127201294378753,
      "loss": 1.5293,
      "step": 36
    },
    {
      "epoch": 12.333333333333334,
      "grad_norm": 1.240251064300537,
      "learning_rate": 0.0003096406799700039,
      "loss": 1.5659,
      "step": 37
    },
    {
      "epoch": 12.666666666666666,
      "grad_norm": 1.3232333660125732,
      "learning_rate": 0.0003180093469962202,
      "loss": 1.5764,
      "step": 38
    },
    {
      "epoch": 13.0,
      "grad_norm": 1.654274344444275,
      "learning_rate": 0.0003263780140224365,
      "loss": 1.5579,
      "step": 39
    },
    {
      "epoch": 13.333333333333334,
      "grad_norm": 1.387739896774292,
      "learning_rate": 0.0003347466810486528,
      "loss": 1.508,
      "step": 40
    },
    {
      "epoch": 13.666666666666666,
      "grad_norm": 1.3560070991516113,
      "learning_rate": 0.0003431153480748691,
      "loss": 1.6159,
      "step": 41
    },
    {
      "epoch": 14.0,
      "grad_norm": 1.3711031675338745,
      "learning_rate": 0.0003514840151010855,
      "loss": 1.5835,
      "step": 42
    },
    {
      "epoch": 14.333333333333334,
      "grad_norm": 1.3778674602508545,
      "learning_rate": 0.00035985268212730177,
      "loss": 1.5546,
      "step": 43
    },
    {
      "epoch": 14.666666666666666,
      "grad_norm": 1.374375343322754,
      "learning_rate": 0.0003682213491535181,
      "loss": 1.5156,
      "step": 44
    },
    {
      "epoch": 15.0,
      "grad_norm": 1.2258570194244385,
      "learning_rate": 0.0003765900161797344,
      "loss": 1.563,
      "step": 45
    },
    {
      "epoch": 15.333333333333334,
      "grad_norm": 1.2608305215835571,
      "learning_rate": 0.0003849586832059507,
      "loss": 1.524,
      "step": 46
    },
    {
      "epoch": 15.666666666666666,
      "grad_norm": 1.4607294797897339,
      "learning_rate": 0.00039332735023216706,
      "loss": 1.5385,
      "step": 47
    },
    {
      "epoch": 16.0,
      "grad_norm": 1.5225094556808472,
      "learning_rate": 0.00040169601725838336,
      "loss": 1.6297,
      "step": 48
    },
    {
      "epoch": 16.333333333333332,
      "grad_norm": 1.229853868484497,
      "learning_rate": 0.00041006468428459976,
      "loss": 1.5654,
      "step": 49
    },
    {
      "epoch": 16.666666666666668,
      "grad_norm": 1.408949375152588,
      "learning_rate": 0.000418433351310816,
      "loss": 1.5197,
      "step": 50
    },
    {
      "epoch": 17.0,
      "grad_norm": 1.9084292650222778,
      "learning_rate": 0.0004268020183370323,
      "loss": 1.5716,
      "step": 51
    },
    {
      "epoch": 17.333333333333332,
      "grad_norm": 1.1105055809020996,
      "learning_rate": 0.0004351706853632487,
      "loss": 1.5266,
      "step": 52
    },
    {
      "epoch": 17.666666666666668,
      "grad_norm": 1.462121605873108,
      "learning_rate": 0.000443539352389465,
      "loss": 1.5207,
      "step": 53
    },
    {
      "epoch": 18.0,
      "grad_norm": 1.2671738862991333,
      "learning_rate": 0.00045190801941568135,
      "loss": 1.482,
      "step": 54
    },
    {
      "epoch": 18.333333333333332,
      "grad_norm": 1.3451542854309082,
      "learning_rate": 0.00046027668644189765,
      "loss": 1.4926,
      "step": 55
    },
    {
      "epoch": 18.666666666666668,
      "grad_norm": 1.2296690940856934,
      "learning_rate": 0.00046864535346811395,
      "loss": 1.5324,
      "step": 56
    },
    {
      "epoch": 19.0,
      "grad_norm": 1.5389080047607422,
      "learning_rate": 0.0004770140204943303,
      "loss": 1.4877,
      "step": 57
    },
    {
      "epoch": 19.333333333333332,
      "grad_norm": 1.3814799785614014,
      "learning_rate": 0.0004853826875205466,
      "loss": 1.4893,
      "step": 58
    },
    {
      "epoch": 19.666666666666668,
      "grad_norm": 1.1420255899429321,
      "learning_rate": 0.000493751354546763,
      "loss": 1.4672,
      "step": 59
    },
    {
      "epoch": 20.0,
      "grad_norm": 1.5678000450134277,
      "learning_rate": 0.0005021200215729793,
      "loss": 1.6355,
      "step": 60
    },
    {
      "epoch": 20.333333333333332,
      "grad_norm": 1.2405885457992554,
      "learning_rate": 0.0005104886885991955,
      "loss": 1.4909,
      "step": 61
    },
    {
      "epoch": 20.666666666666668,
      "grad_norm": 1.3193936347961426,
      "learning_rate": 0.0005188573556254119,
      "loss": 1.4828,
      "step": 62
    },
    {
      "epoch": 21.0,
      "grad_norm": 1.0058021545410156,
      "learning_rate": 0.0005272260226516282,
      "loss": 1.5031,
      "step": 63
    },
    {
      "epoch": 21.333333333333332,
      "grad_norm": 1.0596970319747925,
      "learning_rate": 0.0005355946896778446,
      "loss": 1.4736,
      "step": 64
    },
    {
      "epoch": 21.666666666666668,
      "grad_norm": 1.2575775384902954,
      "learning_rate": 0.0005439633567040609,
      "loss": 1.5186,
      "step": 65
    },
    {
      "epoch": 22.0,
      "grad_norm": 1.1913104057312012,
      "learning_rate": 0.0005523320237302772,
      "loss": 1.4295,
      "step": 66
    },
    {
      "epoch": 22.333333333333332,
      "grad_norm": 1.3764021396636963,
      "learning_rate": 0.0005607006907564935,
      "loss": 1.4641,
      "step": 67
    },
    {
      "epoch": 22.666666666666668,
      "grad_norm": 1.0194435119628906,
      "learning_rate": 0.0005690693577827098,
      "loss": 1.4745,
      "step": 68
    },
    {
      "epoch": 23.0,
      "grad_norm": 1.3729207515716553,
      "learning_rate": 0.0005774380248089262,
      "loss": 1.4658,
      "step": 69
    },
    {
      "epoch": 23.333333333333332,
      "grad_norm": 1.3081276416778564,
      "learning_rate": 0.0005858066918351425,
      "loss": 1.4741,
      "step": 70
    },
    {
      "epoch": 23.666666666666668,
      "grad_norm": 1.1665681600570679,
      "learning_rate": 0.0005941753588613588,
      "loss": 1.4745,
      "step": 71
    },
    {
      "epoch": 24.0,
      "grad_norm": 0.8425025939941406,
      "learning_rate": 0.0006025440258875751,
      "loss": 1.4081,
      "step": 72
    },
    {
      "epoch": 24.333333333333332,
      "grad_norm": 1.029950737953186,
      "learning_rate": 0.0006109126929137914,
      "loss": 1.4833,
      "step": 73
    },
    {
      "epoch": 24.666666666666668,
      "grad_norm": 1.0881860256195068,
      "learning_rate": 0.0006192813599400078,
      "loss": 1.415,
      "step": 74
    },
    {
      "epoch": 25.0,
      "grad_norm": 0.7456756234169006,
      "learning_rate": 0.0006276500269662241,
      "loss": 1.4424,
      "step": 75
    },
    {
      "epoch": 25.333333333333332,
      "grad_norm": 0.9025821089744568,
      "learning_rate": 0.0006360186939924404,
      "loss": 1.4423,
      "step": 76
    },
    {
      "epoch": 25.666666666666668,
      "grad_norm": 1.047092080116272,
      "learning_rate": 0.0006443873610186567,
      "loss": 1.4749,
      "step": 77
    },
    {
      "epoch": 26.0,
      "grad_norm": 1.3221853971481323,
      "learning_rate": 0.000652756028044873,
      "loss": 1.3851,
      "step": 78
    }
  ],
  "logging_steps": 1,
  "max_steps": 1500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4496812320.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
