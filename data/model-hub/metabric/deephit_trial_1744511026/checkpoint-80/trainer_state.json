{
  "best_global_step": 80,
  "best_metric": 0.6431764917638818,
  "best_model_checkpoint": "./data/model-hub/metabric/deephit_trial_1744511026/checkpoint-80",
  "epoch": 40.0,
  "eval_steps": 1,
  "global_step": 80,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 5.481172561645508,
      "learning_rate": 2.3614921289347483e-06,
      "loss": 6.5732,
      "step": 1
    },
    {
      "epoch": 1.0,
      "grad_norm": 5.00656270980835,
      "learning_rate": 4.7229842578694966e-06,
      "loss": 5.9787,
      "step": 2
    },
    {
      "epoch": 1.5,
      "grad_norm": 4.639011859893799,
      "learning_rate": 7.0844763868042444e-06,
      "loss": 5.6386,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 5.922183990478516,
      "learning_rate": 9.445968515738993e-06,
      "loss": 5.2964,
      "step": 4
    },
    {
      "epoch": 2.5,
      "grad_norm": 5.5633978843688965,
      "learning_rate": 1.1807460644673741e-05,
      "loss": 5.2043,
      "step": 5
    },
    {
      "epoch": 3.0,
      "grad_norm": 5.288303852081299,
      "learning_rate": 1.4168952773608489e-05,
      "loss": 5.3807,
      "step": 6
    },
    {
      "epoch": 3.5,
      "grad_norm": 5.416350364685059,
      "learning_rate": 1.6530444902543235e-05,
      "loss": 5.1583,
      "step": 7
    },
    {
      "epoch": 4.0,
      "grad_norm": 5.909364223480225,
      "learning_rate": 1.8891937031477986e-05,
      "loss": 5.0858,
      "step": 8
    },
    {
      "epoch": 4.5,
      "grad_norm": 5.887725830078125,
      "learning_rate": 2.1253429160412734e-05,
      "loss": 5.2556,
      "step": 9
    },
    {
      "epoch": 5.0,
      "grad_norm": 6.459569454193115,
      "learning_rate": 2.3614921289347482e-05,
      "loss": 5.1168,
      "step": 10
    },
    {
      "epoch": 5.5,
      "grad_norm": 6.306469917297363,
      "learning_rate": 2.5976413418282233e-05,
      "loss": 5.3572,
      "step": 11
    },
    {
      "epoch": 6.0,
      "grad_norm": 7.260366439819336,
      "learning_rate": 2.8337905547216978e-05,
      "loss": 5.3382,
      "step": 12
    },
    {
      "epoch": 6.5,
      "grad_norm": 7.231556415557861,
      "learning_rate": 3.0699397676151726e-05,
      "loss": 5.5492,
      "step": 13
    },
    {
      "epoch": 7.0,
      "grad_norm": 7.653872966766357,
      "learning_rate": 3.306088980508647e-05,
      "loss": 5.3326,
      "step": 14
    },
    {
      "epoch": 7.5,
      "grad_norm": 6.876842021942139,
      "learning_rate": 3.542238193402122e-05,
      "loss": 5.642,
      "step": 15
    },
    {
      "epoch": 8.0,
      "grad_norm": 7.395894527435303,
      "learning_rate": 3.778387406295597e-05,
      "loss": 5.5613,
      "step": 16
    },
    {
      "epoch": 8.5,
      "grad_norm": 7.7883806228637695,
      "learning_rate": 4.014536619189072e-05,
      "loss": 5.6157,
      "step": 17
    },
    {
      "epoch": 9.0,
      "grad_norm": 8.18980884552002,
      "learning_rate": 4.250685832082547e-05,
      "loss": 5.8457,
      "step": 18
    },
    {
      "epoch": 9.5,
      "grad_norm": 8.457503318786621,
      "learning_rate": 4.486835044976021e-05,
      "loss": 5.7579,
      "step": 19
    },
    {
      "epoch": 10.0,
      "grad_norm": 7.43519401550293,
      "learning_rate": 4.7229842578694964e-05,
      "loss": 5.8786,
      "step": 20
    },
    {
      "epoch": 10.5,
      "grad_norm": 7.675602912902832,
      "learning_rate": 4.9591334707629715e-05,
      "loss": 5.8981,
      "step": 21
    },
    {
      "epoch": 11.0,
      "grad_norm": 9.146625518798828,
      "learning_rate": 5.1952826836564467e-05,
      "loss": 5.7908,
      "step": 22
    },
    {
      "epoch": 11.5,
      "grad_norm": 8.122703552246094,
      "learning_rate": 5.4314318965499204e-05,
      "loss": 5.8148,
      "step": 23
    },
    {
      "epoch": 12.0,
      "grad_norm": 8.266901016235352,
      "learning_rate": 5.6675811094433955e-05,
      "loss": 6.0292,
      "step": 24
    },
    {
      "epoch": 12.5,
      "grad_norm": 8.614177703857422,
      "learning_rate": 5.903730322336871e-05,
      "loss": 5.9746,
      "step": 25
    },
    {
      "epoch": 13.0,
      "grad_norm": 8.351730346679688,
      "learning_rate": 6.139879535230345e-05,
      "loss": 5.7821,
      "step": 26
    },
    {
      "epoch": 13.5,
      "grad_norm": 7.673836708068848,
      "learning_rate": 6.376028748123821e-05,
      "loss": 5.9472,
      "step": 27
    },
    {
      "epoch": 14.0,
      "grad_norm": 8.509754180908203,
      "learning_rate": 6.612177961017294e-05,
      "loss": 6.0042,
      "step": 28
    },
    {
      "epoch": 14.5,
      "grad_norm": 7.72244119644165,
      "learning_rate": 6.84832717391077e-05,
      "loss": 6.05,
      "step": 29
    },
    {
      "epoch": 15.0,
      "grad_norm": 9.07777214050293,
      "learning_rate": 7.084476386804244e-05,
      "loss": 5.8213,
      "step": 30
    },
    {
      "epoch": 15.5,
      "grad_norm": 8.19096851348877,
      "learning_rate": 7.32062559969772e-05,
      "loss": 6.0867,
      "step": 31
    },
    {
      "epoch": 16.0,
      "grad_norm": 8.708084106445312,
      "learning_rate": 7.556774812591195e-05,
      "loss": 5.7525,
      "step": 32
    },
    {
      "epoch": 16.5,
      "grad_norm": 8.18111515045166,
      "learning_rate": 7.792924025484669e-05,
      "loss": 5.9534,
      "step": 33
    },
    {
      "epoch": 17.0,
      "grad_norm": 8.454337120056152,
      "learning_rate": 8.029073238378143e-05,
      "loss": 6.0473,
      "step": 34
    },
    {
      "epoch": 17.5,
      "grad_norm": 7.978407859802246,
      "learning_rate": 8.265222451271619e-05,
      "loss": 5.8919,
      "step": 35
    },
    {
      "epoch": 18.0,
      "grad_norm": 7.844182014465332,
      "learning_rate": 8.501371664165094e-05,
      "loss": 6.1894,
      "step": 36
    },
    {
      "epoch": 18.5,
      "grad_norm": 7.843198776245117,
      "learning_rate": 8.737520877058568e-05,
      "loss": 5.9796,
      "step": 37
    },
    {
      "epoch": 19.0,
      "grad_norm": 8.51575756072998,
      "learning_rate": 8.973670089952043e-05,
      "loss": 5.9015,
      "step": 38
    },
    {
      "epoch": 19.5,
      "grad_norm": 7.946270942687988,
      "learning_rate": 9.209819302845518e-05,
      "loss": 5.9528,
      "step": 39
    },
    {
      "epoch": 20.0,
      "grad_norm": 8.714548110961914,
      "learning_rate": 9.445968515738993e-05,
      "loss": 5.9418,
      "step": 40
    },
    {
      "epoch": 20.5,
      "grad_norm": 7.665078163146973,
      "learning_rate": 9.682117728632467e-05,
      "loss": 5.8068,
      "step": 41
    },
    {
      "epoch": 21.0,
      "grad_norm": 7.905544281005859,
      "learning_rate": 9.918266941525943e-05,
      "loss": 6.1074,
      "step": 42
    },
    {
      "epoch": 21.5,
      "grad_norm": 8.585647583007812,
      "learning_rate": 0.00010154416154419418,
      "loss": 5.9737,
      "step": 43
    },
    {
      "epoch": 22.0,
      "grad_norm": 7.799946308135986,
      "learning_rate": 0.00010390565367312893,
      "loss": 6.0036,
      "step": 44
    },
    {
      "epoch": 22.5,
      "grad_norm": 7.911664009094238,
      "learning_rate": 0.00010626714580206366,
      "loss": 6.0121,
      "step": 45
    },
    {
      "epoch": 23.0,
      "grad_norm": 9.231622695922852,
      "learning_rate": 0.00010862863793099841,
      "loss": 5.7792,
      "step": 46
    },
    {
      "epoch": 23.5,
      "grad_norm": 7.879152774810791,
      "learning_rate": 0.00011099013005993317,
      "loss": 6.0107,
      "step": 47
    },
    {
      "epoch": 24.0,
      "grad_norm": 9.539298057556152,
      "learning_rate": 0.00011335162218886791,
      "loss": 5.8322,
      "step": 48
    },
    {
      "epoch": 24.5,
      "grad_norm": 8.42708683013916,
      "learning_rate": 0.00011571311431780267,
      "loss": 5.907,
      "step": 49
    },
    {
      "epoch": 25.0,
      "grad_norm": 7.839861869812012,
      "learning_rate": 0.00011807460644673741,
      "loss": 6.1489,
      "step": 50
    },
    {
      "epoch": 25.5,
      "grad_norm": 8.276110649108887,
      "learning_rate": 0.00012043609857567214,
      "loss": 5.9704,
      "step": 51
    },
    {
      "epoch": 26.0,
      "grad_norm": 9.166022300720215,
      "learning_rate": 0.0001227975907046069,
      "loss": 5.9194,
      "step": 52
    },
    {
      "epoch": 26.5,
      "grad_norm": 8.707090377807617,
      "learning_rate": 0.00012515908283354166,
      "loss": 5.858,
      "step": 53
    },
    {
      "epoch": 27.0,
      "grad_norm": 8.733200073242188,
      "learning_rate": 0.00012752057496247642,
      "loss": 6.1236,
      "step": 54
    },
    {
      "epoch": 27.5,
      "grad_norm": 8.55737018585205,
      "learning_rate": 0.00012988206709141115,
      "loss": 5.8986,
      "step": 55
    },
    {
      "epoch": 28.0,
      "grad_norm": 8.90406322479248,
      "learning_rate": 0.00013224355922034588,
      "loss": 5.9263,
      "step": 56
    },
    {
      "epoch": 28.5,
      "grad_norm": 8.751895904541016,
      "learning_rate": 0.00013460505134928064,
      "loss": 5.7547,
      "step": 57
    },
    {
      "epoch": 29.0,
      "grad_norm": 8.291702270507812,
      "learning_rate": 0.0001369665434782154,
      "loss": 6.1827,
      "step": 58
    },
    {
      "epoch": 29.5,
      "grad_norm": 8.41669750213623,
      "learning_rate": 0.00013932803560715015,
      "loss": 5.9305,
      "step": 59
    },
    {
      "epoch": 30.0,
      "grad_norm": 9.639204025268555,
      "learning_rate": 0.00014168952773608489,
      "loss": 5.8911,
      "step": 60
    },
    {
      "epoch": 30.5,
      "grad_norm": 8.697574615478516,
      "learning_rate": 0.00014405101986501964,
      "loss": 5.8848,
      "step": 61
    },
    {
      "epoch": 31.0,
      "grad_norm": 8.865692138671875,
      "learning_rate": 0.0001464125119939544,
      "loss": 5.7968,
      "step": 62
    },
    {
      "epoch": 31.5,
      "grad_norm": 8.949162483215332,
      "learning_rate": 0.00014877400412288913,
      "loss": 6.0328,
      "step": 63
    },
    {
      "epoch": 32.0,
      "grad_norm": 10.67675495147705,
      "learning_rate": 0.0001511354962518239,
      "loss": 5.7447,
      "step": 64
    },
    {
      "epoch": 32.5,
      "grad_norm": 8.160796165466309,
      "learning_rate": 0.00015349698838075862,
      "loss": 6.1063,
      "step": 65
    },
    {
      "epoch": 33.0,
      "grad_norm": 10.115704536437988,
      "learning_rate": 0.00015585848050969338,
      "loss": 5.6823,
      "step": 66
    },
    {
      "epoch": 33.5,
      "grad_norm": 8.138069152832031,
      "learning_rate": 0.00015821997263862814,
      "loss": 6.1412,
      "step": 67
    },
    {
      "epoch": 34.0,
      "grad_norm": 10.23381519317627,
      "learning_rate": 0.00016058146476756287,
      "loss": 5.7001,
      "step": 68
    },
    {
      "epoch": 34.5,
      "grad_norm": 8.693857192993164,
      "learning_rate": 0.00016294295689649763,
      "loss": 5.8572,
      "step": 69
    },
    {
      "epoch": 35.0,
      "grad_norm": 8.870616912841797,
      "learning_rate": 0.00016530444902543238,
      "loss": 6.1718,
      "step": 70
    },
    {
      "epoch": 35.5,
      "grad_norm": 8.3768310546875,
      "learning_rate": 0.00016766594115436712,
      "loss": 6.0404,
      "step": 71
    },
    {
      "epoch": 36.0,
      "grad_norm": 9.51508617401123,
      "learning_rate": 0.00017002743328330187,
      "loss": 5.8696,
      "step": 72
    },
    {
      "epoch": 36.5,
      "grad_norm": 8.580577850341797,
      "learning_rate": 0.0001723889254122366,
      "loss": 5.9572,
      "step": 73
    },
    {
      "epoch": 37.0,
      "grad_norm": 8.997514724731445,
      "learning_rate": 0.00017475041754117136,
      "loss": 5.999,
      "step": 74
    },
    {
      "epoch": 37.5,
      "grad_norm": 7.928534030914307,
      "learning_rate": 0.00017711190967010612,
      "loss": 5.904,
      "step": 75
    },
    {
      "epoch": 38.0,
      "grad_norm": 9.288529396057129,
      "learning_rate": 0.00017947340179904085,
      "loss": 6.0531,
      "step": 76
    },
    {
      "epoch": 38.5,
      "grad_norm": 8.326539039611816,
      "learning_rate": 0.0001818348939279756,
      "loss": 5.8752,
      "step": 77
    },
    {
      "epoch": 39.0,
      "grad_norm": 9.645265579223633,
      "learning_rate": 0.00018419638605691037,
      "loss": 5.9711,
      "step": 78
    },
    {
      "epoch": 39.5,
      "grad_norm": 8.361924171447754,
      "learning_rate": 0.00018655787818584513,
      "loss": 5.9541,
      "step": 79
    },
    {
      "epoch": 40.0,
      "grad_norm": 9.319461822509766,
      "learning_rate": 0.00018891937031477986,
      "loss": 5.9105,
      "step": 80
    },
    {
      "epoch": 40.0,
      "eval_brier_0th_event": 0.19265092211972418,
      "eval_brier_0th_event_n": 255,
      "eval_brier_avg": 0.19265092211972418,
      "eval_brier_weighted_avg": 0.19265092211972418,
      "eval_ipcw": 0.588839979533479,
      "eval_ipcw_0th_event": 0.588839979533479,
      "eval_ipcw_0th_event_0.25": 0.6914749436258444,
      "eval_ipcw_0th_event_0.5": 0.663321346797881,
      "eval_ipcw_0th_event_0.75": 0.629069697098323,
      "eval_ipcw_0th_event_1.0": 0.588839979533479,
      "eval_ipcw_0th_event_n": 255,
      "eval_ipcw_avg": 0.6431764917638818,
      "eval_ipcw_avg_0th_event": 0.6431764917638818,
      "eval_ipcw_weighted_avg": 0.6431764917638818,
      "eval_loss": 2.8580574989318848,
      "eval_runtime": 3.2722,
      "eval_samples_per_second": 135.688,
      "eval_steps_per_second": 0.306,
      "step": 80
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 20041804800.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
