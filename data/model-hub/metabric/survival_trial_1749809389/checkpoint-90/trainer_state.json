{
  "best_global_step": 80,
  "best_metric": 0.632500508898183,
  "best_model_checkpoint": "./data/model-hub/metabric/survival_trial_1749809389/checkpoint-80",
  "epoch": 45.0,
  "eval_steps": 1,
  "global_step": 90,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 2.906846523284912,
      "learning_rate": 4.753567986864208e-05,
      "loss": 1.5911,
      "step": 1
    },
    {
      "epoch": 1.0,
      "grad_norm": 3.4890944957733154,
      "learning_rate": 9.507135973728416e-05,
      "loss": 1.595,
      "step": 2
    },
    {
      "epoch": 1.5,
      "grad_norm": 3.0834786891937256,
      "learning_rate": 0.00014260703960592623,
      "loss": 1.6031,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 3.1396737098693848,
      "learning_rate": 0.00019014271947456833,
      "loss": 1.548,
      "step": 4
    },
    {
      "epoch": 2.5,
      "grad_norm": 3.371469020843506,
      "learning_rate": 0.0002376783993432104,
      "loss": 1.6189,
      "step": 5
    },
    {
      "epoch": 3.0,
      "grad_norm": 2.9193997383117676,
      "learning_rate": 0.00028521407921185246,
      "loss": 1.5231,
      "step": 6
    },
    {
      "epoch": 3.5,
      "grad_norm": 3.1926558017730713,
      "learning_rate": 0.00033274975908049456,
      "loss": 1.5676,
      "step": 7
    },
    {
      "epoch": 4.0,
      "grad_norm": 3.180776596069336,
      "learning_rate": 0.00038028543894913665,
      "loss": 1.5622,
      "step": 8
    },
    {
      "epoch": 4.5,
      "grad_norm": 3.0615150928497314,
      "learning_rate": 0.0004278211188177787,
      "loss": 1.5625,
      "step": 9
    },
    {
      "epoch": 5.0,
      "grad_norm": 3.876309394836426,
      "learning_rate": 0.0004753567986864208,
      "loss": 1.554,
      "step": 10
    },
    {
      "epoch": 5.5,
      "grad_norm": 3.7785868644714355,
      "learning_rate": 0.0005228924785550629,
      "loss": 1.5264,
      "step": 11
    },
    {
      "epoch": 6.0,
      "grad_norm": 3.298628807067871,
      "learning_rate": 0.0005704281584237049,
      "loss": 1.5644,
      "step": 12
    },
    {
      "epoch": 6.5,
      "grad_norm": 3.4038543701171875,
      "learning_rate": 0.000617963838292347,
      "loss": 1.4999,
      "step": 13
    },
    {
      "epoch": 7.0,
      "grad_norm": 3.939617872238159,
      "learning_rate": 0.0006654995181609891,
      "loss": 1.543,
      "step": 14
    },
    {
      "epoch": 7.5,
      "grad_norm": 3.512813091278076,
      "learning_rate": 0.0007130351980296312,
      "loss": 1.5242,
      "step": 15
    },
    {
      "epoch": 8.0,
      "grad_norm": 3.957882881164551,
      "learning_rate": 0.0007605708778982733,
      "loss": 1.4712,
      "step": 16
    },
    {
      "epoch": 8.5,
      "grad_norm": 3.5390701293945312,
      "learning_rate": 0.0008081065577669153,
      "loss": 1.4457,
      "step": 17
    },
    {
      "epoch": 9.0,
      "grad_norm": 3.7666497230529785,
      "learning_rate": 0.0008556422376355574,
      "loss": 1.5076,
      "step": 18
    },
    {
      "epoch": 9.5,
      "grad_norm": 3.8567116260528564,
      "learning_rate": 0.0009031779175041995,
      "loss": 1.4542,
      "step": 19
    },
    {
      "epoch": 10.0,
      "grad_norm": 2.982168197631836,
      "learning_rate": 0.0009507135973728416,
      "loss": 1.4329,
      "step": 20
    },
    {
      "epoch": 10.5,
      "grad_norm": 3.0986149311065674,
      "learning_rate": 0.0009982492772414838,
      "loss": 1.4463,
      "step": 21
    },
    {
      "epoch": 11.0,
      "grad_norm": 3.035068988800049,
      "learning_rate": 0.0010457849571101259,
      "loss": 1.3535,
      "step": 22
    },
    {
      "epoch": 11.5,
      "grad_norm": 3.2519636154174805,
      "learning_rate": 0.0010933206369787677,
      "loss": 1.42,
      "step": 23
    },
    {
      "epoch": 12.0,
      "grad_norm": 1.5181468725204468,
      "learning_rate": 0.0011408563168474098,
      "loss": 1.3427,
      "step": 24
    },
    {
      "epoch": 12.5,
      "grad_norm": 1.9261420965194702,
      "learning_rate": 0.001188391996716052,
      "loss": 1.3804,
      "step": 25
    },
    {
      "epoch": 13.0,
      "grad_norm": 2.0933926105499268,
      "learning_rate": 0.001235927676584694,
      "loss": 1.3293,
      "step": 26
    },
    {
      "epoch": 13.5,
      "grad_norm": 1.586341381072998,
      "learning_rate": 0.0012834633564533361,
      "loss": 1.3574,
      "step": 27
    },
    {
      "epoch": 14.0,
      "grad_norm": 1.4950400590896606,
      "learning_rate": 0.0013309990363219782,
      "loss": 1.3304,
      "step": 28
    },
    {
      "epoch": 14.5,
      "grad_norm": 1.950294852256775,
      "learning_rate": 0.0013785347161906203,
      "loss": 1.3841,
      "step": 29
    },
    {
      "epoch": 15.0,
      "grad_norm": 3.1975653171539307,
      "learning_rate": 0.0014260703960592624,
      "loss": 1.2494,
      "step": 30
    },
    {
      "epoch": 15.5,
      "grad_norm": 1.8161182403564453,
      "learning_rate": 0.0014736060759279045,
      "loss": 1.2965,
      "step": 31
    },
    {
      "epoch": 16.0,
      "grad_norm": 2.482666254043579,
      "learning_rate": 0.0015211417557965466,
      "loss": 1.3505,
      "step": 32
    },
    {
      "epoch": 16.5,
      "grad_norm": 2.0488712787628174,
      "learning_rate": 0.0015686774356651885,
      "loss": 1.3252,
      "step": 33
    },
    {
      "epoch": 17.0,
      "grad_norm": 2.6055426597595215,
      "learning_rate": 0.0016162131155338306,
      "loss": 1.2956,
      "step": 34
    },
    {
      "epoch": 17.5,
      "grad_norm": 1.704508900642395,
      "learning_rate": 0.0016637487954024727,
      "loss": 1.3284,
      "step": 35
    },
    {
      "epoch": 18.0,
      "grad_norm": 2.106578826904297,
      "learning_rate": 0.0017112844752711148,
      "loss": 1.2587,
      "step": 36
    },
    {
      "epoch": 18.5,
      "grad_norm": 1.3569291830062866,
      "learning_rate": 0.001758820155139757,
      "loss": 1.2865,
      "step": 37
    },
    {
      "epoch": 19.0,
      "grad_norm": 1.4430261850357056,
      "learning_rate": 0.001806355835008399,
      "loss": 1.2602,
      "step": 38
    },
    {
      "epoch": 19.5,
      "grad_norm": 1.8026561737060547,
      "learning_rate": 0.001853891514877041,
      "loss": 1.2618,
      "step": 39
    },
    {
      "epoch": 20.0,
      "grad_norm": 2.341181516647339,
      "learning_rate": 0.0019014271947456831,
      "loss": 1.2628,
      "step": 40
    },
    {
      "epoch": 20.5,
      "grad_norm": 1.4805892705917358,
      "learning_rate": 0.001948962874614325,
      "loss": 1.245,
      "step": 41
    },
    {
      "epoch": 21.0,
      "grad_norm": 1.9422873258590698,
      "learning_rate": 0.0019964985544829675,
      "loss": 1.2425,
      "step": 42
    },
    {
      "epoch": 21.5,
      "grad_norm": 2.0768611431121826,
      "learning_rate": 0.0020440342343516094,
      "loss": 1.2189,
      "step": 43
    },
    {
      "epoch": 22.0,
      "grad_norm": 2.636348247528076,
      "learning_rate": 0.0020915699142202517,
      "loss": 1.2611,
      "step": 44
    },
    {
      "epoch": 22.5,
      "grad_norm": 1.445779800415039,
      "learning_rate": 0.0021391055940888936,
      "loss": 1.2,
      "step": 45
    },
    {
      "epoch": 23.0,
      "grad_norm": 1.820188283920288,
      "learning_rate": 0.0021866412739575355,
      "loss": 1.2388,
      "step": 46
    },
    {
      "epoch": 23.5,
      "grad_norm": 1.7242850065231323,
      "learning_rate": 0.002234176953826178,
      "loss": 1.2182,
      "step": 47
    },
    {
      "epoch": 24.0,
      "grad_norm": 1.6942391395568848,
      "learning_rate": 0.0022817126336948197,
      "loss": 1.1885,
      "step": 48
    },
    {
      "epoch": 24.5,
      "grad_norm": 1.7923099994659424,
      "learning_rate": 0.002329248313563462,
      "loss": 1.1584,
      "step": 49
    },
    {
      "epoch": 25.0,
      "grad_norm": 2.768282413482666,
      "learning_rate": 0.002376783993432104,
      "loss": 1.2024,
      "step": 50
    },
    {
      "epoch": 25.5,
      "grad_norm": 2.163357973098755,
      "learning_rate": 0.0024243196733007458,
      "loss": 1.1476,
      "step": 51
    },
    {
      "epoch": 26.0,
      "grad_norm": 3.061596393585205,
      "learning_rate": 0.002471855353169388,
      "loss": 1.2162,
      "step": 52
    },
    {
      "epoch": 26.5,
      "grad_norm": 2.7357797622680664,
      "learning_rate": 0.00251939103303803,
      "loss": 1.1344,
      "step": 53
    },
    {
      "epoch": 27.0,
      "grad_norm": 2.462918281555176,
      "learning_rate": 0.0025669267129066723,
      "loss": 1.1672,
      "step": 54
    },
    {
      "epoch": 27.5,
      "grad_norm": 2.3855721950531006,
      "learning_rate": 0.002614462392775314,
      "loss": 1.1056,
      "step": 55
    },
    {
      "epoch": 28.0,
      "grad_norm": 3.9025423526763916,
      "learning_rate": 0.0026619980726439564,
      "loss": 1.1903,
      "step": 56
    },
    {
      "epoch": 28.5,
      "grad_norm": 2.758072853088379,
      "learning_rate": 0.0027095337525125988,
      "loss": 1.0956,
      "step": 57
    },
    {
      "epoch": 29.0,
      "grad_norm": 3.0441713333129883,
      "learning_rate": 0.0027570694323812406,
      "loss": 1.1386,
      "step": 58
    },
    {
      "epoch": 29.5,
      "grad_norm": 2.6662518978118896,
      "learning_rate": 0.002804605112249883,
      "loss": 1.1256,
      "step": 59
    },
    {
      "epoch": 30.0,
      "grad_norm": 4.171995162963867,
      "learning_rate": 0.002852140792118525,
      "loss": 1.0731,
      "step": 60
    },
    {
      "epoch": 30.5,
      "grad_norm": 3.635798454284668,
      "learning_rate": 0.0028996764719871667,
      "loss": 1.0635,
      "step": 61
    },
    {
      "epoch": 31.0,
      "grad_norm": 3.488300085067749,
      "learning_rate": 0.002947212151855809,
      "loss": 1.1457,
      "step": 62
    },
    {
      "epoch": 31.5,
      "grad_norm": 2.573754072189331,
      "learning_rate": 0.002994747831724451,
      "loss": 1.0468,
      "step": 63
    },
    {
      "epoch": 32.0,
      "grad_norm": 3.8676676750183105,
      "learning_rate": 0.003042283511593093,
      "loss": 1.1276,
      "step": 64
    },
    {
      "epoch": 32.5,
      "grad_norm": 5.0253753662109375,
      "learning_rate": 0.003089819191461735,
      "loss": 1.0321,
      "step": 65
    },
    {
      "epoch": 33.0,
      "grad_norm": 3.882755756378174,
      "learning_rate": 0.003137354871330377,
      "loss": 1.1466,
      "step": 66
    },
    {
      "epoch": 33.5,
      "grad_norm": 2.346050977706909,
      "learning_rate": 0.0031848905511990193,
      "loss": 1.015,
      "step": 67
    },
    {
      "epoch": 34.0,
      "grad_norm": 3.4649081230163574,
      "learning_rate": 0.003232426231067661,
      "loss": 1.1207,
      "step": 68
    },
    {
      "epoch": 34.5,
      "grad_norm": 2.851745367050171,
      "learning_rate": 0.0032799619109363035,
      "loss": 1.0132,
      "step": 69
    },
    {
      "epoch": 35.0,
      "grad_norm": 3.9855117797851562,
      "learning_rate": 0.0033274975908049453,
      "loss": 1.0781,
      "step": 70
    },
    {
      "epoch": 35.5,
      "grad_norm": 2.4799394607543945,
      "learning_rate": 0.003375033270673587,
      "loss": 1.0592,
      "step": 71
    },
    {
      "epoch": 36.0,
      "grad_norm": 4.902554035186768,
      "learning_rate": 0.0034225689505422295,
      "loss": 1.0026,
      "step": 72
    },
    {
      "epoch": 36.5,
      "grad_norm": 3.6161582469940186,
      "learning_rate": 0.003470104630410872,
      "loss": 1.0026,
      "step": 73
    },
    {
      "epoch": 37.0,
      "grad_norm": 3.1668899059295654,
      "learning_rate": 0.003517640310279514,
      "loss": 1.0169,
      "step": 74
    },
    {
      "epoch": 37.5,
      "grad_norm": 4.049436569213867,
      "learning_rate": 0.003565175990148156,
      "loss": 1.026,
      "step": 75
    },
    {
      "epoch": 38.0,
      "grad_norm": 2.792208671569824,
      "learning_rate": 0.003612711670016798,
      "loss": 0.9639,
      "step": 76
    },
    {
      "epoch": 38.5,
      "grad_norm": 5.512238502502441,
      "learning_rate": 0.0036602473498854402,
      "loss": 1.0171,
      "step": 77
    },
    {
      "epoch": 39.0,
      "grad_norm": 3.979485034942627,
      "learning_rate": 0.003707783029754082,
      "loss": 0.939,
      "step": 78
    },
    {
      "epoch": 39.5,
      "grad_norm": 4.968800067901611,
      "learning_rate": 0.0037553187096227244,
      "loss": 0.9402,
      "step": 79
    },
    {
      "epoch": 40.0,
      "grad_norm": 3.2409636974334717,
      "learning_rate": 0.0038028543894913663,
      "loss": 1.0242,
      "step": 80
    },
    {
      "epoch": 40.0,
      "eval_brier_0th_event": 0.2013155072927475,
      "eval_brier_0th_event_n": 253,
      "eval_brier_weighted_avg": 0.2013155072927475,
      "eval_ipcw_0th_event": 0.632500508898183,
      "eval_ipcw_0th_event_0.25": 0.6161971092224121,
      "eval_ipcw_0th_event_0.50": 0.6258903741836548,
      "eval_ipcw_0th_event_0.75": 0.6289963126182556,
      "eval_ipcw_0th_event_1.00": 0.6428771615028381,
      "eval_ipcw_0th_event_n": 411,
      "eval_ipcw_weighted_avg": 0.632500508898183,
      "eval_loss": 0.7175483107566833,
      "eval_runtime": 0.1366,
      "eval_samples_per_second": 3008.186,
      "eval_steps_per_second": 7.319,
      "step": 80
    },
    {
      "epoch": 40.5,
      "grad_norm": 2.6441709995269775,
      "learning_rate": 0.0038028433035296617,
      "loss": 0.9527,
      "step": 81
    },
    {
      "epoch": 40.5,
      "eval_brier_0th_event": 0.20423579216003418,
      "eval_brier_0th_event_n": 253,
      "eval_brier_weighted_avg": 0.20423579216003418,
      "eval_ipcw_0th_event": 0.6276110431911776,
      "eval_ipcw_0th_event_0.25": 0.6121098399162292,
      "eval_ipcw_0th_event_0.50": 0.614789605140686,
      "eval_ipcw_0th_event_0.75": 0.6254437565803528,
      "eval_ipcw_0th_event_1.00": 0.640046238899231,
      "eval_ipcw_0th_event_n": 411,
      "eval_ipcw_weighted_avg": 0.6276110431911776,
      "eval_loss": 0.7287997007369995,
      "eval_runtime": 0.1332,
      "eval_samples_per_second": 3084.864,
      "eval_steps_per_second": 7.506,
      "step": 81
    },
    {
      "epoch": 41.0,
      "grad_norm": 3.6262948513031006,
      "learning_rate": 0.003802810045773817,
      "loss": 0.9874,
      "step": 82
    },
    {
      "epoch": 41.0,
      "eval_brier_0th_event": 0.20435917377471924,
      "eval_brier_0th_event_n": 253,
      "eval_brier_weighted_avg": 0.20435917377471924,
      "eval_ipcw_0th_event": 0.6253126665903688,
      "eval_ipcw_0th_event_0.25": 0.6094723343849182,
      "eval_ipcw_0th_event_0.50": 0.6136704087257385,
      "eval_ipcw_0th_event_0.75": 0.6220977306365967,
      "eval_ipcw_0th_event_1.00": 0.6380137801170349,
      "eval_ipcw_0th_event_n": 411,
      "eval_ipcw_weighted_avg": 0.6253126665903688,
      "eval_loss": 0.7348112463951111,
      "eval_runtime": 0.1352,
      "eval_samples_per_second": 3039.897,
      "eval_steps_per_second": 7.396,
      "step": 82
    },
    {
      "epoch": 41.5,
      "grad_norm": 3.2595620155334473,
      "learning_rate": 0.0038027546166116404,
      "loss": 0.9528,
      "step": 83
    },
    {
      "epoch": 41.5,
      "eval_brier_0th_event": 0.20192255079746246,
      "eval_brier_0th_event_n": 253,
      "eval_brier_weighted_avg": 0.20192255079746246,
      "eval_ipcw_0th_event": 0.6230961700711088,
      "eval_ipcw_0th_event_0.25": 0.6106940507888794,
      "eval_ipcw_0th_event_0.50": 0.612285852432251,
      "eval_ipcw_0th_event_0.75": 0.6196590662002563,
      "eval_ipcw_0th_event_1.00": 0.6346436738967896,
      "eval_ipcw_0th_event_n": 411,
      "eval_ipcw_weighted_avg": 0.6230961700711088,
      "eval_loss": 0.7314654588699341,
      "eval_runtime": 0.1377,
      "eval_samples_per_second": 2984.143,
      "eval_steps_per_second": 7.261,
      "step": 83
    },
    {
      "epoch": 42.0,
      "grad_norm": 4.005532264709473,
      "learning_rate": 0.003802677016689473,
      "loss": 0.972,
      "step": 84
    },
    {
      "epoch": 42.0,
      "eval_brier_0th_event": 0.20245732367038727,
      "eval_brier_0th_event_n": 253,
      "eval_brier_weighted_avg": 0.20245732367038727,
      "eval_ipcw_0th_event": 0.6209164594902712,
      "eval_ipcw_0th_event_0.25": 0.6020019054412842,
      "eval_ipcw_0th_event_0.50": 0.6105477809906006,
      "eval_ipcw_0th_event_0.75": 0.6177327632904053,
      "eval_ipcw_0th_event_1.00": 0.6337088942527771,
      "eval_ipcw_0th_event_n": 411,
      "eval_ipcw_weighted_avg": 0.6209164594902712,
      "eval_loss": 0.7311325669288635,
      "eval_runtime": 0.156,
      "eval_samples_per_second": 2634.11,
      "eval_steps_per_second": 6.409,
      "step": 84
    },
    {
      "epoch": 42.5,
      "grad_norm": 3.2170426845550537,
      "learning_rate": 0.0038025772469121827,
      "loss": 0.9576,
      "step": 85
    },
    {
      "epoch": 42.5,
      "eval_brier_0th_event": 0.20638921856880188,
      "eval_brier_0th_event_n": 253,
      "eval_brier_weighted_avg": 0.20638921856880188,
      "eval_ipcw_0th_event": 0.6193764214360677,
      "eval_ipcw_0th_event_0.25": 0.600559651851654,
      "eval_ipcw_0th_event_0.50": 0.6093535423278809,
      "eval_ipcw_0th_event_0.75": 0.617210328578949,
      "eval_ipcw_0th_event_1.00": 0.6311802864074707,
      "eval_ipcw_0th_event_n": 411,
      "eval_ipcw_weighted_avg": 0.6193764214360677,
      "eval_loss": 0.7414121627807617,
      "eval_runtime": 0.1353,
      "eval_samples_per_second": 3038.231,
      "eval_steps_per_second": 7.392,
      "step": 85
    },
    {
      "epoch": 43.0,
      "grad_norm": 3.980328321456909,
      "learning_rate": 0.003802455308443152,
      "loss": 0.9019,
      "step": 86
    },
    {
      "epoch": 43.0,
      "eval_brier_0th_event": 0.20731134712696075,
      "eval_brier_0th_event_n": 253,
      "eval_brier_weighted_avg": 0.20731134712696075,
      "eval_ipcw_0th_event": 0.6186319373709499,
      "eval_ipcw_0th_event_0.25": 0.6036522388458252,
      "eval_ipcw_0th_event_0.50": 0.6113531589508057,
      "eval_ipcw_0th_event_0.75": 0.6207610368728638,
      "eval_ipcw_0th_event_1.00": 0.624703049659729,
      "eval_ipcw_0th_event_n": 411,
      "eval_ipcw_weighted_avg": 0.6186319373709499,
      "eval_loss": 0.7391079664230347,
      "eval_runtime": 0.1349,
      "eval_samples_per_second": 3046.699,
      "eval_steps_per_second": 7.413,
      "step": 86
    },
    {
      "epoch": 43.5,
      "grad_norm": 2.7590267658233643,
      "learning_rate": 0.0038023112027042653,
      "loss": 0.9038,
      "step": 87
    },
    {
      "epoch": 43.5,
      "eval_brier_0th_event": 0.20829321444034576,
      "eval_brier_0th_event_n": 253,
      "eval_brier_weighted_avg": 0.20829321444034576,
      "eval_ipcw_0th_event": 0.6226267672544663,
      "eval_ipcw_0th_event_0.25": 0.6106605529785156,
      "eval_ipcw_0th_event_0.50": 0.6185597777366638,
      "eval_ipcw_0th_event_0.75": 0.6223545074462891,
      "eval_ipcw_0th_event_1.00": 0.6280639171600342,
      "eval_ipcw_0th_event_n": 411,
      "eval_ipcw_weighted_avg": 0.6226267672544663,
      "eval_loss": 0.7373324632644653,
      "eval_runtime": 0.1396,
      "eval_samples_per_second": 2943.477,
      "eval_steps_per_second": 7.162,
      "step": 87
    },
    {
      "epoch": 44.0,
      "grad_norm": 4.983466148376465,
      "learning_rate": 0.003802144931375894,
      "loss": 0.9918,
      "step": 88
    },
    {
      "epoch": 44.0,
      "eval_brier_0th_event": 0.21042516827583313,
      "eval_brier_0th_event_n": 253,
      "eval_brier_weighted_avg": 0.21042516827583313,
      "eval_ipcw_0th_event": 0.6246169037863196,
      "eval_ipcw_0th_event_0.25": 0.6118053197860718,
      "eval_ipcw_0th_event_0.50": 0.619731068611145,
      "eval_ipcw_0th_event_0.75": 0.6255421042442322,
      "eval_ipcw_0th_event_1.00": 0.6297867298126221,
      "eval_ipcw_0th_event_n": 411,
      "eval_ipcw_weighted_avg": 0.6246169037863196,
      "eval_loss": 0.7427760362625122,
      "eval_runtime": 0.1365,
      "eval_samples_per_second": 3010.524,
      "eval_steps_per_second": 7.325,
      "step": 88
    },
    {
      "epoch": 44.5,
      "grad_norm": 3.3640546798706055,
      "learning_rate": 0.003801956496396873,
      "loss": 0.9266,
      "step": 89
    },
    {
      "epoch": 44.5,
      "eval_brier_0th_event": 0.21250323951244354,
      "eval_brier_0th_event_n": 253,
      "eval_brier_weighted_avg": 0.21250323951244354,
      "eval_ipcw_0th_event": 0.625663062736346,
      "eval_ipcw_0th_event_0.25": 0.612833559513092,
      "eval_ipcw_0th_event_0.50": 0.6226893663406372,
      "eval_ipcw_0th_event_0.75": 0.6267440915107727,
      "eval_ipcw_0th_event_1.00": 0.6297052502632141,
      "eval_ipcw_0th_event_n": 411,
      "eval_ipcw_weighted_avg": 0.625663062736346,
      "eval_loss": 0.7517560720443726,
      "eval_runtime": 0.1336,
      "eval_samples_per_second": 3075.524,
      "eval_steps_per_second": 7.483,
      "step": 89
    },
    {
      "epoch": 45.0,
      "grad_norm": 3.304356813430786,
      "learning_rate": 0.003801745899964481,
      "loss": 0.8904,
      "step": 90
    },
    {
      "epoch": 45.0,
      "eval_brier_0th_event": 0.21289080381393433,
      "eval_brier_0th_event_n": 253,
      "eval_brier_weighted_avg": 0.21289080381393433,
      "eval_ipcw_0th_event": 0.6254140618415809,
      "eval_ipcw_0th_event_0.25": 0.6123487949371338,
      "eval_ipcw_0th_event_0.50": 0.6217901706695557,
      "eval_ipcw_0th_event_0.75": 0.6217160820960999,
      "eval_ipcw_0th_event_1.00": 0.6335257291793823,
      "eval_ipcw_0th_event_n": 411,
      "eval_ipcw_weighted_avg": 0.625414061841581,
      "eval_loss": 0.7590541243553162,
      "eval_runtime": 0.1359,
      "eval_samples_per_second": 3024.356,
      "eval_steps_per_second": 7.359,
      "step": 90
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 10
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 19711576800.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
