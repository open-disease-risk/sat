{
  "best_global_step": 81,
  "best_metric": 0.5993003144457533,
  "best_model_checkpoint": "./data/model-hub/metabric/survival_trial_1749809590_2/checkpoint-81",
  "epoch": 40.5,
  "eval_steps": 1,
  "global_step": 81,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 0.6979249715805054,
      "learning_rate": 5.2621133962866404e-05,
      "loss": 1.6324,
      "step": 1
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.6895236968994141,
      "learning_rate": 0.00010524226792573281,
      "loss": 1.6421,
      "step": 2
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.6463756561279297,
      "learning_rate": 0.0001578634018885992,
      "loss": 1.6437,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.6984904408454895,
      "learning_rate": 0.00021048453585146562,
      "loss": 1.6188,
      "step": 4
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.6450555920600891,
      "learning_rate": 0.000263105669814332,
      "loss": 1.6157,
      "step": 5
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.7886782288551331,
      "learning_rate": 0.0003157268037771984,
      "loss": 1.6807,
      "step": 6
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.7238268256187439,
      "learning_rate": 0.0003683479377400648,
      "loss": 1.6229,
      "step": 7
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.8953289985656738,
      "learning_rate": 0.00042096907170293123,
      "loss": 1.6269,
      "step": 8
    },
    {
      "epoch": 4.5,
      "grad_norm": 0.8792076706886292,
      "learning_rate": 0.0004735902056657976,
      "loss": 1.6159,
      "step": 9
    },
    {
      "epoch": 5.0,
      "grad_norm": 1.0355502367019653,
      "learning_rate": 0.000526211339628664,
      "loss": 1.6289,
      "step": 10
    },
    {
      "epoch": 5.5,
      "grad_norm": 1.0311424732208252,
      "learning_rate": 0.0005788324735915305,
      "loss": 1.6409,
      "step": 11
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.9715626239776611,
      "learning_rate": 0.0006314536075543968,
      "loss": 1.5525,
      "step": 12
    },
    {
      "epoch": 6.5,
      "grad_norm": 1.2151974439620972,
      "learning_rate": 0.0006840747415172633,
      "loss": 1.611,
      "step": 13
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.9958669543266296,
      "learning_rate": 0.0007366958754801296,
      "loss": 1.573,
      "step": 14
    },
    {
      "epoch": 7.5,
      "grad_norm": 1.3920873403549194,
      "learning_rate": 0.000789317009442996,
      "loss": 1.5967,
      "step": 15
    },
    {
      "epoch": 8.0,
      "grad_norm": 1.2702916860580444,
      "learning_rate": 0.0008419381434058625,
      "loss": 1.6039,
      "step": 16
    },
    {
      "epoch": 8.5,
      "grad_norm": 1.3044936656951904,
      "learning_rate": 0.0008945592773687287,
      "loss": 1.6056,
      "step": 17
    },
    {
      "epoch": 9.0,
      "grad_norm": 1.2947040796279907,
      "learning_rate": 0.0009471804113315952,
      "loss": 1.5541,
      "step": 18
    },
    {
      "epoch": 9.5,
      "grad_norm": 1.442723274230957,
      "learning_rate": 0.0009998015452944615,
      "loss": 1.5824,
      "step": 19
    },
    {
      "epoch": 10.0,
      "grad_norm": 1.1144764423370361,
      "learning_rate": 0.001052422679257328,
      "loss": 1.5739,
      "step": 20
    },
    {
      "epoch": 10.5,
      "grad_norm": 1.2182499170303345,
      "learning_rate": 0.0011050438132201945,
      "loss": 1.5652,
      "step": 21
    },
    {
      "epoch": 11.0,
      "grad_norm": 1.5825364589691162,
      "learning_rate": 0.001157664947183061,
      "loss": 1.5136,
      "step": 22
    },
    {
      "epoch": 11.5,
      "grad_norm": 1.258684515953064,
      "learning_rate": 0.001210286081145927,
      "loss": 1.5472,
      "step": 23
    },
    {
      "epoch": 12.0,
      "grad_norm": 1.4754555225372314,
      "learning_rate": 0.0012629072151087936,
      "loss": 1.5193,
      "step": 24
    },
    {
      "epoch": 12.5,
      "grad_norm": 1.2257243394851685,
      "learning_rate": 0.00131552834907166,
      "loss": 1.5279,
      "step": 25
    },
    {
      "epoch": 13.0,
      "grad_norm": 1.6640223264694214,
      "learning_rate": 0.0013681494830345266,
      "loss": 1.5236,
      "step": 26
    },
    {
      "epoch": 13.5,
      "grad_norm": 1.1978474855422974,
      "learning_rate": 0.0014207706169973929,
      "loss": 1.5248,
      "step": 27
    },
    {
      "epoch": 14.0,
      "grad_norm": 1.4505962133407593,
      "learning_rate": 0.0014733917509602591,
      "loss": 1.4606,
      "step": 28
    },
    {
      "epoch": 14.5,
      "grad_norm": 1.2143279314041138,
      "learning_rate": 0.0015260128849231256,
      "loss": 1.4719,
      "step": 29
    },
    {
      "epoch": 15.0,
      "grad_norm": 1.4819419384002686,
      "learning_rate": 0.001578634018885992,
      "loss": 1.5002,
      "step": 30
    },
    {
      "epoch": 15.5,
      "grad_norm": 1.2778239250183105,
      "learning_rate": 0.0016312551528488584,
      "loss": 1.4883,
      "step": 31
    },
    {
      "epoch": 16.0,
      "grad_norm": 1.4375022649765015,
      "learning_rate": 0.001683876286811725,
      "loss": 1.4489,
      "step": 32
    },
    {
      "epoch": 16.5,
      "grad_norm": 0.9854951500892639,
      "learning_rate": 0.0017364974207745912,
      "loss": 1.4498,
      "step": 33
    },
    {
      "epoch": 17.0,
      "grad_norm": 1.548258662223816,
      "learning_rate": 0.0017891185547374575,
      "loss": 1.4481,
      "step": 34
    },
    {
      "epoch": 17.5,
      "grad_norm": 1.029112696647644,
      "learning_rate": 0.001841739688700324,
      "loss": 1.4237,
      "step": 35
    },
    {
      "epoch": 18.0,
      "grad_norm": 1.2795863151550293,
      "learning_rate": 0.0018943608226631905,
      "loss": 1.4657,
      "step": 36
    },
    {
      "epoch": 18.5,
      "grad_norm": 1.0565708875656128,
      "learning_rate": 0.001946981956626057,
      "loss": 1.4293,
      "step": 37
    },
    {
      "epoch": 19.0,
      "grad_norm": 1.2309874296188354,
      "learning_rate": 0.001999603090588923,
      "loss": 1.4167,
      "step": 38
    },
    {
      "epoch": 19.5,
      "grad_norm": 0.8076781630516052,
      "learning_rate": 0.0020522242245517896,
      "loss": 1.4232,
      "step": 39
    },
    {
      "epoch": 20.0,
      "grad_norm": 1.2588590383529663,
      "learning_rate": 0.002104845358514656,
      "loss": 1.3676,
      "step": 40
    },
    {
      "epoch": 20.5,
      "grad_norm": 0.8069667816162109,
      "learning_rate": 0.002157466492477522,
      "loss": 1.4168,
      "step": 41
    },
    {
      "epoch": 21.0,
      "grad_norm": 1.412013053894043,
      "learning_rate": 0.002210087626440389,
      "loss": 1.3687,
      "step": 42
    },
    {
      "epoch": 21.5,
      "grad_norm": 0.6890812516212463,
      "learning_rate": 0.002262708760403255,
      "loss": 1.3888,
      "step": 43
    },
    {
      "epoch": 22.0,
      "grad_norm": 1.5298821926116943,
      "learning_rate": 0.002315329894366122,
      "loss": 1.3522,
      "step": 44
    },
    {
      "epoch": 22.5,
      "grad_norm": 0.8354838490486145,
      "learning_rate": 0.002367951028328988,
      "loss": 1.3687,
      "step": 45
    },
    {
      "epoch": 23.0,
      "grad_norm": 1.6175658702850342,
      "learning_rate": 0.002420572162291854,
      "loss": 1.3776,
      "step": 46
    },
    {
      "epoch": 23.5,
      "grad_norm": 0.8585231304168701,
      "learning_rate": 0.002473193296254721,
      "loss": 1.3975,
      "step": 47
    },
    {
      "epoch": 24.0,
      "grad_norm": 1.4867371320724487,
      "learning_rate": 0.002525814430217587,
      "loss": 1.306,
      "step": 48
    },
    {
      "epoch": 24.5,
      "grad_norm": 1.3966525793075562,
      "learning_rate": 0.0025784355641804537,
      "loss": 1.3607,
      "step": 49
    },
    {
      "epoch": 25.0,
      "grad_norm": 1.1595282554626465,
      "learning_rate": 0.00263105669814332,
      "loss": 1.3735,
      "step": 50
    },
    {
      "epoch": 25.5,
      "grad_norm": 1.2212722301483154,
      "learning_rate": 0.0026836778321061862,
      "loss": 1.3544,
      "step": 51
    },
    {
      "epoch": 26.0,
      "grad_norm": 1.2128713130950928,
      "learning_rate": 0.002736298966069053,
      "loss": 1.3251,
      "step": 52
    },
    {
      "epoch": 26.5,
      "grad_norm": 0.9200707077980042,
      "learning_rate": 0.0027889201000319192,
      "loss": 1.3091,
      "step": 53
    },
    {
      "epoch": 27.0,
      "grad_norm": 1.9256579875946045,
      "learning_rate": 0.0028415412339947857,
      "loss": 1.3808,
      "step": 54
    },
    {
      "epoch": 27.5,
      "grad_norm": 1.0410999059677124,
      "learning_rate": 0.0028941623679576522,
      "loss": 1.3216,
      "step": 55
    },
    {
      "epoch": 28.0,
      "grad_norm": 1.404261827468872,
      "learning_rate": 0.0029467835019205183,
      "loss": 1.2983,
      "step": 56
    },
    {
      "epoch": 28.5,
      "grad_norm": 1.0504344701766968,
      "learning_rate": 0.002999404635883385,
      "loss": 1.2964,
      "step": 57
    },
    {
      "epoch": 29.0,
      "grad_norm": 1.330844521522522,
      "learning_rate": 0.0030520257698462513,
      "loss": 1.3225,
      "step": 58
    },
    {
      "epoch": 29.5,
      "grad_norm": 0.9559302926063538,
      "learning_rate": 0.003104646903809118,
      "loss": 1.3251,
      "step": 59
    },
    {
      "epoch": 30.0,
      "grad_norm": 1.5640476942062378,
      "learning_rate": 0.003157268037771984,
      "loss": 1.3002,
      "step": 60
    },
    {
      "epoch": 30.5,
      "grad_norm": 1.024552583694458,
      "learning_rate": 0.0032098891717348504,
      "loss": 1.3217,
      "step": 61
    },
    {
      "epoch": 31.0,
      "grad_norm": 1.7560335397720337,
      "learning_rate": 0.003262510305697717,
      "loss": 1.2637,
      "step": 62
    },
    {
      "epoch": 31.5,
      "grad_norm": 1.6272461414337158,
      "learning_rate": 0.0033151314396605834,
      "loss": 1.2876,
      "step": 63
    },
    {
      "epoch": 32.0,
      "grad_norm": 2.5741193294525146,
      "learning_rate": 0.00336775257362345,
      "loss": 1.248,
      "step": 64
    },
    {
      "epoch": 32.5,
      "grad_norm": 1.2444682121276855,
      "learning_rate": 0.003420373707586316,
      "loss": 1.2801,
      "step": 65
    },
    {
      "epoch": 33.0,
      "grad_norm": 2.103956460952759,
      "learning_rate": 0.0034729948415491824,
      "loss": 1.2817,
      "step": 66
    },
    {
      "epoch": 33.5,
      "grad_norm": 1.6912811994552612,
      "learning_rate": 0.003525615975512049,
      "loss": 1.2693,
      "step": 67
    },
    {
      "epoch": 34.0,
      "grad_norm": 1.4374679327011108,
      "learning_rate": 0.003578237109474915,
      "loss": 1.2344,
      "step": 68
    },
    {
      "epoch": 34.5,
      "grad_norm": 2.3245723247528076,
      "learning_rate": 0.003630858243437782,
      "loss": 1.2212,
      "step": 69
    },
    {
      "epoch": 35.0,
      "grad_norm": 1.9099559783935547,
      "learning_rate": 0.003683479377400648,
      "loss": 1.2841,
      "step": 70
    },
    {
      "epoch": 35.5,
      "grad_norm": 1.313114047050476,
      "learning_rate": 0.0037361005113635145,
      "loss": 1.228,
      "step": 71
    },
    {
      "epoch": 36.0,
      "grad_norm": 2.126558303833008,
      "learning_rate": 0.003788721645326381,
      "loss": 1.2737,
      "step": 72
    },
    {
      "epoch": 36.5,
      "grad_norm": 1.6925594806671143,
      "learning_rate": 0.003841342779289247,
      "loss": 1.2364,
      "step": 73
    },
    {
      "epoch": 37.0,
      "grad_norm": 1.6820340156555176,
      "learning_rate": 0.003893963913252114,
      "loss": 1.2706,
      "step": 74
    },
    {
      "epoch": 37.5,
      "grad_norm": 2.1124587059020996,
      "learning_rate": 0.00394658504721498,
      "loss": 1.2259,
      "step": 75
    },
    {
      "epoch": 38.0,
      "grad_norm": 2.576017141342163,
      "learning_rate": 0.003999206181177846,
      "loss": 1.2594,
      "step": 76
    },
    {
      "epoch": 38.5,
      "grad_norm": 1.2691340446472168,
      "learning_rate": 0.004051827315140713,
      "loss": 1.2434,
      "step": 77
    },
    {
      "epoch": 39.0,
      "grad_norm": 2.239941358566284,
      "learning_rate": 0.004104448449103579,
      "loss": 1.1666,
      "step": 78
    },
    {
      "epoch": 39.5,
      "grad_norm": 2.0971829891204834,
      "learning_rate": 0.004157069583066446,
      "loss": 1.2224,
      "step": 79
    },
    {
      "epoch": 40.0,
      "grad_norm": 2.288597345352173,
      "learning_rate": 0.004209690717029312,
      "loss": 1.2104,
      "step": 80
    },
    {
      "epoch": 40.0,
      "eval_brier_0th_event": 0.19335909187793732,
      "eval_brier_0th_event_n": 247,
      "eval_brier_weighted_avg": 0.19335909187793732,
      "eval_ipcw_0th_event": 0.5969990690213602,
      "eval_ipcw_0th_event_0.25": 0.5873937606811523,
      "eval_ipcw_0th_event_0.50": 0.5938490629196167,
      "eval_ipcw_0th_event_0.75": 0.6089028120040894,
      "eval_ipcw_0th_event_1.00": 0.59200519323349,
      "eval_ipcw_0th_event_n": 473,
      "eval_ipcw_weighted_avg": 0.5969990690213602,
      "eval_loss": 0.6696167588233948,
      "eval_runtime": 0.1438,
      "eval_samples_per_second": 3290.179,
      "eval_steps_per_second": 6.956,
      "step": 80
    },
    {
      "epoch": 40.5,
      "grad_norm": 2.04826021194458,
      "learning_rate": 0.00420967844507112,
      "loss": 1.1567,
      "step": 81
    },
    {
      "epoch": 40.5,
      "eval_brier_0th_event": 0.19716045260429382,
      "eval_brier_0th_event_n": 247,
      "eval_brier_weighted_avg": 0.19716045260429382,
      "eval_ipcw_0th_event": 0.5993003144457533,
      "eval_ipcw_0th_event_0.25": 0.5898126363754272,
      "eval_ipcw_0th_event_0.50": 0.5954758524894714,
      "eval_ipcw_0th_event_0.75": 0.607111394405365,
      "eval_ipcw_0th_event_1.00": 0.5975205898284912,
      "eval_ipcw_0th_event_n": 473,
      "eval_ipcw_weighted_avg": 0.5993003144457533,
      "eval_loss": 0.6767447590827942,
      "eval_runtime": 0.1505,
      "eval_samples_per_second": 3142.393,
      "eval_steps_per_second": 6.644,
      "step": 81
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 10125987840.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
