{
  "best_global_step": 80,
  "best_metric": 0.6263730777314696,
  "best_model_checkpoint": "./data/model-hub/metabric/survival-moco_trial_1744124531/checkpoint-80",
  "epoch": 40.0,
  "eval_steps": 1,
  "global_step": 80,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 3.795832633972168,
      "learning_rate": 2.091482338524617e-05,
      "loss": 1.5544,
      "step": 1
    },
    {
      "epoch": 1.0,
      "grad_norm": 3.14074969291687,
      "learning_rate": 4.182964677049234e-05,
      "loss": 1.5865,
      "step": 2
    },
    {
      "epoch": 1.5,
      "grad_norm": 3.5693111419677734,
      "learning_rate": 6.27444701557385e-05,
      "loss": 1.5673,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 3.1580402851104736,
      "learning_rate": 8.365929354098468e-05,
      "loss": 1.5905,
      "step": 4
    },
    {
      "epoch": 2.5,
      "grad_norm": 3.2627642154693604,
      "learning_rate": 0.00010457411692623084,
      "loss": 1.5856,
      "step": 5
    },
    {
      "epoch": 3.0,
      "grad_norm": 3.643585205078125,
      "learning_rate": 0.000125488940311477,
      "loss": 1.5502,
      "step": 6
    },
    {
      "epoch": 3.5,
      "grad_norm": 3.3742868900299072,
      "learning_rate": 0.00014640376369672316,
      "loss": 1.5562,
      "step": 7
    },
    {
      "epoch": 4.0,
      "grad_norm": 3.3317716121673584,
      "learning_rate": 0.00016731858708196937,
      "loss": 1.5609,
      "step": 8
    },
    {
      "epoch": 4.5,
      "grad_norm": 3.6649277210235596,
      "learning_rate": 0.00018823341046721553,
      "loss": 1.5733,
      "step": 9
    },
    {
      "epoch": 5.0,
      "grad_norm": 3.292267084121704,
      "learning_rate": 0.00020914823385246168,
      "loss": 1.5245,
      "step": 10
    },
    {
      "epoch": 5.5,
      "grad_norm": 3.8848183155059814,
      "learning_rate": 0.00023006305723770787,
      "loss": 1.5624,
      "step": 11
    },
    {
      "epoch": 6.0,
      "grad_norm": 4.206533432006836,
      "learning_rate": 0.000250977880622954,
      "loss": 1.5493,
      "step": 12
    },
    {
      "epoch": 6.5,
      "grad_norm": 4.232057571411133,
      "learning_rate": 0.0002718927040082002,
      "loss": 1.5558,
      "step": 13
    },
    {
      "epoch": 7.0,
      "grad_norm": 3.8081398010253906,
      "learning_rate": 0.0002928075273934463,
      "loss": 1.5293,
      "step": 14
    },
    {
      "epoch": 7.5,
      "grad_norm": 5.076580047607422,
      "learning_rate": 0.00031372235077869255,
      "loss": 1.5527,
      "step": 15
    },
    {
      "epoch": 8.0,
      "grad_norm": 3.8733713626861572,
      "learning_rate": 0.00033463717416393874,
      "loss": 1.482,
      "step": 16
    },
    {
      "epoch": 8.5,
      "grad_norm": 5.317081451416016,
      "learning_rate": 0.00035555199754918487,
      "loss": 1.5103,
      "step": 17
    },
    {
      "epoch": 9.0,
      "grad_norm": 4.554910182952881,
      "learning_rate": 0.00037646682093443105,
      "loss": 1.4993,
      "step": 18
    },
    {
      "epoch": 9.5,
      "grad_norm": 5.3166184425354,
      "learning_rate": 0.0003973816443196772,
      "loss": 1.5057,
      "step": 19
    },
    {
      "epoch": 10.0,
      "grad_norm": 5.939019203186035,
      "learning_rate": 0.00041829646770492337,
      "loss": 1.4416,
      "step": 20
    },
    {
      "epoch": 10.5,
      "grad_norm": 6.190349102020264,
      "learning_rate": 0.00043921129109016955,
      "loss": 1.4021,
      "step": 21
    },
    {
      "epoch": 11.0,
      "grad_norm": 5.710105895996094,
      "learning_rate": 0.00046012611447541574,
      "loss": 1.511,
      "step": 22
    },
    {
      "epoch": 11.5,
      "grad_norm": 5.174214839935303,
      "learning_rate": 0.0004810409378606618,
      "loss": 1.4428,
      "step": 23
    },
    {
      "epoch": 12.0,
      "grad_norm": 4.401805400848389,
      "learning_rate": 0.000501955761245908,
      "loss": 1.4165,
      "step": 24
    },
    {
      "epoch": 12.5,
      "grad_norm": 5.544548988342285,
      "learning_rate": 0.0005228705846311542,
      "loss": 1.3789,
      "step": 25
    },
    {
      "epoch": 13.0,
      "grad_norm": 4.118934154510498,
      "learning_rate": 0.0005437854080164004,
      "loss": 1.4242,
      "step": 26
    },
    {
      "epoch": 13.5,
      "grad_norm": 5.054153919219971,
      "learning_rate": 0.0005647002314016466,
      "loss": 1.3753,
      "step": 27
    },
    {
      "epoch": 14.0,
      "grad_norm": 3.7825233936309814,
      "learning_rate": 0.0005856150547868926,
      "loss": 1.3984,
      "step": 28
    },
    {
      "epoch": 14.5,
      "grad_norm": 4.853711128234863,
      "learning_rate": 0.0006065298781721388,
      "loss": 1.3656,
      "step": 29
    },
    {
      "epoch": 15.0,
      "grad_norm": 3.7901933193206787,
      "learning_rate": 0.0006274447015573851,
      "loss": 1.4058,
      "step": 30
    },
    {
      "epoch": 15.5,
      "grad_norm": 3.285191535949707,
      "learning_rate": 0.0006483595249426313,
      "loss": 1.3491,
      "step": 31
    },
    {
      "epoch": 16.0,
      "grad_norm": 4.408846378326416,
      "learning_rate": 0.0006692743483278775,
      "loss": 1.3885,
      "step": 32
    },
    {
      "epoch": 16.5,
      "grad_norm": 4.00088357925415,
      "learning_rate": 0.0006901891717131236,
      "loss": 1.3401,
      "step": 33
    },
    {
      "epoch": 17.0,
      "grad_norm": 4.212966442108154,
      "learning_rate": 0.0007111039950983697,
      "loss": 1.3854,
      "step": 34
    },
    {
      "epoch": 17.5,
      "grad_norm": 3.162315607070923,
      "learning_rate": 0.0007320188184836159,
      "loss": 1.3115,
      "step": 35
    },
    {
      "epoch": 18.0,
      "grad_norm": 4.962857246398926,
      "learning_rate": 0.0007529336418688621,
      "loss": 1.3772,
      "step": 36
    },
    {
      "epoch": 18.5,
      "grad_norm": 4.575263023376465,
      "learning_rate": 0.0007738484652541083,
      "loss": 1.3128,
      "step": 37
    },
    {
      "epoch": 19.0,
      "grad_norm": 6.805635929107666,
      "learning_rate": 0.0007947632886393544,
      "loss": 1.3728,
      "step": 38
    },
    {
      "epoch": 19.5,
      "grad_norm": 4.133643627166748,
      "learning_rate": 0.0008156781120246006,
      "loss": 1.3269,
      "step": 39
    },
    {
      "epoch": 20.0,
      "grad_norm": 5.9262919425964355,
      "learning_rate": 0.0008365929354098467,
      "loss": 1.3262,
      "step": 40
    },
    {
      "epoch": 20.5,
      "grad_norm": 5.49075984954834,
      "learning_rate": 0.0008575077587950928,
      "loss": 1.349,
      "step": 41
    },
    {
      "epoch": 21.0,
      "grad_norm": 4.036285400390625,
      "learning_rate": 0.0008784225821803391,
      "loss": 1.2851,
      "step": 42
    },
    {
      "epoch": 21.5,
      "grad_norm": 4.6449174880981445,
      "learning_rate": 0.0008993374055655852,
      "loss": 1.2757,
      "step": 43
    },
    {
      "epoch": 22.0,
      "grad_norm": 5.065885066986084,
      "learning_rate": 0.0009202522289508315,
      "loss": 1.399,
      "step": 44
    },
    {
      "epoch": 22.5,
      "grad_norm": 4.040998458862305,
      "learning_rate": 0.0009411670523360776,
      "loss": 1.2942,
      "step": 45
    },
    {
      "epoch": 23.0,
      "grad_norm": 5.1741156578063965,
      "learning_rate": 0.0009620818757213236,
      "loss": 1.3219,
      "step": 46
    },
    {
      "epoch": 23.5,
      "grad_norm": 2.784067392349243,
      "learning_rate": 0.00098299669910657,
      "loss": 1.2598,
      "step": 47
    },
    {
      "epoch": 24.0,
      "grad_norm": 6.596275329589844,
      "learning_rate": 0.001003911522491816,
      "loss": 1.3401,
      "step": 48
    },
    {
      "epoch": 24.5,
      "grad_norm": 3.8030283451080322,
      "learning_rate": 0.0010248263458770624,
      "loss": 1.2654,
      "step": 49
    },
    {
      "epoch": 25.0,
      "grad_norm": 3.973973035812378,
      "learning_rate": 0.0010457411692623084,
      "loss": 1.3314,
      "step": 50
    },
    {
      "epoch": 25.5,
      "grad_norm": 8.544635772705078,
      "learning_rate": 0.0010666559926475546,
      "loss": 1.2893,
      "step": 51
    },
    {
      "epoch": 26.0,
      "grad_norm": 5.0982465744018555,
      "learning_rate": 0.0010875708160328007,
      "loss": 1.2843,
      "step": 52
    },
    {
      "epoch": 26.5,
      "grad_norm": 3.443315267562866,
      "learning_rate": 0.001108485639418047,
      "loss": 1.26,
      "step": 53
    },
    {
      "epoch": 27.0,
      "grad_norm": 8.742795944213867,
      "learning_rate": 0.001129400462803293,
      "loss": 1.3173,
      "step": 54
    },
    {
      "epoch": 27.5,
      "grad_norm": 4.157273769378662,
      "learning_rate": 0.0011503152861885393,
      "loss": 1.2533,
      "step": 55
    },
    {
      "epoch": 28.0,
      "grad_norm": 6.4098076820373535,
      "learning_rate": 0.0011712301095737853,
      "loss": 1.2648,
      "step": 56
    },
    {
      "epoch": 28.5,
      "grad_norm": 7.163436412811279,
      "learning_rate": 0.0011921449329590317,
      "loss": 1.2118,
      "step": 57
    },
    {
      "epoch": 29.0,
      "grad_norm": 4.655827522277832,
      "learning_rate": 0.0012130597563442776,
      "loss": 1.2879,
      "step": 58
    },
    {
      "epoch": 29.5,
      "grad_norm": 3.1144230365753174,
      "learning_rate": 0.001233974579729524,
      "loss": 1.1936,
      "step": 59
    },
    {
      "epoch": 30.0,
      "grad_norm": 7.621671199798584,
      "learning_rate": 0.0012548894031147702,
      "loss": 1.3059,
      "step": 60
    },
    {
      "epoch": 30.5,
      "grad_norm": 3.782139301300049,
      "learning_rate": 0.0012758042265000162,
      "loss": 1.2136,
      "step": 61
    },
    {
      "epoch": 31.0,
      "grad_norm": 5.329901218414307,
      "learning_rate": 0.0012967190498852626,
      "loss": 1.2716,
      "step": 62
    },
    {
      "epoch": 31.5,
      "grad_norm": 5.327059745788574,
      "learning_rate": 0.0013176338732705086,
      "loss": 1.1946,
      "step": 63
    },
    {
      "epoch": 32.0,
      "grad_norm": 8.2985258102417,
      "learning_rate": 0.001338548696655755,
      "loss": 1.293,
      "step": 64
    },
    {
      "epoch": 32.5,
      "grad_norm": 4.353573799133301,
      "learning_rate": 0.001359463520041001,
      "loss": 1.2594,
      "step": 65
    },
    {
      "epoch": 33.0,
      "grad_norm": 8.706133842468262,
      "learning_rate": 0.001380378343426247,
      "loss": 1.1929,
      "step": 66
    },
    {
      "epoch": 33.5,
      "grad_norm": 5.4024505615234375,
      "learning_rate": 0.0014012931668114933,
      "loss": 1.1941,
      "step": 67
    },
    {
      "epoch": 34.0,
      "grad_norm": 7.2040629386901855,
      "learning_rate": 0.0014222079901967395,
      "loss": 1.2569,
      "step": 68
    },
    {
      "epoch": 34.5,
      "grad_norm": 8.924161911010742,
      "learning_rate": 0.0014431228135819857,
      "loss": 1.2117,
      "step": 69
    },
    {
      "epoch": 35.0,
      "grad_norm": 5.369475841522217,
      "learning_rate": 0.0014640376369672318,
      "loss": 1.2367,
      "step": 70
    },
    {
      "epoch": 35.5,
      "grad_norm": 5.931023120880127,
      "learning_rate": 0.0014849524603524778,
      "loss": 1.2133,
      "step": 71
    },
    {
      "epoch": 36.0,
      "grad_norm": 9.447450637817383,
      "learning_rate": 0.0015058672837377242,
      "loss": 1.2219,
      "step": 72
    },
    {
      "epoch": 36.5,
      "grad_norm": 4.85400390625,
      "learning_rate": 0.0015267821071229702,
      "loss": 1.1895,
      "step": 73
    },
    {
      "epoch": 37.0,
      "grad_norm": 7.053774356842041,
      "learning_rate": 0.0015476969305082166,
      "loss": 1.2199,
      "step": 74
    },
    {
      "epoch": 37.5,
      "grad_norm": 4.087355136871338,
      "learning_rate": 0.0015686117538934626,
      "loss": 1.1762,
      "step": 75
    },
    {
      "epoch": 38.0,
      "grad_norm": 4.756850242614746,
      "learning_rate": 0.0015895265772787087,
      "loss": 1.2039,
      "step": 76
    },
    {
      "epoch": 38.5,
      "grad_norm": 9.027938842773438,
      "learning_rate": 0.001610441400663955,
      "loss": 1.1888,
      "step": 77
    },
    {
      "epoch": 39.0,
      "grad_norm": 6.513187408447266,
      "learning_rate": 0.001631356224049201,
      "loss": 1.2369,
      "step": 78
    },
    {
      "epoch": 39.5,
      "grad_norm": 5.46909236907959,
      "learning_rate": 0.0016522710474344473,
      "loss": 1.1468,
      "step": 79
    },
    {
      "epoch": 40.0,
      "grad_norm": 6.096912860870361,
      "learning_rate": 0.0016731858708196935,
      "loss": 1.2236,
      "step": 80
    },
    {
      "epoch": 40.0,
      "eval_brier_0th_event": 0.20557705302136364,
      "eval_brier_0th_event_n": 252,
      "eval_brier_avg": 0.20557705302136364,
      "eval_brier_weighted_avg": 0.20557705302136364,
      "eval_ipcw": 0.5976288303383581,
      "eval_ipcw_0th_event": 0.5976288303383581,
      "eval_ipcw_0th_event_0.25": 0.6529667245773477,
      "eval_ipcw_0th_event_0.5": 0.6393778573257978,
      "eval_ipcw_0th_event_0.75": 0.6155188986843747,
      "eval_ipcw_0th_event_1.0": 0.5976288303383581,
      "eval_ipcw_0th_event_n": 252,
      "eval_ipcw_avg": 0.6263730777314696,
      "eval_ipcw_avg_0th_event": 0.6263730777314696,
      "eval_ipcw_weighted_avg": 0.6263730777314696,
      "eval_loss": 0.7168920636177063,
      "eval_runtime": 0.0737,
      "eval_samples_per_second": 6021.642,
      "eval_steps_per_second": 13.562,
      "step": 80
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 84864384000.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
