{
  "best_global_step": 84,
  "best_metric": 0.6281958937263896,
  "best_model_checkpoint": "./data/model-hub/metabric/survival_trial_1744212316/checkpoint-84",
  "epoch": 42.0,
  "eval_steps": 1,
  "global_step": 84,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 1.9691894054412842,
      "learning_rate": 3.5176339722704373e-06,
      "loss": 1.6717,
      "step": 1
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.688761591911316,
      "learning_rate": 7.0352679445408746e-06,
      "loss": 1.665,
      "step": 2
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.6996568441390991,
      "learning_rate": 1.0552901916811311e-05,
      "loss": 1.6855,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 2.1226322650909424,
      "learning_rate": 1.4070535889081749e-05,
      "loss": 1.6351,
      "step": 4
    },
    {
      "epoch": 2.5,
      "grad_norm": 1.9118047952651978,
      "learning_rate": 1.7588169861352186e-05,
      "loss": 1.6514,
      "step": 5
    },
    {
      "epoch": 3.0,
      "grad_norm": 1.8459922075271606,
      "learning_rate": 2.1105803833622622e-05,
      "loss": 1.7166,
      "step": 6
    },
    {
      "epoch": 3.5,
      "grad_norm": 1.8017325401306152,
      "learning_rate": 2.462343780589306e-05,
      "loss": 1.6908,
      "step": 7
    },
    {
      "epoch": 4.0,
      "grad_norm": 1.9284783601760864,
      "learning_rate": 2.8141071778163498e-05,
      "loss": 1.6471,
      "step": 8
    },
    {
      "epoch": 4.5,
      "grad_norm": 1.8209433555603027,
      "learning_rate": 3.165870575043394e-05,
      "loss": 1.695,
      "step": 9
    },
    {
      "epoch": 5.0,
      "grad_norm": 1.6938427686691284,
      "learning_rate": 3.517633972270437e-05,
      "loss": 1.6156,
      "step": 10
    },
    {
      "epoch": 5.5,
      "grad_norm": 1.66754949092865,
      "learning_rate": 3.869397369497481e-05,
      "loss": 1.6775,
      "step": 11
    },
    {
      "epoch": 6.0,
      "grad_norm": 2.037074565887451,
      "learning_rate": 4.2211607667245244e-05,
      "loss": 1.6365,
      "step": 12
    },
    {
      "epoch": 6.5,
      "grad_norm": 1.7709590196609497,
      "learning_rate": 4.5729241639515684e-05,
      "loss": 1.6316,
      "step": 13
    },
    {
      "epoch": 7.0,
      "grad_norm": 1.955810546875,
      "learning_rate": 4.924687561178612e-05,
      "loss": 1.7426,
      "step": 14
    },
    {
      "epoch": 7.5,
      "grad_norm": 1.805728793144226,
      "learning_rate": 5.276450958405656e-05,
      "loss": 1.6459,
      "step": 15
    },
    {
      "epoch": 8.0,
      "grad_norm": 1.7157973051071167,
      "learning_rate": 5.6282143556326996e-05,
      "loss": 1.7019,
      "step": 16
    },
    {
      "epoch": 8.5,
      "grad_norm": 1.634023666381836,
      "learning_rate": 5.979977752859743e-05,
      "loss": 1.6526,
      "step": 17
    },
    {
      "epoch": 9.0,
      "grad_norm": 2.0103540420532227,
      "learning_rate": 6.331741150086788e-05,
      "loss": 1.6755,
      "step": 18
    },
    {
      "epoch": 9.5,
      "grad_norm": 1.7398993968963623,
      "learning_rate": 6.68350454731383e-05,
      "loss": 1.6605,
      "step": 19
    },
    {
      "epoch": 10.0,
      "grad_norm": 1.61906099319458,
      "learning_rate": 7.035267944540874e-05,
      "loss": 1.673,
      "step": 20
    },
    {
      "epoch": 10.5,
      "grad_norm": 1.6552927494049072,
      "learning_rate": 7.387031341767919e-05,
      "loss": 1.6397,
      "step": 21
    },
    {
      "epoch": 11.0,
      "grad_norm": 1.9936219453811646,
      "learning_rate": 7.738794738994962e-05,
      "loss": 1.6909,
      "step": 22
    },
    {
      "epoch": 11.5,
      "grad_norm": 1.7449395656585693,
      "learning_rate": 8.090558136222004e-05,
      "loss": 1.6599,
      "step": 23
    },
    {
      "epoch": 12.0,
      "grad_norm": 1.6575649976730347,
      "learning_rate": 8.442321533449049e-05,
      "loss": 1.6601,
      "step": 24
    },
    {
      "epoch": 12.5,
      "grad_norm": 1.7799217700958252,
      "learning_rate": 8.794084930676093e-05,
      "loss": 1.6349,
      "step": 25
    },
    {
      "epoch": 13.0,
      "grad_norm": 1.7585200071334839,
      "learning_rate": 9.145848327903137e-05,
      "loss": 1.6601,
      "step": 26
    },
    {
      "epoch": 13.5,
      "grad_norm": 1.6274733543395996,
      "learning_rate": 9.497611725130181e-05,
      "loss": 1.643,
      "step": 27
    },
    {
      "epoch": 14.0,
      "grad_norm": 1.9614331722259521,
      "learning_rate": 9.849375122357223e-05,
      "loss": 1.661,
      "step": 28
    },
    {
      "epoch": 14.5,
      "grad_norm": 1.6395436525344849,
      "learning_rate": 0.00010201138519584267,
      "loss": 1.671,
      "step": 29
    },
    {
      "epoch": 15.0,
      "grad_norm": 1.9679726362228394,
      "learning_rate": 0.00010552901916811311,
      "loss": 1.6238,
      "step": 30
    },
    {
      "epoch": 15.5,
      "grad_norm": 1.7550004720687866,
      "learning_rate": 0.00010904665314038356,
      "loss": 1.6739,
      "step": 31
    },
    {
      "epoch": 16.0,
      "grad_norm": 2.02482533454895,
      "learning_rate": 0.00011256428711265399,
      "loss": 1.5987,
      "step": 32
    },
    {
      "epoch": 16.5,
      "grad_norm": 1.6655482053756714,
      "learning_rate": 0.00011608192108492441,
      "loss": 1.6202,
      "step": 33
    },
    {
      "epoch": 17.0,
      "grad_norm": 2.307687759399414,
      "learning_rate": 0.00011959955505719486,
      "loss": 1.7075,
      "step": 34
    },
    {
      "epoch": 17.5,
      "grad_norm": 1.9084906578063965,
      "learning_rate": 0.0001231171890294653,
      "loss": 1.6635,
      "step": 35
    },
    {
      "epoch": 18.0,
      "grad_norm": 2.0395658016204834,
      "learning_rate": 0.00012663482300173575,
      "loss": 1.6103,
      "step": 36
    },
    {
      "epoch": 18.5,
      "grad_norm": 2.0124878883361816,
      "learning_rate": 0.00013015245697400619,
      "loss": 1.6345,
      "step": 37
    },
    {
      "epoch": 19.0,
      "grad_norm": 1.9863300323486328,
      "learning_rate": 0.0001336700909462766,
      "loss": 1.655,
      "step": 38
    },
    {
      "epoch": 19.5,
      "grad_norm": 2.104970932006836,
      "learning_rate": 0.00013718772491854705,
      "loss": 1.6236,
      "step": 39
    },
    {
      "epoch": 20.0,
      "grad_norm": 1.9302610158920288,
      "learning_rate": 0.00014070535889081748,
      "loss": 1.6439,
      "step": 40
    },
    {
      "epoch": 20.5,
      "grad_norm": 2.0518879890441895,
      "learning_rate": 0.00014422299286308792,
      "loss": 1.6151,
      "step": 41
    },
    {
      "epoch": 21.0,
      "grad_norm": 2.0088884830474854,
      "learning_rate": 0.00014774062683535838,
      "loss": 1.6668,
      "step": 42
    },
    {
      "epoch": 21.5,
      "grad_norm": 2.2142465114593506,
      "learning_rate": 0.00015125826080762878,
      "loss": 1.633,
      "step": 43
    },
    {
      "epoch": 22.0,
      "grad_norm": 1.8295259475708008,
      "learning_rate": 0.00015477589477989924,
      "loss": 1.6225,
      "step": 44
    },
    {
      "epoch": 22.5,
      "grad_norm": 1.9601545333862305,
      "learning_rate": 0.00015829352875216968,
      "loss": 1.652,
      "step": 45
    },
    {
      "epoch": 23.0,
      "grad_norm": 2.328500986099243,
      "learning_rate": 0.00016181116272444008,
      "loss": 1.5893,
      "step": 46
    },
    {
      "epoch": 23.5,
      "grad_norm": 1.95308256149292,
      "learning_rate": 0.00016532879669671054,
      "loss": 1.6147,
      "step": 47
    },
    {
      "epoch": 24.0,
      "grad_norm": 2.3724775314331055,
      "learning_rate": 0.00016884643066898098,
      "loss": 1.6068,
      "step": 48
    },
    {
      "epoch": 24.5,
      "grad_norm": 2.1332895755767822,
      "learning_rate": 0.00017236406464125144,
      "loss": 1.6239,
      "step": 49
    },
    {
      "epoch": 25.0,
      "grad_norm": 2.2393646240234375,
      "learning_rate": 0.00017588169861352187,
      "loss": 1.6037,
      "step": 50
    },
    {
      "epoch": 25.5,
      "grad_norm": 2.1306140422821045,
      "learning_rate": 0.00017939933258579228,
      "loss": 1.6036,
      "step": 51
    },
    {
      "epoch": 26.0,
      "grad_norm": 2.3120827674865723,
      "learning_rate": 0.00018291696655806274,
      "loss": 1.6088,
      "step": 52
    },
    {
      "epoch": 26.5,
      "grad_norm": 2.258466958999634,
      "learning_rate": 0.00018643460053033317,
      "loss": 1.6187,
      "step": 53
    },
    {
      "epoch": 27.0,
      "grad_norm": 2.379187822341919,
      "learning_rate": 0.00018995223450260363,
      "loss": 1.5676,
      "step": 54
    },
    {
      "epoch": 27.5,
      "grad_norm": 2.190295696258545,
      "learning_rate": 0.00019346986847487403,
      "loss": 1.5945,
      "step": 55
    },
    {
      "epoch": 28.0,
      "grad_norm": 2.3485167026519775,
      "learning_rate": 0.00019698750244714447,
      "loss": 1.5979,
      "step": 56
    },
    {
      "epoch": 28.5,
      "grad_norm": 2.3475916385650635,
      "learning_rate": 0.00020050513641941493,
      "loss": 1.5961,
      "step": 57
    },
    {
      "epoch": 29.0,
      "grad_norm": 2.3505337238311768,
      "learning_rate": 0.00020402277039168533,
      "loss": 1.5794,
      "step": 58
    },
    {
      "epoch": 29.5,
      "grad_norm": 2.5201990604400635,
      "learning_rate": 0.0002075404043639558,
      "loss": 1.5997,
      "step": 59
    },
    {
      "epoch": 30.0,
      "grad_norm": 1.8731262683868408,
      "learning_rate": 0.00021105803833622623,
      "loss": 1.5575,
      "step": 60
    },
    {
      "epoch": 30.5,
      "grad_norm": 2.1734321117401123,
      "learning_rate": 0.00021457567230849666,
      "loss": 1.5674,
      "step": 61
    },
    {
      "epoch": 31.0,
      "grad_norm": 2.3136627674102783,
      "learning_rate": 0.00021809330628076712,
      "loss": 1.5603,
      "step": 62
    },
    {
      "epoch": 31.5,
      "grad_norm": 2.528531074523926,
      "learning_rate": 0.00022161094025303753,
      "loss": 1.5761,
      "step": 63
    },
    {
      "epoch": 32.0,
      "grad_norm": 2.1145663261413574,
      "learning_rate": 0.00022512857422530799,
      "loss": 1.5479,
      "step": 64
    },
    {
      "epoch": 32.5,
      "grad_norm": 2.551715850830078,
      "learning_rate": 0.00022864620819757842,
      "loss": 1.5756,
      "step": 65
    },
    {
      "epoch": 33.0,
      "grad_norm": 2.151527166366577,
      "learning_rate": 0.00023216384216984882,
      "loss": 1.5238,
      "step": 66
    },
    {
      "epoch": 33.5,
      "grad_norm": 2.829216480255127,
      "learning_rate": 0.00023568147614211929,
      "loss": 1.5104,
      "step": 67
    },
    {
      "epoch": 34.0,
      "grad_norm": 2.4145617485046387,
      "learning_rate": 0.00023919911011438972,
      "loss": 1.5915,
      "step": 68
    },
    {
      "epoch": 34.5,
      "grad_norm": 2.3143422603607178,
      "learning_rate": 0.00024271674408666018,
      "loss": 1.5063,
      "step": 69
    },
    {
      "epoch": 35.0,
      "grad_norm": 2.6954421997070312,
      "learning_rate": 0.0002462343780589306,
      "loss": 1.5943,
      "step": 70
    },
    {
      "epoch": 35.5,
      "grad_norm": 2.6223387718200684,
      "learning_rate": 0.000249752012031201,
      "loss": 1.563,
      "step": 71
    },
    {
      "epoch": 36.0,
      "grad_norm": 2.0236427783966064,
      "learning_rate": 0.0002532696460034715,
      "loss": 1.4959,
      "step": 72
    },
    {
      "epoch": 36.5,
      "grad_norm": 2.4147582054138184,
      "learning_rate": 0.0002567872799757419,
      "loss": 1.5486,
      "step": 73
    },
    {
      "epoch": 37.0,
      "grad_norm": 2.657740592956543,
      "learning_rate": 0.00026030491394801237,
      "loss": 1.4997,
      "step": 74
    },
    {
      "epoch": 37.5,
      "grad_norm": 2.669438123703003,
      "learning_rate": 0.0002638225479202828,
      "loss": 1.4863,
      "step": 75
    },
    {
      "epoch": 38.0,
      "grad_norm": 2.5677003860473633,
      "learning_rate": 0.0002673401818925532,
      "loss": 1.5558,
      "step": 76
    },
    {
      "epoch": 38.5,
      "grad_norm": 2.654038429260254,
      "learning_rate": 0.00027085781586482367,
      "loss": 1.5313,
      "step": 77
    },
    {
      "epoch": 39.0,
      "grad_norm": 2.3592026233673096,
      "learning_rate": 0.0002743754498370941,
      "loss": 1.4685,
      "step": 78
    },
    {
      "epoch": 39.5,
      "grad_norm": 2.444279432296753,
      "learning_rate": 0.00027789308380936454,
      "loss": 1.5238,
      "step": 79
    },
    {
      "epoch": 40.0,
      "grad_norm": 2.5960395336151123,
      "learning_rate": 0.00028141071778163497,
      "loss": 1.4745,
      "step": 80
    },
    {
      "epoch": 40.0,
      "eval_brier_0th_event": 0.19483950952273418,
      "eval_brier_0th_event_n": 261,
      "eval_brier_avg": 0.19483950952273418,
      "eval_brier_weighted_avg": 0.19483950952273418,
      "eval_ipcw": 0.6147666928520694,
      "eval_ipcw_0th_event": 0.6147666928520694,
      "eval_ipcw_0th_event_0.25": 0.6193249244680324,
      "eval_ipcw_0th_event_0.5": 0.6376419249605473,
      "eval_ipcw_0th_event_0.75": 0.6334959739525372,
      "eval_ipcw_0th_event_1.0": 0.6147666928520694,
      "eval_ipcw_0th_event_n": 261,
      "eval_ipcw_avg": 0.6263073790582966,
      "eval_ipcw_avg_0th_event": 0.6263073790582966,
      "eval_ipcw_weighted_avg": 0.6263073790582966,
      "eval_loss": 0.7582581639289856,
      "eval_runtime": 0.0795,
      "eval_samples_per_second": 5587.925,
      "eval_steps_per_second": 12.585,
      "step": 80
    },
    {
      "epoch": 40.5,
      "grad_norm": 2.7314984798431396,
      "learning_rate": 0.0002814098974219469,
      "loss": 1.5191,
      "step": 81
    },
    {
      "epoch": 40.5,
      "eval_brier_0th_event": 0.19452191210587866,
      "eval_brier_0th_event_n": 261,
      "eval_brier_avg": 0.19452191210587866,
      "eval_brier_weighted_avg": 0.19452191210587866,
      "eval_ipcw": 0.6157095242966595,
      "eval_ipcw_0th_event": 0.6157095242966595,
      "eval_ipcw_0th_event_0.25": 0.6197037056307927,
      "eval_ipcw_0th_event_0.5": 0.6386485567733988,
      "eval_ipcw_0th_event_0.75": 0.63414631229116,
      "eval_ipcw_0th_event_1.0": 0.6157095242966595,
      "eval_ipcw_0th_event_n": 261,
      "eval_ipcw_avg": 0.6270520247480027,
      "eval_ipcw_avg_0th_event": 0.6270520247480027,
      "eval_ipcw_weighted_avg": 0.6270520247480027,
      "eval_loss": 0.7565968632698059,
      "eval_runtime": 0.0825,
      "eval_samples_per_second": 5383.453,
      "eval_steps_per_second": 12.125,
      "step": 81
    },
    {
      "epoch": 41.0,
      "grad_norm": 2.6970374584198,
      "learning_rate": 0.00028140743635244876,
      "loss": 1.4389,
      "step": 82
    },
    {
      "epoch": 41.0,
      "eval_brier_0th_event": 0.19432477433792875,
      "eval_brier_0th_event_n": 261,
      "eval_brier_avg": 0.19432477433792875,
      "eval_brier_weighted_avg": 0.19432477433792875,
      "eval_ipcw": 0.6167777128496469,
      "eval_ipcw_0th_event": 0.6167777128496469,
      "eval_ipcw_0th_event_0.25": 0.6204436268598067,
      "eval_ipcw_0th_event_0.5": 0.6392730321151476,
      "eval_ipcw_0th_event_0.75": 0.6346499025046203,
      "eval_ipcw_0th_event_1.0": 0.6167777128496469,
      "eval_ipcw_0th_event_n": 261,
      "eval_ipcw_avg": 0.6277860685823053,
      "eval_ipcw_avg_0th_event": 0.6277860685823053,
      "eval_ipcw_weighted_avg": 0.6277860685823053,
      "eval_loss": 0.7550190687179565,
      "eval_runtime": 0.0853,
      "eval_samples_per_second": 5207.402,
      "eval_steps_per_second": 11.728,
      "step": 82
    },
    {
      "epoch": 41.5,
      "grad_norm": 2.6759183406829834,
      "learning_rate": 0.0002814033346018381,
      "loss": 1.5068,
      "step": 83
    },
    {
      "epoch": 41.5,
      "eval_brier_0th_event": 0.19438964994243435,
      "eval_brier_0th_event_n": 261,
      "eval_brier_avg": 0.19438964994243435,
      "eval_brier_weighted_avg": 0.19438964994243435,
      "eval_ipcw": 0.6168510024974795,
      "eval_ipcw_0th_event": 0.6168510024974795,
      "eval_ipcw_0th_event_0.25": 0.6206983609726926,
      "eval_ipcw_0th_event_0.5": 0.6402822599727604,
      "eval_ipcw_0th_event_0.75": 0.6346307725864134,
      "eval_ipcw_0th_event_1.0": 0.6168510024974795,
      "eval_ipcw_0th_event_n": 261,
      "eval_ipcw_avg": 0.6281155990073365,
      "eval_ipcw_avg_0th_event": 0.6281155990073365,
      "eval_ipcw_weighted_avg": 0.6281155990073365,
      "eval_loss": 0.7537679672241211,
      "eval_runtime": 0.0837,
      "eval_samples_per_second": 5303.213,
      "eval_steps_per_second": 11.944,
      "step": 83
    },
    {
      "epoch": 42.0,
      "grad_norm": 2.9705731868743896,
      "learning_rate": 0.00028139759221794424,
      "loss": 1.4458,
      "step": 84
    },
    {
      "epoch": 42.0,
      "eval_brier_0th_event": 0.1942294445926556,
      "eval_brier_0th_event_n": 261,
      "eval_brier_avg": 0.1942294445926556,
      "eval_brier_weighted_avg": 0.1942294445926556,
      "eval_ipcw": 0.6173174711907001,
      "eval_ipcw_0th_event": 0.6173174711907001,
      "eval_ipcw_0th_event_0.25": 0.6203601717382244,
      "eval_ipcw_0th_event_0.5": 0.6400835384148728,
      "eval_ipcw_0th_event_0.75": 0.6350223935617609,
      "eval_ipcw_0th_event_1.0": 0.6173174711907001,
      "eval_ipcw_0th_event_n": 261,
      "eval_ipcw_avg": 0.6281958937263896,
      "eval_ipcw_avg_0th_event": 0.6281958937263896,
      "eval_ipcw_weighted_avg": 0.6281958937263896,
      "eval_loss": 0.7523273229598999,
      "eval_runtime": 0.0708,
      "eval_samples_per_second": 6273.568,
      "eval_steps_per_second": 14.13,
      "step": 84
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 22118019840.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
