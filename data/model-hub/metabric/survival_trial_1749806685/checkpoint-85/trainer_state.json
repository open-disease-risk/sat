{
  "best_global_step": 85,
  "best_metric": 0.6270455794622286,
  "best_model_checkpoint": "./data/model-hub/metabric/survival_trial_1749806685/checkpoint-85",
  "epoch": 42.5,
  "eval_steps": 1,
  "global_step": 85,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 2.2167184352874756,
      "learning_rate": 4.753567986864208e-05,
      "loss": 1.6025,
      "step": 1
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.7191241979599,
      "learning_rate": 9.507135973728416e-05,
      "loss": 1.5808,
      "step": 2
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.7277777194976807,
      "learning_rate": 0.00014260703960592623,
      "loss": 1.5882,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 2.317356586456299,
      "learning_rate": 0.00019014271947456833,
      "loss": 1.5973,
      "step": 4
    },
    {
      "epoch": 2.5,
      "grad_norm": 1.9312963485717773,
      "learning_rate": 0.0002376783993432104,
      "loss": 1.572,
      "step": 5
    },
    {
      "epoch": 3.0,
      "grad_norm": 2.009753465652466,
      "learning_rate": 0.00028521407921185246,
      "loss": 1.6038,
      "step": 6
    },
    {
      "epoch": 3.5,
      "grad_norm": 2.0589656829833984,
      "learning_rate": 0.00033274975908049456,
      "loss": 1.5745,
      "step": 7
    },
    {
      "epoch": 4.0,
      "grad_norm": 2.1399073600769043,
      "learning_rate": 0.00038028543894913665,
      "loss": 1.5839,
      "step": 8
    },
    {
      "epoch": 4.5,
      "grad_norm": 2.1105871200561523,
      "learning_rate": 0.0004278211188177787,
      "loss": 1.5864,
      "step": 9
    },
    {
      "epoch": 5.0,
      "grad_norm": 2.24471116065979,
      "learning_rate": 0.0004753567986864208,
      "loss": 1.5485,
      "step": 10
    },
    {
      "epoch": 5.5,
      "grad_norm": 2.2327280044555664,
      "learning_rate": 0.0005228924785550629,
      "loss": 1.555,
      "step": 11
    },
    {
      "epoch": 6.0,
      "grad_norm": 2.1187353134155273,
      "learning_rate": 0.0005704281584237049,
      "loss": 1.5594,
      "step": 12
    },
    {
      "epoch": 6.5,
      "grad_norm": 2.1243293285369873,
      "learning_rate": 0.000617963838292347,
      "loss": 1.5243,
      "step": 13
    },
    {
      "epoch": 7.0,
      "grad_norm": 2.475722551345825,
      "learning_rate": 0.0006654995181609891,
      "loss": 1.5853,
      "step": 14
    },
    {
      "epoch": 7.5,
      "grad_norm": 2.443096160888672,
      "learning_rate": 0.0007130351980296312,
      "loss": 1.5164,
      "step": 15
    },
    {
      "epoch": 8.0,
      "grad_norm": 2.2868826389312744,
      "learning_rate": 0.0007605708778982733,
      "loss": 1.5664,
      "step": 16
    },
    {
      "epoch": 8.5,
      "grad_norm": 2.240079402923584,
      "learning_rate": 0.0008081065577669153,
      "loss": 1.5537,
      "step": 17
    },
    {
      "epoch": 9.0,
      "grad_norm": 2.708416223526001,
      "learning_rate": 0.0008556422376355574,
      "loss": 1.4843,
      "step": 18
    },
    {
      "epoch": 9.5,
      "grad_norm": 2.1989197731018066,
      "learning_rate": 0.0009031779175041995,
      "loss": 1.499,
      "step": 19
    },
    {
      "epoch": 10.0,
      "grad_norm": 2.3436617851257324,
      "learning_rate": 0.0009507135973728416,
      "loss": 1.5166,
      "step": 20
    },
    {
      "epoch": 10.5,
      "grad_norm": 1.9130783081054688,
      "learning_rate": 0.0009982492772414838,
      "loss": 1.4674,
      "step": 21
    },
    {
      "epoch": 11.0,
      "grad_norm": 2.5996227264404297,
      "learning_rate": 0.0010457849571101259,
      "loss": 1.503,
      "step": 22
    },
    {
      "epoch": 11.5,
      "grad_norm": 1.8568083047866821,
      "learning_rate": 0.0010933206369787677,
      "loss": 1.4646,
      "step": 23
    },
    {
      "epoch": 12.0,
      "grad_norm": 2.364011287689209,
      "learning_rate": 0.0011408563168474098,
      "loss": 1.4399,
      "step": 24
    },
    {
      "epoch": 12.5,
      "grad_norm": 2.0454530715942383,
      "learning_rate": 0.001188391996716052,
      "loss": 1.4757,
      "step": 25
    },
    {
      "epoch": 13.0,
      "grad_norm": 2.1092915534973145,
      "learning_rate": 0.001235927676584694,
      "loss": 1.3869,
      "step": 26
    },
    {
      "epoch": 13.5,
      "grad_norm": 1.9675692319869995,
      "learning_rate": 0.0012834633564533361,
      "loss": 1.4204,
      "step": 27
    },
    {
      "epoch": 14.0,
      "grad_norm": 1.917317509651184,
      "learning_rate": 0.0013309990363219782,
      "loss": 1.4034,
      "step": 28
    },
    {
      "epoch": 14.5,
      "grad_norm": 1.9291871786117554,
      "learning_rate": 0.0013785347161906203,
      "loss": 1.4332,
      "step": 29
    },
    {
      "epoch": 15.0,
      "grad_norm": 1.6670348644256592,
      "learning_rate": 0.0014260703960592624,
      "loss": 1.3523,
      "step": 30
    },
    {
      "epoch": 15.5,
      "grad_norm": 1.7041783332824707,
      "learning_rate": 0.0014736060759279045,
      "loss": 1.3354,
      "step": 31
    },
    {
      "epoch": 16.0,
      "grad_norm": 1.8529894351959229,
      "learning_rate": 0.0015211417557965466,
      "loss": 1.4171,
      "step": 32
    },
    {
      "epoch": 16.5,
      "grad_norm": 1.4683685302734375,
      "learning_rate": 0.0015686774356651885,
      "loss": 1.3324,
      "step": 33
    },
    {
      "epoch": 17.0,
      "grad_norm": 1.2785649299621582,
      "learning_rate": 0.0016162131155338306,
      "loss": 1.3588,
      "step": 34
    },
    {
      "epoch": 17.5,
      "grad_norm": 1.251975178718567,
      "learning_rate": 0.0016637487954024727,
      "loss": 1.3439,
      "step": 35
    },
    {
      "epoch": 18.0,
      "grad_norm": 1.0065464973449707,
      "learning_rate": 0.0017112844752711148,
      "loss": 1.293,
      "step": 36
    },
    {
      "epoch": 18.5,
      "grad_norm": 1.1836985349655151,
      "learning_rate": 0.001758820155139757,
      "loss": 1.2947,
      "step": 37
    },
    {
      "epoch": 19.0,
      "grad_norm": 1.2536550760269165,
      "learning_rate": 0.001806355835008399,
      "loss": 1.3161,
      "step": 38
    },
    {
      "epoch": 19.5,
      "grad_norm": 1.1628366708755493,
      "learning_rate": 0.001853891514877041,
      "loss": 1.3256,
      "step": 39
    },
    {
      "epoch": 20.0,
      "grad_norm": 2.1146390438079834,
      "learning_rate": 0.0019014271947456831,
      "loss": 1.2503,
      "step": 40
    },
    {
      "epoch": 20.5,
      "grad_norm": 0.9889278411865234,
      "learning_rate": 0.001948962874614325,
      "loss": 1.3029,
      "step": 41
    },
    {
      "epoch": 21.0,
      "grad_norm": 1.1173628568649292,
      "learning_rate": 0.0019964985544829675,
      "loss": 1.2298,
      "step": 42
    },
    {
      "epoch": 21.5,
      "grad_norm": 1.113183856010437,
      "learning_rate": 0.0020440342343516094,
      "loss": 1.2547,
      "step": 43
    },
    {
      "epoch": 22.0,
      "grad_norm": 1.7542585134506226,
      "learning_rate": 0.0020915699142202517,
      "loss": 1.2744,
      "step": 44
    },
    {
      "epoch": 22.5,
      "grad_norm": 1.109034538269043,
      "learning_rate": 0.0021391055940888936,
      "loss": 1.2282,
      "step": 45
    },
    {
      "epoch": 23.0,
      "grad_norm": 1.8227863311767578,
      "learning_rate": 0.0021866412739575355,
      "loss": 1.2747,
      "step": 46
    },
    {
      "epoch": 23.5,
      "grad_norm": 1.1187065839767456,
      "learning_rate": 0.002234176953826178,
      "loss": 1.2471,
      "step": 47
    },
    {
      "epoch": 24.0,
      "grad_norm": 1.5009983777999878,
      "learning_rate": 0.0022817126336948197,
      "loss": 1.2279,
      "step": 48
    },
    {
      "epoch": 24.5,
      "grad_norm": 1.3640310764312744,
      "learning_rate": 0.002329248313563462,
      "loss": 1.1918,
      "step": 49
    },
    {
      "epoch": 25.0,
      "grad_norm": 2.8341751098632812,
      "learning_rate": 0.002376783993432104,
      "loss": 1.2569,
      "step": 50
    },
    {
      "epoch": 25.5,
      "grad_norm": 1.563996434211731,
      "learning_rate": 0.0024243196733007458,
      "loss": 1.1936,
      "step": 51
    },
    {
      "epoch": 26.0,
      "grad_norm": 1.7025223970413208,
      "learning_rate": 0.002471855353169388,
      "loss": 1.2272,
      "step": 52
    },
    {
      "epoch": 26.5,
      "grad_norm": 2.2699596881866455,
      "learning_rate": 0.00251939103303803,
      "loss": 1.186,
      "step": 53
    },
    {
      "epoch": 27.0,
      "grad_norm": 1.5491695404052734,
      "learning_rate": 0.0025669267129066723,
      "loss": 1.1959,
      "step": 54
    },
    {
      "epoch": 27.5,
      "grad_norm": 1.4909100532531738,
      "learning_rate": 0.002614462392775314,
      "loss": 1.1796,
      "step": 55
    },
    {
      "epoch": 28.0,
      "grad_norm": 1.7263017892837524,
      "learning_rate": 0.0026619980726439564,
      "loss": 1.1633,
      "step": 56
    },
    {
      "epoch": 28.5,
      "grad_norm": 1.178053379058838,
      "learning_rate": 0.0027095337525125988,
      "loss": 1.1713,
      "step": 57
    },
    {
      "epoch": 29.0,
      "grad_norm": 1.624246597290039,
      "learning_rate": 0.0027570694323812406,
      "loss": 1.1646,
      "step": 58
    },
    {
      "epoch": 29.5,
      "grad_norm": 2.2238845825195312,
      "learning_rate": 0.002804605112249883,
      "loss": 1.124,
      "step": 59
    },
    {
      "epoch": 30.0,
      "grad_norm": 2.0535409450531006,
      "learning_rate": 0.002852140792118525,
      "loss": 1.2052,
      "step": 60
    },
    {
      "epoch": 30.5,
      "grad_norm": 1.4071139097213745,
      "learning_rate": 0.0028996764719871667,
      "loss": 1.128,
      "step": 61
    },
    {
      "epoch": 31.0,
      "grad_norm": 1.704007863998413,
      "learning_rate": 0.002947212151855809,
      "loss": 1.1599,
      "step": 62
    },
    {
      "epoch": 31.5,
      "grad_norm": 1.5570143461227417,
      "learning_rate": 0.002994747831724451,
      "loss": 1.1022,
      "step": 63
    },
    {
      "epoch": 32.0,
      "grad_norm": 2.0167410373687744,
      "learning_rate": 0.003042283511593093,
      "loss": 1.165,
      "step": 64
    },
    {
      "epoch": 32.5,
      "grad_norm": 2.5764358043670654,
      "learning_rate": 0.003089819191461735,
      "loss": 1.0999,
      "step": 65
    },
    {
      "epoch": 33.0,
      "grad_norm": 2.99023699760437,
      "learning_rate": 0.003137354871330377,
      "loss": 1.1208,
      "step": 66
    },
    {
      "epoch": 33.5,
      "grad_norm": 1.6487497091293335,
      "learning_rate": 0.0031848905511990193,
      "loss": 1.1166,
      "step": 67
    },
    {
      "epoch": 34.0,
      "grad_norm": 1.7713943719863892,
      "learning_rate": 0.003232426231067661,
      "loss": 1.0716,
      "step": 68
    },
    {
      "epoch": 34.5,
      "grad_norm": 1.9619777202606201,
      "learning_rate": 0.0032799619109363035,
      "loss": 1.1084,
      "step": 69
    },
    {
      "epoch": 35.0,
      "grad_norm": 1.8694502115249634,
      "learning_rate": 0.0033274975908049453,
      "loss": 1.048,
      "step": 70
    },
    {
      "epoch": 35.5,
      "grad_norm": 1.947702407836914,
      "learning_rate": 0.003375033270673587,
      "loss": 1.0959,
      "step": 71
    },
    {
      "epoch": 36.0,
      "grad_norm": 4.581640720367432,
      "learning_rate": 0.0034225689505422295,
      "loss": 1.0299,
      "step": 72
    },
    {
      "epoch": 36.5,
      "grad_norm": 1.8230599164962769,
      "learning_rate": 0.003470104630410872,
      "loss": 1.0445,
      "step": 73
    },
    {
      "epoch": 37.0,
      "grad_norm": 3.406904458999634,
      "learning_rate": 0.003517640310279514,
      "loss": 1.0824,
      "step": 74
    },
    {
      "epoch": 37.5,
      "grad_norm": 2.5212910175323486,
      "learning_rate": 0.003565175990148156,
      "loss": 1.038,
      "step": 75
    },
    {
      "epoch": 38.0,
      "grad_norm": 2.649320602416992,
      "learning_rate": 0.003612711670016798,
      "loss": 1.0822,
      "step": 76
    },
    {
      "epoch": 38.5,
      "grad_norm": 4.1404523849487305,
      "learning_rate": 0.0036602473498854402,
      "loss": 0.9971,
      "step": 77
    },
    {
      "epoch": 39.0,
      "grad_norm": 2.510571241378784,
      "learning_rate": 0.003707783029754082,
      "loss": 1.0953,
      "step": 78
    },
    {
      "epoch": 39.5,
      "grad_norm": 1.9024198055267334,
      "learning_rate": 0.0037553187096227244,
      "loss": 1.0054,
      "step": 79
    },
    {
      "epoch": 40.0,
      "grad_norm": 2.196080446243286,
      "learning_rate": 0.0038028543894913663,
      "loss": 1.034,
      "step": 80
    },
    {
      "epoch": 40.0,
      "eval_brier_0th_event": 0.19816772639751434,
      "eval_brier_0th_event_n": 253,
      "eval_brier_weighted_avg": 0.19816772639751434,
      "eval_ipcw_0th_event": 0.6170054689833993,
      "eval_ipcw_0th_event_0.25": 0.6054618954658508,
      "eval_ipcw_0th_event_0.50": 0.6164770722389221,
      "eval_ipcw_0th_event_0.75": 0.6262591481208801,
      "eval_ipcw_0th_event_1.00": 0.6131553649902344,
      "eval_ipcw_0th_event_n": 411,
      "eval_ipcw_weighted_avg": 0.6170054689833993,
      "eval_loss": 0.6936497092247009,
      "eval_runtime": 0.1544,
      "eval_samples_per_second": 2661.295,
      "eval_steps_per_second": 6.475,
      "step": 80
    },
    {
      "epoch": 40.5,
      "grad_norm": 2.0115840435028076,
      "learning_rate": 0.0038028433035296617,
      "loss": 1.0137,
      "step": 81
    },
    {
      "epoch": 40.5,
      "eval_brier_0th_event": 0.19963054358959198,
      "eval_brier_0th_event_n": 253,
      "eval_brier_weighted_avg": 0.19963054358959198,
      "eval_ipcw_0th_event": 0.6163007904870592,
      "eval_ipcw_0th_event_0.25": 0.603056013584137,
      "eval_ipcw_0th_event_0.50": 0.6129891872406006,
      "eval_ipcw_0th_event_0.75": 0.6262527108192444,
      "eval_ipcw_0th_event_1.00": 0.6138264536857605,
      "eval_ipcw_0th_event_n": 411,
      "eval_ipcw_weighted_avg": 0.6163007904870592,
      "eval_loss": 0.6978798508644104,
      "eval_runtime": 0.1342,
      "eval_samples_per_second": 3062.498,
      "eval_steps_per_second": 7.451,
      "step": 81
    },
    {
      "epoch": 41.0,
      "grad_norm": 2.5470659732818604,
      "learning_rate": 0.003802810045773817,
      "loss": 1.0144,
      "step": 82
    },
    {
      "epoch": 41.0,
      "eval_brier_0th_event": 0.2000623345375061,
      "eval_brier_0th_event_n": 253,
      "eval_brier_weighted_avg": 0.2000623345375061,
      "eval_ipcw_0th_event": 0.617999474976454,
      "eval_ipcw_0th_event_0.25": 0.6031060218811035,
      "eval_ipcw_0th_event_0.50": 0.6144157648086548,
      "eval_ipcw_0th_event_0.75": 0.6267685890197754,
      "eval_ipcw_0th_event_1.00": 0.6169998049736023,
      "eval_ipcw_0th_event_n": 411,
      "eval_ipcw_weighted_avg": 0.617999474976454,
      "eval_loss": 0.6991382837295532,
      "eval_runtime": 0.1277,
      "eval_samples_per_second": 3218.959,
      "eval_steps_per_second": 7.832,
      "step": 82
    },
    {
      "epoch": 41.5,
      "grad_norm": 2.026529550552368,
      "learning_rate": 0.0038027546166116404,
      "loss": 1.0002,
      "step": 83
    },
    {
      "epoch": 41.5,
      "eval_brier_0th_event": 0.2003125548362732,
      "eval_brier_0th_event_n": 253,
      "eval_brier_weighted_avg": 0.2003125548362732,
      "eval_ipcw_0th_event": 0.6191784757025102,
      "eval_ipcw_0th_event_0.25": 0.6040353178977966,
      "eval_ipcw_0th_event_0.50": 0.614327073097229,
      "eval_ipcw_0th_event_0.75": 0.6296333074569702,
      "eval_ipcw_0th_event_1.00": 0.6176217794418335,
      "eval_ipcw_0th_event_n": 411,
      "eval_ipcw_weighted_avg": 0.6191784757025102,
      "eval_loss": 0.7000933885574341,
      "eval_runtime": 0.1356,
      "eval_samples_per_second": 3031.67,
      "eval_steps_per_second": 7.376,
      "step": 83
    },
    {
      "epoch": 42.0,
      "grad_norm": 2.1622211933135986,
      "learning_rate": 0.003802677016689473,
      "loss": 0.9937,
      "step": 84
    },
    {
      "epoch": 42.0,
      "eval_brier_0th_event": 0.19927746057510376,
      "eval_brier_0th_event_n": 253,
      "eval_brier_weighted_avg": 0.19927746057510376,
      "eval_ipcw_0th_event": 0.6260748097771093,
      "eval_ipcw_0th_event_0.25": 0.6064784526824951,
      "eval_ipcw_0th_event_0.50": 0.6169731616973877,
      "eval_ipcw_0th_event_0.75": 0.638440728187561,
      "eval_ipcw_0th_event_1.00": 0.6264479160308838,
      "eval_ipcw_0th_event_n": 411,
      "eval_ipcw_weighted_avg": 0.6260748097771093,
      "eval_loss": 0.6983604431152344,
      "eval_runtime": 0.1319,
      "eval_samples_per_second": 3116.852,
      "eval_steps_per_second": 7.584,
      "step": 84
    },
    {
      "epoch": 42.5,
      "grad_norm": 1.8905773162841797,
      "learning_rate": 0.0038025772469121827,
      "loss": 0.9685,
      "step": 85
    },
    {
      "epoch": 42.5,
      "eval_brier_0th_event": 0.1978217214345932,
      "eval_brier_0th_event_n": 253,
      "eval_brier_weighted_avg": 0.1978217214345932,
      "eval_ipcw_0th_event": 0.6270455794622286,
      "eval_ipcw_0th_event_0.25": 0.6038407683372498,
      "eval_ipcw_0th_event_0.50": 0.6156421303749084,
      "eval_ipcw_0th_event_0.75": 0.6396885514259338,
      "eval_ipcw_0th_event_1.00": 0.6293524503707886,
      "eval_ipcw_0th_event_n": 411,
      "eval_ipcw_weighted_avg": 0.6270455794622286,
      "eval_loss": 0.6962103843688965,
      "eval_runtime": 0.1345,
      "eval_samples_per_second": 3055.258,
      "eval_steps_per_second": 7.434,
      "step": 85
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 18639668160.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
