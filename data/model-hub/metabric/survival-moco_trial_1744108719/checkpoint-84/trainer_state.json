{
  "best_global_step": 84,
  "best_metric": 0.6416487066324328,
  "best_model_checkpoint": "./data/model-hub/metabric/survival-moco_trial_1744108719/checkpoint-84",
  "epoch": 42.0,
  "eval_steps": 1,
  "global_step": 84,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 2.333792209625244,
      "learning_rate": 1.878501969702987e-05,
      "loss": 1.6376,
      "step": 1
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.1089906692504883,
      "learning_rate": 3.757003939405974e-05,
      "loss": 1.6789,
      "step": 2
    },
    {
      "epoch": 1.5,
      "grad_norm": 2.4734432697296143,
      "learning_rate": 5.63550590910896e-05,
      "loss": 1.6725,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.9672811031341553,
      "learning_rate": 7.514007878811948e-05,
      "loss": 1.6305,
      "step": 4
    },
    {
      "epoch": 2.5,
      "grad_norm": 2.204223155975342,
      "learning_rate": 9.392509848514934e-05,
      "loss": 1.6704,
      "step": 5
    },
    {
      "epoch": 3.0,
      "grad_norm": 1.8382872343063354,
      "learning_rate": 0.0001127101181821792,
      "loss": 1.6179,
      "step": 6
    },
    {
      "epoch": 3.5,
      "grad_norm": 1.9102290868759155,
      "learning_rate": 0.00013149513787920905,
      "loss": 1.6477,
      "step": 7
    },
    {
      "epoch": 4.0,
      "grad_norm": 1.8499178886413574,
      "learning_rate": 0.00015028015757623895,
      "loss": 1.6476,
      "step": 8
    },
    {
      "epoch": 4.5,
      "grad_norm": 1.7615995407104492,
      "learning_rate": 0.0001690651772732688,
      "loss": 1.6321,
      "step": 9
    },
    {
      "epoch": 5.0,
      "grad_norm": 1.851938247680664,
      "learning_rate": 0.00018785019697029867,
      "loss": 1.6338,
      "step": 10
    },
    {
      "epoch": 5.5,
      "grad_norm": 1.692079782485962,
      "learning_rate": 0.00020663521666732854,
      "loss": 1.6314,
      "step": 11
    },
    {
      "epoch": 6.0,
      "grad_norm": 1.4259071350097656,
      "learning_rate": 0.0002254202363643584,
      "loss": 1.6429,
      "step": 12
    },
    {
      "epoch": 6.5,
      "grad_norm": 1.6164494752883911,
      "learning_rate": 0.0002442052560613883,
      "loss": 1.6269,
      "step": 13
    },
    {
      "epoch": 7.0,
      "grad_norm": 1.2142059803009033,
      "learning_rate": 0.0002629902757584181,
      "loss": 1.6446,
      "step": 14
    },
    {
      "epoch": 7.5,
      "grad_norm": 1.2505110502243042,
      "learning_rate": 0.00028177529545544804,
      "loss": 1.6238,
      "step": 15
    },
    {
      "epoch": 8.0,
      "grad_norm": 1.352473258972168,
      "learning_rate": 0.0003005603151524779,
      "loss": 1.615,
      "step": 16
    },
    {
      "epoch": 8.5,
      "grad_norm": 1.2929105758666992,
      "learning_rate": 0.0003193453348495077,
      "loss": 1.613,
      "step": 17
    },
    {
      "epoch": 9.0,
      "grad_norm": 1.0956140756607056,
      "learning_rate": 0.0003381303545465376,
      "loss": 1.6265,
      "step": 18
    },
    {
      "epoch": 9.5,
      "grad_norm": 1.3392844200134277,
      "learning_rate": 0.00035691537424356747,
      "loss": 1.6099,
      "step": 19
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.99010169506073,
      "learning_rate": 0.00037570039394059734,
      "loss": 1.6073,
      "step": 20
    },
    {
      "epoch": 10.5,
      "grad_norm": 1.370711326599121,
      "learning_rate": 0.0003944854136376272,
      "loss": 1.6277,
      "step": 21
    },
    {
      "epoch": 11.0,
      "grad_norm": 1.1369712352752686,
      "learning_rate": 0.0004132704333346571,
      "loss": 1.5782,
      "step": 22
    },
    {
      "epoch": 11.5,
      "grad_norm": 1.3988304138183594,
      "learning_rate": 0.0004320554530316869,
      "loss": 1.6021,
      "step": 23
    },
    {
      "epoch": 12.0,
      "grad_norm": 1.4197454452514648,
      "learning_rate": 0.0004508404727287168,
      "loss": 1.5864,
      "step": 24
    },
    {
      "epoch": 12.5,
      "grad_norm": 1.517090916633606,
      "learning_rate": 0.00046962549242574665,
      "loss": 1.5945,
      "step": 25
    },
    {
      "epoch": 13.0,
      "grad_norm": 1.3067272901535034,
      "learning_rate": 0.0004884105121227766,
      "loss": 1.5807,
      "step": 26
    },
    {
      "epoch": 13.5,
      "grad_norm": 1.6099447011947632,
      "learning_rate": 0.0005071955318198064,
      "loss": 1.5793,
      "step": 27
    },
    {
      "epoch": 14.0,
      "grad_norm": 1.5082900524139404,
      "learning_rate": 0.0005259805515168362,
      "loss": 1.5791,
      "step": 28
    },
    {
      "epoch": 14.5,
      "grad_norm": 1.6838223934173584,
      "learning_rate": 0.0005447655712138661,
      "loss": 1.5387,
      "step": 29
    },
    {
      "epoch": 15.0,
      "grad_norm": 1.4775978326797485,
      "learning_rate": 0.0005635505909108961,
      "loss": 1.6076,
      "step": 30
    },
    {
      "epoch": 15.5,
      "grad_norm": 1.7142717838287354,
      "learning_rate": 0.0005823356106079259,
      "loss": 1.5676,
      "step": 31
    },
    {
      "epoch": 16.0,
      "grad_norm": 1.6815131902694702,
      "learning_rate": 0.0006011206303049558,
      "loss": 1.5417,
      "step": 32
    },
    {
      "epoch": 16.5,
      "grad_norm": 1.3770067691802979,
      "learning_rate": 0.0006199056500019856,
      "loss": 1.553,
      "step": 33
    },
    {
      "epoch": 17.0,
      "grad_norm": 2.041917085647583,
      "learning_rate": 0.0006386906696990155,
      "loss": 1.524,
      "step": 34
    },
    {
      "epoch": 17.5,
      "grad_norm": 1.6341168880462646,
      "learning_rate": 0.0006574756893960454,
      "loss": 1.52,
      "step": 35
    },
    {
      "epoch": 18.0,
      "grad_norm": 1.5064845085144043,
      "learning_rate": 0.0006762607090930752,
      "loss": 1.5379,
      "step": 36
    },
    {
      "epoch": 18.5,
      "grad_norm": 1.350321650505066,
      "learning_rate": 0.0006950457287901051,
      "loss": 1.5372,
      "step": 37
    },
    {
      "epoch": 19.0,
      "grad_norm": 2.0057156085968018,
      "learning_rate": 0.0007138307484871349,
      "loss": 1.4694,
      "step": 38
    },
    {
      "epoch": 19.5,
      "grad_norm": 1.3678319454193115,
      "learning_rate": 0.0007326157681841648,
      "loss": 1.4997,
      "step": 39
    },
    {
      "epoch": 20.0,
      "grad_norm": 1.412630558013916,
      "learning_rate": 0.0007514007878811947,
      "loss": 1.4956,
      "step": 40
    },
    {
      "epoch": 20.5,
      "grad_norm": 1.4034062623977661,
      "learning_rate": 0.0007701858075782245,
      "loss": 1.4994,
      "step": 41
    },
    {
      "epoch": 21.0,
      "grad_norm": 1.1752959489822388,
      "learning_rate": 0.0007889708272752544,
      "loss": 1.4601,
      "step": 42
    },
    {
      "epoch": 21.5,
      "grad_norm": 1.3965206146240234,
      "learning_rate": 0.0008077558469722843,
      "loss": 1.4578,
      "step": 43
    },
    {
      "epoch": 22.0,
      "grad_norm": 1.8235443830490112,
      "learning_rate": 0.0008265408666693142,
      "loss": 1.4799,
      "step": 44
    },
    {
      "epoch": 22.5,
      "grad_norm": 1.0857470035552979,
      "learning_rate": 0.000845325886366344,
      "loss": 1.4479,
      "step": 45
    },
    {
      "epoch": 23.0,
      "grad_norm": 1.6405032873153687,
      "learning_rate": 0.0008641109060633738,
      "loss": 1.4764,
      "step": 46
    },
    {
      "epoch": 23.5,
      "grad_norm": 0.9618734121322632,
      "learning_rate": 0.0008828959257604037,
      "loss": 1.4595,
      "step": 47
    },
    {
      "epoch": 24.0,
      "grad_norm": 1.3008126020431519,
      "learning_rate": 0.0009016809454574336,
      "loss": 1.4399,
      "step": 48
    },
    {
      "epoch": 24.5,
      "grad_norm": 1.064202070236206,
      "learning_rate": 0.0009204659651544636,
      "loss": 1.4267,
      "step": 49
    },
    {
      "epoch": 25.0,
      "grad_norm": 1.1272205114364624,
      "learning_rate": 0.0009392509848514933,
      "loss": 1.446,
      "step": 50
    },
    {
      "epoch": 25.5,
      "grad_norm": 1.5469756126403809,
      "learning_rate": 0.0009580360045485231,
      "loss": 1.4626,
      "step": 51
    },
    {
      "epoch": 26.0,
      "grad_norm": 1.5946673154830933,
      "learning_rate": 0.0009768210242455532,
      "loss": 1.3749,
      "step": 52
    },
    {
      "epoch": 26.5,
      "grad_norm": 1.2762870788574219,
      "learning_rate": 0.0009956060439425829,
      "loss": 1.416,
      "step": 53
    },
    {
      "epoch": 27.0,
      "grad_norm": 1.2600854635238647,
      "learning_rate": 0.0010143910636396128,
      "loss": 1.4192,
      "step": 54
    },
    {
      "epoch": 27.5,
      "grad_norm": 1.1960216760635376,
      "learning_rate": 0.0010331760833366427,
      "loss": 1.3846,
      "step": 55
    },
    {
      "epoch": 28.0,
      "grad_norm": 1.5888539552688599,
      "learning_rate": 0.0010519611030336724,
      "loss": 1.4278,
      "step": 56
    },
    {
      "epoch": 28.5,
      "grad_norm": 1.041296362876892,
      "learning_rate": 0.0010707461227307024,
      "loss": 1.4038,
      "step": 57
    },
    {
      "epoch": 29.0,
      "grad_norm": 1.389214277267456,
      "learning_rate": 0.0010895311424277323,
      "loss": 1.406,
      "step": 58
    },
    {
      "epoch": 29.5,
      "grad_norm": 1.089502215385437,
      "learning_rate": 0.0011083161621247622,
      "loss": 1.3939,
      "step": 59
    },
    {
      "epoch": 30.0,
      "grad_norm": 2.6311168670654297,
      "learning_rate": 0.0011271011818217921,
      "loss": 1.3747,
      "step": 60
    },
    {
      "epoch": 30.5,
      "grad_norm": 1.2870126962661743,
      "learning_rate": 0.0011458862015188219,
      "loss": 1.3721,
      "step": 61
    },
    {
      "epoch": 31.0,
      "grad_norm": 1.8367700576782227,
      "learning_rate": 0.0011646712212158518,
      "loss": 1.382,
      "step": 62
    },
    {
      "epoch": 31.5,
      "grad_norm": 1.7147027254104614,
      "learning_rate": 0.0011834562409128817,
      "loss": 1.4139,
      "step": 63
    },
    {
      "epoch": 32.0,
      "grad_norm": 1.3758257627487183,
      "learning_rate": 0.0012022412606099116,
      "loss": 1.3182,
      "step": 64
    },
    {
      "epoch": 32.5,
      "grad_norm": 1.3520548343658447,
      "learning_rate": 0.0012210262803069413,
      "loss": 1.3317,
      "step": 65
    },
    {
      "epoch": 33.0,
      "grad_norm": 2.4998626708984375,
      "learning_rate": 0.0012398113000039713,
      "loss": 1.4108,
      "step": 66
    },
    {
      "epoch": 33.5,
      "grad_norm": 1.4929871559143066,
      "learning_rate": 0.0012585963197010012,
      "loss": 1.3538,
      "step": 67
    },
    {
      "epoch": 34.0,
      "grad_norm": 1.7018046379089355,
      "learning_rate": 0.001277381339398031,
      "loss": 1.3523,
      "step": 68
    },
    {
      "epoch": 34.5,
      "grad_norm": 1.7277501821517944,
      "learning_rate": 0.0012961663590950608,
      "loss": 1.3623,
      "step": 69
    },
    {
      "epoch": 35.0,
      "grad_norm": 2.2623465061187744,
      "learning_rate": 0.0013149513787920908,
      "loss": 1.3423,
      "step": 70
    },
    {
      "epoch": 35.5,
      "grad_norm": 2.2584474086761475,
      "learning_rate": 0.0013337363984891205,
      "loss": 1.3496,
      "step": 71
    },
    {
      "epoch": 36.0,
      "grad_norm": 2.8385536670684814,
      "learning_rate": 0.0013525214181861504,
      "loss": 1.328,
      "step": 72
    },
    {
      "epoch": 36.5,
      "grad_norm": 3.0397632122039795,
      "learning_rate": 0.0013713064378831803,
      "loss": 1.3394,
      "step": 73
    },
    {
      "epoch": 37.0,
      "grad_norm": 1.8114296197891235,
      "learning_rate": 0.0013900914575802103,
      "loss": 1.3212,
      "step": 74
    },
    {
      "epoch": 37.5,
      "grad_norm": 3.0647735595703125,
      "learning_rate": 0.00140887647727724,
      "loss": 1.3231,
      "step": 75
    },
    {
      "epoch": 38.0,
      "grad_norm": 3.146156072616577,
      "learning_rate": 0.0014276614969742699,
      "loss": 1.3303,
      "step": 76
    },
    {
      "epoch": 38.5,
      "grad_norm": 2.4953317642211914,
      "learning_rate": 0.0014464465166712998,
      "loss": 1.3059,
      "step": 77
    },
    {
      "epoch": 39.0,
      "grad_norm": 1.6209903955459595,
      "learning_rate": 0.0014652315363683295,
      "loss": 1.3341,
      "step": 78
    },
    {
      "epoch": 39.5,
      "grad_norm": 2.3229012489318848,
      "learning_rate": 0.0014840165560653597,
      "loss": 1.2841,
      "step": 79
    },
    {
      "epoch": 40.0,
      "grad_norm": 3.5636684894561768,
      "learning_rate": 0.0015028015757623894,
      "loss": 1.3745,
      "step": 80
    },
    {
      "epoch": 40.0,
      "eval_brier_0th_event": 0.20759107167198426,
      "eval_brier_0th_event_n": 262,
      "eval_brier_avg": 0.20759107167198426,
      "eval_brier_weighted_avg": 0.20759107167198426,
      "eval_ipcw": 0.6007323394382498,
      "eval_ipcw_0th_event": 0.6007323394382498,
      "eval_ipcw_0th_event_0.25": 0.7071703517647959,
      "eval_ipcw_0th_event_0.5": 0.640450860947277,
      "eval_ipcw_0th_event_0.75": 0.615944618867445,
      "eval_ipcw_0th_event_1.0": 0.6007323394382498,
      "eval_ipcw_0th_event_n": 262,
      "eval_ipcw_avg": 0.641074542754442,
      "eval_ipcw_avg_0th_event": 0.641074542754442,
      "eval_ipcw_weighted_avg": 0.641074542754442,
      "eval_loss": 0.7098289728164673,
      "eval_runtime": 0.0833,
      "eval_samples_per_second": 5330.384,
      "eval_steps_per_second": 12.005,
      "step": 80
    },
    {
      "epoch": 40.5,
      "grad_norm": 3.1787495613098145,
      "learning_rate": 0.0015027971948424245,
      "loss": 1.3195,
      "step": 81
    },
    {
      "epoch": 40.5,
      "eval_brier_0th_event": 0.20666409339578987,
      "eval_brier_0th_event_n": 262,
      "eval_brier_avg": 0.20666409339578987,
      "eval_brier_weighted_avg": 0.20666409339578987,
      "eval_ipcw": 0.5975384124767406,
      "eval_ipcw_0th_event": 0.5975384124767406,
      "eval_ipcw_0th_event_0.25": 0.7021662248528452,
      "eval_ipcw_0th_event_0.5": 0.6401782800638364,
      "eval_ipcw_0th_event_0.75": 0.6158972145720557,
      "eval_ipcw_0th_event_1.0": 0.5975384124767406,
      "eval_ipcw_0th_event_n": 262,
      "eval_ipcw_avg": 0.6389450329913694,
      "eval_ipcw_avg_0th_event": 0.6389450329913694,
      "eval_ipcw_weighted_avg": 0.6389450329913694,
      "eval_loss": 0.7070149183273315,
      "eval_runtime": 0.0869,
      "eval_samples_per_second": 5108.158,
      "eval_steps_per_second": 11.505,
      "step": 81
    },
    {
      "epoch": 41.0,
      "grad_norm": 3.6101109981536865,
      "learning_rate": 0.001502784052133614,
      "loss": 1.3023,
      "step": 82
    },
    {
      "epoch": 41.0,
      "eval_brier_0th_event": 0.2063434133648548,
      "eval_brier_0th_event_n": 262,
      "eval_brier_avg": 0.2063434133648548,
      "eval_brier_weighted_avg": 0.2063434133648548,
      "eval_ipcw": 0.5961507965553299,
      "eval_ipcw_0th_event": 0.5961507965553299,
      "eval_ipcw_0th_event_0.25": 0.6992563525147303,
      "eval_ipcw_0th_event_0.5": 0.6408609530128551,
      "eval_ipcw_0th_event_0.75": 0.6152448541658934,
      "eval_ipcw_0th_event_1.0": 0.5961507965553299,
      "eval_ipcw_0th_event_n": 262,
      "eval_ipcw_avg": 0.6378782390622021,
      "eval_ipcw_avg_0th_event": 0.6378782390622021,
      "eval_ipcw_weighted_avg": 0.6378782390622021,
      "eval_loss": 0.704429030418396,
      "eval_runtime": 0.0816,
      "eval_samples_per_second": 5442.579,
      "eval_steps_per_second": 12.258,
      "step": 82
    },
    {
      "epoch": 41.5,
      "grad_norm": 2.7862751483917236,
      "learning_rate": 0.001502762147789211,
      "loss": 1.2738,
      "step": 83
    },
    {
      "epoch": 41.5,
      "eval_brier_0th_event": 0.20654098713073607,
      "eval_brier_0th_event_n": 262,
      "eval_brier_avg": 0.20654098713073607,
      "eval_brier_weighted_avg": 0.20654098713073607,
      "eval_ipcw": 0.6006278105137582,
      "eval_ipcw_0th_event": 0.6006278105137582,
      "eval_ipcw_0th_event_0.25": 0.7017205607510157,
      "eval_ipcw_0th_event_0.5": 0.6434442053800495,
      "eval_ipcw_0th_event_0.75": 0.615079698982387,
      "eval_ipcw_0th_event_1.0": 0.6006278105137582,
      "eval_ipcw_0th_event_n": 262,
      "eval_ipcw_avg": 0.6402180689068027,
      "eval_ipcw_avg_0th_event": 0.6402180689068027,
      "eval_ipcw_weighted_avg": 0.6402180689068027,
      "eval_loss": 0.7040926218032837,
      "eval_runtime": 0.0726,
      "eval_samples_per_second": 6116.556,
      "eval_steps_per_second": 13.776,
      "step": 83
    },
    {
      "epoch": 42.0,
      "grad_norm": 2.222398042678833,
      "learning_rate": 0.0015027314820646345,
      "loss": 1.3337,
      "step": 84
    },
    {
      "epoch": 42.0,
      "eval_brier_0th_event": 0.20781168618300597,
      "eval_brier_0th_event_n": 262,
      "eval_brier_avg": 0.20781168618300597,
      "eval_brier_weighted_avg": 0.20781168618300597,
      "eval_ipcw": 0.6002210676200308,
      "eval_ipcw_0th_event": 0.6002210676200308,
      "eval_ipcw_0th_event_0.25": 0.7057416512187701,
      "eval_ipcw_0th_event_0.5": 0.6459342562081349,
      "eval_ipcw_0th_event_0.75": 0.6146978514827953,
      "eval_ipcw_0th_event_1.0": 0.6002210676200308,
      "eval_ipcw_0th_event_n": 262,
      "eval_ipcw_avg": 0.6416487066324328,
      "eval_ipcw_avg_0th_event": 0.6416487066324328,
      "eval_ipcw_weighted_avg": 0.6416487066324328,
      "eval_loss": 0.7073602080345154,
      "eval_runtime": 0.0842,
      "eval_samples_per_second": 5270.911,
      "eval_steps_per_second": 11.871,
      "step": 84
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 21043895040.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
