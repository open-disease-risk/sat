{
  "best_global_step": 80,
  "best_metric": 0.561287958235756,
  "best_model_checkpoint": "./data/model-hub/metabric/deephit_trial_1744625339/checkpoint-80",
  "epoch": 40.0,
  "eval_steps": 1,
  "global_step": 80,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 4.670727252960205,
      "learning_rate": 4.658333914601679e-07,
      "loss": 6.4393,
      "step": 1
    },
    {
      "epoch": 1.0,
      "grad_norm": 5.851241588592529,
      "learning_rate": 9.316667829203358e-07,
      "loss": 6.1125,
      "step": 2
    },
    {
      "epoch": 1.5,
      "grad_norm": 4.359762668609619,
      "learning_rate": 1.3975001743805037e-06,
      "loss": 5.5995,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 4.974794387817383,
      "learning_rate": 1.8633335658406716e-06,
      "loss": 5.1571,
      "step": 4
    },
    {
      "epoch": 2.5,
      "grad_norm": 4.389898300170898,
      "learning_rate": 2.3291669573008394e-06,
      "loss": 5.2474,
      "step": 5
    },
    {
      "epoch": 3.0,
      "grad_norm": 5.729790210723877,
      "learning_rate": 2.7950003487610073e-06,
      "loss": 5.0857,
      "step": 6
    },
    {
      "epoch": 3.5,
      "grad_norm": 5.0699849128723145,
      "learning_rate": 3.260833740221175e-06,
      "loss": 4.9986,
      "step": 7
    },
    {
      "epoch": 4.0,
      "grad_norm": 6.172569274902344,
      "learning_rate": 3.7266671316813433e-06,
      "loss": 5.2764,
      "step": 8
    },
    {
      "epoch": 4.5,
      "grad_norm": 6.889562606811523,
      "learning_rate": 4.192500523141511e-06,
      "loss": 5.0938,
      "step": 9
    },
    {
      "epoch": 5.0,
      "grad_norm": 7.690035343170166,
      "learning_rate": 4.658333914601679e-06,
      "loss": 5.3226,
      "step": 10
    },
    {
      "epoch": 5.5,
      "grad_norm": 8.288129806518555,
      "learning_rate": 5.124167306061847e-06,
      "loss": 5.2596,
      "step": 11
    },
    {
      "epoch": 6.0,
      "grad_norm": 9.060051918029785,
      "learning_rate": 5.590000697522015e-06,
      "loss": 5.3081,
      "step": 12
    },
    {
      "epoch": 6.5,
      "grad_norm": 9.29909610748291,
      "learning_rate": 6.055834088982183e-06,
      "loss": 5.4483,
      "step": 13
    },
    {
      "epoch": 7.0,
      "grad_norm": 10.52627944946289,
      "learning_rate": 6.52166748044235e-06,
      "loss": 5.4752,
      "step": 14
    },
    {
      "epoch": 7.5,
      "grad_norm": 10.040307998657227,
      "learning_rate": 6.987500871902518e-06,
      "loss": 5.5134,
      "step": 15
    },
    {
      "epoch": 8.0,
      "grad_norm": 11.504617691040039,
      "learning_rate": 7.4533342633626865e-06,
      "loss": 5.7299,
      "step": 16
    },
    {
      "epoch": 8.5,
      "grad_norm": 11.602079391479492,
      "learning_rate": 7.919167654822854e-06,
      "loss": 5.5398,
      "step": 17
    },
    {
      "epoch": 9.0,
      "grad_norm": 12.03431510925293,
      "learning_rate": 8.385001046283022e-06,
      "loss": 5.8627,
      "step": 18
    },
    {
      "epoch": 9.5,
      "grad_norm": 12.213363647460938,
      "learning_rate": 8.85083443774319e-06,
      "loss": 5.8318,
      "step": 19
    },
    {
      "epoch": 10.0,
      "grad_norm": 11.699655532836914,
      "learning_rate": 9.316667829203358e-06,
      "loss": 5.6114,
      "step": 20
    },
    {
      "epoch": 10.5,
      "grad_norm": 12.987778663635254,
      "learning_rate": 9.782501220663526e-06,
      "loss": 5.7368,
      "step": 21
    },
    {
      "epoch": 11.0,
      "grad_norm": 11.297910690307617,
      "learning_rate": 1.0248334612123693e-05,
      "loss": 5.9893,
      "step": 22
    },
    {
      "epoch": 11.5,
      "grad_norm": 13.115495681762695,
      "learning_rate": 1.071416800358386e-05,
      "loss": 5.9142,
      "step": 23
    },
    {
      "epoch": 12.0,
      "grad_norm": 14.162494659423828,
      "learning_rate": 1.118000139504403e-05,
      "loss": 5.8093,
      "step": 24
    },
    {
      "epoch": 12.5,
      "grad_norm": 12.679450035095215,
      "learning_rate": 1.1645834786504197e-05,
      "loss": 5.8291,
      "step": 25
    },
    {
      "epoch": 13.0,
      "grad_norm": 14.341413497924805,
      "learning_rate": 1.2111668177964365e-05,
      "loss": 6.0972,
      "step": 26
    },
    {
      "epoch": 13.5,
      "grad_norm": 13.495210647583008,
      "learning_rate": 1.2577501569424533e-05,
      "loss": 5.878,
      "step": 27
    },
    {
      "epoch": 14.0,
      "grad_norm": 14.947468757629395,
      "learning_rate": 1.30433349608847e-05,
      "loss": 6.051,
      "step": 28
    },
    {
      "epoch": 14.5,
      "grad_norm": 12.991011619567871,
      "learning_rate": 1.3509168352344868e-05,
      "loss": 5.949,
      "step": 29
    },
    {
      "epoch": 15.0,
      "grad_norm": 13.465015411376953,
      "learning_rate": 1.3975001743805035e-05,
      "loss": 6.0188,
      "step": 30
    },
    {
      "epoch": 15.5,
      "grad_norm": 13.884230613708496,
      "learning_rate": 1.4440835135265205e-05,
      "loss": 6.0446,
      "step": 31
    },
    {
      "epoch": 16.0,
      "grad_norm": 14.089905738830566,
      "learning_rate": 1.4906668526725373e-05,
      "loss": 5.8082,
      "step": 32
    },
    {
      "epoch": 16.5,
      "grad_norm": 12.51203441619873,
      "learning_rate": 1.537250191818554e-05,
      "loss": 6.024,
      "step": 33
    },
    {
      "epoch": 17.0,
      "grad_norm": 14.97178840637207,
      "learning_rate": 1.5838335309645707e-05,
      "loss": 5.8721,
      "step": 34
    },
    {
      "epoch": 17.5,
      "grad_norm": 14.25037670135498,
      "learning_rate": 1.6304168701105875e-05,
      "loss": 5.8964,
      "step": 35
    },
    {
      "epoch": 18.0,
      "grad_norm": 14.724822998046875,
      "learning_rate": 1.6770002092566043e-05,
      "loss": 6.0678,
      "step": 36
    },
    {
      "epoch": 18.5,
      "grad_norm": 13.007938385009766,
      "learning_rate": 1.723583548402621e-05,
      "loss": 6.0177,
      "step": 37
    },
    {
      "epoch": 19.0,
      "grad_norm": 15.748804092407227,
      "learning_rate": 1.770166887548638e-05,
      "loss": 5.8547,
      "step": 38
    },
    {
      "epoch": 19.5,
      "grad_norm": 14.021390914916992,
      "learning_rate": 1.8167502266946547e-05,
      "loss": 6.0845,
      "step": 39
    },
    {
      "epoch": 20.0,
      "grad_norm": 12.961772918701172,
      "learning_rate": 1.8633335658406715e-05,
      "loss": 5.9661,
      "step": 40
    },
    {
      "epoch": 20.5,
      "grad_norm": 14.367109298706055,
      "learning_rate": 1.909916904986688e-05,
      "loss": 6.0027,
      "step": 41
    },
    {
      "epoch": 21.0,
      "grad_norm": 13.225970268249512,
      "learning_rate": 1.956500244132705e-05,
      "loss": 5.9344,
      "step": 42
    },
    {
      "epoch": 21.5,
      "grad_norm": 15.712945938110352,
      "learning_rate": 2.003083583278722e-05,
      "loss": 5.8883,
      "step": 43
    },
    {
      "epoch": 22.0,
      "grad_norm": 11.954946517944336,
      "learning_rate": 2.0496669224247387e-05,
      "loss": 6.125,
      "step": 44
    },
    {
      "epoch": 22.5,
      "grad_norm": 12.679354667663574,
      "learning_rate": 2.0962502615707555e-05,
      "loss": 6.0204,
      "step": 45
    },
    {
      "epoch": 23.0,
      "grad_norm": 14.935458183288574,
      "learning_rate": 2.142833600716772e-05,
      "loss": 5.8875,
      "step": 46
    },
    {
      "epoch": 23.5,
      "grad_norm": 15.898111343383789,
      "learning_rate": 2.189416939862789e-05,
      "loss": 5.8835,
      "step": 47
    },
    {
      "epoch": 24.0,
      "grad_norm": 11.346155166625977,
      "learning_rate": 2.236000279008806e-05,
      "loss": 6.2695,
      "step": 48
    },
    {
      "epoch": 24.5,
      "grad_norm": 14.61059856414795,
      "learning_rate": 2.2825836181548227e-05,
      "loss": 5.9904,
      "step": 49
    },
    {
      "epoch": 25.0,
      "grad_norm": 13.114730834960938,
      "learning_rate": 2.3291669573008395e-05,
      "loss": 5.9109,
      "step": 50
    },
    {
      "epoch": 25.5,
      "grad_norm": 14.960083961486816,
      "learning_rate": 2.375750296446856e-05,
      "loss": 6.0275,
      "step": 51
    },
    {
      "epoch": 26.0,
      "grad_norm": 12.892578125,
      "learning_rate": 2.422333635592873e-05,
      "loss": 5.861,
      "step": 52
    },
    {
      "epoch": 26.5,
      "grad_norm": 13.321338653564453,
      "learning_rate": 2.4689169747388895e-05,
      "loss": 6.0407,
      "step": 53
    },
    {
      "epoch": 27.0,
      "grad_norm": 16.4056453704834,
      "learning_rate": 2.5155003138849067e-05,
      "loss": 5.8312,
      "step": 54
    },
    {
      "epoch": 27.5,
      "grad_norm": 13.46300983428955,
      "learning_rate": 2.5620836530309235e-05,
      "loss": 6.19,
      "step": 55
    },
    {
      "epoch": 28.0,
      "grad_norm": 14.534017562866211,
      "learning_rate": 2.60866699217694e-05,
      "loss": 5.6394,
      "step": 56
    },
    {
      "epoch": 28.5,
      "grad_norm": 15.420726776123047,
      "learning_rate": 2.655250331322957e-05,
      "loss": 6.0968,
      "step": 57
    },
    {
      "epoch": 29.0,
      "grad_norm": 13.578483581542969,
      "learning_rate": 2.7018336704689735e-05,
      "loss": 5.8728,
      "step": 58
    },
    {
      "epoch": 29.5,
      "grad_norm": 13.922981262207031,
      "learning_rate": 2.7484170096149906e-05,
      "loss": 6.0544,
      "step": 59
    },
    {
      "epoch": 30.0,
      "grad_norm": 12.10737419128418,
      "learning_rate": 2.795000348761007e-05,
      "loss": 6.0625,
      "step": 60
    },
    {
      "epoch": 30.5,
      "grad_norm": 14.578046798706055,
      "learning_rate": 2.841583687907024e-05,
      "loss": 5.9552,
      "step": 61
    },
    {
      "epoch": 31.0,
      "grad_norm": 13.867985725402832,
      "learning_rate": 2.888167027053041e-05,
      "loss": 6.1047,
      "step": 62
    },
    {
      "epoch": 31.5,
      "grad_norm": 13.44297981262207,
      "learning_rate": 2.9347503661990575e-05,
      "loss": 5.9542,
      "step": 63
    },
    {
      "epoch": 32.0,
      "grad_norm": 14.859492301940918,
      "learning_rate": 2.9813337053450746e-05,
      "loss": 5.8757,
      "step": 64
    },
    {
      "epoch": 32.5,
      "grad_norm": 14.106983184814453,
      "learning_rate": 3.027917044491091e-05,
      "loss": 5.9895,
      "step": 65
    },
    {
      "epoch": 33.0,
      "grad_norm": 13.535994529724121,
      "learning_rate": 3.074500383637108e-05,
      "loss": 5.9832,
      "step": 66
    },
    {
      "epoch": 33.5,
      "grad_norm": 12.462371826171875,
      "learning_rate": 3.121083722783125e-05,
      "loss": 6.1012,
      "step": 67
    },
    {
      "epoch": 34.0,
      "grad_norm": 14.5892333984375,
      "learning_rate": 3.1676670619291415e-05,
      "loss": 5.8122,
      "step": 68
    },
    {
      "epoch": 34.5,
      "grad_norm": 13.676140785217285,
      "learning_rate": 3.214250401075158e-05,
      "loss": 5.9708,
      "step": 69
    },
    {
      "epoch": 35.0,
      "grad_norm": 12.575827598571777,
      "learning_rate": 3.260833740221175e-05,
      "loss": 6.0559,
      "step": 70
    },
    {
      "epoch": 35.5,
      "grad_norm": 11.76121997833252,
      "learning_rate": 3.307417079367192e-05,
      "loss": 5.9383,
      "step": 71
    },
    {
      "epoch": 36.0,
      "grad_norm": 15.38723087310791,
      "learning_rate": 3.3540004185132086e-05,
      "loss": 5.9909,
      "step": 72
    },
    {
      "epoch": 36.5,
      "grad_norm": 11.871478080749512,
      "learning_rate": 3.4005837576592254e-05,
      "loss": 5.9516,
      "step": 73
    },
    {
      "epoch": 37.0,
      "grad_norm": 11.902881622314453,
      "learning_rate": 3.447167096805242e-05,
      "loss": 6.0625,
      "step": 74
    },
    {
      "epoch": 37.5,
      "grad_norm": 13.376124382019043,
      "learning_rate": 3.493750435951259e-05,
      "loss": 5.8665,
      "step": 75
    },
    {
      "epoch": 38.0,
      "grad_norm": 10.674966812133789,
      "learning_rate": 3.540333775097276e-05,
      "loss": 6.1369,
      "step": 76
    },
    {
      "epoch": 38.5,
      "grad_norm": 12.053354263305664,
      "learning_rate": 3.5869171142432926e-05,
      "loss": 5.9713,
      "step": 77
    },
    {
      "epoch": 39.0,
      "grad_norm": 13.00796127319336,
      "learning_rate": 3.6335004533893094e-05,
      "loss": 5.8526,
      "step": 78
    },
    {
      "epoch": 39.5,
      "grad_norm": 10.53811264038086,
      "learning_rate": 3.680083792535326e-05,
      "loss": 5.9798,
      "step": 79
    },
    {
      "epoch": 40.0,
      "grad_norm": 10.53475284576416,
      "learning_rate": 3.726667131681343e-05,
      "loss": 6.0436,
      "step": 80
    },
    {
      "epoch": 40.0,
      "eval_brier_0th_event": 0.20404590708242604,
      "eval_brier_0th_event_n": 257,
      "eval_brier_avg": 0.20404590708242604,
      "eval_brier_weighted_avg": 0.20404590708242604,
      "eval_ipcw": 0.542361253214861,
      "eval_ipcw_0th_event": 0.542361253214861,
      "eval_ipcw_0th_event_0.25": 0.6009073397925266,
      "eval_ipcw_0th_event_0.5": 0.5529459378999056,
      "eval_ipcw_0th_event_0.75": 0.5489373020357303,
      "eval_ipcw_0th_event_1.0": 0.542361253214861,
      "eval_ipcw_0th_event_n": 257,
      "eval_ipcw_avg": 0.561287958235756,
      "eval_ipcw_avg_0th_event": 0.561287958235756,
      "eval_ipcw_weighted_avg": 0.561287958235756,
      "eval_loss": 2.9642183780670166,
      "eval_runtime": 0.1767,
      "eval_samples_per_second": 2512.647,
      "eval_steps_per_second": 5.659,
      "step": 80
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 19496217600.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
