{
  "best_global_step": 88,
  "best_metric": 0.6076359667483417,
  "best_model_checkpoint": "./data/model-hub/metabric/survival_trial_1749809389_1/checkpoint-88",
  "epoch": 44.0,
  "eval_steps": 1,
  "global_step": 88,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 3.7189598083496094,
      "learning_rate": 4.753567986864208e-05,
      "loss": 1.5833,
      "step": 1
    },
    {
      "epoch": 1.0,
      "grad_norm": 3.9735267162323,
      "learning_rate": 9.507135973728416e-05,
      "loss": 1.5864,
      "step": 2
    },
    {
      "epoch": 1.5,
      "grad_norm": 3.6536083221435547,
      "learning_rate": 0.00014260703960592623,
      "loss": 1.5948,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 3.924558401107788,
      "learning_rate": 0.00019014271947456833,
      "loss": 1.5654,
      "step": 4
    },
    {
      "epoch": 2.5,
      "grad_norm": 3.5756030082702637,
      "learning_rate": 0.0002376783993432104,
      "loss": 1.5475,
      "step": 5
    },
    {
      "epoch": 3.0,
      "grad_norm": 3.479701280593872,
      "learning_rate": 0.00028521407921185246,
      "loss": 1.612,
      "step": 6
    },
    {
      "epoch": 3.5,
      "grad_norm": 3.5797269344329834,
      "learning_rate": 0.00033274975908049456,
      "loss": 1.5701,
      "step": 7
    },
    {
      "epoch": 4.0,
      "grad_norm": 3.179009199142456,
      "learning_rate": 0.00038028543894913665,
      "loss": 1.5527,
      "step": 8
    },
    {
      "epoch": 4.5,
      "grad_norm": 3.0752649307250977,
      "learning_rate": 0.0004278211188177787,
      "loss": 1.5574,
      "step": 9
    },
    {
      "epoch": 5.0,
      "grad_norm": 3.465879440307617,
      "learning_rate": 0.0004753567986864208,
      "loss": 1.5237,
      "step": 10
    },
    {
      "epoch": 5.5,
      "grad_norm": 3.0964300632476807,
      "learning_rate": 0.0005228924785550629,
      "loss": 1.5348,
      "step": 11
    },
    {
      "epoch": 6.0,
      "grad_norm": 3.9542922973632812,
      "learning_rate": 0.0005704281584237049,
      "loss": 1.5493,
      "step": 12
    },
    {
      "epoch": 6.5,
      "grad_norm": 3.6500649452209473,
      "learning_rate": 0.000617963838292347,
      "loss": 1.5167,
      "step": 13
    },
    {
      "epoch": 7.0,
      "grad_norm": 3.476053237915039,
      "learning_rate": 0.0006654995181609891,
      "loss": 1.5455,
      "step": 14
    },
    {
      "epoch": 7.5,
      "grad_norm": 3.7993361949920654,
      "learning_rate": 0.0007130351980296312,
      "loss": 1.5108,
      "step": 15
    },
    {
      "epoch": 8.0,
      "grad_norm": 3.364877700805664,
      "learning_rate": 0.0007605708778982733,
      "loss": 1.4763,
      "step": 16
    },
    {
      "epoch": 8.5,
      "grad_norm": 3.2703099250793457,
      "learning_rate": 0.0008081065577669153,
      "loss": 1.4485,
      "step": 17
    },
    {
      "epoch": 9.0,
      "grad_norm": 3.532660722732544,
      "learning_rate": 0.0008556422376355574,
      "loss": 1.4902,
      "step": 18
    },
    {
      "epoch": 9.5,
      "grad_norm": 3.251396656036377,
      "learning_rate": 0.0009031779175041995,
      "loss": 1.4161,
      "step": 19
    },
    {
      "epoch": 10.0,
      "grad_norm": 3.342169761657715,
      "learning_rate": 0.0009507135973728416,
      "loss": 1.4815,
      "step": 20
    },
    {
      "epoch": 10.5,
      "grad_norm": 2.558636426925659,
      "learning_rate": 0.0009982492772414838,
      "loss": 1.4029,
      "step": 21
    },
    {
      "epoch": 11.0,
      "grad_norm": 3.183548927307129,
      "learning_rate": 0.0010457849571101259,
      "loss": 1.3961,
      "step": 22
    },
    {
      "epoch": 11.5,
      "grad_norm": 2.6180624961853027,
      "learning_rate": 0.0010933206369787677,
      "loss": 1.399,
      "step": 23
    },
    {
      "epoch": 12.0,
      "grad_norm": 2.6488006114959717,
      "learning_rate": 0.0011408563168474098,
      "loss": 1.3357,
      "step": 24
    },
    {
      "epoch": 12.5,
      "grad_norm": 2.4089748859405518,
      "learning_rate": 0.001188391996716052,
      "loss": 1.3294,
      "step": 25
    },
    {
      "epoch": 13.0,
      "grad_norm": 2.313778877258301,
      "learning_rate": 0.001235927676584694,
      "loss": 1.3262,
      "step": 26
    },
    {
      "epoch": 13.5,
      "grad_norm": 1.8937100172042847,
      "learning_rate": 0.0012834633564533361,
      "loss": 1.3499,
      "step": 27
    },
    {
      "epoch": 14.0,
      "grad_norm": 2.0297300815582275,
      "learning_rate": 0.0013309990363219782,
      "loss": 1.2253,
      "step": 28
    },
    {
      "epoch": 14.5,
      "grad_norm": 1.501950740814209,
      "learning_rate": 0.0013785347161906203,
      "loss": 1.2298,
      "step": 29
    },
    {
      "epoch": 15.0,
      "grad_norm": 3.4789106845855713,
      "learning_rate": 0.0014260703960592624,
      "loss": 1.3673,
      "step": 30
    },
    {
      "epoch": 15.5,
      "grad_norm": 1.5840222835540771,
      "learning_rate": 0.0014736060759279045,
      "loss": 1.2557,
      "step": 31
    },
    {
      "epoch": 16.0,
      "grad_norm": 2.0839474201202393,
      "learning_rate": 0.0015211417557965466,
      "loss": 1.2588,
      "step": 32
    },
    {
      "epoch": 16.5,
      "grad_norm": 2.287337303161621,
      "learning_rate": 0.0015686774356651885,
      "loss": 1.1806,
      "step": 33
    },
    {
      "epoch": 17.0,
      "grad_norm": 2.4904088973999023,
      "learning_rate": 0.0016162131155338306,
      "loss": 1.3001,
      "step": 34
    },
    {
      "epoch": 17.5,
      "grad_norm": 1.5316036939620972,
      "learning_rate": 0.0016637487954024727,
      "loss": 1.2157,
      "step": 35
    },
    {
      "epoch": 18.0,
      "grad_norm": 2.199357748031616,
      "learning_rate": 0.0017112844752711148,
      "loss": 1.2325,
      "step": 36
    },
    {
      "epoch": 18.5,
      "grad_norm": 1.6314597129821777,
      "learning_rate": 0.001758820155139757,
      "loss": 1.2055,
      "step": 37
    },
    {
      "epoch": 19.0,
      "grad_norm": 2.4244093894958496,
      "learning_rate": 0.001806355835008399,
      "loss": 1.2072,
      "step": 38
    },
    {
      "epoch": 19.5,
      "grad_norm": 1.820243239402771,
      "learning_rate": 0.001853891514877041,
      "loss": 1.1719,
      "step": 39
    },
    {
      "epoch": 20.0,
      "grad_norm": 1.9214204549789429,
      "learning_rate": 0.0019014271947456831,
      "loss": 1.2091,
      "step": 40
    },
    {
      "epoch": 20.5,
      "grad_norm": 1.940942645072937,
      "learning_rate": 0.001948962874614325,
      "loss": 1.157,
      "step": 41
    },
    {
      "epoch": 21.0,
      "grad_norm": 3.04779314994812,
      "learning_rate": 0.0019964985544829675,
      "loss": 1.1802,
      "step": 42
    },
    {
      "epoch": 21.5,
      "grad_norm": 1.7254663705825806,
      "learning_rate": 0.0020440342343516094,
      "loss": 1.15,
      "step": 43
    },
    {
      "epoch": 22.0,
      "grad_norm": 2.401479959487915,
      "learning_rate": 0.0020915699142202517,
      "loss": 1.1505,
      "step": 44
    },
    {
      "epoch": 22.5,
      "grad_norm": 1.806219220161438,
      "learning_rate": 0.0021391055940888936,
      "loss": 1.1461,
      "step": 45
    },
    {
      "epoch": 23.0,
      "grad_norm": 2.135342597961426,
      "learning_rate": 0.0021866412739575355,
      "loss": 1.117,
      "step": 46
    },
    {
      "epoch": 23.5,
      "grad_norm": 1.9852370023727417,
      "learning_rate": 0.002234176953826178,
      "loss": 1.1349,
      "step": 47
    },
    {
      "epoch": 24.0,
      "grad_norm": 2.925288438796997,
      "learning_rate": 0.0022817126336948197,
      "loss": 1.1244,
      "step": 48
    },
    {
      "epoch": 24.5,
      "grad_norm": 1.9893630743026733,
      "learning_rate": 0.002329248313563462,
      "loss": 1.0687,
      "step": 49
    },
    {
      "epoch": 25.0,
      "grad_norm": 3.0993852615356445,
      "learning_rate": 0.002376783993432104,
      "loss": 1.1818,
      "step": 50
    },
    {
      "epoch": 25.5,
      "grad_norm": 1.7574710845947266,
      "learning_rate": 0.0024243196733007458,
      "loss": 1.0879,
      "step": 51
    },
    {
      "epoch": 26.0,
      "grad_norm": 2.4484684467315674,
      "learning_rate": 0.002471855353169388,
      "loss": 1.1246,
      "step": 52
    },
    {
      "epoch": 26.5,
      "grad_norm": 2.626659870147705,
      "learning_rate": 0.00251939103303803,
      "loss": 1.0873,
      "step": 53
    },
    {
      "epoch": 27.0,
      "grad_norm": 2.4040439128875732,
      "learning_rate": 0.0025669267129066723,
      "loss": 1.09,
      "step": 54
    },
    {
      "epoch": 27.5,
      "grad_norm": 2.4829258918762207,
      "learning_rate": 0.002614462392775314,
      "loss": 1.0912,
      "step": 55
    },
    {
      "epoch": 28.0,
      "grad_norm": 3.393850088119507,
      "learning_rate": 0.0026619980726439564,
      "loss": 1.084,
      "step": 56
    },
    {
      "epoch": 28.5,
      "grad_norm": 2.0557167530059814,
      "learning_rate": 0.0027095337525125988,
      "loss": 1.0159,
      "step": 57
    },
    {
      "epoch": 29.0,
      "grad_norm": 2.952296733856201,
      "learning_rate": 0.0027570694323812406,
      "loss": 1.1596,
      "step": 58
    },
    {
      "epoch": 29.5,
      "grad_norm": 1.9655267000198364,
      "learning_rate": 0.002804605112249883,
      "loss": 1.064,
      "step": 59
    },
    {
      "epoch": 30.0,
      "grad_norm": 2.6414504051208496,
      "learning_rate": 0.002852140792118525,
      "loss": 1.0995,
      "step": 60
    },
    {
      "epoch": 30.5,
      "grad_norm": 3.3961398601531982,
      "learning_rate": 0.0028996764719871667,
      "loss": 1.0711,
      "step": 61
    },
    {
      "epoch": 31.0,
      "grad_norm": 2.553421974182129,
      "learning_rate": 0.002947212151855809,
      "loss": 1.0698,
      "step": 62
    },
    {
      "epoch": 31.5,
      "grad_norm": 2.244337320327759,
      "learning_rate": 0.002994747831724451,
      "loss": 1.0264,
      "step": 63
    },
    {
      "epoch": 32.0,
      "grad_norm": 3.7974212169647217,
      "learning_rate": 0.003042283511593093,
      "loss": 1.0713,
      "step": 64
    },
    {
      "epoch": 32.5,
      "grad_norm": 2.1741464138031006,
      "learning_rate": 0.003089819191461735,
      "loss": 0.9951,
      "step": 65
    },
    {
      "epoch": 33.0,
      "grad_norm": 2.8249294757843018,
      "learning_rate": 0.003137354871330377,
      "loss": 1.009,
      "step": 66
    },
    {
      "epoch": 33.5,
      "grad_norm": 2.527064323425293,
      "learning_rate": 0.0031848905511990193,
      "loss": 0.9835,
      "step": 67
    },
    {
      "epoch": 34.0,
      "grad_norm": 3.6214420795440674,
      "learning_rate": 0.003232426231067661,
      "loss": 0.9953,
      "step": 68
    },
    {
      "epoch": 34.5,
      "grad_norm": 2.202191114425659,
      "learning_rate": 0.0032799619109363035,
      "loss": 0.9995,
      "step": 69
    },
    {
      "epoch": 35.0,
      "grad_norm": 5.479929447174072,
      "learning_rate": 0.0033274975908049453,
      "loss": 1.0279,
      "step": 70
    },
    {
      "epoch": 35.5,
      "grad_norm": 3.7223458290100098,
      "learning_rate": 0.003375033270673587,
      "loss": 0.959,
      "step": 71
    },
    {
      "epoch": 36.0,
      "grad_norm": 3.8753931522369385,
      "learning_rate": 0.0034225689505422295,
      "loss": 0.9849,
      "step": 72
    },
    {
      "epoch": 36.5,
      "grad_norm": 5.044778347015381,
      "learning_rate": 0.003470104630410872,
      "loss": 1.0015,
      "step": 73
    },
    {
      "epoch": 37.0,
      "grad_norm": 4.481015205383301,
      "learning_rate": 0.003517640310279514,
      "loss": 0.9528,
      "step": 74
    },
    {
      "epoch": 37.5,
      "grad_norm": 7.669860363006592,
      "learning_rate": 0.003565175990148156,
      "loss": 0.9442,
      "step": 75
    },
    {
      "epoch": 38.0,
      "grad_norm": 7.607299327850342,
      "learning_rate": 0.003612711670016798,
      "loss": 1.079,
      "step": 76
    },
    {
      "epoch": 38.5,
      "grad_norm": 4.403496265411377,
      "learning_rate": 0.0036602473498854402,
      "loss": 0.9687,
      "step": 77
    },
    {
      "epoch": 39.0,
      "grad_norm": 5.325445652008057,
      "learning_rate": 0.003707783029754082,
      "loss": 1.0287,
      "step": 78
    },
    {
      "epoch": 39.5,
      "grad_norm": 5.859447002410889,
      "learning_rate": 0.0037553187096227244,
      "loss": 0.9493,
      "step": 79
    },
    {
      "epoch": 40.0,
      "grad_norm": 4.085155963897705,
      "learning_rate": 0.0038028543894913663,
      "loss": 0.9612,
      "step": 80
    },
    {
      "epoch": 40.0,
      "eval_brier_0th_event": 0.22276964783668518,
      "eval_brier_0th_event_n": 278,
      "eval_brier_weighted_avg": 0.22276964783668518,
      "eval_ipcw_0th_event": 0.601024744154393,
      "eval_ipcw_0th_event_0.25": 0.5858272910118103,
      "eval_ipcw_0th_event_0.50": 0.5984534025192261,
      "eval_ipcw_0th_event_0.75": 0.6055653095245361,
      "eval_ipcw_0th_event_1.00": 0.6030471920967102,
      "eval_ipcw_0th_event_n": 453,
      "eval_ipcw_weighted_avg": 0.601024744154393,
      "eval_loss": 0.8013249039649963,
      "eval_runtime": 0.1458,
      "eval_samples_per_second": 3107.807,
      "eval_steps_per_second": 6.861,
      "step": 80
    },
    {
      "epoch": 40.5,
      "grad_norm": 3.6575794219970703,
      "learning_rate": 0.0038028433035296617,
      "loss": 0.9709,
      "step": 81
    },
    {
      "epoch": 40.5,
      "eval_brier_0th_event": 0.22776539623737335,
      "eval_brier_0th_event_n": 278,
      "eval_brier_weighted_avg": 0.22776539623737335,
      "eval_ipcw_0th_event": 0.5976280660807402,
      "eval_ipcw_0th_event_0.25": 0.5804605484008789,
      "eval_ipcw_0th_event_0.50": 0.5976970195770264,
      "eval_ipcw_0th_event_0.75": 0.6048429012298584,
      "eval_ipcw_0th_event_1.00": 0.5969156622886658,
      "eval_ipcw_0th_event_n": 453,
      "eval_ipcw_weighted_avg": 0.5976280660807402,
      "eval_loss": 0.8190727829933167,
      "eval_runtime": 0.1437,
      "eval_samples_per_second": 3152.048,
      "eval_steps_per_second": 6.958,
      "step": 81
    },
    {
      "epoch": 41.0,
      "grad_norm": 7.637580394744873,
      "learning_rate": 0.003802810045773817,
      "loss": 0.9716,
      "step": 82
    },
    {
      "epoch": 41.0,
      "eval_brier_0th_event": 0.22434087097644806,
      "eval_brier_0th_event_n": 278,
      "eval_brier_weighted_avg": 0.22434087097644806,
      "eval_ipcw_0th_event": 0.5959506356853178,
      "eval_ipcw_0th_event_0.25": 0.5795633792877197,
      "eval_ipcw_0th_event_0.50": 0.5992622375488281,
      "eval_ipcw_0th_event_0.75": 0.602677583694458,
      "eval_ipcw_0th_event_1.00": 0.5938135385513306,
      "eval_ipcw_0th_event_n": 453,
      "eval_ipcw_weighted_avg": 0.5959506356853178,
      "eval_loss": 0.8072484135627747,
      "eval_runtime": 0.1476,
      "eval_samples_per_second": 3069.048,
      "eval_steps_per_second": 6.775,
      "step": 82
    },
    {
      "epoch": 41.5,
      "grad_norm": 3.7467527389526367,
      "learning_rate": 0.0038027546166116404,
      "loss": 0.9659,
      "step": 83
    },
    {
      "epoch": 41.5,
      "eval_brier_0th_event": 0.22321651875972748,
      "eval_brier_0th_event_n": 278,
      "eval_brier_weighted_avg": 0.22321651875972748,
      "eval_ipcw_0th_event": 0.5971840911213009,
      "eval_ipcw_0th_event_0.25": 0.5836207270622253,
      "eval_ipcw_0th_event_0.50": 0.5984946489334106,
      "eval_ipcw_0th_event_0.75": 0.6054317951202393,
      "eval_ipcw_0th_event_1.00": 0.594114363193512,
      "eval_ipcw_0th_event_n": 453,
      "eval_ipcw_weighted_avg": 0.5971840911213009,
      "eval_loss": 0.8049829006195068,
      "eval_runtime": 0.1453,
      "eval_samples_per_second": 3116.702,
      "eval_steps_per_second": 6.88,
      "step": 83
    },
    {
      "epoch": 42.0,
      "grad_norm": 3.8700385093688965,
      "learning_rate": 0.003802677016689473,
      "loss": 0.8728,
      "step": 84
    },
    {
      "epoch": 42.0,
      "eval_brier_0th_event": 0.22531190514564514,
      "eval_brier_0th_event_n": 278,
      "eval_brier_weighted_avg": 0.22531190514564514,
      "eval_ipcw_0th_event": 0.5982278237740198,
      "eval_ipcw_0th_event_0.25": 0.5926486849784851,
      "eval_ipcw_0th_event_0.50": 0.6034464836120605,
      "eval_ipcw_0th_event_0.75": 0.6104387044906616,
      "eval_ipcw_0th_event_1.00": 0.588126540184021,
      "eval_ipcw_0th_event_n": 453,
      "eval_ipcw_weighted_avg": 0.5982278237740198,
      "eval_loss": 0.814489483833313,
      "eval_runtime": 0.1442,
      "eval_samples_per_second": 3142.253,
      "eval_steps_per_second": 6.937,
      "step": 84
    },
    {
      "epoch": 42.5,
      "grad_norm": 5.95357084274292,
      "learning_rate": 0.0038025772469121827,
      "loss": 0.9259,
      "step": 85
    },
    {
      "epoch": 42.5,
      "eval_brier_0th_event": 0.22322866320610046,
      "eval_brier_0th_event_n": 278,
      "eval_brier_weighted_avg": 0.22322866320610046,
      "eval_ipcw_0th_event": 0.6020093846252594,
      "eval_ipcw_0th_event_0.25": 0.5976231098175049,
      "eval_ipcw_0th_event_0.50": 0.6057215332984924,
      "eval_ipcw_0th_event_0.75": 0.6119826436042786,
      "eval_ipcw_0th_event_1.00": 0.5939797163009644,
      "eval_ipcw_0th_event_n": 453,
      "eval_ipcw_weighted_avg": 0.6020093846252594,
      "eval_loss": 0.8062361478805542,
      "eval_runtime": 0.1439,
      "eval_samples_per_second": 3148.126,
      "eval_steps_per_second": 6.95,
      "step": 85
    },
    {
      "epoch": 43.0,
      "grad_norm": 4.7145304679870605,
      "learning_rate": 0.003802455308443152,
      "loss": 0.9565,
      "step": 86
    },
    {
      "epoch": 43.0,
      "eval_brier_0th_event": 0.2249942272901535,
      "eval_brier_0th_event_n": 278,
      "eval_brier_weighted_avg": 0.2249942272901535,
      "eval_ipcw_0th_event": 0.6039329968478488,
      "eval_ipcw_0th_event_0.25": 0.6018975973129272,
      "eval_ipcw_0th_event_0.50": 0.6074063777923584,
      "eval_ipcw_0th_event_0.75": 0.6106604933738708,
      "eval_ipcw_0th_event_1.00": 0.5977934002876282,
      "eval_ipcw_0th_event_n": 453,
      "eval_ipcw_weighted_avg": 0.603932996847849,
      "eval_loss": 0.807807207107544,
      "eval_runtime": 0.1449,
      "eval_samples_per_second": 3125.819,
      "eval_steps_per_second": 6.9,
      "step": 86
    },
    {
      "epoch": 43.5,
      "grad_norm": 2.9420933723449707,
      "learning_rate": 0.0038023112027042653,
      "loss": 0.9072,
      "step": 87
    },
    {
      "epoch": 43.5,
      "eval_brier_0th_event": 0.22813095152378082,
      "eval_brier_0th_event_n": 278,
      "eval_brier_weighted_avg": 0.22813095152378082,
      "eval_ipcw_0th_event": 0.6056553995472261,
      "eval_ipcw_0th_event_0.25": 0.5996608734130859,
      "eval_ipcw_0th_event_0.50": 0.6061522960662842,
      "eval_ipcw_0th_event_0.75": 0.6104707717895508,
      "eval_ipcw_0th_event_1.00": 0.6034673452377319,
      "eval_ipcw_0th_event_n": 453,
      "eval_ipcw_weighted_avg": 0.6056553995472261,
      "eval_loss": 0.8160545825958252,
      "eval_runtime": 0.1583,
      "eval_samples_per_second": 2861.876,
      "eval_steps_per_second": 6.318,
      "step": 87
    },
    {
      "epoch": 44.0,
      "grad_norm": 5.250533580780029,
      "learning_rate": 0.003802144931375894,
      "loss": 0.9099,
      "step": 88
    },
    {
      "epoch": 44.0,
      "eval_brier_0th_event": 0.22669617831707,
      "eval_brier_0th_event_n": 278,
      "eval_brier_weighted_avg": 0.22669617831707,
      "eval_ipcw_0th_event": 0.6076359667483417,
      "eval_ipcw_0th_event_0.25": 0.5997640490531921,
      "eval_ipcw_0th_event_0.50": 0.6115694642066956,
      "eval_ipcw_0th_event_0.75": 0.6115145683288574,
      "eval_ipcw_0th_event_1.00": 0.6049898266792297,
      "eval_ipcw_0th_event_n": 453,
      "eval_ipcw_weighted_avg": 0.6076359667483417,
      "eval_loss": 0.8096151947975159,
      "eval_runtime": 0.1507,
      "eval_samples_per_second": 3005.233,
      "eval_steps_per_second": 6.634,
      "step": 88
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 18399363840.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
