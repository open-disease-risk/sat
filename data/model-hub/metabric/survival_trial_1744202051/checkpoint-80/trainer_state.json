{
  "best_global_step": 80,
  "best_metric": 0.6131214690384842,
  "best_model_checkpoint": "./data/model-hub/metabric/survival_trial_1744202051/checkpoint-80",
  "epoch": 40.0,
  "eval_steps": 1,
  "global_step": 80,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 1.9335006475448608,
      "learning_rate": 8.813986527925571e-05,
      "loss": 1.6031,
      "step": 1
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.6698797941207886,
      "learning_rate": 0.00017627973055851142,
      "loss": 1.5681,
      "step": 2
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.665200114250183,
      "learning_rate": 0.0002644195958377671,
      "loss": 1.5688,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.765496015548706,
      "learning_rate": 0.00035255946111702283,
      "loss": 1.5865,
      "step": 4
    },
    {
      "epoch": 2.5,
      "grad_norm": 1.614225149154663,
      "learning_rate": 0.0004406993263962785,
      "loss": 1.5794,
      "step": 5
    },
    {
      "epoch": 3.0,
      "grad_norm": 1.6250485181808472,
      "learning_rate": 0.0005288391916755342,
      "loss": 1.5853,
      "step": 6
    },
    {
      "epoch": 3.5,
      "grad_norm": 1.2369093894958496,
      "learning_rate": 0.0006169790569547899,
      "loss": 1.5521,
      "step": 7
    },
    {
      "epoch": 4.0,
      "grad_norm": 2.0800185203552246,
      "learning_rate": 0.0007051189222340457,
      "loss": 1.5857,
      "step": 8
    },
    {
      "epoch": 4.5,
      "grad_norm": 1.588187336921692,
      "learning_rate": 0.0007932587875133013,
      "loss": 1.5427,
      "step": 9
    },
    {
      "epoch": 5.0,
      "grad_norm": 1.7691185474395752,
      "learning_rate": 0.000881398652792557,
      "loss": 1.5932,
      "step": 10
    },
    {
      "epoch": 5.5,
      "grad_norm": 1.888043999671936,
      "learning_rate": 0.0009695385180718128,
      "loss": 1.5638,
      "step": 11
    },
    {
      "epoch": 6.0,
      "grad_norm": 1.5732287168502808,
      "learning_rate": 0.0010576783833510684,
      "loss": 1.5225,
      "step": 12
    },
    {
      "epoch": 6.5,
      "grad_norm": 1.8670979738235474,
      "learning_rate": 0.001145818248630324,
      "loss": 1.5411,
      "step": 13
    },
    {
      "epoch": 7.0,
      "grad_norm": 2.0064427852630615,
      "learning_rate": 0.0012339581139095797,
      "loss": 1.4994,
      "step": 14
    },
    {
      "epoch": 7.5,
      "grad_norm": 1.6190111637115479,
      "learning_rate": 0.0013220979791888354,
      "loss": 1.5149,
      "step": 15
    },
    {
      "epoch": 8.0,
      "grad_norm": 2.321258544921875,
      "learning_rate": 0.0014102378444680913,
      "loss": 1.4852,
      "step": 16
    },
    {
      "epoch": 8.5,
      "grad_norm": 2.351644992828369,
      "learning_rate": 0.001498377709747347,
      "loss": 1.4993,
      "step": 17
    },
    {
      "epoch": 9.0,
      "grad_norm": 1.269398808479309,
      "learning_rate": 0.0015865175750266027,
      "loss": 1.4616,
      "step": 18
    },
    {
      "epoch": 9.5,
      "grad_norm": 1.7993929386138916,
      "learning_rate": 0.0016746574403058584,
      "loss": 1.462,
      "step": 19
    },
    {
      "epoch": 10.0,
      "grad_norm": 1.6819816827774048,
      "learning_rate": 0.001762797305585114,
      "loss": 1.4538,
      "step": 20
    },
    {
      "epoch": 10.5,
      "grad_norm": 1.5991771221160889,
      "learning_rate": 0.0018509371708643697,
      "loss": 1.4349,
      "step": 21
    },
    {
      "epoch": 11.0,
      "grad_norm": 1.6934795379638672,
      "learning_rate": 0.0019390770361436256,
      "loss": 1.4352,
      "step": 22
    },
    {
      "epoch": 11.5,
      "grad_norm": 1.5967291593551636,
      "learning_rate": 0.002027216901422881,
      "loss": 1.425,
      "step": 23
    },
    {
      "epoch": 12.0,
      "grad_norm": 1.2876160144805908,
      "learning_rate": 0.0021153567667021368,
      "loss": 1.3307,
      "step": 24
    },
    {
      "epoch": 12.5,
      "grad_norm": 1.1969398260116577,
      "learning_rate": 0.0022034966319813927,
      "loss": 1.3445,
      "step": 25
    },
    {
      "epoch": 13.0,
      "grad_norm": 1.7720361948013306,
      "learning_rate": 0.002291636497260648,
      "loss": 1.4001,
      "step": 26
    },
    {
      "epoch": 13.5,
      "grad_norm": 1.19288969039917,
      "learning_rate": 0.002379776362539904,
      "loss": 1.2999,
      "step": 27
    },
    {
      "epoch": 14.0,
      "grad_norm": 1.3557419776916504,
      "learning_rate": 0.0024679162278191595,
      "loss": 1.3694,
      "step": 28
    },
    {
      "epoch": 14.5,
      "grad_norm": 1.3965049982070923,
      "learning_rate": 0.0025560560930984154,
      "loss": 1.3398,
      "step": 29
    },
    {
      "epoch": 15.0,
      "grad_norm": 1.458478331565857,
      "learning_rate": 0.002644195958377671,
      "loss": 1.3007,
      "step": 30
    },
    {
      "epoch": 15.5,
      "grad_norm": 1.600366234779358,
      "learning_rate": 0.0027323358236569267,
      "loss": 1.2541,
      "step": 31
    },
    {
      "epoch": 16.0,
      "grad_norm": 2.0465941429138184,
      "learning_rate": 0.0028204756889361826,
      "loss": 1.3562,
      "step": 32
    },
    {
      "epoch": 16.5,
      "grad_norm": 1.3406215906143188,
      "learning_rate": 0.002908615554215438,
      "loss": 1.3145,
      "step": 33
    },
    {
      "epoch": 17.0,
      "grad_norm": 3.424168825149536,
      "learning_rate": 0.002996755419494694,
      "loss": 1.2119,
      "step": 34
    },
    {
      "epoch": 17.5,
      "grad_norm": 1.7805793285369873,
      "learning_rate": 0.0030848952847739495,
      "loss": 1.3035,
      "step": 35
    },
    {
      "epoch": 18.0,
      "grad_norm": 1.8321423530578613,
      "learning_rate": 0.0031730351500532054,
      "loss": 1.1907,
      "step": 36
    },
    {
      "epoch": 18.5,
      "grad_norm": 2.2486259937286377,
      "learning_rate": 0.0032611750153324613,
      "loss": 1.2405,
      "step": 37
    },
    {
      "epoch": 19.0,
      "grad_norm": 2.4165384769439697,
      "learning_rate": 0.0033493148806117167,
      "loss": 1.2847,
      "step": 38
    },
    {
      "epoch": 19.5,
      "grad_norm": 1.76555335521698,
      "learning_rate": 0.003437454745890972,
      "loss": 1.2315,
      "step": 39
    },
    {
      "epoch": 20.0,
      "grad_norm": 1.6580498218536377,
      "learning_rate": 0.003525594611170228,
      "loss": 1.2233,
      "step": 40
    },
    {
      "epoch": 20.5,
      "grad_norm": 1.2589101791381836,
      "learning_rate": 0.0036137344764494836,
      "loss": 1.2594,
      "step": 41
    },
    {
      "epoch": 21.0,
      "grad_norm": 2.722358226776123,
      "learning_rate": 0.0037018743417287395,
      "loss": 1.1747,
      "step": 42
    },
    {
      "epoch": 21.5,
      "grad_norm": 1.9618823528289795,
      "learning_rate": 0.003790014207007995,
      "loss": 1.133,
      "step": 43
    },
    {
      "epoch": 22.0,
      "grad_norm": 1.6243878602981567,
      "learning_rate": 0.0038781540722872512,
      "loss": 1.2904,
      "step": 44
    },
    {
      "epoch": 22.5,
      "grad_norm": 3.9437320232391357,
      "learning_rate": 0.003966293937566506,
      "loss": 1.2201,
      "step": 45
    },
    {
      "epoch": 23.0,
      "grad_norm": 2.415825843811035,
      "learning_rate": 0.004054433802845762,
      "loss": 1.2059,
      "step": 46
    },
    {
      "epoch": 23.5,
      "grad_norm": 1.4377561807632446,
      "learning_rate": 0.004142573668125018,
      "loss": 1.2488,
      "step": 47
    },
    {
      "epoch": 24.0,
      "grad_norm": 2.980923652648926,
      "learning_rate": 0.0042307135334042735,
      "loss": 1.1303,
      "step": 48
    },
    {
      "epoch": 24.5,
      "grad_norm": 2.826371192932129,
      "learning_rate": 0.00431885339868353,
      "loss": 1.1589,
      "step": 49
    },
    {
      "epoch": 25.0,
      "grad_norm": 2.024221658706665,
      "learning_rate": 0.004406993263962785,
      "loss": 1.1902,
      "step": 50
    },
    {
      "epoch": 25.5,
      "grad_norm": 1.4605275392532349,
      "learning_rate": 0.004495133129242041,
      "loss": 1.2002,
      "step": 51
    },
    {
      "epoch": 26.0,
      "grad_norm": 1.464632272720337,
      "learning_rate": 0.004583272994521296,
      "loss": 1.1641,
      "step": 52
    },
    {
      "epoch": 26.5,
      "grad_norm": 2.222102403640747,
      "learning_rate": 0.004671412859800552,
      "loss": 1.1755,
      "step": 53
    },
    {
      "epoch": 27.0,
      "grad_norm": 1.5530996322631836,
      "learning_rate": 0.004759552725079808,
      "loss": 1.1613,
      "step": 54
    },
    {
      "epoch": 27.5,
      "grad_norm": 1.3320385217666626,
      "learning_rate": 0.0048476925903590635,
      "loss": 1.2249,
      "step": 55
    },
    {
      "epoch": 28.0,
      "grad_norm": 4.543095588684082,
      "learning_rate": 0.004935832455638319,
      "loss": 1.1147,
      "step": 56
    },
    {
      "epoch": 28.5,
      "grad_norm": 3.2747161388397217,
      "learning_rate": 0.005023972320917575,
      "loss": 1.1742,
      "step": 57
    },
    {
      "epoch": 29.0,
      "grad_norm": 1.5359399318695068,
      "learning_rate": 0.005112112186196831,
      "loss": 1.14,
      "step": 58
    },
    {
      "epoch": 29.5,
      "grad_norm": 2.1936233043670654,
      "learning_rate": 0.005200252051476087,
      "loss": 1.138,
      "step": 59
    },
    {
      "epoch": 30.0,
      "grad_norm": 3.4043502807617188,
      "learning_rate": 0.005288391916755342,
      "loss": 1.2177,
      "step": 60
    },
    {
      "epoch": 30.5,
      "grad_norm": 1.4755144119262695,
      "learning_rate": 0.005376531782034597,
      "loss": 1.1629,
      "step": 61
    },
    {
      "epoch": 31.0,
      "grad_norm": 4.837053298950195,
      "learning_rate": 0.0054646716473138535,
      "loss": 1.2053,
      "step": 62
    },
    {
      "epoch": 31.5,
      "grad_norm": 2.8609611988067627,
      "learning_rate": 0.005552811512593109,
      "loss": 1.1255,
      "step": 63
    },
    {
      "epoch": 32.0,
      "grad_norm": 2.078521728515625,
      "learning_rate": 0.005640951377872365,
      "loss": 1.1755,
      "step": 64
    },
    {
      "epoch": 32.5,
      "grad_norm": 2.0839054584503174,
      "learning_rate": 0.005729091243151621,
      "loss": 1.1424,
      "step": 65
    },
    {
      "epoch": 33.0,
      "grad_norm": 3.6307435035705566,
      "learning_rate": 0.005817231108430876,
      "loss": 1.1779,
      "step": 66
    },
    {
      "epoch": 33.5,
      "grad_norm": 1.9358136653900146,
      "learning_rate": 0.0059053709737101326,
      "loss": 1.1094,
      "step": 67
    },
    {
      "epoch": 34.0,
      "grad_norm": 1.9237133264541626,
      "learning_rate": 0.005993510838989388,
      "loss": 1.1511,
      "step": 68
    },
    {
      "epoch": 34.5,
      "grad_norm": 1.4339723587036133,
      "learning_rate": 0.0060816507042686435,
      "loss": 1.1173,
      "step": 69
    },
    {
      "epoch": 35.0,
      "grad_norm": 2.3943796157836914,
      "learning_rate": 0.006169790569547899,
      "loss": 1.1303,
      "step": 70
    },
    {
      "epoch": 35.5,
      "grad_norm": 1.7234629392623901,
      "learning_rate": 0.006257930434827154,
      "loss": 1.122,
      "step": 71
    },
    {
      "epoch": 36.0,
      "grad_norm": 1.6056305170059204,
      "learning_rate": 0.006346070300106411,
      "loss": 1.0794,
      "step": 72
    },
    {
      "epoch": 36.5,
      "grad_norm": 2.24631667137146,
      "learning_rate": 0.006434210165385666,
      "loss": 1.153,
      "step": 73
    },
    {
      "epoch": 37.0,
      "grad_norm": 2.212739944458008,
      "learning_rate": 0.0065223500306649225,
      "loss": 1.0108,
      "step": 74
    },
    {
      "epoch": 37.5,
      "grad_norm": 1.7955176830291748,
      "learning_rate": 0.006610489895944178,
      "loss": 1.1038,
      "step": 75
    },
    {
      "epoch": 38.0,
      "grad_norm": 2.6313607692718506,
      "learning_rate": 0.0066986297612234335,
      "loss": 1.117,
      "step": 76
    },
    {
      "epoch": 38.5,
      "grad_norm": 2.155095338821411,
      "learning_rate": 0.006786769626502689,
      "loss": 1.0363,
      "step": 77
    },
    {
      "epoch": 39.0,
      "grad_norm": 1.9318841695785522,
      "learning_rate": 0.006874909491781944,
      "loss": 1.1466,
      "step": 78
    },
    {
      "epoch": 39.5,
      "grad_norm": 2.2020621299743652,
      "learning_rate": 0.006963049357061201,
      "loss": 1.0595,
      "step": 79
    },
    {
      "epoch": 40.0,
      "grad_norm": 2.1333987712860107,
      "learning_rate": 0.007051189222340456,
      "loss": 1.0807,
      "step": 80
    },
    {
      "epoch": 40.0,
      "eval_brier_0th_event": 0.21253976372242564,
      "eval_brier_0th_event_n": 262,
      "eval_brier_avg": 0.21253976372242564,
      "eval_brier_weighted_avg": 0.21253976372242564,
      "eval_ipcw": 0.6127840949732137,
      "eval_ipcw_0th_event": 0.6127840949732137,
      "eval_ipcw_0th_event_0.25": 0.6140305767857023,
      "eval_ipcw_0th_event_0.5": 0.6067987304588907,
      "eval_ipcw_0th_event_0.75": 0.6188724739361301,
      "eval_ipcw_0th_event_1.0": 0.6127840949732137,
      "eval_ipcw_0th_event_n": 262,
      "eval_ipcw_avg": 0.6131214690384842,
      "eval_ipcw_avg_0th_event": 0.6131214690384842,
      "eval_ipcw_weighted_avg": 0.6131214690384842,
      "eval_loss": 0.7871127724647522,
      "eval_runtime": 0.067,
      "eval_samples_per_second": 6629.54,
      "eval_steps_per_second": 14.931,
      "step": 80
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 19496217600.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
