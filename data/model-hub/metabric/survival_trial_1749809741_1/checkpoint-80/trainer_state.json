{
  "best_global_step": 80,
  "best_metric": 0.6167176096089955,
  "best_model_checkpoint": "./data/model-hub/metabric/survival_trial_1749809741_1/checkpoint-80",
  "epoch": 40.0,
  "eval_steps": 1,
  "global_step": 80,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 1.5313785076141357,
      "learning_rate": 5.2621133962866404e-05,
      "loss": 1.5949,
      "step": 1
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.6736993789672852,
      "learning_rate": 0.00010524226792573281,
      "loss": 1.5946,
      "step": 2
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.5991532802581787,
      "learning_rate": 0.0001578634018885992,
      "loss": 1.5971,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.3515504598617554,
      "learning_rate": 0.00021048453585146562,
      "loss": 1.5895,
      "step": 4
    },
    {
      "epoch": 2.5,
      "grad_norm": 1.4653464555740356,
      "learning_rate": 0.000263105669814332,
      "loss": 1.575,
      "step": 5
    },
    {
      "epoch": 3.0,
      "grad_norm": 1.1965136528015137,
      "learning_rate": 0.0003157268037771984,
      "loss": 1.6225,
      "step": 6
    },
    {
      "epoch": 3.5,
      "grad_norm": 1.2852872610092163,
      "learning_rate": 0.0003683479377400648,
      "loss": 1.5702,
      "step": 7
    },
    {
      "epoch": 4.0,
      "grad_norm": 1.5194823741912842,
      "learning_rate": 0.00042096907170293123,
      "loss": 1.5969,
      "step": 8
    },
    {
      "epoch": 4.5,
      "grad_norm": 1.4133161306381226,
      "learning_rate": 0.0004735902056657976,
      "loss": 1.58,
      "step": 9
    },
    {
      "epoch": 5.0,
      "grad_norm": 1.8834110498428345,
      "learning_rate": 0.000526211339628664,
      "loss": 1.5853,
      "step": 10
    },
    {
      "epoch": 5.5,
      "grad_norm": 1.794892430305481,
      "learning_rate": 0.0005788324735915305,
      "loss": 1.5428,
      "step": 11
    },
    {
      "epoch": 6.0,
      "grad_norm": 1.8442257642745972,
      "learning_rate": 0.0006314536075543968,
      "loss": 1.5827,
      "step": 12
    },
    {
      "epoch": 6.5,
      "grad_norm": 1.7054588794708252,
      "learning_rate": 0.0006840747415172633,
      "loss": 1.5717,
      "step": 13
    },
    {
      "epoch": 7.0,
      "grad_norm": 1.9949214458465576,
      "learning_rate": 0.0007366958754801296,
      "loss": 1.5316,
      "step": 14
    },
    {
      "epoch": 7.5,
      "grad_norm": 1.872527003288269,
      "learning_rate": 0.000789317009442996,
      "loss": 1.5551,
      "step": 15
    },
    {
      "epoch": 8.0,
      "grad_norm": 1.6219661235809326,
      "learning_rate": 0.0008419381434058625,
      "loss": 1.5421,
      "step": 16
    },
    {
      "epoch": 8.5,
      "grad_norm": 1.7682666778564453,
      "learning_rate": 0.0008945592773687287,
      "loss": 1.5315,
      "step": 17
    },
    {
      "epoch": 9.0,
      "grad_norm": 1.7388253211975098,
      "learning_rate": 0.0009471804113315952,
      "loss": 1.4998,
      "step": 18
    },
    {
      "epoch": 9.5,
      "grad_norm": 1.4872630834579468,
      "learning_rate": 0.0009998015452944615,
      "loss": 1.5162,
      "step": 19
    },
    {
      "epoch": 10.0,
      "grad_norm": 2.257903575897217,
      "learning_rate": 0.001052422679257328,
      "loss": 1.5304,
      "step": 20
    },
    {
      "epoch": 10.5,
      "grad_norm": 1.4885756969451904,
      "learning_rate": 0.0011050438132201945,
      "loss": 1.5051,
      "step": 21
    },
    {
      "epoch": 11.0,
      "grad_norm": 1.770351767539978,
      "learning_rate": 0.001157664947183061,
      "loss": 1.4934,
      "step": 22
    },
    {
      "epoch": 11.5,
      "grad_norm": 1.5117288827896118,
      "learning_rate": 0.001210286081145927,
      "loss": 1.5002,
      "step": 23
    },
    {
      "epoch": 12.0,
      "grad_norm": 1.705562710762024,
      "learning_rate": 0.0012629072151087936,
      "loss": 1.4741,
      "step": 24
    },
    {
      "epoch": 12.5,
      "grad_norm": 1.5237324237823486,
      "learning_rate": 0.00131552834907166,
      "loss": 1.4866,
      "step": 25
    },
    {
      "epoch": 13.0,
      "grad_norm": 1.575816035270691,
      "learning_rate": 0.0013681494830345266,
      "loss": 1.4574,
      "step": 26
    },
    {
      "epoch": 13.5,
      "grad_norm": 1.4097751379013062,
      "learning_rate": 0.0014207706169973929,
      "loss": 1.4851,
      "step": 27
    },
    {
      "epoch": 14.0,
      "grad_norm": 1.5386428833007812,
      "learning_rate": 0.0014733917509602591,
      "loss": 1.4028,
      "step": 28
    },
    {
      "epoch": 14.5,
      "grad_norm": 1.3385792970657349,
      "learning_rate": 0.0015260128849231256,
      "loss": 1.4496,
      "step": 29
    },
    {
      "epoch": 15.0,
      "grad_norm": 1.2610042095184326,
      "learning_rate": 0.001578634018885992,
      "loss": 1.4113,
      "step": 30
    },
    {
      "epoch": 15.5,
      "grad_norm": 0.9291533827781677,
      "learning_rate": 0.0016312551528488584,
      "loss": 1.4398,
      "step": 31
    },
    {
      "epoch": 16.0,
      "grad_norm": 2.0250446796417236,
      "learning_rate": 0.001683876286811725,
      "loss": 1.3838,
      "step": 32
    },
    {
      "epoch": 16.5,
      "grad_norm": 1.1691986322402954,
      "learning_rate": 0.0017364974207745912,
      "loss": 1.4374,
      "step": 33
    },
    {
      "epoch": 17.0,
      "grad_norm": 1.2781217098236084,
      "learning_rate": 0.0017891185547374575,
      "loss": 1.3136,
      "step": 34
    },
    {
      "epoch": 17.5,
      "grad_norm": 1.1903001070022583,
      "learning_rate": 0.001841739688700324,
      "loss": 1.3673,
      "step": 35
    },
    {
      "epoch": 18.0,
      "grad_norm": 1.908237338066101,
      "learning_rate": 0.0018943608226631905,
      "loss": 1.3561,
      "step": 36
    },
    {
      "epoch": 18.5,
      "grad_norm": 1.0865997076034546,
      "learning_rate": 0.001946981956626057,
      "loss": 1.3194,
      "step": 37
    },
    {
      "epoch": 19.0,
      "grad_norm": 1.5937997102737427,
      "learning_rate": 0.001999603090588923,
      "loss": 1.3715,
      "step": 38
    },
    {
      "epoch": 19.5,
      "grad_norm": 1.3111512660980225,
      "learning_rate": 0.0020522242245517896,
      "loss": 1.3799,
      "step": 39
    },
    {
      "epoch": 20.0,
      "grad_norm": 1.5648640394210815,
      "learning_rate": 0.002104845358514656,
      "loss": 1.2821,
      "step": 40
    },
    {
      "epoch": 20.5,
      "grad_norm": 1.096530795097351,
      "learning_rate": 0.002157466492477522,
      "loss": 1.3376,
      "step": 41
    },
    {
      "epoch": 21.0,
      "grad_norm": 1.7514212131500244,
      "learning_rate": 0.002210087626440389,
      "loss": 1.3118,
      "step": 42
    },
    {
      "epoch": 21.5,
      "grad_norm": 1.412398338317871,
      "learning_rate": 0.002262708760403255,
      "loss": 1.3302,
      "step": 43
    },
    {
      "epoch": 22.0,
      "grad_norm": 2.2428784370422363,
      "learning_rate": 0.002315329894366122,
      "loss": 1.2693,
      "step": 44
    },
    {
      "epoch": 22.5,
      "grad_norm": 1.1453588008880615,
      "learning_rate": 0.002367951028328988,
      "loss": 1.3102,
      "step": 45
    },
    {
      "epoch": 23.0,
      "grad_norm": 1.904343605041504,
      "learning_rate": 0.002420572162291854,
      "loss": 1.2968,
      "step": 46
    },
    {
      "epoch": 23.5,
      "grad_norm": 1.4863356351852417,
      "learning_rate": 0.002473193296254721,
      "loss": 1.274,
      "step": 47
    },
    {
      "epoch": 24.0,
      "grad_norm": 1.5057168006896973,
      "learning_rate": 0.002525814430217587,
      "loss": 1.3533,
      "step": 48
    },
    {
      "epoch": 24.5,
      "grad_norm": 1.7790255546569824,
      "learning_rate": 0.0025784355641804537,
      "loss": 1.2597,
      "step": 49
    },
    {
      "epoch": 25.0,
      "grad_norm": 1.9287220239639282,
      "learning_rate": 0.00263105669814332,
      "loss": 1.2738,
      "step": 50
    },
    {
      "epoch": 25.5,
      "grad_norm": 1.6958030462265015,
      "learning_rate": 0.0026836778321061862,
      "loss": 1.2497,
      "step": 51
    },
    {
      "epoch": 26.0,
      "grad_norm": 1.3159223794937134,
      "learning_rate": 0.002736298966069053,
      "loss": 1.3068,
      "step": 52
    },
    {
      "epoch": 26.5,
      "grad_norm": 1.325257420539856,
      "learning_rate": 0.0027889201000319192,
      "loss": 1.3054,
      "step": 53
    },
    {
      "epoch": 27.0,
      "grad_norm": 1.2474697828292847,
      "learning_rate": 0.0028415412339947857,
      "loss": 1.2001,
      "step": 54
    },
    {
      "epoch": 27.5,
      "grad_norm": 1.2622326612472534,
      "learning_rate": 0.0028941623679576522,
      "loss": 1.2924,
      "step": 55
    },
    {
      "epoch": 28.0,
      "grad_norm": 1.3384093046188354,
      "learning_rate": 0.0029467835019205183,
      "loss": 1.1947,
      "step": 56
    },
    {
      "epoch": 28.5,
      "grad_norm": 0.8474158644676208,
      "learning_rate": 0.002999404635883385,
      "loss": 1.2339,
      "step": 57
    },
    {
      "epoch": 29.0,
      "grad_norm": 2.035665273666382,
      "learning_rate": 0.0030520257698462513,
      "loss": 1.2926,
      "step": 58
    },
    {
      "epoch": 29.5,
      "grad_norm": 1.2726415395736694,
      "learning_rate": 0.003104646903809118,
      "loss": 1.2094,
      "step": 59
    },
    {
      "epoch": 30.0,
      "grad_norm": 1.29910147190094,
      "learning_rate": 0.003157268037771984,
      "loss": 1.28,
      "step": 60
    },
    {
      "epoch": 30.5,
      "grad_norm": 1.0854421854019165,
      "learning_rate": 0.0032098891717348504,
      "loss": 1.1948,
      "step": 61
    },
    {
      "epoch": 31.0,
      "grad_norm": 1.2798765897750854,
      "learning_rate": 0.003262510305697717,
      "loss": 1.2464,
      "step": 62
    },
    {
      "epoch": 31.5,
      "grad_norm": 1.2591561079025269,
      "learning_rate": 0.0033151314396605834,
      "loss": 1.1897,
      "step": 63
    },
    {
      "epoch": 32.0,
      "grad_norm": 1.8973360061645508,
      "learning_rate": 0.00336775257362345,
      "loss": 1.2579,
      "step": 64
    },
    {
      "epoch": 32.5,
      "grad_norm": 1.3929282426834106,
      "learning_rate": 0.003420373707586316,
      "loss": 1.1938,
      "step": 65
    },
    {
      "epoch": 33.0,
      "grad_norm": 1.823455810546875,
      "learning_rate": 0.0034729948415491824,
      "loss": 1.2155,
      "step": 66
    },
    {
      "epoch": 33.5,
      "grad_norm": 1.8586182594299316,
      "learning_rate": 0.003525615975512049,
      "loss": 1.2078,
      "step": 67
    },
    {
      "epoch": 34.0,
      "grad_norm": 2.9244139194488525,
      "learning_rate": 0.003578237109474915,
      "loss": 1.2574,
      "step": 68
    },
    {
      "epoch": 34.5,
      "grad_norm": 1.4479607343673706,
      "learning_rate": 0.003630858243437782,
      "loss": 1.192,
      "step": 69
    },
    {
      "epoch": 35.0,
      "grad_norm": 2.084010601043701,
      "learning_rate": 0.003683479377400648,
      "loss": 1.205,
      "step": 70
    },
    {
      "epoch": 35.5,
      "grad_norm": 1.2117563486099243,
      "learning_rate": 0.0037361005113635145,
      "loss": 1.1834,
      "step": 71
    },
    {
      "epoch": 36.0,
      "grad_norm": 1.6434131860733032,
      "learning_rate": 0.003788721645326381,
      "loss": 1.2026,
      "step": 72
    },
    {
      "epoch": 36.5,
      "grad_norm": 1.242612600326538,
      "learning_rate": 0.003841342779289247,
      "loss": 1.1761,
      "step": 73
    },
    {
      "epoch": 37.0,
      "grad_norm": 1.129878282546997,
      "learning_rate": 0.003893963913252114,
      "loss": 1.1691,
      "step": 74
    },
    {
      "epoch": 37.5,
      "grad_norm": 1.1057640314102173,
      "learning_rate": 0.00394658504721498,
      "loss": 1.1813,
      "step": 75
    },
    {
      "epoch": 38.0,
      "grad_norm": 1.2824718952178955,
      "learning_rate": 0.003999206181177846,
      "loss": 1.1688,
      "step": 76
    },
    {
      "epoch": 38.5,
      "grad_norm": 1.2043735980987549,
      "learning_rate": 0.004051827315140713,
      "loss": 1.1845,
      "step": 77
    },
    {
      "epoch": 39.0,
      "grad_norm": 1.5341243743896484,
      "learning_rate": 0.004104448449103579,
      "loss": 1.19,
      "step": 78
    },
    {
      "epoch": 39.5,
      "grad_norm": 0.9688190221786499,
      "learning_rate": 0.004157069583066446,
      "loss": 1.145,
      "step": 79
    },
    {
      "epoch": 40.0,
      "grad_norm": 1.1618564128875732,
      "learning_rate": 0.004209690717029312,
      "loss": 1.1687,
      "step": 80
    },
    {
      "epoch": 40.0,
      "eval_brier_0th_event": 0.21188631653785706,
      "eval_brier_0th_event_n": 278,
      "eval_brier_weighted_avg": 0.21188631653785706,
      "eval_ipcw_0th_event": 0.6167176096089955,
      "eval_ipcw_0th_event_0.25": 0.5983949899673462,
      "eval_ipcw_0th_event_0.50": 0.6182572245597839,
      "eval_ipcw_0th_event_0.75": 0.630133867263794,
      "eval_ipcw_0th_event_1.00": 0.6109892129898071,
      "eval_ipcw_0th_event_n": 453,
      "eval_ipcw_weighted_avg": 0.6167176096089955,
      "eval_loss": 0.7384442687034607,
      "eval_runtime": 0.1671,
      "eval_samples_per_second": 2710.612,
      "eval_steps_per_second": 5.984,
      "step": 80
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 21139622400.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
