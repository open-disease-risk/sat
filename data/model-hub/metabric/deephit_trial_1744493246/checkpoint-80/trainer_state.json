{
  "best_global_step": 80,
  "best_metric": 0.6079862263664484,
  "best_model_checkpoint": "./data/model-hub/metabric/deephit_trial_1744493246/checkpoint-80",
  "epoch": 40.0,
  "eval_steps": 1,
  "global_step": 80,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 1.5255897045135498,
      "learning_rate": 3.798242171584479e-05,
      "loss": 6.3001,
      "step": 1
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.5513793230056763,
      "learning_rate": 7.596484343168958e-05,
      "loss": 6.1846,
      "step": 2
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.53994882106781,
      "learning_rate": 0.00011394726514753435,
      "loss": 5.455,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.7642550468444824,
      "learning_rate": 0.00015192968686337916,
      "loss": 5.5291,
      "step": 4
    },
    {
      "epoch": 2.5,
      "grad_norm": 1.7885339260101318,
      "learning_rate": 0.00018991210857922393,
      "loss": 5.2747,
      "step": 5
    },
    {
      "epoch": 3.0,
      "grad_norm": 2.0583889484405518,
      "learning_rate": 0.0002278945302950687,
      "loss": 4.9839,
      "step": 6
    },
    {
      "epoch": 3.5,
      "grad_norm": 1.9766242504119873,
      "learning_rate": 0.0002658769520109135,
      "loss": 5.1779,
      "step": 7
    },
    {
      "epoch": 4.0,
      "grad_norm": 2.1635727882385254,
      "learning_rate": 0.0003038593737267583,
      "loss": 5.0764,
      "step": 8
    },
    {
      "epoch": 4.5,
      "grad_norm": 2.2288331985473633,
      "learning_rate": 0.00034184179544260307,
      "loss": 5.3065,
      "step": 9
    },
    {
      "epoch": 5.0,
      "grad_norm": 2.5478267669677734,
      "learning_rate": 0.00037982421715844787,
      "loss": 5.1534,
      "step": 10
    },
    {
      "epoch": 5.5,
      "grad_norm": 2.62861704826355,
      "learning_rate": 0.00041780663887429267,
      "loss": 5.2937,
      "step": 11
    },
    {
      "epoch": 6.0,
      "grad_norm": 2.6209566593170166,
      "learning_rate": 0.0004557890605901374,
      "loss": 5.3805,
      "step": 12
    },
    {
      "epoch": 6.5,
      "grad_norm": 2.4807276725769043,
      "learning_rate": 0.0004937714823059822,
      "loss": 5.4005,
      "step": 13
    },
    {
      "epoch": 7.0,
      "grad_norm": 2.71641206741333,
      "learning_rate": 0.000531753904021827,
      "loss": 5.6184,
      "step": 14
    },
    {
      "epoch": 7.5,
      "grad_norm": 2.891503095626831,
      "learning_rate": 0.0005697363257376718,
      "loss": 5.5793,
      "step": 15
    },
    {
      "epoch": 8.0,
      "grad_norm": 2.384077787399292,
      "learning_rate": 0.0006077187474535167,
      "loss": 5.5318,
      "step": 16
    },
    {
      "epoch": 8.5,
      "grad_norm": 2.8944435119628906,
      "learning_rate": 0.0006457011691693614,
      "loss": 5.7677,
      "step": 17
    },
    {
      "epoch": 9.0,
      "grad_norm": 3.749778985977173,
      "learning_rate": 0.0006836835908852061,
      "loss": 5.4257,
      "step": 18
    },
    {
      "epoch": 9.5,
      "grad_norm": 3.476313591003418,
      "learning_rate": 0.0007216660126010509,
      "loss": 5.7613,
      "step": 19
    },
    {
      "epoch": 10.0,
      "grad_norm": 3.813936471939087,
      "learning_rate": 0.0007596484343168957,
      "loss": 5.8743,
      "step": 20
    },
    {
      "epoch": 10.5,
      "grad_norm": 4.1546454429626465,
      "learning_rate": 0.0007976308560327406,
      "loss": 5.9081,
      "step": 21
    },
    {
      "epoch": 11.0,
      "grad_norm": 3.6762826442718506,
      "learning_rate": 0.0008356132777485853,
      "loss": 5.6623,
      "step": 22
    },
    {
      "epoch": 11.5,
      "grad_norm": 3.7142770290374756,
      "learning_rate": 0.0008735956994644301,
      "loss": 5.8641,
      "step": 23
    },
    {
      "epoch": 12.0,
      "grad_norm": 3.5251669883728027,
      "learning_rate": 0.0009115781211802748,
      "loss": 5.9276,
      "step": 24
    },
    {
      "epoch": 12.5,
      "grad_norm": 3.2395777702331543,
      "learning_rate": 0.0009495605428961197,
      "loss": 5.9206,
      "step": 25
    },
    {
      "epoch": 13.0,
      "grad_norm": 3.024953842163086,
      "learning_rate": 0.0009875429646119644,
      "loss": 5.833,
      "step": 26
    },
    {
      "epoch": 13.5,
      "grad_norm": 3.156162738800049,
      "learning_rate": 0.0010255253863278094,
      "loss": 5.9165,
      "step": 27
    },
    {
      "epoch": 14.0,
      "grad_norm": 3.3610851764678955,
      "learning_rate": 0.001063507808043654,
      "loss": 5.9671,
      "step": 28
    },
    {
      "epoch": 14.5,
      "grad_norm": 3.04689359664917,
      "learning_rate": 0.0011014902297594989,
      "loss": 5.9689,
      "step": 29
    },
    {
      "epoch": 15.0,
      "grad_norm": 3.496288537979126,
      "learning_rate": 0.0011394726514753436,
      "loss": 5.7925,
      "step": 30
    },
    {
      "epoch": 15.5,
      "grad_norm": 3.388981819152832,
      "learning_rate": 0.0011774550731911883,
      "loss": 5.8499,
      "step": 31
    },
    {
      "epoch": 16.0,
      "grad_norm": 3.2738051414489746,
      "learning_rate": 0.0012154374949070333,
      "loss": 5.9905,
      "step": 32
    },
    {
      "epoch": 16.5,
      "grad_norm": 3.504272222518921,
      "learning_rate": 0.0012534199166228778,
      "loss": 5.8272,
      "step": 33
    },
    {
      "epoch": 17.0,
      "grad_norm": 3.2790377140045166,
      "learning_rate": 0.0012914023383387228,
      "loss": 5.9601,
      "step": 34
    },
    {
      "epoch": 17.5,
      "grad_norm": 3.8430533409118652,
      "learning_rate": 0.0013293847600545675,
      "loss": 5.8748,
      "step": 35
    },
    {
      "epoch": 18.0,
      "grad_norm": 3.24021315574646,
      "learning_rate": 0.0013673671817704123,
      "loss": 5.8756,
      "step": 36
    },
    {
      "epoch": 18.5,
      "grad_norm": 3.353882312774658,
      "learning_rate": 0.0014053496034862572,
      "loss": 5.7971,
      "step": 37
    },
    {
      "epoch": 19.0,
      "grad_norm": 3.5897560119628906,
      "learning_rate": 0.0014433320252021018,
      "loss": 5.9912,
      "step": 38
    },
    {
      "epoch": 19.5,
      "grad_norm": 3.1269350051879883,
      "learning_rate": 0.0014813144469179467,
      "loss": 5.9379,
      "step": 39
    },
    {
      "epoch": 20.0,
      "grad_norm": 3.7829878330230713,
      "learning_rate": 0.0015192968686337915,
      "loss": 5.7313,
      "step": 40
    },
    {
      "epoch": 20.5,
      "grad_norm": 5.203305721282959,
      "learning_rate": 0.0015572792903496362,
      "loss": 5.927,
      "step": 41
    },
    {
      "epoch": 21.0,
      "grad_norm": 4.7021942138671875,
      "learning_rate": 0.0015952617120654812,
      "loss": 5.8605,
      "step": 42
    },
    {
      "epoch": 21.5,
      "grad_norm": 4.306343078613281,
      "learning_rate": 0.0016332441337813257,
      "loss": 5.8664,
      "step": 43
    },
    {
      "epoch": 22.0,
      "grad_norm": 6.188444137573242,
      "learning_rate": 0.0016712265554971707,
      "loss": 5.7706,
      "step": 44
    },
    {
      "epoch": 22.5,
      "grad_norm": 5.062182426452637,
      "learning_rate": 0.0017092089772130154,
      "loss": 5.8191,
      "step": 45
    },
    {
      "epoch": 23.0,
      "grad_norm": 4.681102275848389,
      "learning_rate": 0.0017471913989288601,
      "loss": 6.0857,
      "step": 46
    },
    {
      "epoch": 23.5,
      "grad_norm": 4.842653751373291,
      "learning_rate": 0.0017851738206447051,
      "loss": 5.7313,
      "step": 47
    },
    {
      "epoch": 24.0,
      "grad_norm": 6.010995864868164,
      "learning_rate": 0.0018231562423605496,
      "loss": 6.0753,
      "step": 48
    },
    {
      "epoch": 24.5,
      "grad_norm": 6.089902400970459,
      "learning_rate": 0.0018611386640763946,
      "loss": 5.7883,
      "step": 49
    },
    {
      "epoch": 25.0,
      "grad_norm": 7.059362411499023,
      "learning_rate": 0.0018991210857922393,
      "loss": 5.9019,
      "step": 50
    },
    {
      "epoch": 25.5,
      "grad_norm": 4.999477386474609,
      "learning_rate": 0.001937103507508084,
      "loss": 5.8961,
      "step": 51
    },
    {
      "epoch": 26.0,
      "grad_norm": 6.923664569854736,
      "learning_rate": 0.001975085929223929,
      "loss": 5.8902,
      "step": 52
    },
    {
      "epoch": 26.5,
      "grad_norm": 5.430113315582275,
      "learning_rate": 0.0020130683509397736,
      "loss": 5.8725,
      "step": 53
    },
    {
      "epoch": 27.0,
      "grad_norm": 7.233638763427734,
      "learning_rate": 0.0020510507726556187,
      "loss": 6.0279,
      "step": 54
    },
    {
      "epoch": 27.5,
      "grad_norm": 5.1461262702941895,
      "learning_rate": 0.002089033194371463,
      "loss": 5.8936,
      "step": 55
    },
    {
      "epoch": 28.0,
      "grad_norm": 5.608817100524902,
      "learning_rate": 0.002127015616087308,
      "loss": 6.0185,
      "step": 56
    },
    {
      "epoch": 28.5,
      "grad_norm": 4.717619895935059,
      "learning_rate": 0.002164998037803153,
      "loss": 5.9255,
      "step": 57
    },
    {
      "epoch": 29.0,
      "grad_norm": 7.3313469886779785,
      "learning_rate": 0.0022029804595189977,
      "loss": 6.0324,
      "step": 58
    },
    {
      "epoch": 29.5,
      "grad_norm": 4.930513381958008,
      "learning_rate": 0.0022409628812348425,
      "loss": 5.9069,
      "step": 59
    },
    {
      "epoch": 30.0,
      "grad_norm": 6.843056678771973,
      "learning_rate": 0.002278945302950687,
      "loss": 6.0137,
      "step": 60
    },
    {
      "epoch": 30.5,
      "grad_norm": 6.976632118225098,
      "learning_rate": 0.002316927724666532,
      "loss": 5.9982,
      "step": 61
    },
    {
      "epoch": 31.0,
      "grad_norm": 6.044989109039307,
      "learning_rate": 0.0023549101463823767,
      "loss": 5.8999,
      "step": 62
    },
    {
      "epoch": 31.5,
      "grad_norm": 5.476347923278809,
      "learning_rate": 0.0023928925680982214,
      "loss": 6.0638,
      "step": 63
    },
    {
      "epoch": 32.0,
      "grad_norm": 7.056601047515869,
      "learning_rate": 0.0024308749898140666,
      "loss": 5.7679,
      "step": 64
    },
    {
      "epoch": 32.5,
      "grad_norm": 5.022063255310059,
      "learning_rate": 0.0024688574115299114,
      "loss": 6.0511,
      "step": 65
    },
    {
      "epoch": 33.0,
      "grad_norm": 8.147419929504395,
      "learning_rate": 0.0025068398332457557,
      "loss": 5.7947,
      "step": 66
    },
    {
      "epoch": 33.5,
      "grad_norm": 5.118597030639648,
      "learning_rate": 0.002544822254961601,
      "loss": 5.8873,
      "step": 67
    },
    {
      "epoch": 34.0,
      "grad_norm": 7.928589820861816,
      "learning_rate": 0.0025828046766774456,
      "loss": 6.1808,
      "step": 68
    },
    {
      "epoch": 34.5,
      "grad_norm": 5.662485122680664,
      "learning_rate": 0.0026207870983932903,
      "loss": 6.0501,
      "step": 69
    },
    {
      "epoch": 35.0,
      "grad_norm": 11.195792198181152,
      "learning_rate": 0.002658769520109135,
      "loss": 5.8491,
      "step": 70
    },
    {
      "epoch": 35.5,
      "grad_norm": 5.844549655914307,
      "learning_rate": 0.00269675194182498,
      "loss": 5.8906,
      "step": 71
    },
    {
      "epoch": 36.0,
      "grad_norm": 6.940743446350098,
      "learning_rate": 0.0027347343635408246,
      "loss": 6.1398,
      "step": 72
    },
    {
      "epoch": 36.5,
      "grad_norm": 5.027975082397461,
      "learning_rate": 0.0027727167852566693,
      "loss": 5.9764,
      "step": 73
    },
    {
      "epoch": 37.0,
      "grad_norm": 8.336153984069824,
      "learning_rate": 0.0028106992069725145,
      "loss": 5.861,
      "step": 74
    },
    {
      "epoch": 37.5,
      "grad_norm": 6.3341755867004395,
      "learning_rate": 0.002848681628688359,
      "loss": 5.8615,
      "step": 75
    },
    {
      "epoch": 38.0,
      "grad_norm": 4.747546672821045,
      "learning_rate": 0.0028866640504042035,
      "loss": 6.358,
      "step": 76
    },
    {
      "epoch": 38.5,
      "grad_norm": 5.425849914550781,
      "learning_rate": 0.0029246464721200487,
      "loss": 5.6143,
      "step": 77
    },
    {
      "epoch": 39.0,
      "grad_norm": 5.632707595825195,
      "learning_rate": 0.0029626288938358935,
      "loss": 6.2498,
      "step": 78
    },
    {
      "epoch": 39.5,
      "grad_norm": 4.971399307250977,
      "learning_rate": 0.003000611315551738,
      "loss": 6.0309,
      "step": 79
    },
    {
      "epoch": 40.0,
      "grad_norm": 8.030517578125,
      "learning_rate": 0.003038593737267583,
      "loss": 5.6358,
      "step": 80
    },
    {
      "epoch": 40.0,
      "eval_brier_0th_event": 0.19429969534699582,
      "eval_brier_0th_event_n": 255,
      "eval_brier_avg": 0.19429969534699582,
      "eval_brier_weighted_avg": 0.19429969534699582,
      "eval_ipcw": 0.6182678706667317,
      "eval_ipcw_0th_event": 0.6182678706667317,
      "eval_ipcw_0th_event_0.25": 0.5953636295434951,
      "eval_ipcw_0th_event_0.5": 0.6047147689909028,
      "eval_ipcw_0th_event_0.75": 0.6135986362646643,
      "eval_ipcw_0th_event_1.0": 0.6182678706667317,
      "eval_ipcw_0th_event_n": 255,
      "eval_ipcw_avg": 0.6079862263664484,
      "eval_ipcw_avg_0th_event": 0.6079862263664484,
      "eval_ipcw_weighted_avg": 0.6079862263664484,
      "eval_loss": 3.233995199203491,
      "eval_runtime": 0.1067,
      "eval_samples_per_second": 4159.947,
      "eval_steps_per_second": 9.369,
      "step": 80
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 19496217600.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
