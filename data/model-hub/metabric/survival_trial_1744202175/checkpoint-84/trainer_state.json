{
  "best_global_step": 84,
  "best_metric": 0.6171751118413159,
  "best_model_checkpoint": "./data/model-hub/metabric/survival_trial_1744202175/checkpoint-84",
  "epoch": 42.0,
  "eval_steps": 1,
  "global_step": 84,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 2.120203733444214,
      "learning_rate": 9.266945127284567e-05,
      "loss": 1.5733,
      "step": 1
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.767135500907898,
      "learning_rate": 0.00018533890254569135,
      "loss": 1.6579,
      "step": 2
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.7830559015274048,
      "learning_rate": 0.000278008353818537,
      "loss": 1.5689,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 2.0250847339630127,
      "learning_rate": 0.0003706778050913827,
      "loss": 1.6572,
      "step": 4
    },
    {
      "epoch": 2.5,
      "grad_norm": 1.5975769758224487,
      "learning_rate": 0.00046334725636422837,
      "loss": 1.5897,
      "step": 5
    },
    {
      "epoch": 3.0,
      "grad_norm": 2.115490674972534,
      "learning_rate": 0.000556016707637074,
      "loss": 1.5636,
      "step": 6
    },
    {
      "epoch": 3.5,
      "grad_norm": 1.7238963842391968,
      "learning_rate": 0.0006486861589099197,
      "loss": 1.5665,
      "step": 7
    },
    {
      "epoch": 4.0,
      "grad_norm": 2.3254237174987793,
      "learning_rate": 0.0007413556101827654,
      "loss": 1.5978,
      "step": 8
    },
    {
      "epoch": 4.5,
      "grad_norm": 2.203460454940796,
      "learning_rate": 0.0008340250614556111,
      "loss": 1.5443,
      "step": 9
    },
    {
      "epoch": 5.0,
      "grad_norm": 2.71601939201355,
      "learning_rate": 0.0009266945127284567,
      "loss": 1.5946,
      "step": 10
    },
    {
      "epoch": 5.5,
      "grad_norm": 2.7243549823760986,
      "learning_rate": 0.0010193639640013025,
      "loss": 1.5563,
      "step": 11
    },
    {
      "epoch": 6.0,
      "grad_norm": 2.5413293838500977,
      "learning_rate": 0.001112033415274148,
      "loss": 1.5176,
      "step": 12
    },
    {
      "epoch": 6.5,
      "grad_norm": 2.9416072368621826,
      "learning_rate": 0.0012047028665469939,
      "loss": 1.5234,
      "step": 13
    },
    {
      "epoch": 7.0,
      "grad_norm": 2.318378210067749,
      "learning_rate": 0.0012973723178198394,
      "loss": 1.5357,
      "step": 14
    },
    {
      "epoch": 7.5,
      "grad_norm": 2.5831680297851562,
      "learning_rate": 0.0013900417690926852,
      "loss": 1.4548,
      "step": 15
    },
    {
      "epoch": 8.0,
      "grad_norm": 2.6023850440979004,
      "learning_rate": 0.0014827112203655308,
      "loss": 1.5276,
      "step": 16
    },
    {
      "epoch": 8.5,
      "grad_norm": 2.879880905151367,
      "learning_rate": 0.0015753806716383763,
      "loss": 1.5196,
      "step": 17
    },
    {
      "epoch": 9.0,
      "grad_norm": 2.034212827682495,
      "learning_rate": 0.0016680501229112221,
      "loss": 1.3937,
      "step": 18
    },
    {
      "epoch": 9.5,
      "grad_norm": 2.16511869430542,
      "learning_rate": 0.0017607195741840677,
      "loss": 1.4373,
      "step": 19
    },
    {
      "epoch": 10.0,
      "grad_norm": 2.8363356590270996,
      "learning_rate": 0.0018533890254569135,
      "loss": 1.4123,
      "step": 20
    },
    {
      "epoch": 10.5,
      "grad_norm": 1.9967707395553589,
      "learning_rate": 0.0019460584767297593,
      "loss": 1.3676,
      "step": 21
    },
    {
      "epoch": 11.0,
      "grad_norm": 2.7962281703948975,
      "learning_rate": 0.002038727928002605,
      "loss": 1.4664,
      "step": 22
    },
    {
      "epoch": 11.5,
      "grad_norm": 1.6769824028015137,
      "learning_rate": 0.00213139737927545,
      "loss": 1.4016,
      "step": 23
    },
    {
      "epoch": 12.0,
      "grad_norm": 1.4207050800323486,
      "learning_rate": 0.002224066830548296,
      "loss": 1.37,
      "step": 24
    },
    {
      "epoch": 12.5,
      "grad_norm": 1.2113409042358398,
      "learning_rate": 0.0023167362818211417,
      "loss": 1.376,
      "step": 25
    },
    {
      "epoch": 13.0,
      "grad_norm": 1.5785447359085083,
      "learning_rate": 0.0024094057330939877,
      "loss": 1.3522,
      "step": 26
    },
    {
      "epoch": 13.5,
      "grad_norm": 1.6477229595184326,
      "learning_rate": 0.0025020751843668333,
      "loss": 1.3689,
      "step": 27
    },
    {
      "epoch": 14.0,
      "grad_norm": 2.7805774211883545,
      "learning_rate": 0.002594744635639679,
      "loss": 1.3367,
      "step": 28
    },
    {
      "epoch": 14.5,
      "grad_norm": 1.8744406700134277,
      "learning_rate": 0.0026874140869125244,
      "loss": 1.3772,
      "step": 29
    },
    {
      "epoch": 15.0,
      "grad_norm": 3.491992950439453,
      "learning_rate": 0.0027800835381853704,
      "loss": 1.2791,
      "step": 30
    },
    {
      "epoch": 15.5,
      "grad_norm": 2.518373966217041,
      "learning_rate": 0.002872752989458216,
      "loss": 1.3114,
      "step": 31
    },
    {
      "epoch": 16.0,
      "grad_norm": 2.2225821018218994,
      "learning_rate": 0.0029654224407310616,
      "loss": 1.3074,
      "step": 32
    },
    {
      "epoch": 16.5,
      "grad_norm": 2.314483165740967,
      "learning_rate": 0.003058091892003907,
      "loss": 1.2691,
      "step": 33
    },
    {
      "epoch": 17.0,
      "grad_norm": 1.9718114137649536,
      "learning_rate": 0.0031507613432767527,
      "loss": 1.2894,
      "step": 34
    },
    {
      "epoch": 17.5,
      "grad_norm": 1.5945607423782349,
      "learning_rate": 0.0032434307945495987,
      "loss": 1.2648,
      "step": 35
    },
    {
      "epoch": 18.0,
      "grad_norm": 2.9238569736480713,
      "learning_rate": 0.0033361002458224443,
      "loss": 1.272,
      "step": 36
    },
    {
      "epoch": 18.5,
      "grad_norm": 1.7067043781280518,
      "learning_rate": 0.0034287696970952903,
      "loss": 1.2354,
      "step": 37
    },
    {
      "epoch": 19.0,
      "grad_norm": 2.2813720703125,
      "learning_rate": 0.0035214391483681354,
      "loss": 1.2491,
      "step": 38
    },
    {
      "epoch": 19.5,
      "grad_norm": 1.6790876388549805,
      "learning_rate": 0.0036141085996409814,
      "loss": 1.1727,
      "step": 39
    },
    {
      "epoch": 20.0,
      "grad_norm": 3.318389892578125,
      "learning_rate": 0.003706778050913827,
      "loss": 1.2771,
      "step": 40
    },
    {
      "epoch": 20.5,
      "grad_norm": 2.4116902351379395,
      "learning_rate": 0.003799447502186672,
      "loss": 1.1658,
      "step": 41
    },
    {
      "epoch": 21.0,
      "grad_norm": 3.1964359283447266,
      "learning_rate": 0.0038921169534595185,
      "loss": 1.2821,
      "step": 42
    },
    {
      "epoch": 21.5,
      "grad_norm": 3.014986753463745,
      "learning_rate": 0.003984786404732364,
      "loss": 1.2229,
      "step": 43
    },
    {
      "epoch": 22.0,
      "grad_norm": 2.9062747955322266,
      "learning_rate": 0.00407745585600521,
      "loss": 1.1545,
      "step": 44
    },
    {
      "epoch": 22.5,
      "grad_norm": 3.777540683746338,
      "learning_rate": 0.004170125307278056,
      "loss": 1.2344,
      "step": 45
    },
    {
      "epoch": 23.0,
      "grad_norm": 3.909250020980835,
      "learning_rate": 0.0042627947585509,
      "loss": 1.139,
      "step": 46
    },
    {
      "epoch": 23.5,
      "grad_norm": 2.5889883041381836,
      "learning_rate": 0.004355464209823747,
      "loss": 1.1332,
      "step": 47
    },
    {
      "epoch": 24.0,
      "grad_norm": 2.765646457672119,
      "learning_rate": 0.004448133661096592,
      "loss": 1.2873,
      "step": 48
    },
    {
      "epoch": 24.5,
      "grad_norm": 2.016392469406128,
      "learning_rate": 0.004540803112369439,
      "loss": 1.1785,
      "step": 49
    },
    {
      "epoch": 25.0,
      "grad_norm": 2.552428960800171,
      "learning_rate": 0.0046334725636422835,
      "loss": 1.1721,
      "step": 50
    },
    {
      "epoch": 25.5,
      "grad_norm": 2.7186787128448486,
      "learning_rate": 0.004726142014915129,
      "loss": 1.1533,
      "step": 51
    },
    {
      "epoch": 26.0,
      "grad_norm": 2.8827672004699707,
      "learning_rate": 0.0048188114661879755,
      "loss": 1.185,
      "step": 52
    },
    {
      "epoch": 26.5,
      "grad_norm": 5.411910057067871,
      "learning_rate": 0.00491148091746082,
      "loss": 1.1773,
      "step": 53
    },
    {
      "epoch": 27.0,
      "grad_norm": 4.007946014404297,
      "learning_rate": 0.005004150368733667,
      "loss": 1.1324,
      "step": 54
    },
    {
      "epoch": 27.5,
      "grad_norm": 1.465466022491455,
      "learning_rate": 0.005096819820006512,
      "loss": 1.0994,
      "step": 55
    },
    {
      "epoch": 28.0,
      "grad_norm": 2.0528762340545654,
      "learning_rate": 0.005189489271279358,
      "loss": 1.1925,
      "step": 56
    },
    {
      "epoch": 28.5,
      "grad_norm": 2.1782259941101074,
      "learning_rate": 0.005282158722552203,
      "loss": 1.1335,
      "step": 57
    },
    {
      "epoch": 29.0,
      "grad_norm": 3.243971824645996,
      "learning_rate": 0.005374828173825049,
      "loss": 1.1932,
      "step": 58
    },
    {
      "epoch": 29.5,
      "grad_norm": 1.3232247829437256,
      "learning_rate": 0.005467497625097895,
      "loss": 1.1212,
      "step": 59
    },
    {
      "epoch": 30.0,
      "grad_norm": 2.6874096393585205,
      "learning_rate": 0.005560167076370741,
      "loss": 1.1455,
      "step": 60
    },
    {
      "epoch": 30.5,
      "grad_norm": 1.6523154973983765,
      "learning_rate": 0.005652836527643586,
      "loss": 1.106,
      "step": 61
    },
    {
      "epoch": 31.0,
      "grad_norm": 2.9341907501220703,
      "learning_rate": 0.005745505978916432,
      "loss": 1.1655,
      "step": 62
    },
    {
      "epoch": 31.5,
      "grad_norm": 2.0575554370880127,
      "learning_rate": 0.0058381754301892776,
      "loss": 1.0989,
      "step": 63
    },
    {
      "epoch": 32.0,
      "grad_norm": 2.7740471363067627,
      "learning_rate": 0.005930844881462123,
      "loss": 1.1095,
      "step": 64
    },
    {
      "epoch": 32.5,
      "grad_norm": 2.752169132232666,
      "learning_rate": 0.006023514332734969,
      "loss": 1.1187,
      "step": 65
    },
    {
      "epoch": 33.0,
      "grad_norm": 2.6235570907592773,
      "learning_rate": 0.006116183784007814,
      "loss": 1.1059,
      "step": 66
    },
    {
      "epoch": 33.5,
      "grad_norm": 4.598926544189453,
      "learning_rate": 0.006208853235280661,
      "loss": 1.1155,
      "step": 67
    },
    {
      "epoch": 34.0,
      "grad_norm": 3.3669750690460205,
      "learning_rate": 0.006301522686553505,
      "loss": 1.1502,
      "step": 68
    },
    {
      "epoch": 34.5,
      "grad_norm": 2.2424182891845703,
      "learning_rate": 0.006394192137826352,
      "loss": 1.0695,
      "step": 69
    },
    {
      "epoch": 35.0,
      "grad_norm": 2.783647298812866,
      "learning_rate": 0.006486861589099197,
      "loss": 1.1528,
      "step": 70
    },
    {
      "epoch": 35.5,
      "grad_norm": 2.5795369148254395,
      "learning_rate": 0.006579531040372042,
      "loss": 1.1112,
      "step": 71
    },
    {
      "epoch": 36.0,
      "grad_norm": 2.243253231048584,
      "learning_rate": 0.0066722004916448885,
      "loss": 1.1169,
      "step": 72
    },
    {
      "epoch": 36.5,
      "grad_norm": 1.8384212255477905,
      "learning_rate": 0.006764869942917734,
      "loss": 1.0742,
      "step": 73
    },
    {
      "epoch": 37.0,
      "grad_norm": 2.4675657749176025,
      "learning_rate": 0.0068575393941905805,
      "loss": 1.1252,
      "step": 74
    },
    {
      "epoch": 37.5,
      "grad_norm": 1.9708364009857178,
      "learning_rate": 0.006950208845463425,
      "loss": 1.0707,
      "step": 75
    },
    {
      "epoch": 38.0,
      "grad_norm": 3.489558696746826,
      "learning_rate": 0.007042878296736271,
      "loss": 1.1445,
      "step": 76
    },
    {
      "epoch": 38.5,
      "grad_norm": 2.4603004455566406,
      "learning_rate": 0.007135547748009117,
      "loss": 1.1035,
      "step": 77
    },
    {
      "epoch": 39.0,
      "grad_norm": 2.7937915325164795,
      "learning_rate": 0.007228217199281963,
      "loss": 1.1287,
      "step": 78
    },
    {
      "epoch": 39.5,
      "grad_norm": 2.1619253158569336,
      "learning_rate": 0.007320886650554808,
      "loss": 1.1343,
      "step": 79
    },
    {
      "epoch": 40.0,
      "grad_norm": 4.0031538009643555,
      "learning_rate": 0.007413556101827654,
      "loss": 1.0389,
      "step": 80
    },
    {
      "epoch": 40.0,
      "eval_brier_0th_event": 0.22771895783258364,
      "eval_brier_0th_event_n": 253,
      "eval_brier_avg": 0.22771895783258364,
      "eval_brier_weighted_avg": 0.22771895783258364,
      "eval_ipcw": 0.5769977366051369,
      "eval_ipcw_0th_event": 0.5769977366051369,
      "eval_ipcw_0th_event_0.25": 0.6162880349204579,
      "eval_ipcw_0th_event_0.5": 0.5962085726537092,
      "eval_ipcw_0th_event_0.75": 0.5944865223305345,
      "eval_ipcw_0th_event_1.0": 0.5769977366051369,
      "eval_ipcw_0th_event_n": 253,
      "eval_ipcw_avg": 0.5959952166274596,
      "eval_ipcw_avg_0th_event": 0.5959952166274596,
      "eval_ipcw_weighted_avg": 0.5959952166274596,
      "eval_loss": 0.8073738813400269,
      "eval_runtime": 0.0836,
      "eval_samples_per_second": 5308.655,
      "eval_steps_per_second": 11.956,
      "step": 80
    },
    {
      "epoch": 40.5,
      "grad_norm": 2.587110996246338,
      "learning_rate": 0.0074135344900616955,
      "loss": 1.0747,
      "step": 81
    },
    {
      "epoch": 40.5,
      "eval_brier_0th_event": 0.22783461976812,
      "eval_brier_0th_event_n": 253,
      "eval_brier_avg": 0.22783461976812,
      "eval_brier_weighted_avg": 0.22783461976812,
      "eval_ipcw": 0.5798324937932674,
      "eval_ipcw_0th_event": 0.5798324937932674,
      "eval_ipcw_0th_event_0.25": 0.6184811593753092,
      "eval_ipcw_0th_event_0.5": 0.5989123390878301,
      "eval_ipcw_0th_event_0.75": 0.6003311795401841,
      "eval_ipcw_0th_event_1.0": 0.5798324937932674,
      "eval_ipcw_0th_event_n": 253,
      "eval_ipcw_avg": 0.5993892929491477,
      "eval_ipcw_avg_0th_event": 0.5993892929491477,
      "eval_ipcw_weighted_avg": 0.5993892929491477,
      "eval_loss": 0.8142451643943787,
      "eval_runtime": 0.0696,
      "eval_samples_per_second": 6375.741,
      "eval_steps_per_second": 14.36,
      "step": 81
    },
    {
      "epoch": 41.0,
      "grad_norm": 2.8609347343444824,
      "learning_rate": 0.007413469655015826,
      "loss": 1.1263,
      "step": 82
    },
    {
      "epoch": 41.0,
      "eval_brier_0th_event": 0.2289224250383381,
      "eval_brier_0th_event_n": 253,
      "eval_brier_avg": 0.2289224250383381,
      "eval_brier_weighted_avg": 0.2289224250383381,
      "eval_ipcw": 0.5869313579723723,
      "eval_ipcw_0th_event": 0.5869313579723723,
      "eval_ipcw_0th_event_0.25": 0.6177543137823058,
      "eval_ipcw_0th_event_0.5": 0.6032163574640139,
      "eval_ipcw_0th_event_0.75": 0.6066151224765015,
      "eval_ipcw_0th_event_1.0": 0.5869313579723723,
      "eval_ipcw_0th_event_n": 253,
      "eval_ipcw_avg": 0.6036292879237983,
      "eval_ipcw_avg_0th_event": 0.6036292879237983,
      "eval_ipcw_weighted_avg": 0.6036292879237983,
      "eval_loss": 0.8091403245925903,
      "eval_runtime": 0.0712,
      "eval_samples_per_second": 6238.931,
      "eval_steps_per_second": 14.052,
      "step": 82
    },
    {
      "epoch": 41.5,
      "grad_norm": 1.7957743406295776,
      "learning_rate": 0.007413361597446068,
      "loss": 1.0749,
      "step": 83
    },
    {
      "epoch": 41.5,
      "eval_brier_0th_event": 0.2256049359503835,
      "eval_brier_0th_event_n": 253,
      "eval_brier_avg": 0.2256049359503835,
      "eval_brier_weighted_avg": 0.2256049359503835,
      "eval_ipcw": 0.5984384396774881,
      "eval_ipcw_0th_event": 0.5984384396774881,
      "eval_ipcw_0th_event_0.25": 0.6254173368871658,
      "eval_ipcw_0th_event_0.5": 0.6070267826132768,
      "eval_ipcw_0th_event_0.75": 0.613021763958519,
      "eval_ipcw_0th_event_1.0": 0.5984384396774881,
      "eval_ipcw_0th_event_n": 253,
      "eval_ipcw_avg": 0.6109760807841124,
      "eval_ipcw_avg_0th_event": 0.6109760807841124,
      "eval_ipcw_weighted_avg": 0.6109760807841124,
      "eval_loss": 0.7770259976387024,
      "eval_runtime": 0.0808,
      "eval_samples_per_second": 5492.453,
      "eval_steps_per_second": 12.37,
      "step": 83
    },
    {
      "epoch": 42.0,
      "grad_norm": 2.483651638031006,
      "learning_rate": 0.007413210318612444,
      "loss": 1.1104,
      "step": 84
    },
    {
      "epoch": 42.0,
      "eval_brier_0th_event": 0.22597812305452317,
      "eval_brier_0th_event_n": 253,
      "eval_brier_avg": 0.22597812305452317,
      "eval_brier_weighted_avg": 0.2259781230545232,
      "eval_ipcw": 0.609805302987439,
      "eval_ipcw_0th_event": 0.609805302987439,
      "eval_ipcw_0th_event_0.25": 0.6283404329937062,
      "eval_ipcw_0th_event_0.5": 0.6141508897827435,
      "eval_ipcw_0th_event_0.75": 0.616403821601375,
      "eval_ipcw_0th_event_1.0": 0.609805302987439,
      "eval_ipcw_0th_event_n": 253,
      "eval_ipcw_avg": 0.6171751118413159,
      "eval_ipcw_avg_0th_event": 0.6171751118413159,
      "eval_ipcw_weighted_avg": 0.6171751118413159,
      "eval_loss": 0.7518581748008728,
      "eval_runtime": 0.0819,
      "eval_samples_per_second": 5423.622,
      "eval_steps_per_second": 12.215,
      "step": 84
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 30424584960.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
