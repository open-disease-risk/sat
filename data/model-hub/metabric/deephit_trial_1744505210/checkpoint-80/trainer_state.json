{
  "best_global_step": 80,
  "best_metric": 0.6209128934691117,
  "best_model_checkpoint": "./data/model-hub/metabric/deephit_trial_1744505210/checkpoint-80",
  "epoch": 40.0,
  "eval_steps": 1,
  "global_step": 80,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 9.82855224609375,
      "learning_rate": 1.1322209203976209e-05,
      "loss": 6.6345,
      "step": 1
    },
    {
      "epoch": 1.0,
      "grad_norm": 13.017477035522461,
      "learning_rate": 2.2644418407952418e-05,
      "loss": 5.9536,
      "step": 2
    },
    {
      "epoch": 1.5,
      "grad_norm": 10.175960540771484,
      "learning_rate": 3.396662761192862e-05,
      "loss": 5.6948,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 12.017510414123535,
      "learning_rate": 4.5288836815904836e-05,
      "loss": 5.3408,
      "step": 4
    },
    {
      "epoch": 2.5,
      "grad_norm": 9.401200294494629,
      "learning_rate": 5.661104601988104e-05,
      "loss": 5.0248,
      "step": 5
    },
    {
      "epoch": 3.0,
      "grad_norm": 9.951399803161621,
      "learning_rate": 6.793325522385724e-05,
      "loss": 5.3447,
      "step": 6
    },
    {
      "epoch": 3.5,
      "grad_norm": 9.112946510314941,
      "learning_rate": 7.925546442783344e-05,
      "loss": 5.1607,
      "step": 7
    },
    {
      "epoch": 4.0,
      "grad_norm": 13.949850082397461,
      "learning_rate": 9.057767363180967e-05,
      "loss": 4.9157,
      "step": 8
    },
    {
      "epoch": 4.5,
      "grad_norm": 9.931046485900879,
      "learning_rate": 0.00010189988283578588,
      "loss": 5.1661,
      "step": 9
    },
    {
      "epoch": 5.0,
      "grad_norm": 12.648516654968262,
      "learning_rate": 0.00011322209203976208,
      "loss": 5.164,
      "step": 10
    },
    {
      "epoch": 5.5,
      "grad_norm": 10.797894477844238,
      "learning_rate": 0.0001245443012437383,
      "loss": 5.2647,
      "step": 11
    },
    {
      "epoch": 6.0,
      "grad_norm": 11.293440818786621,
      "learning_rate": 0.00013586651044771448,
      "loss": 5.2753,
      "step": 12
    },
    {
      "epoch": 6.5,
      "grad_norm": 10.260400772094727,
      "learning_rate": 0.0001471887196516907,
      "loss": 5.4821,
      "step": 13
    },
    {
      "epoch": 7.0,
      "grad_norm": 13.818511962890625,
      "learning_rate": 0.0001585109288556669,
      "loss": 5.1062,
      "step": 14
    },
    {
      "epoch": 7.5,
      "grad_norm": 10.718297004699707,
      "learning_rate": 0.00016983313805964313,
      "loss": 5.4805,
      "step": 15
    },
    {
      "epoch": 8.0,
      "grad_norm": 13.19333553314209,
      "learning_rate": 0.00018115534726361935,
      "loss": 5.4017,
      "step": 16
    },
    {
      "epoch": 8.5,
      "grad_norm": 10.351737976074219,
      "learning_rate": 0.00019247755646759553,
      "loss": 5.7067,
      "step": 17
    },
    {
      "epoch": 9.0,
      "grad_norm": 12.774520874023438,
      "learning_rate": 0.00020379976567157175,
      "loss": 5.494,
      "step": 18
    },
    {
      "epoch": 9.5,
      "grad_norm": 9.668975830078125,
      "learning_rate": 0.00021512197487554794,
      "loss": 5.7621,
      "step": 19
    },
    {
      "epoch": 10.0,
      "grad_norm": 10.144954681396484,
      "learning_rate": 0.00022644418407952415,
      "loss": 5.5832,
      "step": 20
    },
    {
      "epoch": 10.5,
      "grad_norm": 8.970198631286621,
      "learning_rate": 0.00023776639328350037,
      "loss": 5.6841,
      "step": 21
    },
    {
      "epoch": 11.0,
      "grad_norm": 8.965439796447754,
      "learning_rate": 0.0002490886024874766,
      "loss": 6.0031,
      "step": 22
    },
    {
      "epoch": 11.5,
      "grad_norm": 7.689438819885254,
      "learning_rate": 0.00026041081169145275,
      "loss": 5.8671,
      "step": 23
    },
    {
      "epoch": 12.0,
      "grad_norm": 9.158595085144043,
      "learning_rate": 0.00027173302089542896,
      "loss": 5.6346,
      "step": 24
    },
    {
      "epoch": 12.5,
      "grad_norm": 7.2867536544799805,
      "learning_rate": 0.0002830552300994052,
      "loss": 5.7643,
      "step": 25
    },
    {
      "epoch": 13.0,
      "grad_norm": 7.36683988571167,
      "learning_rate": 0.0002943774393033814,
      "loss": 6.041,
      "step": 26
    },
    {
      "epoch": 13.5,
      "grad_norm": 6.385512351989746,
      "learning_rate": 0.0003056996485073576,
      "loss": 5.8111,
      "step": 27
    },
    {
      "epoch": 14.0,
      "grad_norm": 7.421661853790283,
      "learning_rate": 0.0003170218577113338,
      "loss": 5.9365,
      "step": 28
    },
    {
      "epoch": 14.5,
      "grad_norm": 6.369227886199951,
      "learning_rate": 0.00032834406691531,
      "loss": 5.8111,
      "step": 29
    },
    {
      "epoch": 15.0,
      "grad_norm": 7.957867622375488,
      "learning_rate": 0.00033966627611928626,
      "loss": 5.8496,
      "step": 30
    },
    {
      "epoch": 15.5,
      "grad_norm": 6.263990879058838,
      "learning_rate": 0.0003509884853232625,
      "loss": 5.8765,
      "step": 31
    },
    {
      "epoch": 16.0,
      "grad_norm": 7.8628435134887695,
      "learning_rate": 0.0003623106945272387,
      "loss": 6.1186,
      "step": 32
    },
    {
      "epoch": 16.5,
      "grad_norm": 6.516788959503174,
      "learning_rate": 0.00037363290373121485,
      "loss": 5.8747,
      "step": 33
    },
    {
      "epoch": 17.0,
      "grad_norm": 7.186489582061768,
      "learning_rate": 0.00038495511293519107,
      "loss": 5.9234,
      "step": 34
    },
    {
      "epoch": 17.5,
      "grad_norm": 5.879036903381348,
      "learning_rate": 0.0003962773221391673,
      "loss": 5.8411,
      "step": 35
    },
    {
      "epoch": 18.0,
      "grad_norm": 7.411900520324707,
      "learning_rate": 0.0004075995313431435,
      "loss": 5.9967,
      "step": 36
    },
    {
      "epoch": 18.5,
      "grad_norm": 6.04979133605957,
      "learning_rate": 0.0004189217405471197,
      "loss": 5.943,
      "step": 37
    },
    {
      "epoch": 19.0,
      "grad_norm": 7.128410816192627,
      "learning_rate": 0.0004302439497510959,
      "loss": 5.8388,
      "step": 38
    },
    {
      "epoch": 19.5,
      "grad_norm": 6.185840606689453,
      "learning_rate": 0.0004415661589550721,
      "loss": 5.8857,
      "step": 39
    },
    {
      "epoch": 20.0,
      "grad_norm": 8.604717254638672,
      "learning_rate": 0.0004528883681590483,
      "loss": 5.9852,
      "step": 40
    },
    {
      "epoch": 20.5,
      "grad_norm": 7.052898406982422,
      "learning_rate": 0.00046421057736302447,
      "loss": 6.0722,
      "step": 41
    },
    {
      "epoch": 21.0,
      "grad_norm": 8.655086517333984,
      "learning_rate": 0.00047553278656700074,
      "loss": 5.6652,
      "step": 42
    },
    {
      "epoch": 21.5,
      "grad_norm": 7.81643009185791,
      "learning_rate": 0.0004868549957709769,
      "loss": 5.8688,
      "step": 43
    },
    {
      "epoch": 22.0,
      "grad_norm": 7.305234909057617,
      "learning_rate": 0.0004981772049749532,
      "loss": 6.0989,
      "step": 44
    },
    {
      "epoch": 22.5,
      "grad_norm": 6.759859085083008,
      "learning_rate": 0.0005094994141789294,
      "loss": 5.9206,
      "step": 45
    },
    {
      "epoch": 23.0,
      "grad_norm": 11.075559616088867,
      "learning_rate": 0.0005208216233829055,
      "loss": 6.1478,
      "step": 46
    },
    {
      "epoch": 23.5,
      "grad_norm": 6.636799335479736,
      "learning_rate": 0.0005321438325868818,
      "loss": 5.871,
      "step": 47
    },
    {
      "epoch": 24.0,
      "grad_norm": 8.504668235778809,
      "learning_rate": 0.0005434660417908579,
      "loss": 6.029,
      "step": 48
    },
    {
      "epoch": 24.5,
      "grad_norm": 7.504735946655273,
      "learning_rate": 0.0005547882509948343,
      "loss": 5.7743,
      "step": 49
    },
    {
      "epoch": 25.0,
      "grad_norm": 8.68566608428955,
      "learning_rate": 0.0005661104601988104,
      "loss": 6.1307,
      "step": 50
    },
    {
      "epoch": 25.5,
      "grad_norm": 6.634162902832031,
      "learning_rate": 0.0005774326694027866,
      "loss": 5.9525,
      "step": 51
    },
    {
      "epoch": 26.0,
      "grad_norm": 9.344517707824707,
      "learning_rate": 0.0005887548786067628,
      "loss": 5.7643,
      "step": 52
    },
    {
      "epoch": 26.5,
      "grad_norm": 8.078337669372559,
      "learning_rate": 0.000600077087810739,
      "loss": 6.1005,
      "step": 53
    },
    {
      "epoch": 27.0,
      "grad_norm": 9.784806251525879,
      "learning_rate": 0.0006113992970147152,
      "loss": 5.7423,
      "step": 54
    },
    {
      "epoch": 27.5,
      "grad_norm": 8.30976676940918,
      "learning_rate": 0.0006227215062186914,
      "loss": 5.7749,
      "step": 55
    },
    {
      "epoch": 28.0,
      "grad_norm": 11.676477432250977,
      "learning_rate": 0.0006340437154226675,
      "loss": 6.3509,
      "step": 56
    },
    {
      "epoch": 28.5,
      "grad_norm": 8.359408378601074,
      "learning_rate": 0.0006453659246266439,
      "loss": 5.9534,
      "step": 57
    },
    {
      "epoch": 29.0,
      "grad_norm": 11.013009071350098,
      "learning_rate": 0.00065668813383062,
      "loss": 5.8919,
      "step": 58
    },
    {
      "epoch": 29.5,
      "grad_norm": 8.085698127746582,
      "learning_rate": 0.0006680103430345963,
      "loss": 6.0819,
      "step": 59
    },
    {
      "epoch": 30.0,
      "grad_norm": 12.75702953338623,
      "learning_rate": 0.0006793325522385725,
      "loss": 5.6591,
      "step": 60
    },
    {
      "epoch": 30.5,
      "grad_norm": 9.515168190002441,
      "learning_rate": 0.0006906547614425486,
      "loss": 5.8501,
      "step": 61
    },
    {
      "epoch": 31.0,
      "grad_norm": 12.712021827697754,
      "learning_rate": 0.000701976970646525,
      "loss": 6.173,
      "step": 62
    },
    {
      "epoch": 31.5,
      "grad_norm": 11.360372543334961,
      "learning_rate": 0.0007132991798505011,
      "loss": 6.0214,
      "step": 63
    },
    {
      "epoch": 32.0,
      "grad_norm": 15.292299270629883,
      "learning_rate": 0.0007246213890544774,
      "loss": 5.9682,
      "step": 64
    },
    {
      "epoch": 32.5,
      "grad_norm": 10.196075439453125,
      "learning_rate": 0.0007359435982584535,
      "loss": 5.9767,
      "step": 65
    },
    {
      "epoch": 33.0,
      "grad_norm": 14.095061302185059,
      "learning_rate": 0.0007472658074624297,
      "loss": 6.0525,
      "step": 66
    },
    {
      "epoch": 33.5,
      "grad_norm": 9.81027603149414,
      "learning_rate": 0.0007585880166664059,
      "loss": 6.1692,
      "step": 67
    },
    {
      "epoch": 34.0,
      "grad_norm": 13.007160186767578,
      "learning_rate": 0.0007699102258703821,
      "loss": 5.6601,
      "step": 68
    },
    {
      "epoch": 34.5,
      "grad_norm": 9.993670463562012,
      "learning_rate": 0.0007812324350743584,
      "loss": 6.0459,
      "step": 69
    },
    {
      "epoch": 35.0,
      "grad_norm": 13.643518447875977,
      "learning_rate": 0.0007925546442783346,
      "loss": 5.8864,
      "step": 70
    },
    {
      "epoch": 35.5,
      "grad_norm": 12.348998069763184,
      "learning_rate": 0.0008038768534823107,
      "loss": 5.8539,
      "step": 71
    },
    {
      "epoch": 36.0,
      "grad_norm": 13.897743225097656,
      "learning_rate": 0.000815199062686287,
      "loss": 6.1247,
      "step": 72
    },
    {
      "epoch": 36.5,
      "grad_norm": 11.362508773803711,
      "learning_rate": 0.0008265212718902631,
      "loss": 5.9699,
      "step": 73
    },
    {
      "epoch": 37.0,
      "grad_norm": 15.445929527282715,
      "learning_rate": 0.0008378434810942394,
      "loss": 5.8146,
      "step": 74
    },
    {
      "epoch": 37.5,
      "grad_norm": 10.988869667053223,
      "learning_rate": 0.0008491656902982155,
      "loss": 5.9228,
      "step": 75
    },
    {
      "epoch": 38.0,
      "grad_norm": 15.332724571228027,
      "learning_rate": 0.0008604878995021918,
      "loss": 5.984,
      "step": 76
    },
    {
      "epoch": 38.5,
      "grad_norm": 12.377668380737305,
      "learning_rate": 0.000871810108706168,
      "loss": 6.0088,
      "step": 77
    },
    {
      "epoch": 39.0,
      "grad_norm": 14.571446418762207,
      "learning_rate": 0.0008831323179101442,
      "loss": 5.674,
      "step": 78
    },
    {
      "epoch": 39.5,
      "grad_norm": 14.831340789794922,
      "learning_rate": 0.0008944545271141204,
      "loss": 6.1094,
      "step": 79
    },
    {
      "epoch": 40.0,
      "grad_norm": 14.180489540100098,
      "learning_rate": 0.0009057767363180966,
      "loss": 5.873,
      "step": 80
    },
    {
      "epoch": 40.0,
      "eval_brier_0th_event": 0.20519534267480088,
      "eval_brier_0th_event_n": 265,
      "eval_brier_avg": 0.20519534267480088,
      "eval_brier_weighted_avg": 0.20519534267480088,
      "eval_ipcw": 0.6287713210449597,
      "eval_ipcw_0th_event": 0.6287713210449597,
      "eval_ipcw_0th_event_0.25": 0.6238547815294971,
      "eval_ipcw_0th_event_0.5": 0.6177476550744424,
      "eval_ipcw_0th_event_0.75": 0.6132778162275477,
      "eval_ipcw_0th_event_1.0": 0.6287713210449597,
      "eval_ipcw_0th_event_n": 265,
      "eval_ipcw_avg": 0.6209128934691117,
      "eval_ipcw_avg_0th_event": 0.6209128934691117,
      "eval_ipcw_weighted_avg": 0.6209128934691117,
      "eval_loss": 3.4879112243652344,
      "eval_runtime": 0.1365,
      "eval_samples_per_second": 3252.648,
      "eval_steps_per_second": 7.326,
      "step": 80
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 40535424000.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
