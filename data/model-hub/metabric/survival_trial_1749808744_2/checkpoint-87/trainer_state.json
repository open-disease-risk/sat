{
  "best_global_step": 87,
  "best_metric": 0.617694371354741,
  "best_model_checkpoint": "./data/model-hub/metabric/survival_trial_1749808744_2/checkpoint-87",
  "epoch": 43.5,
  "eval_steps": 1,
  "global_step": 87,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 6.356951713562012,
      "learning_rate": 5.2621133962866404e-05,
      "loss": 1.6471,
      "step": 1
    },
    {
      "epoch": 1.0,
      "grad_norm": 7.2873148918151855,
      "learning_rate": 0.00010524226792573281,
      "loss": 1.6026,
      "step": 2
    },
    {
      "epoch": 1.5,
      "grad_norm": 6.187431335449219,
      "learning_rate": 0.0001578634018885992,
      "loss": 1.6517,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 6.252248287200928,
      "learning_rate": 0.00021048453585146562,
      "loss": 1.6119,
      "step": 4
    },
    {
      "epoch": 2.5,
      "grad_norm": 5.942114353179932,
      "learning_rate": 0.000263105669814332,
      "loss": 1.6421,
      "step": 5
    },
    {
      "epoch": 3.0,
      "grad_norm": 6.521852493286133,
      "learning_rate": 0.0003157268037771984,
      "loss": 1.6063,
      "step": 6
    },
    {
      "epoch": 3.5,
      "grad_norm": 5.844549655914307,
      "learning_rate": 0.0003683479377400648,
      "loss": 1.5708,
      "step": 7
    },
    {
      "epoch": 4.0,
      "grad_norm": 5.984325885772705,
      "learning_rate": 0.00042096907170293123,
      "loss": 1.6395,
      "step": 8
    },
    {
      "epoch": 4.5,
      "grad_norm": 5.945573329925537,
      "learning_rate": 0.0004735902056657976,
      "loss": 1.5657,
      "step": 9
    },
    {
      "epoch": 5.0,
      "grad_norm": 6.253399848937988,
      "learning_rate": 0.000526211339628664,
      "loss": 1.5706,
      "step": 10
    },
    {
      "epoch": 5.5,
      "grad_norm": 8.994112014770508,
      "learning_rate": 0.0005788324735915305,
      "loss": 1.5245,
      "step": 11
    },
    {
      "epoch": 6.0,
      "grad_norm": 6.363385200500488,
      "learning_rate": 0.0006314536075543968,
      "loss": 1.5373,
      "step": 12
    },
    {
      "epoch": 6.5,
      "grad_norm": 7.397312164306641,
      "learning_rate": 0.0006840747415172633,
      "loss": 1.4954,
      "step": 13
    },
    {
      "epoch": 7.0,
      "grad_norm": 9.103925704956055,
      "learning_rate": 0.0007366958754801296,
      "loss": 1.4549,
      "step": 14
    },
    {
      "epoch": 7.5,
      "grad_norm": 7.203227519989014,
      "learning_rate": 0.000789317009442996,
      "loss": 1.4252,
      "step": 15
    },
    {
      "epoch": 8.0,
      "grad_norm": 7.534711837768555,
      "learning_rate": 0.0008419381434058625,
      "loss": 1.4497,
      "step": 16
    },
    {
      "epoch": 8.5,
      "grad_norm": 4.932991981506348,
      "learning_rate": 0.0008945592773687287,
      "loss": 1.379,
      "step": 17
    },
    {
      "epoch": 9.0,
      "grad_norm": 9.832099914550781,
      "learning_rate": 0.0009471804113315952,
      "loss": 1.4017,
      "step": 18
    },
    {
      "epoch": 9.5,
      "grad_norm": 5.711519241333008,
      "learning_rate": 0.0009998015452944615,
      "loss": 1.377,
      "step": 19
    },
    {
      "epoch": 10.0,
      "grad_norm": 5.358098030090332,
      "learning_rate": 0.001052422679257328,
      "loss": 1.3965,
      "step": 20
    },
    {
      "epoch": 10.5,
      "grad_norm": 5.8785576820373535,
      "learning_rate": 0.0011050438132201945,
      "loss": 1.3625,
      "step": 21
    },
    {
      "epoch": 11.0,
      "grad_norm": 6.7048211097717285,
      "learning_rate": 0.001157664947183061,
      "loss": 1.3621,
      "step": 22
    },
    {
      "epoch": 11.5,
      "grad_norm": 5.331327438354492,
      "learning_rate": 0.001210286081145927,
      "loss": 1.3351,
      "step": 23
    },
    {
      "epoch": 12.0,
      "grad_norm": 7.380247116088867,
      "learning_rate": 0.0012629072151087936,
      "loss": 1.3632,
      "step": 24
    },
    {
      "epoch": 12.5,
      "grad_norm": 4.272938251495361,
      "learning_rate": 0.00131552834907166,
      "loss": 1.3381,
      "step": 25
    },
    {
      "epoch": 13.0,
      "grad_norm": 3.6093618869781494,
      "learning_rate": 0.0013681494830345266,
      "loss": 1.2992,
      "step": 26
    },
    {
      "epoch": 13.5,
      "grad_norm": 3.596287727355957,
      "learning_rate": 0.0014207706169973929,
      "loss": 1.2787,
      "step": 27
    },
    {
      "epoch": 14.0,
      "grad_norm": 3.205195665359497,
      "learning_rate": 0.0014733917509602591,
      "loss": 1.3607,
      "step": 28
    },
    {
      "epoch": 14.5,
      "grad_norm": 3.17016863822937,
      "learning_rate": 0.0015260128849231256,
      "loss": 1.3012,
      "step": 29
    },
    {
      "epoch": 15.0,
      "grad_norm": 3.113999128341675,
      "learning_rate": 0.001578634018885992,
      "loss": 1.2485,
      "step": 30
    },
    {
      "epoch": 15.5,
      "grad_norm": 4.688212871551514,
      "learning_rate": 0.0016312551528488584,
      "loss": 1.2966,
      "step": 31
    },
    {
      "epoch": 16.0,
      "grad_norm": 5.306263446807861,
      "learning_rate": 0.001683876286811725,
      "loss": 1.2606,
      "step": 32
    },
    {
      "epoch": 16.5,
      "grad_norm": 3.2142579555511475,
      "learning_rate": 0.0017364974207745912,
      "loss": 1.2359,
      "step": 33
    },
    {
      "epoch": 17.0,
      "grad_norm": 7.27971076965332,
      "learning_rate": 0.0017891185547374575,
      "loss": 1.303,
      "step": 34
    },
    {
      "epoch": 17.5,
      "grad_norm": 3.8837411403656006,
      "learning_rate": 0.001841739688700324,
      "loss": 1.2394,
      "step": 35
    },
    {
      "epoch": 18.0,
      "grad_norm": 3.163696527481079,
      "learning_rate": 0.0018943608226631905,
      "loss": 1.2704,
      "step": 36
    },
    {
      "epoch": 18.5,
      "grad_norm": 5.961400032043457,
      "learning_rate": 0.001946981956626057,
      "loss": 1.2325,
      "step": 37
    },
    {
      "epoch": 19.0,
      "grad_norm": 6.112563133239746,
      "learning_rate": 0.001999603090588923,
      "loss": 1.2612,
      "step": 38
    },
    {
      "epoch": 19.5,
      "grad_norm": 2.942742109298706,
      "learning_rate": 0.0020522242245517896,
      "loss": 1.2372,
      "step": 39
    },
    {
      "epoch": 20.0,
      "grad_norm": 7.032294750213623,
      "learning_rate": 0.002104845358514656,
      "loss": 1.1909,
      "step": 40
    },
    {
      "epoch": 20.5,
      "grad_norm": 5.762543678283691,
      "learning_rate": 0.002157466492477522,
      "loss": 1.2194,
      "step": 41
    },
    {
      "epoch": 21.0,
      "grad_norm": 3.8122031688690186,
      "learning_rate": 0.002210087626440389,
      "loss": 1.2038,
      "step": 42
    },
    {
      "epoch": 21.5,
      "grad_norm": 3.830092668533325,
      "learning_rate": 0.002262708760403255,
      "loss": 1.1693,
      "step": 43
    },
    {
      "epoch": 22.0,
      "grad_norm": 3.3809051513671875,
      "learning_rate": 0.002315329894366122,
      "loss": 1.1859,
      "step": 44
    },
    {
      "epoch": 22.5,
      "grad_norm": 2.468202829360962,
      "learning_rate": 0.002367951028328988,
      "loss": 1.126,
      "step": 45
    },
    {
      "epoch": 23.0,
      "grad_norm": 3.1740529537200928,
      "learning_rate": 0.002420572162291854,
      "loss": 1.2008,
      "step": 46
    },
    {
      "epoch": 23.5,
      "grad_norm": 3.063511610031128,
      "learning_rate": 0.002473193296254721,
      "loss": 1.168,
      "step": 47
    },
    {
      "epoch": 24.0,
      "grad_norm": 4.744181156158447,
      "learning_rate": 0.002525814430217587,
      "loss": 1.2058,
      "step": 48
    },
    {
      "epoch": 24.5,
      "grad_norm": 4.694266319274902,
      "learning_rate": 0.0025784355641804537,
      "loss": 1.1286,
      "step": 49
    },
    {
      "epoch": 25.0,
      "grad_norm": 5.3063764572143555,
      "learning_rate": 0.00263105669814332,
      "loss": 1.1174,
      "step": 50
    },
    {
      "epoch": 25.5,
      "grad_norm": 5.274696350097656,
      "learning_rate": 0.0026836778321061862,
      "loss": 1.1627,
      "step": 51
    },
    {
      "epoch": 26.0,
      "grad_norm": 5.674091339111328,
      "learning_rate": 0.002736298966069053,
      "loss": 1.0959,
      "step": 52
    },
    {
      "epoch": 26.5,
      "grad_norm": 3.2946412563323975,
      "learning_rate": 0.0027889201000319192,
      "loss": 1.0907,
      "step": 53
    },
    {
      "epoch": 27.0,
      "grad_norm": 4.173820495605469,
      "learning_rate": 0.0028415412339947857,
      "loss": 1.1277,
      "step": 54
    },
    {
      "epoch": 27.5,
      "grad_norm": 3.583693265914917,
      "learning_rate": 0.0028941623679576522,
      "loss": 1.0485,
      "step": 55
    },
    {
      "epoch": 28.0,
      "grad_norm": 4.72598934173584,
      "learning_rate": 0.0029467835019205183,
      "loss": 1.101,
      "step": 56
    },
    {
      "epoch": 28.5,
      "grad_norm": 3.592695951461792,
      "learning_rate": 0.002999404635883385,
      "loss": 1.0405,
      "step": 57
    },
    {
      "epoch": 29.0,
      "grad_norm": 5.298420429229736,
      "learning_rate": 0.0030520257698462513,
      "loss": 1.0639,
      "step": 58
    },
    {
      "epoch": 29.5,
      "grad_norm": 7.569778919219971,
      "learning_rate": 0.003104646903809118,
      "loss": 1.1553,
      "step": 59
    },
    {
      "epoch": 30.0,
      "grad_norm": 5.420616626739502,
      "learning_rate": 0.003157268037771984,
      "loss": 0.9039,
      "step": 60
    },
    {
      "epoch": 30.5,
      "grad_norm": 3.874486207962036,
      "learning_rate": 0.0032098891717348504,
      "loss": 0.9791,
      "step": 61
    },
    {
      "epoch": 31.0,
      "grad_norm": 6.919495582580566,
      "learning_rate": 0.003262510305697717,
      "loss": 1.036,
      "step": 62
    },
    {
      "epoch": 31.5,
      "grad_norm": 2.9022815227508545,
      "learning_rate": 0.0033151314396605834,
      "loss": 1.0121,
      "step": 63
    },
    {
      "epoch": 32.0,
      "grad_norm": 6.6615214347839355,
      "learning_rate": 0.00336775257362345,
      "loss": 0.9729,
      "step": 64
    },
    {
      "epoch": 32.5,
      "grad_norm": 2.9181365966796875,
      "learning_rate": 0.003420373707586316,
      "loss": 0.9377,
      "step": 65
    },
    {
      "epoch": 33.0,
      "grad_norm": 5.679737567901611,
      "learning_rate": 0.0034729948415491824,
      "loss": 0.9667,
      "step": 66
    },
    {
      "epoch": 33.5,
      "grad_norm": 3.9116127490997314,
      "learning_rate": 0.003525615975512049,
      "loss": 0.8988,
      "step": 67
    },
    {
      "epoch": 34.0,
      "grad_norm": 6.80882453918457,
      "learning_rate": 0.003578237109474915,
      "loss": 0.959,
      "step": 68
    },
    {
      "epoch": 34.5,
      "grad_norm": 3.876194953918457,
      "learning_rate": 0.003630858243437782,
      "loss": 0.9302,
      "step": 69
    },
    {
      "epoch": 35.0,
      "grad_norm": 5.582991600036621,
      "learning_rate": 0.003683479377400648,
      "loss": 0.9299,
      "step": 70
    },
    {
      "epoch": 35.5,
      "grad_norm": 3.6214959621429443,
      "learning_rate": 0.0037361005113635145,
      "loss": 0.858,
      "step": 71
    },
    {
      "epoch": 36.0,
      "grad_norm": 5.652708530426025,
      "learning_rate": 0.003788721645326381,
      "loss": 0.9694,
      "step": 72
    },
    {
      "epoch": 36.5,
      "grad_norm": 5.013482570648193,
      "learning_rate": 0.003841342779289247,
      "loss": 0.8642,
      "step": 73
    },
    {
      "epoch": 37.0,
      "grad_norm": 7.177271842956543,
      "learning_rate": 0.003893963913252114,
      "loss": 0.906,
      "step": 74
    },
    {
      "epoch": 37.5,
      "grad_norm": 5.758229732513428,
      "learning_rate": 0.00394658504721498,
      "loss": 0.803,
      "step": 75
    },
    {
      "epoch": 38.0,
      "grad_norm": 5.234281063079834,
      "learning_rate": 0.003999206181177846,
      "loss": 0.8303,
      "step": 76
    },
    {
      "epoch": 38.5,
      "grad_norm": 7.305679798126221,
      "learning_rate": 0.004051827315140713,
      "loss": 0.8813,
      "step": 77
    },
    {
      "epoch": 39.0,
      "grad_norm": 7.558746337890625,
      "learning_rate": 0.004104448449103579,
      "loss": 0.7988,
      "step": 78
    },
    {
      "epoch": 39.5,
      "grad_norm": 4.03544282913208,
      "learning_rate": 0.004157069583066446,
      "loss": 0.7966,
      "step": 79
    },
    {
      "epoch": 40.0,
      "grad_norm": 5.213527202606201,
      "learning_rate": 0.004209690717029312,
      "loss": 0.8583,
      "step": 80
    },
    {
      "epoch": 40.0,
      "eval_brier_0th_event": 0.2023162692785263,
      "eval_brier_0th_event_n": 247,
      "eval_brier_weighted_avg": 0.2023162692785263,
      "eval_ipcw_0th_event": 0.612389566427147,
      "eval_ipcw_0th_event_0.25": 0.5889813899993896,
      "eval_ipcw_0th_event_0.50": 0.6069387793540955,
      "eval_ipcw_0th_event_0.75": 0.6114023327827454,
      "eval_ipcw_0th_event_1.00": 0.6205303072929382,
      "eval_ipcw_0th_event_n": 473,
      "eval_ipcw_weighted_avg": 0.612389566427147,
      "eval_loss": 0.7967917323112488,
      "eval_runtime": 0.2015,
      "eval_samples_per_second": 2347.079,
      "eval_steps_per_second": 4.962,
      "step": 80
    },
    {
      "epoch": 40.5,
      "grad_norm": 7.311962604522705,
      "learning_rate": 0.00420967844507112,
      "loss": 0.8506,
      "step": 81
    },
    {
      "epoch": 40.5,
      "eval_brier_0th_event": 0.21334625780582428,
      "eval_brier_0th_event_n": 247,
      "eval_brier_weighted_avg": 0.21334625780582428,
      "eval_ipcw_0th_event": 0.6099157099788253,
      "eval_ipcw_0th_event_0.25": 0.588654637336731,
      "eval_ipcw_0th_event_0.50": 0.6069552302360535,
      "eval_ipcw_0th_event_0.75": 0.6073582768440247,
      "eval_ipcw_0th_event_1.00": 0.6175422668457031,
      "eval_ipcw_0th_event_n": 473,
      "eval_ipcw_weighted_avg": 0.6099157099788253,
      "eval_loss": 0.8270120620727539,
      "eval_runtime": 0.2021,
      "eval_samples_per_second": 2340.052,
      "eval_steps_per_second": 4.947,
      "step": 81
    },
    {
      "epoch": 41.0,
      "grad_norm": 7.457455635070801,
      "learning_rate": 0.004209641629339644,
      "loss": 0.8193,
      "step": 82
    },
    {
      "epoch": 41.0,
      "eval_brier_0th_event": 0.21428878605365753,
      "eval_brier_0th_event_n": 247,
      "eval_brier_weighted_avg": 0.21428878605365753,
      "eval_ipcw_0th_event": 0.6062117662985582,
      "eval_ipcw_0th_event_0.25": 0.5866648554801941,
      "eval_ipcw_0th_event_0.50": 0.6027402877807617,
      "eval_ipcw_0th_event_0.75": 0.6034783124923706,
      "eval_ipcw_0th_event_1.00": 0.613853931427002,
      "eval_ipcw_0th_event_n": 473,
      "eval_ipcw_weighted_avg": 0.6062117662985581,
      "eval_loss": 0.8351479172706604,
      "eval_runtime": 0.2061,
      "eval_samples_per_second": 2294.634,
      "eval_steps_per_second": 4.851,
      "step": 82
    },
    {
      "epoch": 41.5,
      "grad_norm": 3.727231979370117,
      "learning_rate": 0.004209580270264178,
      "loss": 0.7858,
      "step": 83
    },
    {
      "epoch": 41.5,
      "eval_brier_0th_event": 0.20948322117328644,
      "eval_brier_0th_event_n": 247,
      "eval_brier_weighted_avg": 0.20948322117328644,
      "eval_ipcw_0th_event": 0.6032533356668176,
      "eval_ipcw_0th_event_0.25": 0.5922181606292725,
      "eval_ipcw_0th_event_0.50": 0.6060430407524109,
      "eval_ipcw_0th_event_0.75": 0.5971112847328186,
      "eval_ipcw_0th_event_1.00": 0.6085756421089172,
      "eval_ipcw_0th_event_n": 473,
      "eval_ipcw_weighted_avg": 0.6032533356668176,
      "eval_loss": 0.8491983413696289,
      "eval_runtime": 0.2197,
      "eval_samples_per_second": 2153.395,
      "eval_steps_per_second": 4.553,
      "step": 83
    },
    {
      "epoch": 42.0,
      "grad_norm": 7.396463394165039,
      "learning_rate": 0.004209494368560213,
      "loss": 0.894,
      "step": 84
    },
    {
      "epoch": 42.0,
      "eval_brier_0th_event": 0.2118178755044937,
      "eval_brier_0th_event_n": 247,
      "eval_brier_weighted_avg": 0.2118178755044937,
      "eval_ipcw_0th_event": 0.609367131482105,
      "eval_ipcw_0th_event_0.25": 0.6016132235527039,
      "eval_ipcw_0th_event_0.50": 0.6109852194786072,
      "eval_ipcw_0th_event_0.75": 0.60745769739151,
      "eval_ipcw_0th_event_1.00": 0.6115556955337524,
      "eval_ipcw_0th_event_n": 473,
      "eval_ipcw_weighted_avg": 0.609367131482105,
      "eval_loss": 0.8706154227256775,
      "eval_runtime": 0.153,
      "eval_samples_per_second": 3090.73,
      "eval_steps_per_second": 6.534,
      "step": 84
    },
    {
      "epoch": 42.5,
      "grad_norm": 5.648839473724365,
      "learning_rate": 0.004209383925229419,
      "loss": 0.8318,
      "step": 85
    },
    {
      "epoch": 42.5,
      "eval_brier_0th_event": 0.21501421928405762,
      "eval_brier_0th_event_n": 247,
      "eval_brier_weighted_avg": 0.21501421928405762,
      "eval_ipcw_0th_event": 0.614013291593339,
      "eval_ipcw_0th_event_0.25": 0.6011383533477783,
      "eval_ipcw_0th_event_0.50": 0.6173862814903259,
      "eval_ipcw_0th_event_0.75": 0.6180586218833923,
      "eval_ipcw_0th_event_1.00": 0.6121777892112732,
      "eval_ipcw_0th_event_n": 473,
      "eval_ipcw_weighted_avg": 0.6140132915933388,
      "eval_loss": 0.8638707995414734,
      "eval_runtime": 0.2066,
      "eval_samples_per_second": 2289.193,
      "eval_steps_per_second": 4.84,
      "step": 85
    },
    {
      "epoch": 43.0,
      "grad_norm": 5.56012487411499,
      "learning_rate": 0.004209248941559641,
      "loss": 0.7386,
      "step": 86
    },
    {
      "epoch": 43.0,
      "eval_brier_0th_event": 0.21791109442710876,
      "eval_brier_0th_event_n": 247,
      "eval_brier_weighted_avg": 0.21791109442710876,
      "eval_ipcw_0th_event": 0.6165811577560129,
      "eval_ipcw_0th_event_0.25": 0.6044911742210388,
      "eval_ipcw_0th_event_0.50": 0.6202903985977173,
      "eval_ipcw_0th_event_0.75": 0.6234577298164368,
      "eval_ipcw_0th_event_1.00": 0.61240553855896,
      "eval_ipcw_0th_event_n": 473,
      "eval_ipcw_weighted_avg": 0.6165811577560129,
      "eval_loss": 0.8561798930168152,
      "eval_runtime": 0.1588,
      "eval_samples_per_second": 2977.823,
      "eval_steps_per_second": 6.296,
      "step": 86
    },
    {
      "epoch": 43.5,
      "grad_norm": 6.073890686035156,
      "learning_rate": 0.004209089419124877,
      "loss": 0.7302,
      "step": 87
    },
    {
      "epoch": 43.5,
      "eval_brier_0th_event": 0.21117503941059113,
      "eval_brier_0th_event_n": 247,
      "eval_brier_weighted_avg": 0.21117503941059113,
      "eval_ipcw_0th_event": 0.617694371354741,
      "eval_ipcw_0th_event_0.25": 0.6049975156784058,
      "eval_ipcw_0th_event_0.50": 0.6246017217636108,
      "eval_ipcw_0th_event_0.75": 0.6273587346076965,
      "eval_ipcw_0th_event_1.00": 0.6101297736167908,
      "eval_ipcw_0th_event_n": 473,
      "eval_ipcw_weighted_avg": 0.617694371354741,
      "eval_loss": 0.8453940749168396,
      "eval_runtime": 0.2662,
      "eval_samples_per_second": 1777.034,
      "eval_steps_per_second": 3.757,
      "step": 87
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 32424184320.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
