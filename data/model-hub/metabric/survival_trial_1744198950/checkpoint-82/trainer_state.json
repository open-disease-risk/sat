{
  "best_global_step": 82,
  "best_metric": 0.595014331473712,
  "best_model_checkpoint": "./data/model-hub/metabric/survival_trial_1744198950/checkpoint-82",
  "epoch": 41.0,
  "eval_steps": 1,
  "global_step": 82,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 11.124856948852539,
      "learning_rate": 9.062604165920073e-05,
      "loss": 1.6832,
      "step": 1
    },
    {
      "epoch": 1.0,
      "grad_norm": 9.54099178314209,
      "learning_rate": 0.00018125208331840146,
      "loss": 1.6187,
      "step": 2
    },
    {
      "epoch": 1.5,
      "grad_norm": 10.268967628479004,
      "learning_rate": 0.0002718781249776022,
      "loss": 1.6268,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 7.590391635894775,
      "learning_rate": 0.0003625041666368029,
      "loss": 1.6251,
      "step": 4
    },
    {
      "epoch": 2.5,
      "grad_norm": 5.418191909790039,
      "learning_rate": 0.00045313020829600365,
      "loss": 1.6071,
      "step": 5
    },
    {
      "epoch": 3.0,
      "grad_norm": 4.381726264953613,
      "learning_rate": 0.0005437562499552044,
      "loss": 1.5219,
      "step": 6
    },
    {
      "epoch": 3.5,
      "grad_norm": 3.372169256210327,
      "learning_rate": 0.0006343822916144051,
      "loss": 1.548,
      "step": 7
    },
    {
      "epoch": 4.0,
      "grad_norm": 3.6948559284210205,
      "learning_rate": 0.0007250083332736058,
      "loss": 1.571,
      "step": 8
    },
    {
      "epoch": 4.5,
      "grad_norm": 4.089213848114014,
      "learning_rate": 0.0008156343749328066,
      "loss": 1.5463,
      "step": 9
    },
    {
      "epoch": 5.0,
      "grad_norm": 4.1194071769714355,
      "learning_rate": 0.0009062604165920073,
      "loss": 1.5586,
      "step": 10
    },
    {
      "epoch": 5.5,
      "grad_norm": 3.7190022468566895,
      "learning_rate": 0.000996886458251208,
      "loss": 1.5105,
      "step": 11
    },
    {
      "epoch": 6.0,
      "grad_norm": 3.4809794425964355,
      "learning_rate": 0.0010875124999104088,
      "loss": 1.5164,
      "step": 12
    },
    {
      "epoch": 6.5,
      "grad_norm": 3.5152361392974854,
      "learning_rate": 0.0011781385415696095,
      "loss": 1.5141,
      "step": 13
    },
    {
      "epoch": 7.0,
      "grad_norm": 3.161055326461792,
      "learning_rate": 0.0012687645832288102,
      "loss": 1.4287,
      "step": 14
    },
    {
      "epoch": 7.5,
      "grad_norm": 3.8709471225738525,
      "learning_rate": 0.001359390624888011,
      "loss": 1.4562,
      "step": 15
    },
    {
      "epoch": 8.0,
      "grad_norm": 3.4781336784362793,
      "learning_rate": 0.0014500166665472117,
      "loss": 1.3613,
      "step": 16
    },
    {
      "epoch": 8.5,
      "grad_norm": 2.571021795272827,
      "learning_rate": 0.0015406427082064124,
      "loss": 1.3731,
      "step": 17
    },
    {
      "epoch": 9.0,
      "grad_norm": 5.154203414916992,
      "learning_rate": 0.0016312687498656131,
      "loss": 1.3814,
      "step": 18
    },
    {
      "epoch": 9.5,
      "grad_norm": 4.060704708099365,
      "learning_rate": 0.0017218947915248139,
      "loss": 1.3547,
      "step": 19
    },
    {
      "epoch": 10.0,
      "grad_norm": 5.296169281005859,
      "learning_rate": 0.0018125208331840146,
      "loss": 1.4031,
      "step": 20
    },
    {
      "epoch": 10.5,
      "grad_norm": 4.112919807434082,
      "learning_rate": 0.0019031468748432153,
      "loss": 1.3674,
      "step": 21
    },
    {
      "epoch": 11.0,
      "grad_norm": 2.826979398727417,
      "learning_rate": 0.001993772916502416,
      "loss": 1.3356,
      "step": 22
    },
    {
      "epoch": 11.5,
      "grad_norm": 4.956469535827637,
      "learning_rate": 0.0020843989581616168,
      "loss": 1.3368,
      "step": 23
    },
    {
      "epoch": 12.0,
      "grad_norm": 3.42439603805542,
      "learning_rate": 0.0021750249998208175,
      "loss": 1.3687,
      "step": 24
    },
    {
      "epoch": 12.5,
      "grad_norm": 3.4802398681640625,
      "learning_rate": 0.0022656510414800182,
      "loss": 1.3498,
      "step": 25
    },
    {
      "epoch": 13.0,
      "grad_norm": 3.382889747619629,
      "learning_rate": 0.002356277083139219,
      "loss": 1.3296,
      "step": 26
    },
    {
      "epoch": 13.5,
      "grad_norm": 3.1374664306640625,
      "learning_rate": 0.0024469031247984197,
      "loss": 1.32,
      "step": 27
    },
    {
      "epoch": 14.0,
      "grad_norm": 3.506294012069702,
      "learning_rate": 0.0025375291664576204,
      "loss": 1.3227,
      "step": 28
    },
    {
      "epoch": 14.5,
      "grad_norm": 3.4054815769195557,
      "learning_rate": 0.002628155208116821,
      "loss": 1.2836,
      "step": 29
    },
    {
      "epoch": 15.0,
      "grad_norm": 2.154059886932373,
      "learning_rate": 0.002718781249776022,
      "loss": 1.3029,
      "step": 30
    },
    {
      "epoch": 15.5,
      "grad_norm": 2.7850677967071533,
      "learning_rate": 0.0028094072914352226,
      "loss": 1.2893,
      "step": 31
    },
    {
      "epoch": 16.0,
      "grad_norm": 3.327526807785034,
      "learning_rate": 0.0029000333330944233,
      "loss": 1.2505,
      "step": 32
    },
    {
      "epoch": 16.5,
      "grad_norm": 2.3567850589752197,
      "learning_rate": 0.002990659374753624,
      "loss": 1.2683,
      "step": 33
    },
    {
      "epoch": 17.0,
      "grad_norm": 2.3570051193237305,
      "learning_rate": 0.003081285416412825,
      "loss": 1.2801,
      "step": 34
    },
    {
      "epoch": 17.5,
      "grad_norm": 1.8464863300323486,
      "learning_rate": 0.0031719114580720255,
      "loss": 1.2569,
      "step": 35
    },
    {
      "epoch": 18.0,
      "grad_norm": 3.6975808143615723,
      "learning_rate": 0.0032625374997312263,
      "loss": 1.2114,
      "step": 36
    },
    {
      "epoch": 18.5,
      "grad_norm": 1.706897497177124,
      "learning_rate": 0.003353163541390427,
      "loss": 1.2266,
      "step": 37
    },
    {
      "epoch": 19.0,
      "grad_norm": 2.8512887954711914,
      "learning_rate": 0.0034437895830496277,
      "loss": 1.2518,
      "step": 38
    },
    {
      "epoch": 19.5,
      "grad_norm": 1.6331020593643188,
      "learning_rate": 0.0035344156247088285,
      "loss": 1.2199,
      "step": 39
    },
    {
      "epoch": 20.0,
      "grad_norm": 3.0279133319854736,
      "learning_rate": 0.003625041666368029,
      "loss": 1.2131,
      "step": 40
    },
    {
      "epoch": 20.5,
      "grad_norm": 2.2320830821990967,
      "learning_rate": 0.0037156677080272295,
      "loss": 1.1915,
      "step": 41
    },
    {
      "epoch": 21.0,
      "grad_norm": 3.530886173248291,
      "learning_rate": 0.0038062937496864306,
      "loss": 1.2403,
      "step": 42
    },
    {
      "epoch": 21.5,
      "grad_norm": 3.703756332397461,
      "learning_rate": 0.0038969197913456314,
      "loss": 1.1936,
      "step": 43
    },
    {
      "epoch": 22.0,
      "grad_norm": 4.017922401428223,
      "learning_rate": 0.003987545833004832,
      "loss": 1.1789,
      "step": 44
    },
    {
      "epoch": 22.5,
      "grad_norm": 2.622096300125122,
      "learning_rate": 0.004078171874664032,
      "loss": 1.165,
      "step": 45
    },
    {
      "epoch": 23.0,
      "grad_norm": 6.362107753753662,
      "learning_rate": 0.0041687979163232336,
      "loss": 1.2102,
      "step": 46
    },
    {
      "epoch": 23.5,
      "grad_norm": 3.73068904876709,
      "learning_rate": 0.004259423957982435,
      "loss": 1.2005,
      "step": 47
    },
    {
      "epoch": 24.0,
      "grad_norm": 3.825582265853882,
      "learning_rate": 0.004350049999641635,
      "loss": 1.1543,
      "step": 48
    },
    {
      "epoch": 24.5,
      "grad_norm": 5.803061485290527,
      "learning_rate": 0.004440676041300836,
      "loss": 1.2227,
      "step": 49
    },
    {
      "epoch": 25.0,
      "grad_norm": 2.867741584777832,
      "learning_rate": 0.0045313020829600365,
      "loss": 1.1242,
      "step": 50
    },
    {
      "epoch": 25.5,
      "grad_norm": 5.106815338134766,
      "learning_rate": 0.004621928124619237,
      "loss": 1.172,
      "step": 51
    },
    {
      "epoch": 26.0,
      "grad_norm": 2.7446231842041016,
      "learning_rate": 0.004712554166278438,
      "loss": 1.1153,
      "step": 52
    },
    {
      "epoch": 26.5,
      "grad_norm": 3.4487550258636475,
      "learning_rate": 0.004803180207937638,
      "loss": 1.1406,
      "step": 53
    },
    {
      "epoch": 27.0,
      "grad_norm": 4.490710258483887,
      "learning_rate": 0.004893806249596839,
      "loss": 1.1457,
      "step": 54
    },
    {
      "epoch": 27.5,
      "grad_norm": 3.3080413341522217,
      "learning_rate": 0.0049844322912560406,
      "loss": 1.1503,
      "step": 55
    },
    {
      "epoch": 28.0,
      "grad_norm": 5.7691497802734375,
      "learning_rate": 0.005075058332915241,
      "loss": 1.1265,
      "step": 56
    },
    {
      "epoch": 28.5,
      "grad_norm": 3.4814088344573975,
      "learning_rate": 0.005165684374574442,
      "loss": 1.0896,
      "step": 57
    },
    {
      "epoch": 29.0,
      "grad_norm": 5.1233673095703125,
      "learning_rate": 0.005256310416233642,
      "loss": 1.148,
      "step": 58
    },
    {
      "epoch": 29.5,
      "grad_norm": 4.654361248016357,
      "learning_rate": 0.0053469364578928435,
      "loss": 1.1119,
      "step": 59
    },
    {
      "epoch": 30.0,
      "grad_norm": 3.426975965499878,
      "learning_rate": 0.005437562499552044,
      "loss": 1.1379,
      "step": 60
    },
    {
      "epoch": 30.5,
      "grad_norm": 2.3707334995269775,
      "learning_rate": 0.005528188541211244,
      "loss": 1.0993,
      "step": 61
    },
    {
      "epoch": 31.0,
      "grad_norm": 3.0107052326202393,
      "learning_rate": 0.005618814582870445,
      "loss": 1.0222,
      "step": 62
    },
    {
      "epoch": 31.5,
      "grad_norm": 3.1456050872802734,
      "learning_rate": 0.0057094406245296455,
      "loss": 1.0569,
      "step": 63
    },
    {
      "epoch": 32.0,
      "grad_norm": 4.677732467651367,
      "learning_rate": 0.005800066666188847,
      "loss": 1.0553,
      "step": 64
    },
    {
      "epoch": 32.5,
      "grad_norm": 3.73284649848938,
      "learning_rate": 0.005890692707848047,
      "loss": 1.04,
      "step": 65
    },
    {
      "epoch": 33.0,
      "grad_norm": 3.4569873809814453,
      "learning_rate": 0.005981318749507248,
      "loss": 1.1462,
      "step": 66
    },
    {
      "epoch": 33.5,
      "grad_norm": 4.43751335144043,
      "learning_rate": 0.006071944791166449,
      "loss": 1.0176,
      "step": 67
    },
    {
      "epoch": 34.0,
      "grad_norm": 3.014132499694824,
      "learning_rate": 0.00616257083282565,
      "loss": 1.0956,
      "step": 68
    },
    {
      "epoch": 34.5,
      "grad_norm": 3.6723053455352783,
      "learning_rate": 0.006253196874484851,
      "loss": 1.074,
      "step": 69
    },
    {
      "epoch": 35.0,
      "grad_norm": 2.7037513256073,
      "learning_rate": 0.006343822916144051,
      "loss": 0.9996,
      "step": 70
    },
    {
      "epoch": 35.5,
      "grad_norm": 3.525641441345215,
      "learning_rate": 0.006434448957803251,
      "loss": 0.9707,
      "step": 71
    },
    {
      "epoch": 36.0,
      "grad_norm": 3.3686633110046387,
      "learning_rate": 0.0065250749994624525,
      "loss": 1.0964,
      "step": 72
    },
    {
      "epoch": 36.5,
      "grad_norm": 2.6632375717163086,
      "learning_rate": 0.006615701041121653,
      "loss": 1.0031,
      "step": 73
    },
    {
      "epoch": 37.0,
      "grad_norm": 4.654915809631348,
      "learning_rate": 0.006706327082780854,
      "loss": 1.0438,
      "step": 74
    },
    {
      "epoch": 37.5,
      "grad_norm": 3.391352891921997,
      "learning_rate": 0.006796953124440055,
      "loss": 0.9706,
      "step": 75
    },
    {
      "epoch": 38.0,
      "grad_norm": 4.6768693923950195,
      "learning_rate": 0.0068875791660992555,
      "loss": 1.1278,
      "step": 76
    },
    {
      "epoch": 38.5,
      "grad_norm": 2.978255033493042,
      "learning_rate": 0.006978205207758457,
      "loss": 0.9898,
      "step": 77
    },
    {
      "epoch": 39.0,
      "grad_norm": 3.4187848567962646,
      "learning_rate": 0.007068831249417657,
      "loss": 1.0636,
      "step": 78
    },
    {
      "epoch": 39.5,
      "grad_norm": 2.381148338317871,
      "learning_rate": 0.007159457291076858,
      "loss": 0.9769,
      "step": 79
    },
    {
      "epoch": 40.0,
      "grad_norm": 3.809171199798584,
      "learning_rate": 0.007250083332736058,
      "loss": 0.9914,
      "step": 80
    },
    {
      "epoch": 40.0,
      "eval_brier_0th_event": 0.2155922240601189,
      "eval_brier_0th_event_n": 249,
      "eval_brier_avg": 0.2155922240601189,
      "eval_brier_weighted_avg": 0.2155922240601189,
      "eval_ipcw": 0.6037261711543025,
      "eval_ipcw_0th_event": 0.6037261711543025,
      "eval_ipcw_0th_event_0.25": 0.5803698236802627,
      "eval_ipcw_0th_event_0.5": 0.59780129643031,
      "eval_ipcw_0th_event_0.75": 0.5974337987937053,
      "eval_ipcw_0th_event_1.0": 0.6037261711543025,
      "eval_ipcw_0th_event_n": 249,
      "eval_ipcw_avg": 0.5948327725146452,
      "eval_ipcw_avg_0th_event": 0.5948327725146452,
      "eval_ipcw_weighted_avg": 0.5948327725146452,
      "eval_loss": 0.7580779194831848,
      "eval_runtime": 0.0746,
      "eval_samples_per_second": 5951.896,
      "eval_steps_per_second": 13.405,
      "step": 80
    },
    {
      "epoch": 40.5,
      "grad_norm": 3.921194314956665,
      "learning_rate": 0.0072500621975207825,
      "loss": 1.0181,
      "step": 81
    },
    {
      "epoch": 40.5,
      "eval_brier_0th_event": 0.21639469174512171,
      "eval_brier_0th_event_n": 249,
      "eval_brier_avg": 0.21639469174512171,
      "eval_brier_weighted_avg": 0.21639469174512171,
      "eval_ipcw": 0.6066366292949608,
      "eval_ipcw_0th_event": 0.6066366292949608,
      "eval_ipcw_0th_event_0.25": 0.570723206802192,
      "eval_ipcw_0th_event_0.5": 0.5891313855766785,
      "eval_ipcw_0th_event_0.75": 0.5941476597928003,
      "eval_ipcw_0th_event_1.0": 0.6066366292949608,
      "eval_ipcw_0th_event_n": 249,
      "eval_ipcw_avg": 0.590159720366658,
      "eval_ipcw_avg_0th_event": 0.590159720366658,
      "eval_ipcw_weighted_avg": 0.590159720366658,
      "eval_loss": 0.7655678987503052,
      "eval_runtime": 0.0718,
      "eval_samples_per_second": 6188.036,
      "eval_steps_per_second": 13.937,
      "step": 81
    },
    {
      "epoch": 41.0,
      "grad_norm": 3.012334108352661,
      "learning_rate": 0.007249998792121407,
      "loss": 0.9289,
      "step": 82
    },
    {
      "epoch": 41.0,
      "eval_brier_0th_event": 0.22297470821275897,
      "eval_brier_0th_event_n": 249,
      "eval_brier_avg": 0.22297470821275897,
      "eval_brier_weighted_avg": 0.22297470821275897,
      "eval_ipcw": 0.6259923221139825,
      "eval_ipcw_0th_event": 0.6259923221139825,
      "eval_ipcw_0th_event_0.25": 0.5706398870174606,
      "eval_ipcw_0th_event_0.5": 0.5878731637877559,
      "eval_ipcw_0th_event_0.75": 0.5955519529756491,
      "eval_ipcw_0th_event_1.0": 0.6259923221139825,
      "eval_ipcw_0th_event_n": 249,
      "eval_ipcw_avg": 0.595014331473712,
      "eval_ipcw_avg_0th_event": 0.595014331473712,
      "eval_ipcw_weighted_avg": 0.595014331473712,
      "eval_loss": 0.7964056730270386,
      "eval_runtime": 0.0719,
      "eval_samples_per_second": 6174.475,
      "eval_steps_per_second": 13.906,
      "step": 82
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 28092412800.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
