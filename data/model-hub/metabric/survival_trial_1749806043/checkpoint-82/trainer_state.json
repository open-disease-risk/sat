{
  "best_global_step": 82,
  "best_metric": 0.6273947767798009,
  "best_model_checkpoint": "./data/model-hub/metabric/survival_trial_1749806043/checkpoint-82",
  "epoch": 41.0,
  "eval_steps": 1,
  "global_step": 82,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 2.7837419509887695,
      "learning_rate": 5.2621133962866404e-05,
      "loss": 1.5826,
      "step": 1
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.9684746265411377,
      "learning_rate": 0.00010524226792573281,
      "loss": 1.6417,
      "step": 2
    },
    {
      "epoch": 1.5,
      "grad_norm": 2.4543633460998535,
      "learning_rate": 0.0001578634018885992,
      "loss": 1.6547,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 3.1887295246124268,
      "learning_rate": 0.00021048453585146562,
      "loss": 1.5478,
      "step": 4
    },
    {
      "epoch": 2.5,
      "grad_norm": 2.556581497192383,
      "learning_rate": 0.000263105669814332,
      "loss": 1.6072,
      "step": 5
    },
    {
      "epoch": 3.0,
      "grad_norm": 2.502915859222412,
      "learning_rate": 0.0003157268037771984,
      "loss": 1.5932,
      "step": 6
    },
    {
      "epoch": 3.5,
      "grad_norm": 2.4032256603240967,
      "learning_rate": 0.0003683479377400648,
      "loss": 1.6318,
      "step": 7
    },
    {
      "epoch": 4.0,
      "grad_norm": 2.3337345123291016,
      "learning_rate": 0.00042096907170293123,
      "loss": 1.5363,
      "step": 8
    },
    {
      "epoch": 4.5,
      "grad_norm": 2.2950499057769775,
      "learning_rate": 0.0004735902056657976,
      "loss": 1.5532,
      "step": 9
    },
    {
      "epoch": 5.0,
      "grad_norm": 1.9839468002319336,
      "learning_rate": 0.000526211339628664,
      "loss": 1.6035,
      "step": 10
    },
    {
      "epoch": 5.5,
      "grad_norm": 2.076526641845703,
      "learning_rate": 0.0005788324735915305,
      "loss": 1.5736,
      "step": 11
    },
    {
      "epoch": 6.0,
      "grad_norm": 2.067774534225464,
      "learning_rate": 0.0006314536075543968,
      "loss": 1.5644,
      "step": 12
    },
    {
      "epoch": 6.5,
      "grad_norm": 2.382039785385132,
      "learning_rate": 0.0006840747415172633,
      "loss": 1.5576,
      "step": 13
    },
    {
      "epoch": 7.0,
      "grad_norm": 1.774206519126892,
      "learning_rate": 0.0007366958754801296,
      "loss": 1.5549,
      "step": 14
    },
    {
      "epoch": 7.5,
      "grad_norm": 2.116908550262451,
      "learning_rate": 0.000789317009442996,
      "loss": 1.5023,
      "step": 15
    },
    {
      "epoch": 8.0,
      "grad_norm": 2.1651360988616943,
      "learning_rate": 0.0008419381434058625,
      "loss": 1.5839,
      "step": 16
    },
    {
      "epoch": 8.5,
      "grad_norm": 2.3312292098999023,
      "learning_rate": 0.0008945592773687287,
      "loss": 1.5332,
      "step": 17
    },
    {
      "epoch": 9.0,
      "grad_norm": 1.877421259880066,
      "learning_rate": 0.0009471804113315952,
      "loss": 1.5234,
      "step": 18
    },
    {
      "epoch": 9.5,
      "grad_norm": 2.164896011352539,
      "learning_rate": 0.0009998015452944615,
      "loss": 1.5302,
      "step": 19
    },
    {
      "epoch": 10.0,
      "grad_norm": 1.9928879737854004,
      "learning_rate": 0.001052422679257328,
      "loss": 1.4615,
      "step": 20
    },
    {
      "epoch": 10.5,
      "grad_norm": 2.0970959663391113,
      "learning_rate": 0.0011050438132201945,
      "loss": 1.4989,
      "step": 21
    },
    {
      "epoch": 11.0,
      "grad_norm": 1.9896425008773804,
      "learning_rate": 0.001157664947183061,
      "loss": 1.4607,
      "step": 22
    },
    {
      "epoch": 11.5,
      "grad_norm": 1.6800051927566528,
      "learning_rate": 0.001210286081145927,
      "loss": 1.4328,
      "step": 23
    },
    {
      "epoch": 12.0,
      "grad_norm": 2.135399580001831,
      "learning_rate": 0.0012629072151087936,
      "loss": 1.4828,
      "step": 24
    },
    {
      "epoch": 12.5,
      "grad_norm": 1.7963881492614746,
      "learning_rate": 0.00131552834907166,
      "loss": 1.4613,
      "step": 25
    },
    {
      "epoch": 13.0,
      "grad_norm": 2.0349044799804688,
      "learning_rate": 0.0013681494830345266,
      "loss": 1.3797,
      "step": 26
    },
    {
      "epoch": 13.5,
      "grad_norm": 1.9011449813842773,
      "learning_rate": 0.0014207706169973929,
      "loss": 1.4406,
      "step": 27
    },
    {
      "epoch": 14.0,
      "grad_norm": 1.3219857215881348,
      "learning_rate": 0.0014733917509602591,
      "loss": 1.3474,
      "step": 28
    },
    {
      "epoch": 14.5,
      "grad_norm": 1.3925045728683472,
      "learning_rate": 0.0015260128849231256,
      "loss": 1.3547,
      "step": 29
    },
    {
      "epoch": 15.0,
      "grad_norm": 1.7129853963851929,
      "learning_rate": 0.001578634018885992,
      "loss": 1.3911,
      "step": 30
    },
    {
      "epoch": 15.5,
      "grad_norm": 1.334739089012146,
      "learning_rate": 0.0016312551528488584,
      "loss": 1.3791,
      "step": 31
    },
    {
      "epoch": 16.0,
      "grad_norm": 1.3198245763778687,
      "learning_rate": 0.001683876286811725,
      "loss": 1.3379,
      "step": 32
    },
    {
      "epoch": 16.5,
      "grad_norm": 1.2875940799713135,
      "learning_rate": 0.0017364974207745912,
      "loss": 1.3506,
      "step": 33
    },
    {
      "epoch": 17.0,
      "grad_norm": 1.0261523723602295,
      "learning_rate": 0.0017891185547374575,
      "loss": 1.3217,
      "step": 34
    },
    {
      "epoch": 17.5,
      "grad_norm": 0.8884643912315369,
      "learning_rate": 0.001841739688700324,
      "loss": 1.3576,
      "step": 35
    },
    {
      "epoch": 18.0,
      "grad_norm": 1.8856111764907837,
      "learning_rate": 0.0018943608226631905,
      "loss": 1.27,
      "step": 36
    },
    {
      "epoch": 18.5,
      "grad_norm": 1.0279675722122192,
      "learning_rate": 0.001946981956626057,
      "loss": 1.3337,
      "step": 37
    },
    {
      "epoch": 19.0,
      "grad_norm": 1.1270393133163452,
      "learning_rate": 0.001999603090588923,
      "loss": 1.2565,
      "step": 38
    },
    {
      "epoch": 19.5,
      "grad_norm": 1.09566068649292,
      "learning_rate": 0.0020522242245517896,
      "loss": 1.2545,
      "step": 39
    },
    {
      "epoch": 20.0,
      "grad_norm": 1.344864010810852,
      "learning_rate": 0.002104845358514656,
      "loss": 1.3325,
      "step": 40
    },
    {
      "epoch": 20.5,
      "grad_norm": 0.9332312345504761,
      "learning_rate": 0.002157466492477522,
      "loss": 1.2921,
      "step": 41
    },
    {
      "epoch": 21.0,
      "grad_norm": 1.5663450956344604,
      "learning_rate": 0.002210087626440389,
      "loss": 1.2324,
      "step": 42
    },
    {
      "epoch": 21.5,
      "grad_norm": 1.0792280435562134,
      "learning_rate": 0.002262708760403255,
      "loss": 1.2771,
      "step": 43
    },
    {
      "epoch": 22.0,
      "grad_norm": 1.18910551071167,
      "learning_rate": 0.002315329894366122,
      "loss": 1.2317,
      "step": 44
    },
    {
      "epoch": 22.5,
      "grad_norm": 1.0938546657562256,
      "learning_rate": 0.002367951028328988,
      "loss": 1.2452,
      "step": 45
    },
    {
      "epoch": 23.0,
      "grad_norm": 1.8254019021987915,
      "learning_rate": 0.002420572162291854,
      "loss": 1.2165,
      "step": 46
    },
    {
      "epoch": 23.5,
      "grad_norm": 1.3114548921585083,
      "learning_rate": 0.002473193296254721,
      "loss": 1.1922,
      "step": 47
    },
    {
      "epoch": 24.0,
      "grad_norm": 1.4187427759170532,
      "learning_rate": 0.002525814430217587,
      "loss": 1.2566,
      "step": 48
    },
    {
      "epoch": 24.5,
      "grad_norm": 1.6137560606002808,
      "learning_rate": 0.0025784355641804537,
      "loss": 1.1951,
      "step": 49
    },
    {
      "epoch": 25.0,
      "grad_norm": 1.6870988607406616,
      "learning_rate": 0.00263105669814332,
      "loss": 1.2152,
      "step": 50
    },
    {
      "epoch": 25.5,
      "grad_norm": 1.9511128664016724,
      "learning_rate": 0.0026836778321061862,
      "loss": 1.2051,
      "step": 51
    },
    {
      "epoch": 26.0,
      "grad_norm": 1.4992402791976929,
      "learning_rate": 0.002736298966069053,
      "loss": 1.158,
      "step": 52
    },
    {
      "epoch": 26.5,
      "grad_norm": 1.5817492008209229,
      "learning_rate": 0.0027889201000319192,
      "loss": 1.2227,
      "step": 53
    },
    {
      "epoch": 27.0,
      "grad_norm": 2.053859233856201,
      "learning_rate": 0.0028415412339947857,
      "loss": 1.1031,
      "step": 54
    },
    {
      "epoch": 27.5,
      "grad_norm": 1.4958289861679077,
      "learning_rate": 0.0028941623679576522,
      "loss": 1.1892,
      "step": 55
    },
    {
      "epoch": 28.0,
      "grad_norm": 2.6828696727752686,
      "learning_rate": 0.0029467835019205183,
      "loss": 1.1287,
      "step": 56
    },
    {
      "epoch": 28.5,
      "grad_norm": 1.6831218004226685,
      "learning_rate": 0.002999404635883385,
      "loss": 1.1301,
      "step": 57
    },
    {
      "epoch": 29.0,
      "grad_norm": 3.314061403274536,
      "learning_rate": 0.0030520257698462513,
      "loss": 1.1794,
      "step": 58
    },
    {
      "epoch": 29.5,
      "grad_norm": 3.9196455478668213,
      "learning_rate": 0.003104646903809118,
      "loss": 1.1732,
      "step": 59
    },
    {
      "epoch": 30.0,
      "grad_norm": 1.9900184869766235,
      "learning_rate": 0.003157268037771984,
      "loss": 1.108,
      "step": 60
    },
    {
      "epoch": 30.5,
      "grad_norm": 1.582783818244934,
      "learning_rate": 0.0032098891717348504,
      "loss": 1.0878,
      "step": 61
    },
    {
      "epoch": 31.0,
      "grad_norm": 1.536749005317688,
      "learning_rate": 0.003262510305697717,
      "loss": 1.1876,
      "step": 62
    },
    {
      "epoch": 31.5,
      "grad_norm": 1.5430353879928589,
      "learning_rate": 0.0033151314396605834,
      "loss": 1.0795,
      "step": 63
    },
    {
      "epoch": 32.0,
      "grad_norm": 2.6609482765197754,
      "learning_rate": 0.00336775257362345,
      "loss": 1.1241,
      "step": 64
    },
    {
      "epoch": 32.5,
      "grad_norm": 1.716048002243042,
      "learning_rate": 0.003420373707586316,
      "loss": 1.1279,
      "step": 65
    },
    {
      "epoch": 33.0,
      "grad_norm": 2.8981759548187256,
      "learning_rate": 0.0034729948415491824,
      "loss": 1.0562,
      "step": 66
    },
    {
      "epoch": 33.5,
      "grad_norm": 2.3073291778564453,
      "learning_rate": 0.003525615975512049,
      "loss": 1.0909,
      "step": 67
    },
    {
      "epoch": 34.0,
      "grad_norm": 1.8214269876480103,
      "learning_rate": 0.003578237109474915,
      "loss": 1.0916,
      "step": 68
    },
    {
      "epoch": 34.5,
      "grad_norm": 2.2376346588134766,
      "learning_rate": 0.003630858243437782,
      "loss": 1.0198,
      "step": 69
    },
    {
      "epoch": 35.0,
      "grad_norm": 1.9214987754821777,
      "learning_rate": 0.003683479377400648,
      "loss": 1.1262,
      "step": 70
    },
    {
      "epoch": 35.5,
      "grad_norm": 1.8282194137573242,
      "learning_rate": 0.0037361005113635145,
      "loss": 1.1232,
      "step": 71
    },
    {
      "epoch": 36.0,
      "grad_norm": 2.984480857849121,
      "learning_rate": 0.003788721645326381,
      "loss": 0.9852,
      "step": 72
    },
    {
      "epoch": 36.5,
      "grad_norm": 2.059938430786133,
      "learning_rate": 0.003841342779289247,
      "loss": 1.0277,
      "step": 73
    },
    {
      "epoch": 37.0,
      "grad_norm": 3.1353795528411865,
      "learning_rate": 0.003893963913252114,
      "loss": 1.078,
      "step": 74
    },
    {
      "epoch": 37.5,
      "grad_norm": 3.17004132270813,
      "learning_rate": 0.00394658504721498,
      "loss": 1.0799,
      "step": 75
    },
    {
      "epoch": 38.0,
      "grad_norm": 2.1071486473083496,
      "learning_rate": 0.003999206181177846,
      "loss": 1.028,
      "step": 76
    },
    {
      "epoch": 38.5,
      "grad_norm": 2.1919634342193604,
      "learning_rate": 0.004051827315140713,
      "loss": 1.0091,
      "step": 77
    },
    {
      "epoch": 39.0,
      "grad_norm": 2.453632116317749,
      "learning_rate": 0.004104448449103579,
      "loss": 1.002,
      "step": 78
    },
    {
      "epoch": 39.5,
      "grad_norm": 2.1126294136047363,
      "learning_rate": 0.004157069583066446,
      "loss": 0.9924,
      "step": 79
    },
    {
      "epoch": 40.0,
      "grad_norm": 2.0887064933776855,
      "learning_rate": 0.004209690717029312,
      "loss": 1.0024,
      "step": 80
    },
    {
      "epoch": 40.0,
      "eval_brier_0th_event": 0.20456987619400024,
      "eval_brier_0th_event_n": 253,
      "eval_brier_weighted_avg": 0.20456987619400024,
      "eval_ipcw_0th_event": 0.619819619430477,
      "eval_ipcw_0th_event_0.25": 0.5984178185462952,
      "eval_ipcw_0th_event_0.50": 0.6157554388046265,
      "eval_ipcw_0th_event_0.75": 0.6246222853660583,
      "eval_ipcw_0th_event_1.00": 0.6237879991531372,
      "eval_ipcw_0th_event_n": 411,
      "eval_ipcw_weighted_avg": 0.619819619430477,
      "eval_loss": 0.7051860094070435,
      "eval_runtime": 0.271,
      "eval_samples_per_second": 1516.478,
      "eval_steps_per_second": 3.69,
      "step": 80
    },
    {
      "epoch": 40.5,
      "grad_norm": 2.565119743347168,
      "learning_rate": 0.00420967844507112,
      "loss": 0.9988,
      "step": 81
    },
    {
      "epoch": 40.5,
      "eval_brier_0th_event": 0.2053636759519577,
      "eval_brier_0th_event_n": 253,
      "eval_brier_weighted_avg": 0.2053636759519577,
      "eval_ipcw_0th_event": 0.6207729737640535,
      "eval_ipcw_0th_event_0.25": 0.5995872616767883,
      "eval_ipcw_0th_event_0.50": 0.6167964339256287,
      "eval_ipcw_0th_event_0.75": 0.6268535852432251,
      "eval_ipcw_0th_event_1.00": 0.6236594915390015,
      "eval_ipcw_0th_event_n": 411,
      "eval_ipcw_weighted_avg": 0.6207729737640535,
      "eval_loss": 0.708299994468689,
      "eval_runtime": 0.2223,
      "eval_samples_per_second": 1849.128,
      "eval_steps_per_second": 4.499,
      "step": 81
    },
    {
      "epoch": 41.0,
      "grad_norm": 2.6810121536254883,
      "learning_rate": 0.004209641629339644,
      "loss": 1.0157,
      "step": 82
    },
    {
      "epoch": 41.0,
      "eval_brier_0th_event": 0.20585431158542633,
      "eval_brier_0th_event_n": 253,
      "eval_brier_weighted_avg": 0.20585431158542633,
      "eval_ipcw_0th_event": 0.6273947767798008,
      "eval_ipcw_0th_event_0.25": 0.603488564491272,
      "eval_ipcw_0th_event_0.50": 0.6214297413825989,
      "eval_ipcw_0th_event_0.75": 0.6334176659584045,
      "eval_ipcw_0th_event_1.00": 0.632077693939209,
      "eval_ipcw_0th_event_n": 411,
      "eval_ipcw_weighted_avg": 0.6273947767798009,
      "eval_loss": 0.7102586030960083,
      "eval_runtime": 0.2197,
      "eval_samples_per_second": 1870.484,
      "eval_steps_per_second": 4.551,
      "step": 82
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 27435750240.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
