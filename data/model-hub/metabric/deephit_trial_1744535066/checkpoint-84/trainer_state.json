{
  "best_global_step": 84,
  "best_metric": 0.5040445423293642,
  "best_model_checkpoint": "./data/model-hub/metabric/deephit_trial_1744535066/checkpoint-84",
  "epoch": 42.0,
  "eval_steps": 1,
  "global_step": 84,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 6.245763301849365,
      "learning_rate": 4.658333914601679e-07,
      "loss": 6.705,
      "step": 1
    },
    {
      "epoch": 1.0,
      "grad_norm": 6.418667793273926,
      "learning_rate": 9.316667829203358e-07,
      "loss": 5.6984,
      "step": 2
    },
    {
      "epoch": 1.5,
      "grad_norm": 7.215574741363525,
      "learning_rate": 1.3975001743805037e-06,
      "loss": 5.6296,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 6.260925769805908,
      "learning_rate": 1.8633335658406716e-06,
      "loss": 5.2587,
      "step": 4
    },
    {
      "epoch": 2.5,
      "grad_norm": 7.746217250823975,
      "learning_rate": 2.3291669573008394e-06,
      "loss": 5.4641,
      "step": 5
    },
    {
      "epoch": 3.0,
      "grad_norm": 6.731419086456299,
      "learning_rate": 2.7950003487610073e-06,
      "loss": 4.9782,
      "step": 6
    },
    {
      "epoch": 3.5,
      "grad_norm": 7.8434295654296875,
      "learning_rate": 3.260833740221175e-06,
      "loss": 5.1447,
      "step": 7
    },
    {
      "epoch": 4.0,
      "grad_norm": 8.321608543395996,
      "learning_rate": 3.7266671316813433e-06,
      "loss": 5.3891,
      "step": 8
    },
    {
      "epoch": 4.5,
      "grad_norm": 9.080058097839355,
      "learning_rate": 4.192500523141511e-06,
      "loss": 5.373,
      "step": 9
    },
    {
      "epoch": 5.0,
      "grad_norm": 8.613134384155273,
      "learning_rate": 4.658333914601679e-06,
      "loss": 5.1943,
      "step": 10
    },
    {
      "epoch": 5.5,
      "grad_norm": 9.680222511291504,
      "learning_rate": 5.124167306061847e-06,
      "loss": 5.4289,
      "step": 11
    },
    {
      "epoch": 6.0,
      "grad_norm": 7.914968013763428,
      "learning_rate": 5.590000697522015e-06,
      "loss": 5.2947,
      "step": 12
    },
    {
      "epoch": 6.5,
      "grad_norm": 10.603285789489746,
      "learning_rate": 6.055834088982183e-06,
      "loss": 5.4946,
      "step": 13
    },
    {
      "epoch": 7.0,
      "grad_norm": 11.159566879272461,
      "learning_rate": 6.52166748044235e-06,
      "loss": 5.5589,
      "step": 14
    },
    {
      "epoch": 7.5,
      "grad_norm": 10.703681945800781,
      "learning_rate": 6.987500871902518e-06,
      "loss": 5.6059,
      "step": 15
    },
    {
      "epoch": 8.0,
      "grad_norm": 11.597884178161621,
      "learning_rate": 7.4533342633626865e-06,
      "loss": 5.7613,
      "step": 16
    },
    {
      "epoch": 8.5,
      "grad_norm": 10.66981315612793,
      "learning_rate": 7.919167654822854e-06,
      "loss": 5.8073,
      "step": 17
    },
    {
      "epoch": 9.0,
      "grad_norm": 13.835678100585938,
      "learning_rate": 8.385001046283022e-06,
      "loss": 5.604,
      "step": 18
    },
    {
      "epoch": 9.5,
      "grad_norm": 11.129334449768066,
      "learning_rate": 8.85083443774319e-06,
      "loss": 5.7367,
      "step": 19
    },
    {
      "epoch": 10.0,
      "grad_norm": 11.99357795715332,
      "learning_rate": 9.316667829203358e-06,
      "loss": 6.0189,
      "step": 20
    },
    {
      "epoch": 10.5,
      "grad_norm": 11.840620040893555,
      "learning_rate": 9.782501220663526e-06,
      "loss": 5.8735,
      "step": 21
    },
    {
      "epoch": 11.0,
      "grad_norm": 12.814833641052246,
      "learning_rate": 1.0248334612123693e-05,
      "loss": 5.9223,
      "step": 22
    },
    {
      "epoch": 11.5,
      "grad_norm": 11.51529312133789,
      "learning_rate": 1.071416800358386e-05,
      "loss": 6.0149,
      "step": 23
    },
    {
      "epoch": 12.0,
      "grad_norm": 13.23857593536377,
      "learning_rate": 1.118000139504403e-05,
      "loss": 5.6869,
      "step": 24
    },
    {
      "epoch": 12.5,
      "grad_norm": 13.049413681030273,
      "learning_rate": 1.1645834786504197e-05,
      "loss": 5.9434,
      "step": 25
    },
    {
      "epoch": 13.0,
      "grad_norm": 12.15061092376709,
      "learning_rate": 1.2111668177964365e-05,
      "loss": 5.882,
      "step": 26
    },
    {
      "epoch": 13.5,
      "grad_norm": 11.361245155334473,
      "learning_rate": 1.2577501569424533e-05,
      "loss": 5.9821,
      "step": 27
    },
    {
      "epoch": 14.0,
      "grad_norm": 12.690399169921875,
      "learning_rate": 1.30433349608847e-05,
      "loss": 6.0249,
      "step": 28
    },
    {
      "epoch": 14.5,
      "grad_norm": 12.286286354064941,
      "learning_rate": 1.3509168352344868e-05,
      "loss": 6.0584,
      "step": 29
    },
    {
      "epoch": 15.0,
      "grad_norm": 12.88084888458252,
      "learning_rate": 1.3975001743805035e-05,
      "loss": 5.8842,
      "step": 30
    },
    {
      "epoch": 15.5,
      "grad_norm": 11.600419998168945,
      "learning_rate": 1.4440835135265205e-05,
      "loss": 6.0026,
      "step": 31
    },
    {
      "epoch": 16.0,
      "grad_norm": 12.332701683044434,
      "learning_rate": 1.4906668526725373e-05,
      "loss": 6.0588,
      "step": 32
    },
    {
      "epoch": 16.5,
      "grad_norm": 11.339052200317383,
      "learning_rate": 1.537250191818554e-05,
      "loss": 5.9881,
      "step": 33
    },
    {
      "epoch": 17.0,
      "grad_norm": 11.084118843078613,
      "learning_rate": 1.5838335309645707e-05,
      "loss": 5.9228,
      "step": 34
    },
    {
      "epoch": 17.5,
      "grad_norm": 12.090960502624512,
      "learning_rate": 1.6304168701105875e-05,
      "loss": 5.9628,
      "step": 35
    },
    {
      "epoch": 18.0,
      "grad_norm": 12.14377212524414,
      "learning_rate": 1.6770002092566043e-05,
      "loss": 5.9988,
      "step": 36
    },
    {
      "epoch": 18.5,
      "grad_norm": 11.994427680969238,
      "learning_rate": 1.723583548402621e-05,
      "loss": 6.0596,
      "step": 37
    },
    {
      "epoch": 19.0,
      "grad_norm": 12.329534530639648,
      "learning_rate": 1.770166887548638e-05,
      "loss": 5.9189,
      "step": 38
    },
    {
      "epoch": 19.5,
      "grad_norm": 12.337371826171875,
      "learning_rate": 1.8167502266946547e-05,
      "loss": 5.9185,
      "step": 39
    },
    {
      "epoch": 20.0,
      "grad_norm": 11.521947860717773,
      "learning_rate": 1.8633335658406715e-05,
      "loss": 5.9836,
      "step": 40
    },
    {
      "epoch": 20.5,
      "grad_norm": 12.120655059814453,
      "learning_rate": 1.909916904986688e-05,
      "loss": 6.0229,
      "step": 41
    },
    {
      "epoch": 21.0,
      "grad_norm": 10.473088264465332,
      "learning_rate": 1.956500244132705e-05,
      "loss": 5.9912,
      "step": 42
    },
    {
      "epoch": 21.5,
      "grad_norm": 12.33923625946045,
      "learning_rate": 2.003083583278722e-05,
      "loss": 5.9925,
      "step": 43
    },
    {
      "epoch": 22.0,
      "grad_norm": 12.573609352111816,
      "learning_rate": 2.0496669224247387e-05,
      "loss": 5.9076,
      "step": 44
    },
    {
      "epoch": 22.5,
      "grad_norm": 11.464411735534668,
      "learning_rate": 2.0962502615707555e-05,
      "loss": 6.0736,
      "step": 45
    },
    {
      "epoch": 23.0,
      "grad_norm": 10.76844310760498,
      "learning_rate": 2.142833600716772e-05,
      "loss": 6.017,
      "step": 46
    },
    {
      "epoch": 23.5,
      "grad_norm": 11.920573234558105,
      "learning_rate": 2.189416939862789e-05,
      "loss": 6.0162,
      "step": 47
    },
    {
      "epoch": 24.0,
      "grad_norm": 11.444660186767578,
      "learning_rate": 2.236000279008806e-05,
      "loss": 5.9279,
      "step": 48
    },
    {
      "epoch": 24.5,
      "grad_norm": 11.096652030944824,
      "learning_rate": 2.2825836181548227e-05,
      "loss": 6.0755,
      "step": 49
    },
    {
      "epoch": 25.0,
      "grad_norm": 13.621572494506836,
      "learning_rate": 2.3291669573008395e-05,
      "loss": 5.8204,
      "step": 50
    },
    {
      "epoch": 25.5,
      "grad_norm": 10.46830940246582,
      "learning_rate": 2.375750296446856e-05,
      "loss": 6.0994,
      "step": 51
    },
    {
      "epoch": 26.0,
      "grad_norm": 11.705709457397461,
      "learning_rate": 2.422333635592873e-05,
      "loss": 5.9501,
      "step": 52
    },
    {
      "epoch": 26.5,
      "grad_norm": 11.82848072052002,
      "learning_rate": 2.4689169747388895e-05,
      "loss": 5.9084,
      "step": 53
    },
    {
      "epoch": 27.0,
      "grad_norm": 10.945396423339844,
      "learning_rate": 2.5155003138849067e-05,
      "loss": 6.1154,
      "step": 54
    },
    {
      "epoch": 27.5,
      "grad_norm": 11.186200141906738,
      "learning_rate": 2.5620836530309235e-05,
      "loss": 5.9884,
      "step": 55
    },
    {
      "epoch": 28.0,
      "grad_norm": 11.91386604309082,
      "learning_rate": 2.60866699217694e-05,
      "loss": 5.9895,
      "step": 56
    },
    {
      "epoch": 28.5,
      "grad_norm": 9.625983238220215,
      "learning_rate": 2.655250331322957e-05,
      "loss": 6.1827,
      "step": 57
    },
    {
      "epoch": 29.0,
      "grad_norm": 12.75706958770752,
      "learning_rate": 2.7018336704689735e-05,
      "loss": 5.6707,
      "step": 58
    },
    {
      "epoch": 29.5,
      "grad_norm": 10.778996467590332,
      "learning_rate": 2.7484170096149906e-05,
      "loss": 5.932,
      "step": 59
    },
    {
      "epoch": 30.0,
      "grad_norm": 11.256553649902344,
      "learning_rate": 2.795000348761007e-05,
      "loss": 6.1961,
      "step": 60
    },
    {
      "epoch": 30.5,
      "grad_norm": 10.574844360351562,
      "learning_rate": 2.841583687907024e-05,
      "loss": 5.9801,
      "step": 61
    },
    {
      "epoch": 31.0,
      "grad_norm": 11.300830841064453,
      "learning_rate": 2.888167027053041e-05,
      "loss": 6.0018,
      "step": 62
    },
    {
      "epoch": 31.5,
      "grad_norm": 11.313888549804688,
      "learning_rate": 2.9347503661990575e-05,
      "loss": 5.9611,
      "step": 63
    },
    {
      "epoch": 32.0,
      "grad_norm": 10.659714698791504,
      "learning_rate": 2.9813337053450746e-05,
      "loss": 5.8937,
      "step": 64
    },
    {
      "epoch": 32.5,
      "grad_norm": 11.904641151428223,
      "learning_rate": 3.027917044491091e-05,
      "loss": 6.0312,
      "step": 65
    },
    {
      "epoch": 33.0,
      "grad_norm": 11.042248725891113,
      "learning_rate": 3.074500383637108e-05,
      "loss": 6.0011,
      "step": 66
    },
    {
      "epoch": 33.5,
      "grad_norm": 11.294525146484375,
      "learning_rate": 3.121083722783125e-05,
      "loss": 5.9849,
      "step": 67
    },
    {
      "epoch": 34.0,
      "grad_norm": 9.153867721557617,
      "learning_rate": 3.1676670619291415e-05,
      "loss": 5.9407,
      "step": 68
    },
    {
      "epoch": 34.5,
      "grad_norm": 9.639015197753906,
      "learning_rate": 3.214250401075158e-05,
      "loss": 6.0376,
      "step": 69
    },
    {
      "epoch": 35.0,
      "grad_norm": 13.055779457092285,
      "learning_rate": 3.260833740221175e-05,
      "loss": 5.8914,
      "step": 70
    },
    {
      "epoch": 35.5,
      "grad_norm": 10.379666328430176,
      "learning_rate": 3.307417079367192e-05,
      "loss": 5.9076,
      "step": 71
    },
    {
      "epoch": 36.0,
      "grad_norm": 11.043145179748535,
      "learning_rate": 3.3540004185132086e-05,
      "loss": 6.1372,
      "step": 72
    },
    {
      "epoch": 36.5,
      "grad_norm": 10.855050086975098,
      "learning_rate": 3.4005837576592254e-05,
      "loss": 5.9571,
      "step": 73
    },
    {
      "epoch": 37.0,
      "grad_norm": 11.004704475402832,
      "learning_rate": 3.447167096805242e-05,
      "loss": 6.1226,
      "step": 74
    },
    {
      "epoch": 37.5,
      "grad_norm": 11.057805061340332,
      "learning_rate": 3.493750435951259e-05,
      "loss": 5.8993,
      "step": 75
    },
    {
      "epoch": 38.0,
      "grad_norm": 10.696372032165527,
      "learning_rate": 3.540333775097276e-05,
      "loss": 6.099,
      "step": 76
    },
    {
      "epoch": 38.5,
      "grad_norm": 10.346552848815918,
      "learning_rate": 3.5869171142432926e-05,
      "loss": 5.8947,
      "step": 77
    },
    {
      "epoch": 39.0,
      "grad_norm": 11.3052978515625,
      "learning_rate": 3.6335004533893094e-05,
      "loss": 6.0145,
      "step": 78
    },
    {
      "epoch": 39.5,
      "grad_norm": 10.34659481048584,
      "learning_rate": 3.680083792535326e-05,
      "loss": 6.0661,
      "step": 79
    },
    {
      "epoch": 40.0,
      "grad_norm": 9.299695014953613,
      "learning_rate": 3.726667131681343e-05,
      "loss": 5.76,
      "step": 80
    },
    {
      "epoch": 40.0,
      "eval_brier_0th_event": 0.22876289605707587,
      "eval_brier_0th_event_n": 248,
      "eval_brier_avg": 0.22876289605707587,
      "eval_brier_weighted_avg": 0.22876289605707587,
      "eval_ipcw": 0.5213350849275299,
      "eval_ipcw_0th_event": 0.5213350849275299,
      "eval_ipcw_0th_event_0.25": 0.48363061921984984,
      "eval_ipcw_0th_event_0.5": 0.5046481911693884,
      "eval_ipcw_0th_event_0.75": 0.503141624819421,
      "eval_ipcw_0th_event_1.0": 0.5213350849275299,
      "eval_ipcw_0th_event_n": 248,
      "eval_ipcw_avg": 0.5031888800340473,
      "eval_ipcw_avg_0th_event": 0.5031888800340473,
      "eval_ipcw_weighted_avg": 0.5031888800340473,
      "eval_loss": 3.105335235595703,
      "eval_runtime": 0.1101,
      "eval_samples_per_second": 4034.452,
      "eval_steps_per_second": 9.087,
      "step": 80
    },
    {
      "epoch": 40.5,
      "grad_norm": 10.20895767211914,
      "learning_rate": 3.7266562678183396e-05,
      "loss": 5.8941,
      "step": 81
    },
    {
      "epoch": 40.5,
      "eval_brier_0th_event": 0.22859032094685727,
      "eval_brier_0th_event_n": 248,
      "eval_brier_avg": 0.22859032094685727,
      "eval_brier_weighted_avg": 0.22859032094685727,
      "eval_ipcw": 0.5209426322699505,
      "eval_ipcw_0th_event": 0.5209426322699505,
      "eval_ipcw_0th_event_0.25": 0.48603099469702343,
      "eval_ipcw_0th_event_0.5": 0.5051592408211131,
      "eval_ipcw_0th_event_0.75": 0.5027388527718776,
      "eval_ipcw_0th_event_1.0": 0.5209426322699505,
      "eval_ipcw_0th_event_n": 248,
      "eval_ipcw_avg": 0.5037179301399911,
      "eval_ipcw_avg_0th_event": 0.5037179301399911,
      "eval_ipcw_weighted_avg": 0.5037179301399911,
      "eval_loss": 3.1166129112243652,
      "eval_runtime": 0.0847,
      "eval_samples_per_second": 5239.251,
      "eval_steps_per_second": 11.8,
      "step": 81
    },
    {
      "epoch": 41.0,
      "grad_norm": 11.32239055633545,
      "learning_rate": 3.7266236763560104e-05,
      "loss": 6.094,
      "step": 82
    },
    {
      "epoch": 41.0,
      "eval_brier_0th_event": 0.22842146685085224,
      "eval_brier_0th_event_n": 248,
      "eval_brier_avg": 0.22842146685085224,
      "eval_brier_weighted_avg": 0.22842146685085224,
      "eval_ipcw": 0.5206733021078244,
      "eval_ipcw_0th_event": 0.5206733021078244,
      "eval_ipcw_0th_event_0.25": 0.4876289251205449,
      "eval_ipcw_0th_event_0.5": 0.50501766213376,
      "eval_ipcw_0th_event_0.75": 0.5018851890640761,
      "eval_ipcw_0th_event_1.0": 0.5206733021078244,
      "eval_ipcw_0th_event_n": 248,
      "eval_ipcw_avg": 0.5038012696065514,
      "eval_ipcw_avg_0th_event": 0.5038012696065514,
      "eval_ipcw_weighted_avg": 0.5038012696065514,
      "eval_loss": 3.1036484241485596,
      "eval_runtime": 0.096,
      "eval_samples_per_second": 4626.68,
      "eval_steps_per_second": 10.42,
      "step": 82
    },
    {
      "epoch": 41.5,
      "grad_norm": 9.81186580657959,
      "learning_rate": 3.7265693576743926e-05,
      "loss": 6.1601,
      "step": 83
    },
    {
      "epoch": 41.5,
      "eval_brier_0th_event": 0.22825479110201286,
      "eval_brier_0th_event_n": 248,
      "eval_brier_avg": 0.22825479110201286,
      "eval_brier_weighted_avg": 0.22825479110201286,
      "eval_ipcw": 0.5198463492238122,
      "eval_ipcw_0th_event": 0.5198463492238122,
      "eval_ipcw_0th_event_0.25": 0.4894325660426987,
      "eval_ipcw_0th_event_0.5": 0.5051828778142354,
      "eval_ipcw_0th_event_0.75": 0.5007061714004716,
      "eval_ipcw_0th_event_1.0": 0.5198463492238122,
      "eval_ipcw_0th_event_n": 248,
      "eval_ipcw_avg": 0.5037919911203045,
      "eval_ipcw_avg_0th_event": 0.5037919911203045,
      "eval_ipcw_weighted_avg": 0.5037919911203045,
      "eval_loss": 3.0829851627349854,
      "eval_runtime": 0.0889,
      "eval_samples_per_second": 4991.733,
      "eval_steps_per_second": 11.243,
      "step": 83
    },
    {
      "epoch": 42.0,
      "grad_norm": 11.172338485717773,
      "learning_rate": 3.72649331240688e-05,
      "loss": 5.8158,
      "step": 84
    },
    {
      "epoch": 42.0,
      "eval_brier_0th_event": 0.22809041939497882,
      "eval_brier_0th_event_n": 248,
      "eval_brier_avg": 0.22809041939497882,
      "eval_brier_weighted_avg": 0.22809041939497882,
      "eval_ipcw": 0.5193914686277872,
      "eval_ipcw_0th_event": 0.5193914686277872,
      "eval_ipcw_0th_event_0.25": 0.4906144579900453,
      "eval_ipcw_0th_event_0.5": 0.5056731975433263,
      "eval_ipcw_0th_event_0.75": 0.5004990451562983,
      "eval_ipcw_0th_event_1.0": 0.5193914686277872,
      "eval_ipcw_0th_event_n": 248,
      "eval_ipcw_avg": 0.5040445423293642,
      "eval_ipcw_avg_0th_event": 0.5040445423293642,
      "eval_ipcw_weighted_avg": 0.5040445423293642,
      "eval_loss": 3.103895425796509,
      "eval_runtime": 0.083,
      "eval_samples_per_second": 5346.882,
      "eval_steps_per_second": 12.043,
      "step": 84
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4824610560.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
