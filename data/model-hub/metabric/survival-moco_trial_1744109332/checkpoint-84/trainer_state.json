{
  "best_global_step": 84,
  "best_metric": 0.6117953013948128,
  "best_model_checkpoint": "./data/model-hub/metabric/survival-moco_trial_1744109332/checkpoint-84",
  "epoch": 42.0,
  "eval_steps": 1,
  "global_step": 84,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 2.819502592086792,
      "learning_rate": 6.793556304325592e-05,
      "loss": 1.5739,
      "step": 1
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.1984055042266846,
      "learning_rate": 0.00013587112608651184,
      "loss": 1.5918,
      "step": 2
    },
    {
      "epoch": 1.5,
      "grad_norm": 2.7558224201202393,
      "learning_rate": 0.00020380668912976777,
      "loss": 1.5691,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.9314740896224976,
      "learning_rate": 0.0002717422521730237,
      "loss": 1.5904,
      "step": 4
    },
    {
      "epoch": 2.5,
      "grad_norm": 2.3745040893554688,
      "learning_rate": 0.0003396778152162796,
      "loss": 1.566,
      "step": 5
    },
    {
      "epoch": 3.0,
      "grad_norm": 1.9555909633636475,
      "learning_rate": 0.00040761337825953554,
      "loss": 1.5659,
      "step": 6
    },
    {
      "epoch": 3.5,
      "grad_norm": 2.1810028553009033,
      "learning_rate": 0.0004755489413027914,
      "loss": 1.5587,
      "step": 7
    },
    {
      "epoch": 4.0,
      "grad_norm": 2.136423110961914,
      "learning_rate": 0.0005434845043460473,
      "loss": 1.5472,
      "step": 8
    },
    {
      "epoch": 4.5,
      "grad_norm": 2.4029541015625,
      "learning_rate": 0.0006114200673893033,
      "loss": 1.541,
      "step": 9
    },
    {
      "epoch": 5.0,
      "grad_norm": 2.3251051902770996,
      "learning_rate": 0.0006793556304325592,
      "loss": 1.5482,
      "step": 10
    },
    {
      "epoch": 5.5,
      "grad_norm": 2.772475004196167,
      "learning_rate": 0.0007472911934758152,
      "loss": 1.5247,
      "step": 11
    },
    {
      "epoch": 6.0,
      "grad_norm": 2.8018863201141357,
      "learning_rate": 0.0008152267565190711,
      "loss": 1.5374,
      "step": 12
    },
    {
      "epoch": 6.5,
      "grad_norm": 2.3570408821105957,
      "learning_rate": 0.000883162319562327,
      "loss": 1.5157,
      "step": 13
    },
    {
      "epoch": 7.0,
      "grad_norm": 3.190953016281128,
      "learning_rate": 0.0009510978826055828,
      "loss": 1.5135,
      "step": 14
    },
    {
      "epoch": 7.5,
      "grad_norm": 2.883236885070801,
      "learning_rate": 0.001019033445648839,
      "loss": 1.4934,
      "step": 15
    },
    {
      "epoch": 8.0,
      "grad_norm": 2.5636866092681885,
      "learning_rate": 0.0010869690086920947,
      "loss": 1.4662,
      "step": 16
    },
    {
      "epoch": 8.5,
      "grad_norm": 2.696199655532837,
      "learning_rate": 0.0011549045717353507,
      "loss": 1.4561,
      "step": 17
    },
    {
      "epoch": 9.0,
      "grad_norm": 2.4206175804138184,
      "learning_rate": 0.0012228401347786067,
      "loss": 1.4483,
      "step": 18
    },
    {
      "epoch": 9.5,
      "grad_norm": 2.679572820663452,
      "learning_rate": 0.0012907756978218624,
      "loss": 1.4228,
      "step": 19
    },
    {
      "epoch": 10.0,
      "grad_norm": 2.093536615371704,
      "learning_rate": 0.0013587112608651184,
      "loss": 1.4282,
      "step": 20
    },
    {
      "epoch": 10.5,
      "grad_norm": 1.586362600326538,
      "learning_rate": 0.0014266468239083744,
      "loss": 1.3936,
      "step": 21
    },
    {
      "epoch": 11.0,
      "grad_norm": 1.7438442707061768,
      "learning_rate": 0.0014945823869516304,
      "loss": 1.4122,
      "step": 22
    },
    {
      "epoch": 11.5,
      "grad_norm": 1.6214641332626343,
      "learning_rate": 0.0015625179499948862,
      "loss": 1.3862,
      "step": 23
    },
    {
      "epoch": 12.0,
      "grad_norm": 1.1777924299240112,
      "learning_rate": 0.0016304535130381422,
      "loss": 1.396,
      "step": 24
    },
    {
      "epoch": 12.5,
      "grad_norm": 1.8870412111282349,
      "learning_rate": 0.001698389076081398,
      "loss": 1.3691,
      "step": 25
    },
    {
      "epoch": 13.0,
      "grad_norm": 1.5389100313186646,
      "learning_rate": 0.001766324639124654,
      "loss": 1.3795,
      "step": 26
    },
    {
      "epoch": 13.5,
      "grad_norm": 1.6696887016296387,
      "learning_rate": 0.00183426020216791,
      "loss": 1.3568,
      "step": 27
    },
    {
      "epoch": 14.0,
      "grad_norm": 1.7625539302825928,
      "learning_rate": 0.0019021957652111657,
      "loss": 1.3698,
      "step": 28
    },
    {
      "epoch": 14.5,
      "grad_norm": 1.74649178981781,
      "learning_rate": 0.001970131328254422,
      "loss": 1.3548,
      "step": 29
    },
    {
      "epoch": 15.0,
      "grad_norm": 1.8746349811553955,
      "learning_rate": 0.002038066891297678,
      "loss": 1.3553,
      "step": 30
    },
    {
      "epoch": 15.5,
      "grad_norm": 1.5396158695220947,
      "learning_rate": 0.0021060024543409334,
      "loss": 1.3465,
      "step": 31
    },
    {
      "epoch": 16.0,
      "grad_norm": 2.10802960395813,
      "learning_rate": 0.0021739380173841894,
      "loss": 1.352,
      "step": 32
    },
    {
      "epoch": 16.5,
      "grad_norm": 1.6719475984573364,
      "learning_rate": 0.0022418735804274454,
      "loss": 1.3088,
      "step": 33
    },
    {
      "epoch": 17.0,
      "grad_norm": 2.1314640045166016,
      "learning_rate": 0.0023098091434707014,
      "loss": 1.3487,
      "step": 34
    },
    {
      "epoch": 17.5,
      "grad_norm": 1.938827633857727,
      "learning_rate": 0.0023777447065139574,
      "loss": 1.3317,
      "step": 35
    },
    {
      "epoch": 18.0,
      "grad_norm": 1.8071539402008057,
      "learning_rate": 0.0024456802695572133,
      "loss": 1.3089,
      "step": 36
    },
    {
      "epoch": 18.5,
      "grad_norm": 1.5273035764694214,
      "learning_rate": 0.0025136158326004693,
      "loss": 1.3191,
      "step": 37
    },
    {
      "epoch": 19.0,
      "grad_norm": 2.0852811336517334,
      "learning_rate": 0.002581551395643725,
      "loss": 1.2791,
      "step": 38
    },
    {
      "epoch": 19.5,
      "grad_norm": 2.1485495567321777,
      "learning_rate": 0.002649486958686981,
      "loss": 1.3013,
      "step": 39
    },
    {
      "epoch": 20.0,
      "grad_norm": 2.3760125637054443,
      "learning_rate": 0.002717422521730237,
      "loss": 1.2855,
      "step": 40
    },
    {
      "epoch": 20.5,
      "grad_norm": 1.8799939155578613,
      "learning_rate": 0.0027853580847734924,
      "loss": 1.2786,
      "step": 41
    },
    {
      "epoch": 21.0,
      "grad_norm": 2.240469455718994,
      "learning_rate": 0.002853293647816749,
      "loss": 1.2919,
      "step": 42
    },
    {
      "epoch": 21.5,
      "grad_norm": 3.2575385570526123,
      "learning_rate": 0.0029212292108600044,
      "loss": 1.2562,
      "step": 43
    },
    {
      "epoch": 22.0,
      "grad_norm": 3.244321823120117,
      "learning_rate": 0.002989164773903261,
      "loss": 1.3049,
      "step": 44
    },
    {
      "epoch": 22.5,
      "grad_norm": 2.3836779594421387,
      "learning_rate": 0.0030571003369465164,
      "loss": 1.2788,
      "step": 45
    },
    {
      "epoch": 23.0,
      "grad_norm": 4.024979591369629,
      "learning_rate": 0.0031250358999897723,
      "loss": 1.2688,
      "step": 46
    },
    {
      "epoch": 23.5,
      "grad_norm": 2.8468832969665527,
      "learning_rate": 0.0031929714630330283,
      "loss": 1.2364,
      "step": 47
    },
    {
      "epoch": 24.0,
      "grad_norm": 3.840761423110962,
      "learning_rate": 0.0032609070260762843,
      "loss": 1.3068,
      "step": 48
    },
    {
      "epoch": 24.5,
      "grad_norm": 2.1119093894958496,
      "learning_rate": 0.0033288425891195403,
      "loss": 1.2169,
      "step": 49
    },
    {
      "epoch": 25.0,
      "grad_norm": 2.5955724716186523,
      "learning_rate": 0.003396778152162796,
      "loss": 1.232,
      "step": 50
    },
    {
      "epoch": 25.5,
      "grad_norm": 4.046038627624512,
      "learning_rate": 0.003464713715206052,
      "loss": 1.2646,
      "step": 51
    },
    {
      "epoch": 26.0,
      "grad_norm": 2.5983846187591553,
      "learning_rate": 0.003532649278249308,
      "loss": 1.201,
      "step": 52
    },
    {
      "epoch": 26.5,
      "grad_norm": 3.1296286582946777,
      "learning_rate": 0.003600584841292564,
      "loss": 1.2238,
      "step": 53
    },
    {
      "epoch": 27.0,
      "grad_norm": 2.565713405609131,
      "learning_rate": 0.00366852040433582,
      "loss": 1.222,
      "step": 54
    },
    {
      "epoch": 27.5,
      "grad_norm": 3.1561734676361084,
      "learning_rate": 0.003736455967379076,
      "loss": 1.2146,
      "step": 55
    },
    {
      "epoch": 28.0,
      "grad_norm": 2.937617301940918,
      "learning_rate": 0.0038043915304223313,
      "loss": 1.1971,
      "step": 56
    },
    {
      "epoch": 28.5,
      "grad_norm": 2.7201759815216064,
      "learning_rate": 0.0038723270934655878,
      "loss": 1.1885,
      "step": 57
    },
    {
      "epoch": 29.0,
      "grad_norm": 3.0772595405578613,
      "learning_rate": 0.003940262656508844,
      "loss": 1.2027,
      "step": 58
    },
    {
      "epoch": 29.5,
      "grad_norm": 2.7382254600524902,
      "learning_rate": 0.0040081982195521,
      "loss": 1.1737,
      "step": 59
    },
    {
      "epoch": 30.0,
      "grad_norm": 2.606698751449585,
      "learning_rate": 0.004076133782595356,
      "loss": 1.2385,
      "step": 60
    },
    {
      "epoch": 30.5,
      "grad_norm": 1.9139699935913086,
      "learning_rate": 0.004144069345638611,
      "loss": 1.1521,
      "step": 61
    },
    {
      "epoch": 31.0,
      "grad_norm": 4.162480354309082,
      "learning_rate": 0.004212004908681867,
      "loss": 1.2192,
      "step": 62
    },
    {
      "epoch": 31.5,
      "grad_norm": 2.0837347507476807,
      "learning_rate": 0.004279940471725123,
      "loss": 1.144,
      "step": 63
    },
    {
      "epoch": 32.0,
      "grad_norm": 2.538116931915283,
      "learning_rate": 0.004347876034768379,
      "loss": 1.1759,
      "step": 64
    },
    {
      "epoch": 32.5,
      "grad_norm": 3.770038366317749,
      "learning_rate": 0.004415811597811635,
      "loss": 1.1299,
      "step": 65
    },
    {
      "epoch": 33.0,
      "grad_norm": 3.273681640625,
      "learning_rate": 0.004483747160854891,
      "loss": 1.172,
      "step": 66
    },
    {
      "epoch": 33.5,
      "grad_norm": 2.911363363265991,
      "learning_rate": 0.004551682723898147,
      "loss": 1.124,
      "step": 67
    },
    {
      "epoch": 34.0,
      "grad_norm": 3.5393974781036377,
      "learning_rate": 0.004619618286941403,
      "loss": 1.115,
      "step": 68
    },
    {
      "epoch": 34.5,
      "grad_norm": 3.411121368408203,
      "learning_rate": 0.004687553849984659,
      "loss": 1.1587,
      "step": 69
    },
    {
      "epoch": 35.0,
      "grad_norm": 3.2163407802581787,
      "learning_rate": 0.004755489413027915,
      "loss": 1.1501,
      "step": 70
    },
    {
      "epoch": 35.5,
      "grad_norm": 2.673478841781616,
      "learning_rate": 0.00482342497607117,
      "loss": 1.1143,
      "step": 71
    },
    {
      "epoch": 36.0,
      "grad_norm": 5.274588584899902,
      "learning_rate": 0.004891360539114427,
      "loss": 1.1985,
      "step": 72
    },
    {
      "epoch": 36.5,
      "grad_norm": 3.1869354248046875,
      "learning_rate": 0.004959296102157682,
      "loss": 1.1297,
      "step": 73
    },
    {
      "epoch": 37.0,
      "grad_norm": 4.143502235412598,
      "learning_rate": 0.005027231665200939,
      "loss": 1.1022,
      "step": 74
    },
    {
      "epoch": 37.5,
      "grad_norm": 3.3998124599456787,
      "learning_rate": 0.005095167228244194,
      "loss": 1.0849,
      "step": 75
    },
    {
      "epoch": 38.0,
      "grad_norm": 3.559161424636841,
      "learning_rate": 0.00516310279128745,
      "loss": 1.1504,
      "step": 76
    },
    {
      "epoch": 38.5,
      "grad_norm": 3.833648204803467,
      "learning_rate": 0.005231038354330706,
      "loss": 1.0877,
      "step": 77
    },
    {
      "epoch": 39.0,
      "grad_norm": 3.16288685798645,
      "learning_rate": 0.005298973917373962,
      "loss": 1.1144,
      "step": 78
    },
    {
      "epoch": 39.5,
      "grad_norm": 3.596269130706787,
      "learning_rate": 0.005366909480417218,
      "loss": 1.0562,
      "step": 79
    },
    {
      "epoch": 40.0,
      "grad_norm": 2.9814670085906982,
      "learning_rate": 0.005434845043460474,
      "loss": 1.1329,
      "step": 80
    },
    {
      "epoch": 40.0,
      "eval_brier_0th_event": 0.2386215736606697,
      "eval_brier_0th_event_n": 264,
      "eval_brier_avg": 0.2386215736606697,
      "eval_brier_weighted_avg": 0.2386215736606697,
      "eval_ipcw": 0.5988632360242858,
      "eval_ipcw_0th_event": 0.5988632360242858,
      "eval_ipcw_0th_event_0.25": 0.6114878723236834,
      "eval_ipcw_0th_event_0.5": 0.5859719380635692,
      "eval_ipcw_0th_event_0.75": 0.5973013213501263,
      "eval_ipcw_0th_event_1.0": 0.5988632360242858,
      "eval_ipcw_0th_event_n": 264,
      "eval_ipcw_avg": 0.5984060919404162,
      "eval_ipcw_avg_0th_event": 0.5984060919404162,
      "eval_ipcw_weighted_avg": 0.5984060919404162,
      "eval_loss": 0.8792813420295715,
      "eval_runtime": 0.0698,
      "eval_samples_per_second": 6363.584,
      "eval_steps_per_second": 14.332,
      "step": 80
    },
    {
      "epoch": 40.5,
      "grad_norm": 3.033022403717041,
      "learning_rate": 0.00543482919997086,
      "loss": 1.0385,
      "step": 81
    },
    {
      "epoch": 40.5,
      "eval_brier_0th_event": 0.2357223928453787,
      "eval_brier_0th_event_n": 264,
      "eval_brier_avg": 0.2357223928453787,
      "eval_brier_weighted_avg": 0.2357223928453787,
      "eval_ipcw": 0.6013721010684424,
      "eval_ipcw_0th_event": 0.6013721010684424,
      "eval_ipcw_0th_event_0.25": 0.6134064573296815,
      "eval_ipcw_0th_event_0.5": 0.5913495258811098,
      "eval_ipcw_0th_event_0.75": 0.5991903379708217,
      "eval_ipcw_0th_event_1.0": 0.6013721010684424,
      "eval_ipcw_0th_event_n": 264,
      "eval_ipcw_avg": 0.6013296055625138,
      "eval_ipcw_avg_0th_event": 0.6013296055625138,
      "eval_ipcw_weighted_avg": 0.6013296055625138,
      "eval_loss": 0.8766819834709167,
      "eval_runtime": 0.0667,
      "eval_samples_per_second": 6652.465,
      "eval_steps_per_second": 14.983,
      "step": 81
    },
    {
      "epoch": 41.0,
      "grad_norm": 3.6901588439941406,
      "learning_rate": 0.005434781669686764,
      "loss": 1.1264,
      "step": 82
    },
    {
      "epoch": 41.0,
      "eval_brier_0th_event": 0.23846774679961216,
      "eval_brier_0th_event_n": 264,
      "eval_brier_avg": 0.23846774679961216,
      "eval_brier_weighted_avg": 0.23846774679961216,
      "eval_ipcw": 0.5960165897508406,
      "eval_ipcw_0th_event": 0.5960165897508406,
      "eval_ipcw_0th_event_0.25": 0.62635379247802,
      "eval_ipcw_0th_event_0.5": 0.5972378395045138,
      "eval_ipcw_0th_event_0.75": 0.5997223835478944,
      "eval_ipcw_0th_event_1.0": 0.5960165897508406,
      "eval_ipcw_0th_event_n": 264,
      "eval_ipcw_avg": 0.6048326513203172,
      "eval_ipcw_avg_0th_event": 0.6048326513203172,
      "eval_ipcw_weighted_avg": 0.6048326513203172,
      "eval_loss": 0.8758917450904846,
      "eval_runtime": 0.0686,
      "eval_samples_per_second": 6474.086,
      "eval_steps_per_second": 14.581,
      "step": 82
    },
    {
      "epoch": 41.5,
      "grad_norm": 2.323765516281128,
      "learning_rate": 0.00543470245316242,
      "loss": 1.0368,
      "step": 83
    },
    {
      "epoch": 41.5,
      "eval_brier_0th_event": 0.23593930757564108,
      "eval_brier_0th_event_n": 264,
      "eval_brier_avg": 0.23593930757564108,
      "eval_brier_weighted_avg": 0.23593930757564108,
      "eval_ipcw": 0.5925262903258846,
      "eval_ipcw_0th_event": 0.5925262903258846,
      "eval_ipcw_0th_event_0.25": 0.6322260682257413,
      "eval_ipcw_0th_event_0.5": 0.6018869772254741,
      "eval_ipcw_0th_event_0.75": 0.5999144045602693,
      "eval_ipcw_0th_event_1.0": 0.5925262903258846,
      "eval_ipcw_0th_event_n": 264,
      "eval_ipcw_avg": 0.6066384350843423,
      "eval_ipcw_avg_0th_event": 0.6066384350843423,
      "eval_ipcw_weighted_avg": 0.6066384350843423,
      "eval_loss": 0.8706810474395752,
      "eval_runtime": 0.0676,
      "eval_samples_per_second": 6566.865,
      "eval_steps_per_second": 14.79,
      "step": 83
    },
    {
      "epoch": 42.0,
      "grad_norm": 5.158982753753662,
      "learning_rate": 0.005434591551321548,
      "loss": 1.1535,
      "step": 84
    },
    {
      "epoch": 42.0,
      "eval_brier_0th_event": 0.24798896381359517,
      "eval_brier_0th_event_n": 264,
      "eval_brier_avg": 0.24798896381359517,
      "eval_brier_weighted_avg": 0.24798896381359514,
      "eval_ipcw": 0.6112074773573797,
      "eval_ipcw_0th_event": 0.6112074773573797,
      "eval_ipcw_0th_event_0.25": 0.6313261760578485,
      "eval_ipcw_0th_event_0.5": 0.6072796309917775,
      "eval_ipcw_0th_event_0.75": 0.5973679211722452,
      "eval_ipcw_0th_event_1.0": 0.6112074773573797,
      "eval_ipcw_0th_event_n": 264,
      "eval_ipcw_avg": 0.6117953013948128,
      "eval_ipcw_avg_0th_event": 0.6117953013948128,
      "eval_ipcw_weighted_avg": 0.6117953013948128,
      "eval_loss": 0.8938148021697998,
      "eval_runtime": 0.0693,
      "eval_samples_per_second": 6402.923,
      "eval_steps_per_second": 14.421,
      "step": 84
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 50725543680.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
