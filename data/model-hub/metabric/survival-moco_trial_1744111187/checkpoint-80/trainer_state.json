{
  "best_global_step": 80,
  "best_metric": 0.6065204920451955,
  "best_model_checkpoint": "./data/model-hub/metabric/survival-moco_trial_1744111187/checkpoint-80",
  "epoch": 40.0,
  "eval_steps": 1,
  "global_step": 80,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 1.0790001153945923,
      "learning_rate": 2.776489248159247e-05,
      "loss": 1.626,
      "step": 1
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.065390706062317,
      "learning_rate": 5.552978496318494e-05,
      "loss": 1.6343,
      "step": 2
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.0891547203063965,
      "learning_rate": 8.32946774447774e-05,
      "loss": 1.6336,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.0028421878814697,
      "learning_rate": 0.00011105956992636989,
      "loss": 1.6156,
      "step": 4
    },
    {
      "epoch": 2.5,
      "grad_norm": 1.087296485900879,
      "learning_rate": 0.00013882446240796235,
      "loss": 1.6431,
      "step": 5
    },
    {
      "epoch": 3.0,
      "grad_norm": 1.069726586341858,
      "learning_rate": 0.0001665893548895548,
      "loss": 1.5951,
      "step": 6
    },
    {
      "epoch": 3.5,
      "grad_norm": 1.236602783203125,
      "learning_rate": 0.0001943542473711473,
      "loss": 1.6299,
      "step": 7
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.7376046776771545,
      "learning_rate": 0.00022211913985273977,
      "loss": 1.6139,
      "step": 8
    },
    {
      "epoch": 4.5,
      "grad_norm": 1.0265254974365234,
      "learning_rate": 0.00024988403233433223,
      "loss": 1.6206,
      "step": 9
    },
    {
      "epoch": 5.0,
      "grad_norm": 1.0272588729858398,
      "learning_rate": 0.0002776489248159247,
      "loss": 1.6056,
      "step": 10
    },
    {
      "epoch": 5.5,
      "grad_norm": 1.0274105072021484,
      "learning_rate": 0.0003054138172975172,
      "loss": 1.5897,
      "step": 11
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.9093729853630066,
      "learning_rate": 0.0003331787097791096,
      "loss": 1.645,
      "step": 12
    },
    {
      "epoch": 6.5,
      "grad_norm": 1.0278878211975098,
      "learning_rate": 0.00036094360226070216,
      "loss": 1.5984,
      "step": 13
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.9201748371124268,
      "learning_rate": 0.0003887084947422946,
      "loss": 1.6192,
      "step": 14
    },
    {
      "epoch": 7.5,
      "grad_norm": 0.939071774482727,
      "learning_rate": 0.00041647338722388706,
      "loss": 1.6015,
      "step": 15
    },
    {
      "epoch": 8.0,
      "grad_norm": 1.061414361000061,
      "learning_rate": 0.00044423827970547955,
      "loss": 1.6263,
      "step": 16
    },
    {
      "epoch": 8.5,
      "grad_norm": 1.082541584968567,
      "learning_rate": 0.000472003172187072,
      "loss": 1.6046,
      "step": 17
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.9667346477508545,
      "learning_rate": 0.0004997680646686645,
      "loss": 1.5872,
      "step": 18
    },
    {
      "epoch": 9.5,
      "grad_norm": 1.195164680480957,
      "learning_rate": 0.0005275329571502569,
      "loss": 1.6032,
      "step": 19
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.8709734082221985,
      "learning_rate": 0.0005552978496318494,
      "loss": 1.593,
      "step": 20
    },
    {
      "epoch": 10.5,
      "grad_norm": 1.171517252922058,
      "learning_rate": 0.000583062742113442,
      "loss": 1.618,
      "step": 21
    },
    {
      "epoch": 11.0,
      "grad_norm": 0.9265216588973999,
      "learning_rate": 0.0006108276345950344,
      "loss": 1.5495,
      "step": 22
    },
    {
      "epoch": 11.5,
      "grad_norm": 1.2475911378860474,
      "learning_rate": 0.0006385925270766268,
      "loss": 1.5648,
      "step": 23
    },
    {
      "epoch": 12.0,
      "grad_norm": 0.8521059155464172,
      "learning_rate": 0.0006663574195582192,
      "loss": 1.6096,
      "step": 24
    },
    {
      "epoch": 12.5,
      "grad_norm": 0.9909973740577698,
      "learning_rate": 0.0006941223120398118,
      "loss": 1.5886,
      "step": 25
    },
    {
      "epoch": 13.0,
      "grad_norm": 1.0829386711120605,
      "learning_rate": 0.0007218872045214043,
      "loss": 1.5561,
      "step": 26
    },
    {
      "epoch": 13.5,
      "grad_norm": 1.0850363969802856,
      "learning_rate": 0.0007496520970029967,
      "loss": 1.5698,
      "step": 27
    },
    {
      "epoch": 14.0,
      "grad_norm": 0.9124197363853455,
      "learning_rate": 0.0007774169894845892,
      "loss": 1.5619,
      "step": 28
    },
    {
      "epoch": 14.5,
      "grad_norm": 0.9217560291290283,
      "learning_rate": 0.0008051818819661816,
      "loss": 1.5454,
      "step": 29
    },
    {
      "epoch": 15.0,
      "grad_norm": 1.0958991050720215,
      "learning_rate": 0.0008329467744477741,
      "loss": 1.5648,
      "step": 30
    },
    {
      "epoch": 15.5,
      "grad_norm": 1.0480518341064453,
      "learning_rate": 0.0008607116669293667,
      "loss": 1.5544,
      "step": 31
    },
    {
      "epoch": 16.0,
      "grad_norm": 0.8258888125419617,
      "learning_rate": 0.0008884765594109591,
      "loss": 1.5278,
      "step": 32
    },
    {
      "epoch": 16.5,
      "grad_norm": 1.142086148262024,
      "learning_rate": 0.0009162414518925515,
      "loss": 1.5361,
      "step": 33
    },
    {
      "epoch": 17.0,
      "grad_norm": 0.5867539048194885,
      "learning_rate": 0.000944006344374144,
      "loss": 1.5367,
      "step": 34
    },
    {
      "epoch": 17.5,
      "grad_norm": 0.8906975984573364,
      "learning_rate": 0.0009717712368557365,
      "loss": 1.5118,
      "step": 35
    },
    {
      "epoch": 18.0,
      "grad_norm": 0.9419276714324951,
      "learning_rate": 0.000999536129337329,
      "loss": 1.5603,
      "step": 36
    },
    {
      "epoch": 18.5,
      "grad_norm": 0.9175705313682556,
      "learning_rate": 0.0010273010218189214,
      "loss": 1.5233,
      "step": 37
    },
    {
      "epoch": 19.0,
      "grad_norm": 0.7506919503211975,
      "learning_rate": 0.0010550659143005138,
      "loss": 1.521,
      "step": 38
    },
    {
      "epoch": 19.5,
      "grad_norm": 1.093485713005066,
      "learning_rate": 0.0010828308067821063,
      "loss": 1.5095,
      "step": 39
    },
    {
      "epoch": 20.0,
      "grad_norm": 0.6475686430931091,
      "learning_rate": 0.0011105956992636988,
      "loss": 1.4967,
      "step": 40
    },
    {
      "epoch": 20.5,
      "grad_norm": 0.7180377244949341,
      "learning_rate": 0.0011383605917452912,
      "loss": 1.4931,
      "step": 41
    },
    {
      "epoch": 21.0,
      "grad_norm": 1.0233361721038818,
      "learning_rate": 0.001166125484226884,
      "loss": 1.5052,
      "step": 42
    },
    {
      "epoch": 21.5,
      "grad_norm": 0.9526122212409973,
      "learning_rate": 0.0011938903767084762,
      "loss": 1.502,
      "step": 43
    },
    {
      "epoch": 22.0,
      "grad_norm": 0.8142420649528503,
      "learning_rate": 0.0012216552691900688,
      "loss": 1.4615,
      "step": 44
    },
    {
      "epoch": 22.5,
      "grad_norm": 0.8329067826271057,
      "learning_rate": 0.001249420161671661,
      "loss": 1.4917,
      "step": 45
    },
    {
      "epoch": 23.0,
      "grad_norm": 1.013961672782898,
      "learning_rate": 0.0012771850541532536,
      "loss": 1.4432,
      "step": 46
    },
    {
      "epoch": 23.5,
      "grad_norm": 0.8575177788734436,
      "learning_rate": 0.0013049499466348462,
      "loss": 1.4511,
      "step": 47
    },
    {
      "epoch": 24.0,
      "grad_norm": 0.8426820635795593,
      "learning_rate": 0.0013327148391164385,
      "loss": 1.4708,
      "step": 48
    },
    {
      "epoch": 24.5,
      "grad_norm": 0.8824630975723267,
      "learning_rate": 0.0013604797315980312,
      "loss": 1.465,
      "step": 49
    },
    {
      "epoch": 25.0,
      "grad_norm": 0.787530779838562,
      "learning_rate": 0.0013882446240796235,
      "loss": 1.4033,
      "step": 50
    },
    {
      "epoch": 25.5,
      "grad_norm": 0.7612876892089844,
      "learning_rate": 0.0014160095165612159,
      "loss": 1.4425,
      "step": 51
    },
    {
      "epoch": 26.0,
      "grad_norm": 0.9111860394477844,
      "learning_rate": 0.0014437744090428086,
      "loss": 1.4285,
      "step": 52
    },
    {
      "epoch": 26.5,
      "grad_norm": 0.7876518368721008,
      "learning_rate": 0.001471539301524401,
      "loss": 1.3822,
      "step": 53
    },
    {
      "epoch": 27.0,
      "grad_norm": 1.007320523262024,
      "learning_rate": 0.0014993041940059935,
      "loss": 1.4611,
      "step": 54
    },
    {
      "epoch": 27.5,
      "grad_norm": 0.7122024297714233,
      "learning_rate": 0.001527069086487586,
      "loss": 1.3928,
      "step": 55
    },
    {
      "epoch": 28.0,
      "grad_norm": 1.0687534809112549,
      "learning_rate": 0.0015548339789691783,
      "loss": 1.4218,
      "step": 56
    },
    {
      "epoch": 28.5,
      "grad_norm": 0.7258408069610596,
      "learning_rate": 0.0015825988714507709,
      "loss": 1.4158,
      "step": 57
    },
    {
      "epoch": 29.0,
      "grad_norm": 1.2677851915359497,
      "learning_rate": 0.0016103637639323632,
      "loss": 1.3626,
      "step": 58
    },
    {
      "epoch": 29.5,
      "grad_norm": 0.8618292212486267,
      "learning_rate": 0.001638128656413956,
      "loss": 1.3808,
      "step": 59
    },
    {
      "epoch": 30.0,
      "grad_norm": 1.0436880588531494,
      "learning_rate": 0.0016658935488955483,
      "loss": 1.3633,
      "step": 60
    },
    {
      "epoch": 30.5,
      "grad_norm": 0.9067439436912537,
      "learning_rate": 0.0016936584413771406,
      "loss": 1.3875,
      "step": 61
    },
    {
      "epoch": 31.0,
      "grad_norm": 1.921213150024414,
      "learning_rate": 0.0017214233338587333,
      "loss": 1.3614,
      "step": 62
    },
    {
      "epoch": 31.5,
      "grad_norm": 1.281860113143921,
      "learning_rate": 0.0017491882263403257,
      "loss": 1.3666,
      "step": 63
    },
    {
      "epoch": 32.0,
      "grad_norm": 2.8019089698791504,
      "learning_rate": 0.0017769531188219182,
      "loss": 1.3759,
      "step": 64
    },
    {
      "epoch": 32.5,
      "grad_norm": 2.634310722351074,
      "learning_rate": 0.0018047180113035105,
      "loss": 1.3545,
      "step": 65
    },
    {
      "epoch": 33.0,
      "grad_norm": 2.3442509174346924,
      "learning_rate": 0.001832482903785103,
      "loss": 1.384,
      "step": 66
    },
    {
      "epoch": 33.5,
      "grad_norm": 0.9584209322929382,
      "learning_rate": 0.0018602477962666956,
      "loss": 1.3212,
      "step": 67
    },
    {
      "epoch": 34.0,
      "grad_norm": 2.4134981632232666,
      "learning_rate": 0.001888012688748288,
      "loss": 1.4096,
      "step": 68
    },
    {
      "epoch": 34.5,
      "grad_norm": 2.88584041595459,
      "learning_rate": 0.0019157775812298806,
      "loss": 1.3421,
      "step": 69
    },
    {
      "epoch": 35.0,
      "grad_norm": 1.850699782371521,
      "learning_rate": 0.001943542473711473,
      "loss": 1.3725,
      "step": 70
    },
    {
      "epoch": 35.5,
      "grad_norm": 1.1532551050186157,
      "learning_rate": 0.0019713073661930653,
      "loss": 1.309,
      "step": 71
    },
    {
      "epoch": 36.0,
      "grad_norm": 1.2326494455337524,
      "learning_rate": 0.001999072258674658,
      "loss": 1.3484,
      "step": 72
    },
    {
      "epoch": 36.5,
      "grad_norm": 3.1532981395721436,
      "learning_rate": 0.0020268371511562504,
      "loss": 1.3501,
      "step": 73
    },
    {
      "epoch": 37.0,
      "grad_norm": 3.2132222652435303,
      "learning_rate": 0.002054602043637843,
      "loss": 1.3107,
      "step": 74
    },
    {
      "epoch": 37.5,
      "grad_norm": 1.5905015468597412,
      "learning_rate": 0.0020823669361194354,
      "loss": 1.2796,
      "step": 75
    },
    {
      "epoch": 38.0,
      "grad_norm": 1.8423082828521729,
      "learning_rate": 0.0021101318286010275,
      "loss": 1.3674,
      "step": 76
    },
    {
      "epoch": 38.5,
      "grad_norm": 1.4182707071304321,
      "learning_rate": 0.0021378967210826205,
      "loss": 1.2878,
      "step": 77
    },
    {
      "epoch": 39.0,
      "grad_norm": 3.6392018795013428,
      "learning_rate": 0.0021656616135642126,
      "loss": 1.3408,
      "step": 78
    },
    {
      "epoch": 39.5,
      "grad_norm": 1.1923831701278687,
      "learning_rate": 0.002193426506045805,
      "loss": 1.2855,
      "step": 79
    },
    {
      "epoch": 40.0,
      "grad_norm": 1.7665036916732788,
      "learning_rate": 0.0022211913985273977,
      "loss": 1.3511,
      "step": 80
    },
    {
      "epoch": 40.0,
      "eval_brier_0th_event": 0.21710494376887385,
      "eval_brier_0th_event_n": 276,
      "eval_brier_avg": 0.21710494376887385,
      "eval_brier_weighted_avg": 0.21710494376887385,
      "eval_ipcw": 0.5748187880690535,
      "eval_ipcw_0th_event": 0.5748187880690535,
      "eval_ipcw_0th_event_0.25": 0.6277701452227159,
      "eval_ipcw_0th_event_0.5": 0.6118453227134762,
      "eval_ipcw_0th_event_0.75": 0.6116477121755366,
      "eval_ipcw_0th_event_1.0": 0.5748187880690535,
      "eval_ipcw_0th_event_n": 276,
      "eval_ipcw_avg": 0.6065204920451955,
      "eval_ipcw_avg_0th_event": 0.6065204920451955,
      "eval_ipcw_weighted_avg": 0.6065204920451955,
      "eval_loss": 0.7458353042602539,
      "eval_runtime": 0.0648,
      "eval_samples_per_second": 6851.648,
      "eval_steps_per_second": 15.432,
      "step": 80
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 8277580800.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
