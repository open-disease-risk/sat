{
  "best_global_step": 80,
  "best_metric": 0.6004734203458776,
  "best_model_checkpoint": "./data/model-hub/metabric/survival-moco_trial_1744107544/checkpoint-80",
  "epoch": 40.0,
  "eval_steps": 1,
  "global_step": 80,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 6.527313709259033,
      "learning_rate": 2.091482338524617e-05,
      "loss": 1.6035,
      "step": 1
    },
    {
      "epoch": 1.0,
      "grad_norm": 7.523159980773926,
      "learning_rate": 4.182964677049234e-05,
      "loss": 1.6113,
      "step": 2
    },
    {
      "epoch": 1.5,
      "grad_norm": 7.308111667633057,
      "learning_rate": 6.27444701557385e-05,
      "loss": 1.6062,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 5.4387407302856445,
      "learning_rate": 8.365929354098468e-05,
      "loss": 1.5876,
      "step": 4
    },
    {
      "epoch": 2.5,
      "grad_norm": 6.690847396850586,
      "learning_rate": 0.00010457411692623084,
      "loss": 1.589,
      "step": 5
    },
    {
      "epoch": 3.0,
      "grad_norm": 4.742029190063477,
      "learning_rate": 0.000125488940311477,
      "loss": 1.5897,
      "step": 6
    },
    {
      "epoch": 3.5,
      "grad_norm": 5.714354038238525,
      "learning_rate": 0.00014640376369672316,
      "loss": 1.576,
      "step": 7
    },
    {
      "epoch": 4.0,
      "grad_norm": 4.351827144622803,
      "learning_rate": 0.00016731858708196937,
      "loss": 1.5658,
      "step": 8
    },
    {
      "epoch": 4.5,
      "grad_norm": 5.552060127258301,
      "learning_rate": 0.00018823341046721553,
      "loss": 1.5989,
      "step": 9
    },
    {
      "epoch": 5.0,
      "grad_norm": 4.426687717437744,
      "learning_rate": 0.00020914823385246168,
      "loss": 1.5299,
      "step": 10
    },
    {
      "epoch": 5.5,
      "grad_norm": 5.395477294921875,
      "learning_rate": 0.00023006305723770787,
      "loss": 1.5486,
      "step": 11
    },
    {
      "epoch": 6.0,
      "grad_norm": 5.328455924987793,
      "learning_rate": 0.000250977880622954,
      "loss": 1.5839,
      "step": 12
    },
    {
      "epoch": 6.5,
      "grad_norm": 5.610877513885498,
      "learning_rate": 0.0002718927040082002,
      "loss": 1.5614,
      "step": 13
    },
    {
      "epoch": 7.0,
      "grad_norm": 4.59860897064209,
      "learning_rate": 0.0002928075273934463,
      "loss": 1.533,
      "step": 14
    },
    {
      "epoch": 7.5,
      "grad_norm": 4.617795467376709,
      "learning_rate": 0.00031372235077869255,
      "loss": 1.5069,
      "step": 15
    },
    {
      "epoch": 8.0,
      "grad_norm": 5.2304887771606445,
      "learning_rate": 0.00033463717416393874,
      "loss": 1.5515,
      "step": 16
    },
    {
      "epoch": 8.5,
      "grad_norm": 5.165219306945801,
      "learning_rate": 0.00035555199754918487,
      "loss": 1.5279,
      "step": 17
    },
    {
      "epoch": 9.0,
      "grad_norm": 6.998342514038086,
      "learning_rate": 0.00037646682093443105,
      "loss": 1.4912,
      "step": 18
    },
    {
      "epoch": 9.5,
      "grad_norm": 5.835367679595947,
      "learning_rate": 0.0003973816443196772,
      "loss": 1.5065,
      "step": 19
    },
    {
      "epoch": 10.0,
      "grad_norm": 4.645992755889893,
      "learning_rate": 0.00041829646770492337,
      "loss": 1.4706,
      "step": 20
    },
    {
      "epoch": 10.5,
      "grad_norm": 4.722224235534668,
      "learning_rate": 0.00043921129109016955,
      "loss": 1.4959,
      "step": 21
    },
    {
      "epoch": 11.0,
      "grad_norm": 5.2857890129089355,
      "learning_rate": 0.00046012611447541574,
      "loss": 1.4263,
      "step": 22
    },
    {
      "epoch": 11.5,
      "grad_norm": 3.6220335960388184,
      "learning_rate": 0.0004810409378606618,
      "loss": 1.4454,
      "step": 23
    },
    {
      "epoch": 12.0,
      "grad_norm": 5.563904762268066,
      "learning_rate": 0.000501955761245908,
      "loss": 1.4521,
      "step": 24
    },
    {
      "epoch": 12.5,
      "grad_norm": 4.844179630279541,
      "learning_rate": 0.0005228705846311542,
      "loss": 1.4264,
      "step": 25
    },
    {
      "epoch": 13.0,
      "grad_norm": 2.7425687313079834,
      "learning_rate": 0.0005437854080164004,
      "loss": 1.4228,
      "step": 26
    },
    {
      "epoch": 13.5,
      "grad_norm": 2.329127073287964,
      "learning_rate": 0.0005647002314016466,
      "loss": 1.3971,
      "step": 27
    },
    {
      "epoch": 14.0,
      "grad_norm": 3.3033173084259033,
      "learning_rate": 0.0005856150547868926,
      "loss": 1.4103,
      "step": 28
    },
    {
      "epoch": 14.5,
      "grad_norm": 2.446141004562378,
      "learning_rate": 0.0006065298781721388,
      "loss": 1.3971,
      "step": 29
    },
    {
      "epoch": 15.0,
      "grad_norm": 3.3799030780792236,
      "learning_rate": 0.0006274447015573851,
      "loss": 1.4088,
      "step": 30
    },
    {
      "epoch": 15.5,
      "grad_norm": 2.941852569580078,
      "learning_rate": 0.0006483595249426313,
      "loss": 1.4182,
      "step": 31
    },
    {
      "epoch": 16.0,
      "grad_norm": 4.503753185272217,
      "learning_rate": 0.0006692743483278775,
      "loss": 1.3671,
      "step": 32
    },
    {
      "epoch": 16.5,
      "grad_norm": 4.024239540100098,
      "learning_rate": 0.0006901891717131236,
      "loss": 1.394,
      "step": 33
    },
    {
      "epoch": 17.0,
      "grad_norm": 4.175181865692139,
      "learning_rate": 0.0007111039950983697,
      "loss": 1.3862,
      "step": 34
    },
    {
      "epoch": 17.5,
      "grad_norm": 2.4377644062042236,
      "learning_rate": 0.0007320188184836159,
      "loss": 1.3802,
      "step": 35
    },
    {
      "epoch": 18.0,
      "grad_norm": 5.112488269805908,
      "learning_rate": 0.0007529336418688621,
      "loss": 1.3806,
      "step": 36
    },
    {
      "epoch": 18.5,
      "grad_norm": 3.4016191959381104,
      "learning_rate": 0.0007738484652541083,
      "loss": 1.3608,
      "step": 37
    },
    {
      "epoch": 19.0,
      "grad_norm": 2.860558032989502,
      "learning_rate": 0.0007947632886393544,
      "loss": 1.3445,
      "step": 38
    },
    {
      "epoch": 19.5,
      "grad_norm": 4.524142265319824,
      "learning_rate": 0.0008156781120246006,
      "loss": 1.3563,
      "step": 39
    },
    {
      "epoch": 20.0,
      "grad_norm": 3.964399814605713,
      "learning_rate": 0.0008365929354098467,
      "loss": 1.3576,
      "step": 40
    },
    {
      "epoch": 20.5,
      "grad_norm": 3.7428174018859863,
      "learning_rate": 0.0008575077587950928,
      "loss": 1.3363,
      "step": 41
    },
    {
      "epoch": 21.0,
      "grad_norm": 3.965008020401001,
      "learning_rate": 0.0008784225821803391,
      "loss": 1.3381,
      "step": 42
    },
    {
      "epoch": 21.5,
      "grad_norm": 3.6186580657958984,
      "learning_rate": 0.0008993374055655852,
      "loss": 1.3249,
      "step": 43
    },
    {
      "epoch": 22.0,
      "grad_norm": 3.9944264888763428,
      "learning_rate": 0.0009202522289508315,
      "loss": 1.3643,
      "step": 44
    },
    {
      "epoch": 22.5,
      "grad_norm": 6.014133930206299,
      "learning_rate": 0.0009411670523360776,
      "loss": 1.3398,
      "step": 45
    },
    {
      "epoch": 23.0,
      "grad_norm": 3.410827875137329,
      "learning_rate": 0.0009620818757213236,
      "loss": 1.3336,
      "step": 46
    },
    {
      "epoch": 23.5,
      "grad_norm": 3.628817319869995,
      "learning_rate": 0.00098299669910657,
      "loss": 1.3044,
      "step": 47
    },
    {
      "epoch": 24.0,
      "grad_norm": 3.60544753074646,
      "learning_rate": 0.001003911522491816,
      "loss": 1.3497,
      "step": 48
    },
    {
      "epoch": 24.5,
      "grad_norm": 5.764073848724365,
      "learning_rate": 0.0010248263458770624,
      "loss": 1.2929,
      "step": 49
    },
    {
      "epoch": 25.0,
      "grad_norm": 3.2912158966064453,
      "learning_rate": 0.0010457411692623084,
      "loss": 1.3424,
      "step": 50
    },
    {
      "epoch": 25.5,
      "grad_norm": 2.7478151321411133,
      "learning_rate": 0.0010666559926475546,
      "loss": 1.3278,
      "step": 51
    },
    {
      "epoch": 26.0,
      "grad_norm": 4.161917686462402,
      "learning_rate": 0.0010875708160328007,
      "loss": 1.2855,
      "step": 52
    },
    {
      "epoch": 26.5,
      "grad_norm": 4.125740051269531,
      "learning_rate": 0.001108485639418047,
      "loss": 1.2805,
      "step": 53
    },
    {
      "epoch": 27.0,
      "grad_norm": 3.63619327545166,
      "learning_rate": 0.001129400462803293,
      "loss": 1.3247,
      "step": 54
    },
    {
      "epoch": 27.5,
      "grad_norm": 2.5584259033203125,
      "learning_rate": 0.0011503152861885393,
      "loss": 1.3144,
      "step": 55
    },
    {
      "epoch": 28.0,
      "grad_norm": 3.622896909713745,
      "learning_rate": 0.0011712301095737853,
      "loss": 1.2848,
      "step": 56
    },
    {
      "epoch": 28.5,
      "grad_norm": 4.111937522888184,
      "learning_rate": 0.0011921449329590317,
      "loss": 1.2721,
      "step": 57
    },
    {
      "epoch": 29.0,
      "grad_norm": 3.3305439949035645,
      "learning_rate": 0.0012130597563442776,
      "loss": 1.2833,
      "step": 58
    },
    {
      "epoch": 29.5,
      "grad_norm": 3.3885087966918945,
      "learning_rate": 0.001233974579729524,
      "loss": 1.2628,
      "step": 59
    },
    {
      "epoch": 30.0,
      "grad_norm": 4.401439666748047,
      "learning_rate": 0.0012548894031147702,
      "loss": 1.2648,
      "step": 60
    },
    {
      "epoch": 30.5,
      "grad_norm": 4.916366100311279,
      "learning_rate": 0.0012758042265000162,
      "loss": 1.2687,
      "step": 61
    },
    {
      "epoch": 31.0,
      "grad_norm": 4.558837413787842,
      "learning_rate": 0.0012967190498852626,
      "loss": 1.2595,
      "step": 62
    },
    {
      "epoch": 31.5,
      "grad_norm": 4.262394428253174,
      "learning_rate": 0.0013176338732705086,
      "loss": 1.2662,
      "step": 63
    },
    {
      "epoch": 32.0,
      "grad_norm": 4.442921161651611,
      "learning_rate": 0.001338548696655755,
      "loss": 1.2604,
      "step": 64
    },
    {
      "epoch": 32.5,
      "grad_norm": 4.101352691650391,
      "learning_rate": 0.001359463520041001,
      "loss": 1.234,
      "step": 65
    },
    {
      "epoch": 33.0,
      "grad_norm": 4.730836868286133,
      "learning_rate": 0.001380378343426247,
      "loss": 1.2803,
      "step": 66
    },
    {
      "epoch": 33.5,
      "grad_norm": 4.887126445770264,
      "learning_rate": 0.0014012931668114933,
      "loss": 1.244,
      "step": 67
    },
    {
      "epoch": 34.0,
      "grad_norm": 4.158761501312256,
      "learning_rate": 0.0014222079901967395,
      "loss": 1.2044,
      "step": 68
    },
    {
      "epoch": 34.5,
      "grad_norm": 3.8921399116516113,
      "learning_rate": 0.0014431228135819857,
      "loss": 1.2359,
      "step": 69
    },
    {
      "epoch": 35.0,
      "grad_norm": 3.7185604572296143,
      "learning_rate": 0.0014640376369672318,
      "loss": 1.2654,
      "step": 70
    },
    {
      "epoch": 35.5,
      "grad_norm": 3.62923002243042,
      "learning_rate": 0.0014849524603524778,
      "loss": 1.2269,
      "step": 71
    },
    {
      "epoch": 36.0,
      "grad_norm": 4.002668380737305,
      "learning_rate": 0.0015058672837377242,
      "loss": 1.2464,
      "step": 72
    },
    {
      "epoch": 36.5,
      "grad_norm": 3.815117597579956,
      "learning_rate": 0.0015267821071229702,
      "loss": 1.1767,
      "step": 73
    },
    {
      "epoch": 37.0,
      "grad_norm": 4.2228288650512695,
      "learning_rate": 0.0015476969305082166,
      "loss": 1.266,
      "step": 74
    },
    {
      "epoch": 37.5,
      "grad_norm": 3.104224681854248,
      "learning_rate": 0.0015686117538934626,
      "loss": 1.1611,
      "step": 75
    },
    {
      "epoch": 38.0,
      "grad_norm": 5.584043502807617,
      "learning_rate": 0.0015895265772787087,
      "loss": 1.2441,
      "step": 76
    },
    {
      "epoch": 38.5,
      "grad_norm": 3.8965845108032227,
      "learning_rate": 0.001610441400663955,
      "loss": 1.1871,
      "step": 77
    },
    {
      "epoch": 39.0,
      "grad_norm": 5.149591445922852,
      "learning_rate": 0.001631356224049201,
      "loss": 1.1745,
      "step": 78
    },
    {
      "epoch": 39.5,
      "grad_norm": 5.036476135253906,
      "learning_rate": 0.0016522710474344473,
      "loss": 1.1951,
      "step": 79
    },
    {
      "epoch": 40.0,
      "grad_norm": 6.090713024139404,
      "learning_rate": 0.0016731858708196935,
      "loss": 1.2289,
      "step": 80
    },
    {
      "epoch": 40.0,
      "eval_brier_0th_event": 0.2145297244574226,
      "eval_brier_0th_event_n": 254,
      "eval_brier_avg": 0.2145297244574226,
      "eval_brier_weighted_avg": 0.2145297244574226,
      "eval_ipcw": 0.5963541366318752,
      "eval_ipcw_0th_event": 0.5963541366318752,
      "eval_ipcw_0th_event_0.25": 0.6164458347708124,
      "eval_ipcw_0th_event_0.5": 0.6014421621087764,
      "eval_ipcw_0th_event_0.75": 0.5876515478720463,
      "eval_ipcw_0th_event_1.0": 0.5963541366318752,
      "eval_ipcw_0th_event_n": 254,
      "eval_ipcw_avg": 0.6004734203458776,
      "eval_ipcw_avg_0th_event": 0.6004734203458776,
      "eval_ipcw_weighted_avg": 0.6004734203458776,
      "eval_loss": 0.7493366599082947,
      "eval_runtime": 0.0831,
      "eval_samples_per_second": 5343.844,
      "eval_steps_per_second": 12.036,
      "step": 80
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 84864384000.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
