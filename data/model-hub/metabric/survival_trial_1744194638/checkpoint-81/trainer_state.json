{
  "best_global_step": 81,
  "best_metric": 0.6527387703158392,
  "best_model_checkpoint": "./data/model-hub/metabric/survival_trial_1744194638/checkpoint-81",
  "epoch": 40.5,
  "eval_steps": 1,
  "global_step": 81,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 0.9091341495513916,
      "learning_rate": 1.460651018363716e-05,
      "loss": 1.6063,
      "step": 1
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.843048632144928,
      "learning_rate": 2.921302036727432e-05,
      "loss": 1.5199,
      "step": 2
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.8362201452255249,
      "learning_rate": 4.381953055091148e-05,
      "loss": 1.6248,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.9877211451530457,
      "learning_rate": 5.842604073454864e-05,
      "loss": 1.4929,
      "step": 4
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.9066202044487,
      "learning_rate": 7.30325509181858e-05,
      "loss": 1.6026,
      "step": 5
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.9617922902107239,
      "learning_rate": 8.763906110182296e-05,
      "loss": 1.503,
      "step": 6
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.8537729382514954,
      "learning_rate": 0.00010224557128546012,
      "loss": 1.5777,
      "step": 7
    },
    {
      "epoch": 4.0,
      "grad_norm": 1.1468303203582764,
      "learning_rate": 0.00011685208146909728,
      "loss": 1.5578,
      "step": 8
    },
    {
      "epoch": 4.5,
      "grad_norm": 0.9524454474449158,
      "learning_rate": 0.00013145859165273444,
      "loss": 1.572,
      "step": 9
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.9651115536689758,
      "learning_rate": 0.0001460651018363716,
      "loss": 1.5421,
      "step": 10
    },
    {
      "epoch": 5.5,
      "grad_norm": 0.9773924946784973,
      "learning_rate": 0.00016067161202000876,
      "loss": 1.5196,
      "step": 11
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.9681920409202576,
      "learning_rate": 0.00017527812220364592,
      "loss": 1.6289,
      "step": 12
    },
    {
      "epoch": 6.5,
      "grad_norm": 1.076094150543213,
      "learning_rate": 0.00018988463238728308,
      "loss": 1.5773,
      "step": 13
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.9026676416397095,
      "learning_rate": 0.00020449114257092024,
      "loss": 1.5449,
      "step": 14
    },
    {
      "epoch": 7.5,
      "grad_norm": 1.1561933755874634,
      "learning_rate": 0.0002190976527545574,
      "loss": 1.5491,
      "step": 15
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.9820820093154907,
      "learning_rate": 0.00023370416293819456,
      "loss": 1.5847,
      "step": 16
    },
    {
      "epoch": 8.5,
      "grad_norm": 1.0756465196609497,
      "learning_rate": 0.0002483106731218317,
      "loss": 1.5879,
      "step": 17
    },
    {
      "epoch": 9.0,
      "grad_norm": 1.1363844871520996,
      "learning_rate": 0.0002629171833054689,
      "loss": 1.5266,
      "step": 18
    },
    {
      "epoch": 9.5,
      "grad_norm": 1.0963298082351685,
      "learning_rate": 0.00027752369348910604,
      "loss": 1.5573,
      "step": 19
    },
    {
      "epoch": 10.0,
      "grad_norm": 1.1113935708999634,
      "learning_rate": 0.0002921302036727432,
      "loss": 1.5311,
      "step": 20
    },
    {
      "epoch": 10.5,
      "grad_norm": 1.119226336479187,
      "learning_rate": 0.00030673671385638036,
      "loss": 1.5714,
      "step": 21
    },
    {
      "epoch": 11.0,
      "grad_norm": 1.3057981729507446,
      "learning_rate": 0.0003213432240400175,
      "loss": 1.5515,
      "step": 22
    },
    {
      "epoch": 11.5,
      "grad_norm": 1.1830657720565796,
      "learning_rate": 0.0003359497342236547,
      "loss": 1.5147,
      "step": 23
    },
    {
      "epoch": 12.0,
      "grad_norm": 1.159906029701233,
      "learning_rate": 0.00035055624440729185,
      "loss": 1.5954,
      "step": 24
    },
    {
      "epoch": 12.5,
      "grad_norm": 1.27657151222229,
      "learning_rate": 0.000365162754590929,
      "loss": 1.5898,
      "step": 25
    },
    {
      "epoch": 13.0,
      "grad_norm": 1.2076982259750366,
      "learning_rate": 0.00037976926477456617,
      "loss": 1.4898,
      "step": 26
    },
    {
      "epoch": 13.5,
      "grad_norm": 1.15424382686615,
      "learning_rate": 0.0003943757749582033,
      "loss": 1.553,
      "step": 27
    },
    {
      "epoch": 14.0,
      "grad_norm": 1.3732250928878784,
      "learning_rate": 0.0004089822851418405,
      "loss": 1.4984,
      "step": 28
    },
    {
      "epoch": 14.5,
      "grad_norm": 1.1406431198120117,
      "learning_rate": 0.00042358879532547765,
      "loss": 1.528,
      "step": 29
    },
    {
      "epoch": 15.0,
      "grad_norm": 1.3908815383911133,
      "learning_rate": 0.0004381953055091148,
      "loss": 1.5266,
      "step": 30
    },
    {
      "epoch": 15.5,
      "grad_norm": 1.263932466506958,
      "learning_rate": 0.00045280181569275197,
      "loss": 1.5288,
      "step": 31
    },
    {
      "epoch": 16.0,
      "grad_norm": 1.2105730772018433,
      "learning_rate": 0.00046740832587638913,
      "loss": 1.5061,
      "step": 32
    },
    {
      "epoch": 16.5,
      "grad_norm": 1.1502734422683716,
      "learning_rate": 0.0004820148360600263,
      "loss": 1.4936,
      "step": 33
    },
    {
      "epoch": 17.0,
      "grad_norm": 1.4446526765823364,
      "learning_rate": 0.0004966213462436634,
      "loss": 1.5649,
      "step": 34
    },
    {
      "epoch": 17.5,
      "grad_norm": 1.1352959871292114,
      "learning_rate": 0.0005112278564273006,
      "loss": 1.4934,
      "step": 35
    },
    {
      "epoch": 18.0,
      "grad_norm": 1.4433866739273071,
      "learning_rate": 0.0005258343666109378,
      "loss": 1.5569,
      "step": 36
    },
    {
      "epoch": 18.5,
      "grad_norm": 1.2658274173736572,
      "learning_rate": 0.000540440876794575,
      "loss": 1.5333,
      "step": 37
    },
    {
      "epoch": 19.0,
      "grad_norm": 1.3164249658584595,
      "learning_rate": 0.0005550473869782121,
      "loss": 1.4681,
      "step": 38
    },
    {
      "epoch": 19.5,
      "grad_norm": 1.2684353590011597,
      "learning_rate": 0.0005696538971618492,
      "loss": 1.536,
      "step": 39
    },
    {
      "epoch": 20.0,
      "grad_norm": 1.3332452774047852,
      "learning_rate": 0.0005842604073454864,
      "loss": 1.4294,
      "step": 40
    },
    {
      "epoch": 20.5,
      "grad_norm": 1.2369149923324585,
      "learning_rate": 0.0005988669175291235,
      "loss": 1.4939,
      "step": 41
    },
    {
      "epoch": 21.0,
      "grad_norm": 1.5547353029251099,
      "learning_rate": 0.0006134734277127607,
      "loss": 1.4665,
      "step": 42
    },
    {
      "epoch": 21.5,
      "grad_norm": 1.0140373706817627,
      "learning_rate": 0.0006280799378963978,
      "loss": 1.4821,
      "step": 43
    },
    {
      "epoch": 22.0,
      "grad_norm": 1.7434730529785156,
      "learning_rate": 0.000642686448080035,
      "loss": 1.4632,
      "step": 44
    },
    {
      "epoch": 22.5,
      "grad_norm": 1.2395782470703125,
      "learning_rate": 0.0006572929582636723,
      "loss": 1.4908,
      "step": 45
    },
    {
      "epoch": 23.0,
      "grad_norm": 1.5080820322036743,
      "learning_rate": 0.0006718994684473094,
      "loss": 1.421,
      "step": 46
    },
    {
      "epoch": 23.5,
      "grad_norm": 1.4388394355773926,
      "learning_rate": 0.0006865059786309466,
      "loss": 1.457,
      "step": 47
    },
    {
      "epoch": 24.0,
      "grad_norm": 1.3546499013900757,
      "learning_rate": 0.0007011124888145837,
      "loss": 1.4593,
      "step": 48
    },
    {
      "epoch": 24.5,
      "grad_norm": 1.3522475957870483,
      "learning_rate": 0.0007157189989982209,
      "loss": 1.4551,
      "step": 49
    },
    {
      "epoch": 25.0,
      "grad_norm": 1.5567773580551147,
      "learning_rate": 0.000730325509181858,
      "loss": 1.4463,
      "step": 50
    },
    {
      "epoch": 25.5,
      "grad_norm": 1.3926140069961548,
      "learning_rate": 0.0007449320193654951,
      "loss": 1.4079,
      "step": 51
    },
    {
      "epoch": 26.0,
      "grad_norm": 1.7125247716903687,
      "learning_rate": 0.0007595385295491323,
      "loss": 1.4971,
      "step": 52
    },
    {
      "epoch": 26.5,
      "grad_norm": 1.3828883171081543,
      "learning_rate": 0.0007741450397327694,
      "loss": 1.4319,
      "step": 53
    },
    {
      "epoch": 27.0,
      "grad_norm": 1.9912394285202026,
      "learning_rate": 0.0007887515499164067,
      "loss": 1.4414,
      "step": 54
    },
    {
      "epoch": 27.5,
      "grad_norm": 1.4629899263381958,
      "learning_rate": 0.0008033580601000438,
      "loss": 1.416,
      "step": 55
    },
    {
      "epoch": 28.0,
      "grad_norm": 2.071408271789551,
      "learning_rate": 0.000817964570283681,
      "loss": 1.4462,
      "step": 56
    },
    {
      "epoch": 28.5,
      "grad_norm": 2.060664415359497,
      "learning_rate": 0.0008325710804673182,
      "loss": 1.4199,
      "step": 57
    },
    {
      "epoch": 29.0,
      "grad_norm": 1.5474108457565308,
      "learning_rate": 0.0008471775906509553,
      "loss": 1.3876,
      "step": 58
    },
    {
      "epoch": 29.5,
      "grad_norm": 1.566868543624878,
      "learning_rate": 0.0008617841008345925,
      "loss": 1.3759,
      "step": 59
    },
    {
      "epoch": 30.0,
      "grad_norm": 1.6258900165557861,
      "learning_rate": 0.0008763906110182296,
      "loss": 1.4152,
      "step": 60
    },
    {
      "epoch": 30.5,
      "grad_norm": 1.6047942638397217,
      "learning_rate": 0.0008909971212018667,
      "loss": 1.4107,
      "step": 61
    },
    {
      "epoch": 31.0,
      "grad_norm": 2.1191906929016113,
      "learning_rate": 0.0009056036313855039,
      "loss": 1.3701,
      "step": 62
    },
    {
      "epoch": 31.5,
      "grad_norm": 1.6524968147277832,
      "learning_rate": 0.000920210141569141,
      "loss": 1.3554,
      "step": 63
    },
    {
      "epoch": 32.0,
      "grad_norm": 1.8277562856674194,
      "learning_rate": 0.0009348166517527783,
      "loss": 1.4002,
      "step": 64
    },
    {
      "epoch": 32.5,
      "grad_norm": 2.6953625679016113,
      "learning_rate": 0.0009494231619364155,
      "loss": 1.3694,
      "step": 65
    },
    {
      "epoch": 33.0,
      "grad_norm": 1.7231642007827759,
      "learning_rate": 0.0009640296721200526,
      "loss": 1.3558,
      "step": 66
    },
    {
      "epoch": 33.5,
      "grad_norm": 1.3750600814819336,
      "learning_rate": 0.0009786361823036897,
      "loss": 1.3952,
      "step": 67
    },
    {
      "epoch": 34.0,
      "grad_norm": 2.32792592048645,
      "learning_rate": 0.000993242692487327,
      "loss": 1.2778,
      "step": 68
    },
    {
      "epoch": 34.5,
      "grad_norm": 3.055366039276123,
      "learning_rate": 0.0010078492026709641,
      "loss": 1.3752,
      "step": 69
    },
    {
      "epoch": 35.0,
      "grad_norm": 1.912065029144287,
      "learning_rate": 0.001022455712854601,
      "loss": 1.3098,
      "step": 70
    },
    {
      "epoch": 35.5,
      "grad_norm": 1.8712215423583984,
      "learning_rate": 0.0010370622230382383,
      "loss": 1.3498,
      "step": 71
    },
    {
      "epoch": 36.0,
      "grad_norm": 2.477794647216797,
      "learning_rate": 0.0010516687332218755,
      "loss": 1.346,
      "step": 72
    },
    {
      "epoch": 36.5,
      "grad_norm": 2.0505995750427246,
      "learning_rate": 0.0010662752434055128,
      "loss": 1.3409,
      "step": 73
    },
    {
      "epoch": 37.0,
      "grad_norm": 1.9470235109329224,
      "learning_rate": 0.00108088175358915,
      "loss": 1.3113,
      "step": 74
    },
    {
      "epoch": 37.5,
      "grad_norm": 2.3359978199005127,
      "learning_rate": 0.001095488263772787,
      "loss": 1.312,
      "step": 75
    },
    {
      "epoch": 38.0,
      "grad_norm": 2.2648556232452393,
      "learning_rate": 0.0011100947739564242,
      "loss": 1.3211,
      "step": 76
    },
    {
      "epoch": 38.5,
      "grad_norm": 1.8099963665008545,
      "learning_rate": 0.0011247012841400614,
      "loss": 1.2658,
      "step": 77
    },
    {
      "epoch": 39.0,
      "grad_norm": 2.7761526107788086,
      "learning_rate": 0.0011393077943236984,
      "loss": 1.3663,
      "step": 78
    },
    {
      "epoch": 39.5,
      "grad_norm": 2.4606828689575195,
      "learning_rate": 0.0011539143045073356,
      "loss": 1.28,
      "step": 79
    },
    {
      "epoch": 40.0,
      "grad_norm": 4.345248699188232,
      "learning_rate": 0.0011685208146909728,
      "loss": 1.3488,
      "step": 80
    },
    {
      "epoch": 40.0,
      "eval_brier_0th_event": 0.19021868589851226,
      "eval_brier_0th_event_n": 263,
      "eval_brier_avg": 0.19021868589851226,
      "eval_brier_weighted_avg": 0.19021868589851226,
      "eval_ipcw": 0.5742998287809574,
      "eval_ipcw_0th_event": 0.5742998287809574,
      "eval_ipcw_0th_event_0.25": 0.7289926678832409,
      "eval_ipcw_0th_event_0.5": 0.6625456579112539,
      "eval_ipcw_0th_event_0.75": 0.6303428747281544,
      "eval_ipcw_0th_event_1.0": 0.5742998287809574,
      "eval_ipcw_0th_event_n": 263,
      "eval_ipcw_avg": 0.6490452573259017,
      "eval_ipcw_avg_0th_event": 0.6490452573259017,
      "eval_ipcw_weighted_avg": 0.6490452573259017,
      "eval_loss": 0.6939235329627991,
      "eval_runtime": 0.0833,
      "eval_samples_per_second": 5332.048,
      "eval_steps_per_second": 12.009,
      "step": 80
    },
    {
      "epoch": 40.5,
      "grad_norm": 2.7853968143463135,
      "learning_rate": 0.001168517408255786,
      "loss": 1.2698,
      "step": 81
    },
    {
      "epoch": 40.5,
      "eval_brier_0th_event": 0.19193551214921756,
      "eval_brier_0th_event_n": 263,
      "eval_brier_avg": 0.19193551214921756,
      "eval_brier_weighted_avg": 0.19193551214921756,
      "eval_ipcw": 0.5841938808252827,
      "eval_ipcw_0th_event": 0.5841938808252827,
      "eval_ipcw_0th_event_0.25": 0.7359561329477278,
      "eval_ipcw_0th_event_0.5": 0.6599188523203967,
      "eval_ipcw_0th_event_0.75": 0.6308862151699494,
      "eval_ipcw_0th_event_1.0": 0.5841938808252827,
      "eval_ipcw_0th_event_n": 263,
      "eval_ipcw_avg": 0.6527387703158392,
      "eval_ipcw_avg_0th_event": 0.6527387703158392,
      "eval_ipcw_weighted_avg": 0.6527387703158392,
      "eval_loss": 0.6951137185096741,
      "eval_runtime": 0.0709,
      "eval_samples_per_second": 6263.924,
      "eval_steps_per_second": 14.108,
      "step": 81
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 38525414400.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
