{
  "best_global_step": 82,
  "best_metric": 0.6226727361413273,
  "best_model_checkpoint": "./data/model-hub/metabric/survival_trial_1749818736_2/checkpoint-82",
  "epoch": 41.0,
  "eval_steps": 1,
  "global_step": 82,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 0.8827259540557861,
      "learning_rate": 2.3932225816159727e-05,
      "loss": 1.6726,
      "step": 1
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.7097811698913574,
      "learning_rate": 4.7864451632319455e-05,
      "loss": 1.6045,
      "step": 2
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.8745501041412354,
      "learning_rate": 7.179667744847918e-05,
      "loss": 1.6582,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.7490777969360352,
      "learning_rate": 9.572890326463891e-05,
      "loss": 1.6348,
      "step": 4
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.8360424637794495,
      "learning_rate": 0.00011966112908079863,
      "loss": 1.6392,
      "step": 5
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.8310010433197021,
      "learning_rate": 0.00014359335489695836,
      "loss": 1.6454,
      "step": 6
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.8481824398040771,
      "learning_rate": 0.00016752558071311807,
      "loss": 1.6446,
      "step": 7
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.7674623727798462,
      "learning_rate": 0.00019145780652927782,
      "loss": 1.6507,
      "step": 8
    },
    {
      "epoch": 4.5,
      "grad_norm": 0.8498740792274475,
      "learning_rate": 0.00021539003234543754,
      "loss": 1.6202,
      "step": 9
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.9194559454917908,
      "learning_rate": 0.00023932225816159725,
      "loss": 1.6278,
      "step": 10
    },
    {
      "epoch": 5.5,
      "grad_norm": 0.8525247573852539,
      "learning_rate": 0.000263254483977757,
      "loss": 1.656,
      "step": 11
    },
    {
      "epoch": 6.0,
      "grad_norm": 1.2561278343200684,
      "learning_rate": 0.0002871867097939167,
      "loss": 1.5989,
      "step": 12
    },
    {
      "epoch": 6.5,
      "grad_norm": 1.0547255277633667,
      "learning_rate": 0.00031111893561007643,
      "loss": 1.6295,
      "step": 13
    },
    {
      "epoch": 7.0,
      "grad_norm": 1.1726773977279663,
      "learning_rate": 0.00033505116142623615,
      "loss": 1.5836,
      "step": 14
    },
    {
      "epoch": 7.5,
      "grad_norm": 1.3333015441894531,
      "learning_rate": 0.00035898338724239587,
      "loss": 1.614,
      "step": 15
    },
    {
      "epoch": 8.0,
      "grad_norm": 1.0072901248931885,
      "learning_rate": 0.00038291561305855564,
      "loss": 1.5734,
      "step": 16
    },
    {
      "epoch": 8.5,
      "grad_norm": 1.310884952545166,
      "learning_rate": 0.0004068478388747153,
      "loss": 1.6157,
      "step": 17
    },
    {
      "epoch": 9.0,
      "grad_norm": 1.7258421182632446,
      "learning_rate": 0.00043078006469087507,
      "loss": 1.6176,
      "step": 18
    },
    {
      "epoch": 9.5,
      "grad_norm": 1.5151865482330322,
      "learning_rate": 0.00045471229050703473,
      "loss": 1.5947,
      "step": 19
    },
    {
      "epoch": 10.0,
      "grad_norm": 1.7047138214111328,
      "learning_rate": 0.0004786445163231945,
      "loss": 1.5693,
      "step": 20
    },
    {
      "epoch": 10.5,
      "grad_norm": 1.6153197288513184,
      "learning_rate": 0.0005025767421393542,
      "loss": 1.5565,
      "step": 21
    },
    {
      "epoch": 11.0,
      "grad_norm": 1.8291244506835938,
      "learning_rate": 0.000526508967955514,
      "loss": 1.6062,
      "step": 22
    },
    {
      "epoch": 11.5,
      "grad_norm": 1.7537055015563965,
      "learning_rate": 0.0005504411937716737,
      "loss": 1.5907,
      "step": 23
    },
    {
      "epoch": 12.0,
      "grad_norm": 1.8541513681411743,
      "learning_rate": 0.0005743734195878334,
      "loss": 1.5208,
      "step": 24
    },
    {
      "epoch": 12.5,
      "grad_norm": 2.0178589820861816,
      "learning_rate": 0.0005983056454039931,
      "loss": 1.5557,
      "step": 25
    },
    {
      "epoch": 13.0,
      "grad_norm": 1.7525790929794312,
      "learning_rate": 0.0006222378712201529,
      "loss": 1.5223,
      "step": 26
    },
    {
      "epoch": 13.5,
      "grad_norm": 1.8009170293807983,
      "learning_rate": 0.0006461700970363126,
      "loss": 1.5538,
      "step": 27
    },
    {
      "epoch": 14.0,
      "grad_norm": 2.0836148262023926,
      "learning_rate": 0.0006701023228524723,
      "loss": 1.521,
      "step": 28
    },
    {
      "epoch": 14.5,
      "grad_norm": 2.4968974590301514,
      "learning_rate": 0.000694034548668632,
      "loss": 1.5291,
      "step": 29
    },
    {
      "epoch": 15.0,
      "grad_norm": 1.4896777868270874,
      "learning_rate": 0.0007179667744847917,
      "loss": 1.522,
      "step": 30
    },
    {
      "epoch": 15.5,
      "grad_norm": 1.7076879739761353,
      "learning_rate": 0.0007418990003009515,
      "loss": 1.5163,
      "step": 31
    },
    {
      "epoch": 16.0,
      "grad_norm": 2.3993325233459473,
      "learning_rate": 0.0007658312261171113,
      "loss": 1.5038,
      "step": 32
    },
    {
      "epoch": 16.5,
      "grad_norm": 1.915602207183838,
      "learning_rate": 0.0007897634519332709,
      "loss": 1.4778,
      "step": 33
    },
    {
      "epoch": 17.0,
      "grad_norm": 1.9113574028015137,
      "learning_rate": 0.0008136956777494306,
      "loss": 1.5017,
      "step": 34
    },
    {
      "epoch": 17.5,
      "grad_norm": 2.2971041202545166,
      "learning_rate": 0.0008376279035655904,
      "loss": 1.4804,
      "step": 35
    },
    {
      "epoch": 18.0,
      "grad_norm": 1.873348355293274,
      "learning_rate": 0.0008615601293817501,
      "loss": 1.4428,
      "step": 36
    },
    {
      "epoch": 18.5,
      "grad_norm": 2.194683313369751,
      "learning_rate": 0.0008854923551979099,
      "loss": 1.4585,
      "step": 37
    },
    {
      "epoch": 19.0,
      "grad_norm": 1.750970721244812,
      "learning_rate": 0.0009094245810140695,
      "loss": 1.4525,
      "step": 38
    },
    {
      "epoch": 19.5,
      "grad_norm": 1.7042874097824097,
      "learning_rate": 0.0009333568068302292,
      "loss": 1.3976,
      "step": 39
    },
    {
      "epoch": 20.0,
      "grad_norm": 2.362488269805908,
      "learning_rate": 0.000957289032646389,
      "loss": 1.4798,
      "step": 40
    },
    {
      "epoch": 20.5,
      "grad_norm": 1.469584345817566,
      "learning_rate": 0.0009812212584625487,
      "loss": 1.4095,
      "step": 41
    },
    {
      "epoch": 21.0,
      "grad_norm": 2.3792192935943604,
      "learning_rate": 0.0010051534842787084,
      "loss": 1.4212,
      "step": 42
    },
    {
      "epoch": 21.5,
      "grad_norm": 1.645531415939331,
      "learning_rate": 0.0010290857100948682,
      "loss": 1.3762,
      "step": 43
    },
    {
      "epoch": 22.0,
      "grad_norm": 1.4771268367767334,
      "learning_rate": 0.001053017935911028,
      "loss": 1.4172,
      "step": 44
    },
    {
      "epoch": 22.5,
      "grad_norm": 1.7102943658828735,
      "learning_rate": 0.0010769501617271875,
      "loss": 1.3943,
      "step": 45
    },
    {
      "epoch": 23.0,
      "grad_norm": 1.4508925676345825,
      "learning_rate": 0.0011008823875433473,
      "loss": 1.3906,
      "step": 46
    },
    {
      "epoch": 23.5,
      "grad_norm": 1.7994407415390015,
      "learning_rate": 0.001124814613359507,
      "loss": 1.359,
      "step": 47
    },
    {
      "epoch": 24.0,
      "grad_norm": 1.5526273250579834,
      "learning_rate": 0.0011487468391756669,
      "loss": 1.3926,
      "step": 48
    },
    {
      "epoch": 24.5,
      "grad_norm": 1.437315583229065,
      "learning_rate": 0.0011726790649918266,
      "loss": 1.3467,
      "step": 49
    },
    {
      "epoch": 25.0,
      "grad_norm": 1.5433152914047241,
      "learning_rate": 0.0011966112908079862,
      "loss": 1.3635,
      "step": 50
    },
    {
      "epoch": 25.5,
      "grad_norm": 1.5221333503723145,
      "learning_rate": 0.001220543516624146,
      "loss": 1.3229,
      "step": 51
    },
    {
      "epoch": 26.0,
      "grad_norm": 2.1717820167541504,
      "learning_rate": 0.0012444757424403057,
      "loss": 1.4082,
      "step": 52
    },
    {
      "epoch": 26.5,
      "grad_norm": 1.2405611276626587,
      "learning_rate": 0.0012684079682564655,
      "loss": 1.3472,
      "step": 53
    },
    {
      "epoch": 27.0,
      "grad_norm": 1.788855791091919,
      "learning_rate": 0.0012923401940726253,
      "loss": 1.2936,
      "step": 54
    },
    {
      "epoch": 27.5,
      "grad_norm": 1.406530737876892,
      "learning_rate": 0.0013162724198887848,
      "loss": 1.3488,
      "step": 55
    },
    {
      "epoch": 28.0,
      "grad_norm": 1.5683969259262085,
      "learning_rate": 0.0013402046457049446,
      "loss": 1.267,
      "step": 56
    },
    {
      "epoch": 28.5,
      "grad_norm": 1.4947762489318848,
      "learning_rate": 0.0013641368715211044,
      "loss": 1.2989,
      "step": 57
    },
    {
      "epoch": 29.0,
      "grad_norm": 1.4807761907577515,
      "learning_rate": 0.001388069097337264,
      "loss": 1.3247,
      "step": 58
    },
    {
      "epoch": 29.5,
      "grad_norm": 1.371175765991211,
      "learning_rate": 0.001412001323153424,
      "loss": 1.2879,
      "step": 59
    },
    {
      "epoch": 30.0,
      "grad_norm": 1.3475425243377686,
      "learning_rate": 0.0014359335489695835,
      "loss": 1.3116,
      "step": 60
    },
    {
      "epoch": 30.5,
      "grad_norm": 1.3321738243103027,
      "learning_rate": 0.0014598657747857432,
      "loss": 1.2959,
      "step": 61
    },
    {
      "epoch": 31.0,
      "grad_norm": 2.240788459777832,
      "learning_rate": 0.001483798000601903,
      "loss": 1.2533,
      "step": 62
    },
    {
      "epoch": 31.5,
      "grad_norm": 1.4195209741592407,
      "learning_rate": 0.0015077302264180626,
      "loss": 1.2586,
      "step": 63
    },
    {
      "epoch": 32.0,
      "grad_norm": 1.8244162797927856,
      "learning_rate": 0.0015316624522342225,
      "loss": 1.2733,
      "step": 64
    },
    {
      "epoch": 32.5,
      "grad_norm": 1.35088312625885,
      "learning_rate": 0.001555594678050382,
      "loss": 1.2463,
      "step": 65
    },
    {
      "epoch": 33.0,
      "grad_norm": 1.9120248556137085,
      "learning_rate": 0.0015795269038665419,
      "loss": 1.2461,
      "step": 66
    },
    {
      "epoch": 33.5,
      "grad_norm": 1.5295222997665405,
      "learning_rate": 0.0016034591296827016,
      "loss": 1.1977,
      "step": 67
    },
    {
      "epoch": 34.0,
      "grad_norm": 3.125006914138794,
      "learning_rate": 0.0016273913554988612,
      "loss": 1.3002,
      "step": 68
    },
    {
      "epoch": 34.5,
      "grad_norm": 1.6896884441375732,
      "learning_rate": 0.0016513235813150212,
      "loss": 1.2135,
      "step": 69
    },
    {
      "epoch": 35.0,
      "grad_norm": 2.479715347290039,
      "learning_rate": 0.0016752558071311807,
      "loss": 1.2426,
      "step": 70
    },
    {
      "epoch": 35.5,
      "grad_norm": 2.0578081607818604,
      "learning_rate": 0.0016991880329473405,
      "loss": 1.2221,
      "step": 71
    },
    {
      "epoch": 36.0,
      "grad_norm": 2.1430752277374268,
      "learning_rate": 0.0017231202587635003,
      "loss": 1.2244,
      "step": 72
    },
    {
      "epoch": 36.5,
      "grad_norm": 1.7581678628921509,
      "learning_rate": 0.0017470524845796598,
      "loss": 1.2144,
      "step": 73
    },
    {
      "epoch": 37.0,
      "grad_norm": 2.4288716316223145,
      "learning_rate": 0.0017709847103958198,
      "loss": 1.1598,
      "step": 74
    },
    {
      "epoch": 37.5,
      "grad_norm": 2.5681090354919434,
      "learning_rate": 0.0017949169362119794,
      "loss": 1.1666,
      "step": 75
    },
    {
      "epoch": 38.0,
      "grad_norm": 2.9335620403289795,
      "learning_rate": 0.001818849162028139,
      "loss": 1.2106,
      "step": 76
    },
    {
      "epoch": 38.5,
      "grad_norm": 1.7806800603866577,
      "learning_rate": 0.001842781387844299,
      "loss": 1.1765,
      "step": 77
    },
    {
      "epoch": 39.0,
      "grad_norm": 3.9460601806640625,
      "learning_rate": 0.0018667136136604585,
      "loss": 1.2325,
      "step": 78
    },
    {
      "epoch": 39.5,
      "grad_norm": 1.9013142585754395,
      "learning_rate": 0.0018906458394766185,
      "loss": 1.149,
      "step": 79
    },
    {
      "epoch": 40.0,
      "grad_norm": 2.8234474658966064,
      "learning_rate": 0.001914578065292778,
      "loss": 1.1763,
      "step": 80
    },
    {
      "epoch": 40.0,
      "eval_brier_0th_event": 0.1868784874677658,
      "eval_brier_0th_event_n": 247,
      "eval_brier_weighted_avg": 0.1868784874677658,
      "eval_ipcw_0th_event": 0.6226217922930781,
      "eval_ipcw_0th_event_0.25": 0.6025845408439636,
      "eval_ipcw_0th_event_0.50": 0.6173466444015503,
      "eval_ipcw_0th_event_0.75": 0.6390273571014404,
      "eval_ipcw_0th_event_1.00": 0.6175893545150757,
      "eval_ipcw_0th_event_n": 473,
      "eval_ipcw_weighted_avg": 0.6226217922930781,
      "eval_loss": 0.646945059299469,
      "eval_runtime": 0.1556,
      "eval_samples_per_second": 3040.506,
      "eval_steps_per_second": 6.428,
      "step": 80
    },
    {
      "epoch": 40.5,
      "grad_norm": 2.571014881134033,
      "learning_rate": 0.0019145724839749207,
      "loss": 1.1353,
      "step": 81
    },
    {
      "epoch": 40.5,
      "eval_brier_0th_event": 0.18901018798351288,
      "eval_brier_0th_event_n": 247,
      "eval_brier_weighted_avg": 0.18901018798351288,
      "eval_ipcw_0th_event": 0.622580578198304,
      "eval_ipcw_0th_event_0.25": 0.6026725769042969,
      "eval_ipcw_0th_event_0.50": 0.6166320443153381,
      "eval_ipcw_0th_event_0.75": 0.6401453614234924,
      "eval_ipcw_0th_event_1.00": 0.6170171499252319,
      "eval_ipcw_0th_event_n": 473,
      "eval_ipcw_weighted_avg": 0.622580578198304,
      "eval_loss": 0.6521926522254944,
      "eval_runtime": 0.1665,
      "eval_samples_per_second": 2841.266,
      "eval_steps_per_second": 6.007,
      "step": 81
    },
    {
      "epoch": 41.0,
      "grad_norm": 2.7775402069091797,
      "learning_rate": 0.0019145557400864308,
      "loss": 1.1966,
      "step": 82
    },
    {
      "epoch": 41.0,
      "eval_brier_0th_event": 0.18719592690467834,
      "eval_brier_0th_event_n": 247,
      "eval_brier_weighted_avg": 0.18719592690467834,
      "eval_ipcw_0th_event": 0.6226727361413273,
      "eval_ipcw_0th_event_0.25": 0.6018272042274475,
      "eval_ipcw_0th_event_0.50": 0.6153988242149353,
      "eval_ipcw_0th_event_0.75": 0.6417810916900635,
      "eval_ipcw_0th_event_1.00": 0.6168361902236938,
      "eval_ipcw_0th_event_n": 473,
      "eval_ipcw_weighted_avg": 0.6226727361413273,
      "eval_loss": 0.6471924185752869,
      "eval_runtime": 0.1465,
      "eval_samples_per_second": 3229.045,
      "eval_steps_per_second": 6.827,
      "step": 82
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 25598799360.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
