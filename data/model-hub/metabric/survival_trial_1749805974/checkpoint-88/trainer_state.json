{
  "best_global_step": 88,
  "best_metric": 0.6395118324195638,
  "best_model_checkpoint": "./data/model-hub/metabric/survival_trial_1749805974/checkpoint-88",
  "epoch": 44.0,
  "eval_steps": 1,
  "global_step": 88,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 3.383885622024536,
      "learning_rate": 0.00010642761901071999,
      "loss": 1.6065,
      "step": 1
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.9543612003326416,
      "learning_rate": 0.00021285523802143998,
      "loss": 1.5834,
      "step": 2
    },
    {
      "epoch": 1.5,
      "grad_norm": 3.023555278778076,
      "learning_rate": 0.0003192828570321599,
      "loss": 1.6022,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 3.1549081802368164,
      "learning_rate": 0.00042571047604287996,
      "loss": 1.5701,
      "step": 4
    },
    {
      "epoch": 2.5,
      "grad_norm": 2.944413661956787,
      "learning_rate": 0.0005321380950535999,
      "loss": 1.5491,
      "step": 5
    },
    {
      "epoch": 3.0,
      "grad_norm": 3.248563528060913,
      "learning_rate": 0.0006385657140643198,
      "loss": 1.6098,
      "step": 6
    },
    {
      "epoch": 3.5,
      "grad_norm": 2.9092485904693604,
      "learning_rate": 0.0007449933330750398,
      "loss": 1.5799,
      "step": 7
    },
    {
      "epoch": 4.0,
      "grad_norm": 3.0986764430999756,
      "learning_rate": 0.0008514209520857599,
      "loss": 1.539,
      "step": 8
    },
    {
      "epoch": 4.5,
      "grad_norm": 3.1178030967712402,
      "learning_rate": 0.0009578485710964799,
      "loss": 1.5627,
      "step": 9
    },
    {
      "epoch": 5.0,
      "grad_norm": 2.958416223526001,
      "learning_rate": 0.0010642761901071998,
      "loss": 1.5169,
      "step": 10
    },
    {
      "epoch": 5.5,
      "grad_norm": 3.05015230178833,
      "learning_rate": 0.00117070380911792,
      "loss": 1.5076,
      "step": 11
    },
    {
      "epoch": 6.0,
      "grad_norm": 3.4348719120025635,
      "learning_rate": 0.0012771314281286397,
      "loss": 1.5241,
      "step": 12
    },
    {
      "epoch": 6.5,
      "grad_norm": 2.7525134086608887,
      "learning_rate": 0.0013835590471393598,
      "loss": 1.4551,
      "step": 13
    },
    {
      "epoch": 7.0,
      "grad_norm": 3.19155216217041,
      "learning_rate": 0.0014899866661500795,
      "loss": 1.4965,
      "step": 14
    },
    {
      "epoch": 7.5,
      "grad_norm": 2.7839696407318115,
      "learning_rate": 0.0015964142851607997,
      "loss": 1.4446,
      "step": 15
    },
    {
      "epoch": 8.0,
      "grad_norm": 2.233596086502075,
      "learning_rate": 0.0017028419041715199,
      "loss": 1.4291,
      "step": 16
    },
    {
      "epoch": 8.5,
      "grad_norm": 2.5227653980255127,
      "learning_rate": 0.0018092695231822396,
      "loss": 1.4339,
      "step": 17
    },
    {
      "epoch": 9.0,
      "grad_norm": 1.8289180994033813,
      "learning_rate": 0.0019156971421929597,
      "loss": 1.373,
      "step": 18
    },
    {
      "epoch": 9.5,
      "grad_norm": 1.8450560569763184,
      "learning_rate": 0.0020221247612036797,
      "loss": 1.4142,
      "step": 19
    },
    {
      "epoch": 10.0,
      "grad_norm": 1.9888675212860107,
      "learning_rate": 0.0021285523802143996,
      "loss": 1.3415,
      "step": 20
    },
    {
      "epoch": 10.5,
      "grad_norm": 1.4041657447814941,
      "learning_rate": 0.0022349799992251195,
      "loss": 1.3631,
      "step": 21
    },
    {
      "epoch": 11.0,
      "grad_norm": 1.9734113216400146,
      "learning_rate": 0.00234140761823584,
      "loss": 1.3765,
      "step": 22
    },
    {
      "epoch": 11.5,
      "grad_norm": 2.537949800491333,
      "learning_rate": 0.0024478352372465594,
      "loss": 1.3105,
      "step": 23
    },
    {
      "epoch": 12.0,
      "grad_norm": 2.174529790878296,
      "learning_rate": 0.0025542628562572793,
      "loss": 1.3997,
      "step": 24
    },
    {
      "epoch": 12.5,
      "grad_norm": 2.0782008171081543,
      "learning_rate": 0.0026606904752679997,
      "loss": 1.3773,
      "step": 25
    },
    {
      "epoch": 13.0,
      "grad_norm": 2.0971295833587646,
      "learning_rate": 0.0027671180942787196,
      "loss": 1.3007,
      "step": 26
    },
    {
      "epoch": 13.5,
      "grad_norm": 3.809892416000366,
      "learning_rate": 0.0028735457132894396,
      "loss": 1.3366,
      "step": 27
    },
    {
      "epoch": 14.0,
      "grad_norm": 1.9754409790039062,
      "learning_rate": 0.002979973332300159,
      "loss": 1.3406,
      "step": 28
    },
    {
      "epoch": 14.5,
      "grad_norm": 1.8092424869537354,
      "learning_rate": 0.0030864009513108795,
      "loss": 1.3636,
      "step": 29
    },
    {
      "epoch": 15.0,
      "grad_norm": 2.0195353031158447,
      "learning_rate": 0.0031928285703215994,
      "loss": 1.2677,
      "step": 30
    },
    {
      "epoch": 15.5,
      "grad_norm": 1.7822301387786865,
      "learning_rate": 0.0032992561893323193,
      "loss": 1.3276,
      "step": 31
    },
    {
      "epoch": 16.0,
      "grad_norm": 2.0134634971618652,
      "learning_rate": 0.0034056838083430397,
      "loss": 1.2575,
      "step": 32
    },
    {
      "epoch": 16.5,
      "grad_norm": 1.586624264717102,
      "learning_rate": 0.003512111427353759,
      "loss": 1.2743,
      "step": 33
    },
    {
      "epoch": 17.0,
      "grad_norm": 2.827735424041748,
      "learning_rate": 0.003618539046364479,
      "loss": 1.2783,
      "step": 34
    },
    {
      "epoch": 17.5,
      "grad_norm": 1.5670137405395508,
      "learning_rate": 0.003724966665375199,
      "loss": 1.2825,
      "step": 35
    },
    {
      "epoch": 18.0,
      "grad_norm": 3.198651075363159,
      "learning_rate": 0.0038313942843859194,
      "loss": 1.2572,
      "step": 36
    },
    {
      "epoch": 18.5,
      "grad_norm": 2.347874879837036,
      "learning_rate": 0.00393782190339664,
      "loss": 1.2734,
      "step": 37
    },
    {
      "epoch": 19.0,
      "grad_norm": 3.482057571411133,
      "learning_rate": 0.004044249522407359,
      "loss": 1.2415,
      "step": 38
    },
    {
      "epoch": 19.5,
      "grad_norm": 2.4946506023406982,
      "learning_rate": 0.004150677141418079,
      "loss": 1.2422,
      "step": 39
    },
    {
      "epoch": 20.0,
      "grad_norm": 3.740971088409424,
      "learning_rate": 0.004257104760428799,
      "loss": 1.2824,
      "step": 40
    },
    {
      "epoch": 20.5,
      "grad_norm": 4.686857223510742,
      "learning_rate": 0.004363532379439519,
      "loss": 1.2576,
      "step": 41
    },
    {
      "epoch": 21.0,
      "grad_norm": 2.1727004051208496,
      "learning_rate": 0.004469959998450239,
      "loss": 1.2431,
      "step": 42
    },
    {
      "epoch": 21.5,
      "grad_norm": 2.211620330810547,
      "learning_rate": 0.004576387617460959,
      "loss": 1.2086,
      "step": 43
    },
    {
      "epoch": 22.0,
      "grad_norm": 5.236941814422607,
      "learning_rate": 0.00468281523647168,
      "loss": 1.2572,
      "step": 44
    },
    {
      "epoch": 22.5,
      "grad_norm": 1.8790199756622314,
      "learning_rate": 0.004789242855482399,
      "loss": 1.2393,
      "step": 45
    },
    {
      "epoch": 23.0,
      "grad_norm": 2.65830135345459,
      "learning_rate": 0.004895670474493119,
      "loss": 1.1964,
      "step": 46
    },
    {
      "epoch": 23.5,
      "grad_norm": 2.9012749195098877,
      "learning_rate": 0.005002098093503839,
      "loss": 1.2511,
      "step": 47
    },
    {
      "epoch": 24.0,
      "grad_norm": 2.4949235916137695,
      "learning_rate": 0.005108525712514559,
      "loss": 1.1863,
      "step": 48
    },
    {
      "epoch": 24.5,
      "grad_norm": 4.470977306365967,
      "learning_rate": 0.005214953331525279,
      "loss": 1.2198,
      "step": 49
    },
    {
      "epoch": 25.0,
      "grad_norm": 2.9145469665527344,
      "learning_rate": 0.005321380950535999,
      "loss": 1.1981,
      "step": 50
    },
    {
      "epoch": 25.5,
      "grad_norm": 2.5700156688690186,
      "learning_rate": 0.005427808569546719,
      "loss": 1.1623,
      "step": 51
    },
    {
      "epoch": 26.0,
      "grad_norm": 3.2546372413635254,
      "learning_rate": 0.005534236188557439,
      "loss": 1.2506,
      "step": 52
    },
    {
      "epoch": 26.5,
      "grad_norm": 2.352130174636841,
      "learning_rate": 0.005640663807568159,
      "loss": 1.1794,
      "step": 53
    },
    {
      "epoch": 27.0,
      "grad_norm": 2.2154603004455566,
      "learning_rate": 0.005747091426578879,
      "loss": 1.2012,
      "step": 54
    },
    {
      "epoch": 27.5,
      "grad_norm": 2.782116651535034,
      "learning_rate": 0.005853519045589599,
      "loss": 1.1385,
      "step": 55
    },
    {
      "epoch": 28.0,
      "grad_norm": 3.159715414047241,
      "learning_rate": 0.005959946664600318,
      "loss": 1.2187,
      "step": 56
    },
    {
      "epoch": 28.5,
      "grad_norm": 1.7565841674804688,
      "learning_rate": 0.006066374283611039,
      "loss": 1.1378,
      "step": 57
    },
    {
      "epoch": 29.0,
      "grad_norm": 3.207066297531128,
      "learning_rate": 0.006172801902621759,
      "loss": 1.2005,
      "step": 58
    },
    {
      "epoch": 29.5,
      "grad_norm": 1.664878010749817,
      "learning_rate": 0.006279229521632479,
      "loss": 1.1802,
      "step": 59
    },
    {
      "epoch": 30.0,
      "grad_norm": 5.885863780975342,
      "learning_rate": 0.006385657140643199,
      "loss": 1.1528,
      "step": 60
    },
    {
      "epoch": 30.5,
      "grad_norm": 1.8822548389434814,
      "learning_rate": 0.006492084759653918,
      "loss": 1.1675,
      "step": 61
    },
    {
      "epoch": 31.0,
      "grad_norm": 3.3921239376068115,
      "learning_rate": 0.006598512378664639,
      "loss": 1.1292,
      "step": 62
    },
    {
      "epoch": 31.5,
      "grad_norm": 3.4779775142669678,
      "learning_rate": 0.006704939997675358,
      "loss": 1.1682,
      "step": 63
    },
    {
      "epoch": 32.0,
      "grad_norm": 2.0810821056365967,
      "learning_rate": 0.006811367616686079,
      "loss": 1.1672,
      "step": 64
    },
    {
      "epoch": 32.5,
      "grad_norm": 2.3606364727020264,
      "learning_rate": 0.006917795235696799,
      "loss": 1.1205,
      "step": 65
    },
    {
      "epoch": 33.0,
      "grad_norm": 2.7215065956115723,
      "learning_rate": 0.007024222854707518,
      "loss": 1.1136,
      "step": 66
    },
    {
      "epoch": 33.5,
      "grad_norm": 2.0283710956573486,
      "learning_rate": 0.007130650473718239,
      "loss": 1.1247,
      "step": 67
    },
    {
      "epoch": 34.0,
      "grad_norm": 4.930081844329834,
      "learning_rate": 0.007237078092728958,
      "loss": 1.2218,
      "step": 68
    },
    {
      "epoch": 34.5,
      "grad_norm": 2.9149603843688965,
      "learning_rate": 0.007343505711739679,
      "loss": 1.1048,
      "step": 69
    },
    {
      "epoch": 35.0,
      "grad_norm": 4.692079544067383,
      "learning_rate": 0.007449933330750398,
      "loss": 1.2061,
      "step": 70
    },
    {
      "epoch": 35.5,
      "grad_norm": 4.870663166046143,
      "learning_rate": 0.0075563609497611185,
      "loss": 1.1869,
      "step": 71
    },
    {
      "epoch": 36.0,
      "grad_norm": 2.324021577835083,
      "learning_rate": 0.007662788568771839,
      "loss": 1.0842,
      "step": 72
    },
    {
      "epoch": 36.5,
      "grad_norm": 3.603189706802368,
      "learning_rate": 0.007769216187782558,
      "loss": 1.1624,
      "step": 73
    },
    {
      "epoch": 37.0,
      "grad_norm": 2.21431040763855,
      "learning_rate": 0.00787564380679328,
      "loss": 1.1263,
      "step": 74
    },
    {
      "epoch": 37.5,
      "grad_norm": 2.7912333011627197,
      "learning_rate": 0.007982071425803998,
      "loss": 1.1299,
      "step": 75
    },
    {
      "epoch": 38.0,
      "grad_norm": 3.3220343589782715,
      "learning_rate": 0.008088499044814719,
      "loss": 1.1649,
      "step": 76
    },
    {
      "epoch": 38.5,
      "grad_norm": 3.5559144020080566,
      "learning_rate": 0.008194926663825439,
      "loss": 1.1268,
      "step": 77
    },
    {
      "epoch": 39.0,
      "grad_norm": 4.598690986633301,
      "learning_rate": 0.008301354282836158,
      "loss": 1.16,
      "step": 78
    },
    {
      "epoch": 39.5,
      "grad_norm": 2.0099377632141113,
      "learning_rate": 0.008407781901846878,
      "loss": 1.1449,
      "step": 79
    },
    {
      "epoch": 40.0,
      "grad_norm": 2.936774730682373,
      "learning_rate": 0.008514209520857598,
      "loss": 1.1321,
      "step": 80
    },
    {
      "epoch": 40.0,
      "eval_brier_0th_event": 0.19939552247524261,
      "eval_brier_0th_event_n": 253,
      "eval_brier_weighted_avg": 0.19939552247524261,
      "eval_ipcw_0th_event": 0.6047936018221888,
      "eval_ipcw_0th_event_0.25": 0.5973051190376282,
      "eval_ipcw_0th_event_0.50": 0.6161445379257202,
      "eval_ipcw_0th_event_0.75": 0.6195955276489258,
      "eval_ipcw_0th_event_1.00": 0.58935546875,
      "eval_ipcw_0th_event_n": 411,
      "eval_ipcw_weighted_avg": 0.6047936018221888,
      "eval_loss": 0.6894055008888245,
      "eval_runtime": 0.6701,
      "eval_samples_per_second": 613.318,
      "eval_steps_per_second": 1.492,
      "step": 80
    },
    {
      "epoch": 40.5,
      "grad_norm": 2.7522075176239014,
      "learning_rate": 0.008514184700501354,
      "loss": 1.1225,
      "step": 81
    },
    {
      "epoch": 40.5,
      "eval_brier_0th_event": 0.2007678747177124,
      "eval_brier_0th_event_n": 253,
      "eval_brier_weighted_avg": 0.2007678747177124,
      "eval_ipcw_0th_event": 0.6047162580600833,
      "eval_ipcw_0th_event_0.25": 0.5976775884628296,
      "eval_ipcw_0th_event_0.50": 0.6152240037918091,
      "eval_ipcw_0th_event_0.75": 0.6200233697891235,
      "eval_ipcw_0th_event_1.00": 0.5892217755317688,
      "eval_ipcw_0th_event_n": 411,
      "eval_ipcw_weighted_avg": 0.6047162580600833,
      "eval_loss": 0.690526008605957,
      "eval_runtime": 0.1469,
      "eval_samples_per_second": 2798.123,
      "eval_steps_per_second": 6.808,
      "step": 81
    },
    {
      "epoch": 41.0,
      "grad_norm": 1.9754716157913208,
      "learning_rate": 0.008514110239722041,
      "loss": 1.1613,
      "step": 82
    },
    {
      "epoch": 41.0,
      "eval_brier_0th_event": 0.1991448700428009,
      "eval_brier_0th_event_n": 253,
      "eval_brier_weighted_avg": 0.1991448700428009,
      "eval_ipcw_0th_event": 0.6087183140379726,
      "eval_ipcw_0th_event_0.25": 0.6010023355484009,
      "eval_ipcw_0th_event_0.50": 0.6158339381217957,
      "eval_ipcw_0th_event_0.75": 0.6248621344566345,
      "eval_ipcw_0th_event_1.00": 0.5945528745651245,
      "eval_ipcw_0th_event_n": 411,
      "eval_ipcw_weighted_avg": 0.6087183140379726,
      "eval_loss": 0.6900849938392639,
      "eval_runtime": 0.1427,
      "eval_samples_per_second": 2880.853,
      "eval_steps_per_second": 7.009,
      "step": 82
    },
    {
      "epoch": 41.5,
      "grad_norm": 1.4679155349731445,
      "learning_rate": 0.008513986139387923,
      "loss": 1.1225,
      "step": 83
    },
    {
      "epoch": 41.5,
      "eval_brier_0th_event": 0.20030957460403442,
      "eval_brier_0th_event_n": 253,
      "eval_brier_weighted_avg": 0.20030957460403442,
      "eval_ipcw_0th_event": 0.6137772365804797,
      "eval_ipcw_0th_event_0.25": 0.610100269317627,
      "eval_ipcw_0th_event_0.50": 0.6191455721855164,
      "eval_ipcw_0th_event_0.75": 0.6281536221504211,
      "eval_ipcw_0th_event_1.00": 0.6008548140525818,
      "eval_ipcw_0th_event_n": 411,
      "eval_ipcw_weighted_avg": 0.6137772365804797,
      "eval_loss": 0.6928874254226685,
      "eval_runtime": 0.1472,
      "eval_samples_per_second": 2791.494,
      "eval_steps_per_second": 6.792,
      "step": 83
    },
    {
      "epoch": 42.0,
      "grad_norm": 2.9785008430480957,
      "learning_rate": 0.008513812400946093,
      "loss": 1.0753,
      "step": 84
    },
    {
      "epoch": 42.0,
      "eval_brier_0th_event": 0.20010881125926971,
      "eval_brier_0th_event_n": 253,
      "eval_brier_weighted_avg": 0.20010881125926971,
      "eval_ipcw_0th_event": 0.6177139170583188,
      "eval_ipcw_0th_event_0.25": 0.6151434779167175,
      "eval_ipcw_0th_event_0.50": 0.6253280639648438,
      "eval_ipcw_0th_event_0.75": 0.6298184990882874,
      "eval_ipcw_0th_event_1.00": 0.6050597429275513,
      "eval_ipcw_0th_event_n": 411,
      "eval_ipcw_weighted_avg": 0.6177139170583188,
      "eval_loss": 0.6927347779273987,
      "eval_runtime": 0.141,
      "eval_samples_per_second": 2914.829,
      "eval_steps_per_second": 7.092,
      "step": 84
    },
    {
      "epoch": 42.5,
      "grad_norm": 1.7832756042480469,
      "learning_rate": 0.00851358902642246,
      "loss": 1.1052,
      "step": 85
    },
    {
      "epoch": 42.5,
      "eval_brier_0th_event": 0.2027648389339447,
      "eval_brier_0th_event_n": 253,
      "eval_brier_weighted_avg": 0.2027648389339447,
      "eval_ipcw_0th_event": 0.6219074925402002,
      "eval_ipcw_0th_event_0.25": 0.6181829571723938,
      "eval_ipcw_0th_event_0.50": 0.6211754083633423,
      "eval_ipcw_0th_event_0.75": 0.6328632235527039,
      "eval_ipcw_0th_event_1.00": 0.6148512959480286,
      "eval_ipcw_0th_event_n": 411,
      "eval_ipcw_weighted_avg": 0.6219074925402002,
      "eval_loss": 0.7056060433387756,
      "eval_runtime": 0.1441,
      "eval_samples_per_second": 2851.611,
      "eval_steps_per_second": 6.938,
      "step": 85
    },
    {
      "epoch": 43.0,
      "grad_norm": 1.6165827512741089,
      "learning_rate": 0.008513316018421719,
      "loss": 1.0645,
      "step": 86
    },
    {
      "epoch": 43.0,
      "eval_brier_0th_event": 0.20329175889492035,
      "eval_brier_0th_event_n": 253,
      "eval_brier_weighted_avg": 0.20329175889492035,
      "eval_ipcw_0th_event": 0.6309618243122987,
      "eval_ipcw_0th_event_0.25": 0.6200250387191772,
      "eval_ipcw_0th_event_0.50": 0.630062997341156,
      "eval_ipcw_0th_event_0.75": 0.6383678913116455,
      "eval_ipcw_0th_event_1.00": 0.6285687685012817,
      "eval_ipcw_0th_event_n": 411,
      "eval_ipcw_weighted_avg": 0.6309618243122987,
      "eval_loss": 0.7121300101280212,
      "eval_runtime": 0.1387,
      "eval_samples_per_second": 2964.279,
      "eval_steps_per_second": 7.212,
      "step": 86
    },
    {
      "epoch": 43.5,
      "grad_norm": 2.1794850826263428,
      "learning_rate": 0.00851299338012733,
      "loss": 1.067,
      "step": 87
    },
    {
      "epoch": 43.5,
      "eval_brier_0th_event": 0.20153330266475677,
      "eval_brier_0th_event_n": 253,
      "eval_brier_weighted_avg": 0.20153330266475677,
      "eval_ipcw_0th_event": 0.6360481367576233,
      "eval_ipcw_0th_event_0.25": 0.625564694404602,
      "eval_ipcw_0th_event_0.50": 0.6383176445960999,
      "eval_ipcw_0th_event_0.75": 0.6445400714874268,
      "eval_ipcw_0th_event_1.00": 0.63102787733078,
      "eval_ipcw_0th_event_n": 411,
      "eval_ipcw_weighted_avg": 0.6360481367576233,
      "eval_loss": 0.7082080245018005,
      "eval_runtime": 0.1469,
      "eval_samples_per_second": 2798.645,
      "eval_steps_per_second": 6.809,
      "step": 87
    },
    {
      "epoch": 44.0,
      "grad_norm": 4.553487777709961,
      "learning_rate": 0.008512621115301473,
      "loss": 1.1539,
      "step": 88
    },
    {
      "epoch": 44.0,
      "eval_brier_0th_event": 0.19754400849342346,
      "eval_brier_0th_event_n": 253,
      "eval_brier_weighted_avg": 0.19754400849342346,
      "eval_ipcw_0th_event": 0.6395118324195638,
      "eval_ipcw_0th_event_0.25": 0.6285123825073242,
      "eval_ipcw_0th_event_0.50": 0.6512812972068787,
      "eval_ipcw_0th_event_0.75": 0.6471167802810669,
      "eval_ipcw_0th_event_1.00": 0.6302726864814758,
      "eval_ipcw_0th_event_n": 411,
      "eval_ipcw_weighted_avg": 0.6395118324195638,
      "eval_loss": 0.7013733983039856,
      "eval_runtime": 0.1441,
      "eval_samples_per_second": 2851.357,
      "eval_steps_per_second": 6.938,
      "step": 88
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 44815140480.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
