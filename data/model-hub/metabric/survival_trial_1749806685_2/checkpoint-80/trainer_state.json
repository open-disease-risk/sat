{
  "best_global_step": 80,
  "best_metric": 0.6176944266299945,
  "best_model_checkpoint": "./data/model-hub/metabric/survival_trial_1749806685_2/checkpoint-80",
  "epoch": 40.0,
  "eval_steps": 1,
  "global_step": 80,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 1.6192543506622314,
      "learning_rate": 4.753567986864208e-05,
      "loss": 1.6647,
      "step": 1
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.0366320610046387,
      "learning_rate": 9.507135973728416e-05,
      "loss": 1.6123,
      "step": 2
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.608538031578064,
      "learning_rate": 0.00014260703960592623,
      "loss": 1.637,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.7686448097229004,
      "learning_rate": 0.00019014271947456833,
      "loss": 1.6432,
      "step": 4
    },
    {
      "epoch": 2.5,
      "grad_norm": 1.6344112157821655,
      "learning_rate": 0.0002376783993432104,
      "loss": 1.6759,
      "step": 5
    },
    {
      "epoch": 3.0,
      "grad_norm": 1.5031660795211792,
      "learning_rate": 0.00028521407921185246,
      "loss": 1.6096,
      "step": 6
    },
    {
      "epoch": 3.5,
      "grad_norm": 1.529011607170105,
      "learning_rate": 0.00033274975908049456,
      "loss": 1.637,
      "step": 7
    },
    {
      "epoch": 4.0,
      "grad_norm": 1.4153739213943481,
      "learning_rate": 0.00038028543894913665,
      "loss": 1.6128,
      "step": 8
    },
    {
      "epoch": 4.5,
      "grad_norm": 1.3658175468444824,
      "learning_rate": 0.0004278211188177787,
      "loss": 1.6061,
      "step": 9
    },
    {
      "epoch": 5.0,
      "grad_norm": 1.4662266969680786,
      "learning_rate": 0.0004753567986864208,
      "loss": 1.6787,
      "step": 10
    },
    {
      "epoch": 5.5,
      "grad_norm": 1.5581356287002563,
      "learning_rate": 0.0005228924785550629,
      "loss": 1.614,
      "step": 11
    },
    {
      "epoch": 6.0,
      "grad_norm": 1.524083137512207,
      "learning_rate": 0.0005704281584237049,
      "loss": 1.5992,
      "step": 12
    },
    {
      "epoch": 6.5,
      "grad_norm": 1.6724269390106201,
      "learning_rate": 0.000617963838292347,
      "loss": 1.6129,
      "step": 13
    },
    {
      "epoch": 7.0,
      "grad_norm": 1.7060365676879883,
      "learning_rate": 0.0006654995181609891,
      "loss": 1.5841,
      "step": 14
    },
    {
      "epoch": 7.5,
      "grad_norm": 1.7695831060409546,
      "learning_rate": 0.0007130351980296312,
      "loss": 1.614,
      "step": 15
    },
    {
      "epoch": 8.0,
      "grad_norm": 1.979392647743225,
      "learning_rate": 0.0007605708778982733,
      "loss": 1.5978,
      "step": 16
    },
    {
      "epoch": 8.5,
      "grad_norm": 2.0119028091430664,
      "learning_rate": 0.0008081065577669153,
      "loss": 1.5947,
      "step": 17
    },
    {
      "epoch": 9.0,
      "grad_norm": 1.810131311416626,
      "learning_rate": 0.0008556422376355574,
      "loss": 1.5493,
      "step": 18
    },
    {
      "epoch": 9.5,
      "grad_norm": 1.7497854232788086,
      "learning_rate": 0.0009031779175041995,
      "loss": 1.5623,
      "step": 19
    },
    {
      "epoch": 10.0,
      "grad_norm": 2.1017909049987793,
      "learning_rate": 0.0009507135973728416,
      "loss": 1.5386,
      "step": 20
    },
    {
      "epoch": 10.5,
      "grad_norm": 2.0843920707702637,
      "learning_rate": 0.0009982492772414838,
      "loss": 1.5227,
      "step": 21
    },
    {
      "epoch": 11.0,
      "grad_norm": 1.7725355625152588,
      "learning_rate": 0.0010457849571101259,
      "loss": 1.5505,
      "step": 22
    },
    {
      "epoch": 11.5,
      "grad_norm": 1.9151980876922607,
      "learning_rate": 0.0010933206369787677,
      "loss": 1.4949,
      "step": 23
    },
    {
      "epoch": 12.0,
      "grad_norm": 2.0761196613311768,
      "learning_rate": 0.0011408563168474098,
      "loss": 1.5402,
      "step": 24
    },
    {
      "epoch": 12.5,
      "grad_norm": 1.5396077632904053,
      "learning_rate": 0.001188391996716052,
      "loss": 1.4846,
      "step": 25
    },
    {
      "epoch": 13.0,
      "grad_norm": 2.507251739501953,
      "learning_rate": 0.001235927676584694,
      "loss": 1.5262,
      "step": 26
    },
    {
      "epoch": 13.5,
      "grad_norm": 2.0160155296325684,
      "learning_rate": 0.0012834633564533361,
      "loss": 1.4394,
      "step": 27
    },
    {
      "epoch": 14.0,
      "grad_norm": 1.5809189081192017,
      "learning_rate": 0.0013309990363219782,
      "loss": 1.5174,
      "step": 28
    },
    {
      "epoch": 14.5,
      "grad_norm": 1.8416956663131714,
      "learning_rate": 0.0013785347161906203,
      "loss": 1.4393,
      "step": 29
    },
    {
      "epoch": 15.0,
      "grad_norm": 1.6612300872802734,
      "learning_rate": 0.0014260703960592624,
      "loss": 1.4145,
      "step": 30
    },
    {
      "epoch": 15.5,
      "grad_norm": 1.645460605621338,
      "learning_rate": 0.0014736060759279045,
      "loss": 1.4067,
      "step": 31
    },
    {
      "epoch": 16.0,
      "grad_norm": 1.665906548500061,
      "learning_rate": 0.0015211417557965466,
      "loss": 1.4237,
      "step": 32
    },
    {
      "epoch": 16.5,
      "grad_norm": 1.5365957021713257,
      "learning_rate": 0.0015686774356651885,
      "loss": 1.4234,
      "step": 33
    },
    {
      "epoch": 17.0,
      "grad_norm": 1.1128711700439453,
      "learning_rate": 0.0016162131155338306,
      "loss": 1.3783,
      "step": 34
    },
    {
      "epoch": 17.5,
      "grad_norm": 1.0278737545013428,
      "learning_rate": 0.0016637487954024727,
      "loss": 1.3692,
      "step": 35
    },
    {
      "epoch": 18.0,
      "grad_norm": 1.8933203220367432,
      "learning_rate": 0.0017112844752711148,
      "loss": 1.4292,
      "step": 36
    },
    {
      "epoch": 18.5,
      "grad_norm": 1.3294668197631836,
      "learning_rate": 0.001758820155139757,
      "loss": 1.34,
      "step": 37
    },
    {
      "epoch": 19.0,
      "grad_norm": 1.4703311920166016,
      "learning_rate": 0.001806355835008399,
      "loss": 1.3585,
      "step": 38
    },
    {
      "epoch": 19.5,
      "grad_norm": 1.289582371711731,
      "learning_rate": 0.001853891514877041,
      "loss": 1.3564,
      "step": 39
    },
    {
      "epoch": 20.0,
      "grad_norm": 1.2488670349121094,
      "learning_rate": 0.0019014271947456831,
      "loss": 1.3301,
      "step": 40
    },
    {
      "epoch": 20.5,
      "grad_norm": 1.1352413892745972,
      "learning_rate": 0.001948962874614325,
      "loss": 1.3037,
      "step": 41
    },
    {
      "epoch": 21.0,
      "grad_norm": 1.3506724834442139,
      "learning_rate": 0.0019964985544829675,
      "loss": 1.3485,
      "step": 42
    },
    {
      "epoch": 21.5,
      "grad_norm": 1.3728042840957642,
      "learning_rate": 0.0020440342343516094,
      "loss": 1.279,
      "step": 43
    },
    {
      "epoch": 22.0,
      "grad_norm": 2.3750030994415283,
      "learning_rate": 0.0020915699142202517,
      "loss": 1.3757,
      "step": 44
    },
    {
      "epoch": 22.5,
      "grad_norm": 1.245784044265747,
      "learning_rate": 0.0021391055940888936,
      "loss": 1.2942,
      "step": 45
    },
    {
      "epoch": 23.0,
      "grad_norm": 1.2867447137832642,
      "learning_rate": 0.0021866412739575355,
      "loss": 1.321,
      "step": 46
    },
    {
      "epoch": 23.5,
      "grad_norm": 1.6130508184432983,
      "learning_rate": 0.002234176953826178,
      "loss": 1.287,
      "step": 47
    },
    {
      "epoch": 24.0,
      "grad_norm": 1.7011358737945557,
      "learning_rate": 0.0022817126336948197,
      "loss": 1.2761,
      "step": 48
    },
    {
      "epoch": 24.5,
      "grad_norm": 1.1713473796844482,
      "learning_rate": 0.002329248313563462,
      "loss": 1.2585,
      "step": 49
    },
    {
      "epoch": 25.0,
      "grad_norm": 2.069291114807129,
      "learning_rate": 0.002376783993432104,
      "loss": 1.3102,
      "step": 50
    },
    {
      "epoch": 25.5,
      "grad_norm": 1.3847442865371704,
      "learning_rate": 0.0024243196733007458,
      "loss": 1.2596,
      "step": 51
    },
    {
      "epoch": 26.0,
      "grad_norm": 1.6200634241104126,
      "learning_rate": 0.002471855353169388,
      "loss": 1.2445,
      "step": 52
    },
    {
      "epoch": 26.5,
      "grad_norm": 2.258726119995117,
      "learning_rate": 0.00251939103303803,
      "loss": 1.2325,
      "step": 53
    },
    {
      "epoch": 27.0,
      "grad_norm": 2.908726692199707,
      "learning_rate": 0.0025669267129066723,
      "loss": 1.2524,
      "step": 54
    },
    {
      "epoch": 27.5,
      "grad_norm": 1.3873376846313477,
      "learning_rate": 0.002614462392775314,
      "loss": 1.2321,
      "step": 55
    },
    {
      "epoch": 28.0,
      "grad_norm": 1.8487087488174438,
      "learning_rate": 0.0026619980726439564,
      "loss": 1.2386,
      "step": 56
    },
    {
      "epoch": 28.5,
      "grad_norm": 2.5098793506622314,
      "learning_rate": 0.0027095337525125988,
      "loss": 1.2542,
      "step": 57
    },
    {
      "epoch": 29.0,
      "grad_norm": 2.028815746307373,
      "learning_rate": 0.0027570694323812406,
      "loss": 1.1838,
      "step": 58
    },
    {
      "epoch": 29.5,
      "grad_norm": 1.6657078266143799,
      "learning_rate": 0.002804605112249883,
      "loss": 1.261,
      "step": 59
    },
    {
      "epoch": 30.0,
      "grad_norm": 4.941650390625,
      "learning_rate": 0.002852140792118525,
      "loss": 1.1543,
      "step": 60
    },
    {
      "epoch": 30.5,
      "grad_norm": 2.4813525676727295,
      "learning_rate": 0.0028996764719871667,
      "loss": 1.175,
      "step": 61
    },
    {
      "epoch": 31.0,
      "grad_norm": 1.7724062204360962,
      "learning_rate": 0.002947212151855809,
      "loss": 1.1836,
      "step": 62
    },
    {
      "epoch": 31.5,
      "grad_norm": 1.3353890180587769,
      "learning_rate": 0.002994747831724451,
      "loss": 1.1487,
      "step": 63
    },
    {
      "epoch": 32.0,
      "grad_norm": 3.0931644439697266,
      "learning_rate": 0.003042283511593093,
      "loss": 1.2144,
      "step": 64
    },
    {
      "epoch": 32.5,
      "grad_norm": 1.340787649154663,
      "learning_rate": 0.003089819191461735,
      "loss": 1.1718,
      "step": 65
    },
    {
      "epoch": 33.0,
      "grad_norm": 1.7918026447296143,
      "learning_rate": 0.003137354871330377,
      "loss": 1.1779,
      "step": 66
    },
    {
      "epoch": 33.5,
      "grad_norm": 1.9680461883544922,
      "learning_rate": 0.0031848905511990193,
      "loss": 1.1536,
      "step": 67
    },
    {
      "epoch": 34.0,
      "grad_norm": 2.3809165954589844,
      "learning_rate": 0.003232426231067661,
      "loss": 1.186,
      "step": 68
    },
    {
      "epoch": 34.5,
      "grad_norm": 2.199751853942871,
      "learning_rate": 0.0032799619109363035,
      "loss": 1.1456,
      "step": 69
    },
    {
      "epoch": 35.0,
      "grad_norm": 1.7473407983779907,
      "learning_rate": 0.0033274975908049453,
      "loss": 1.1794,
      "step": 70
    },
    {
      "epoch": 35.5,
      "grad_norm": 1.5768163204193115,
      "learning_rate": 0.003375033270673587,
      "loss": 1.1413,
      "step": 71
    },
    {
      "epoch": 36.0,
      "grad_norm": 2.289511203765869,
      "learning_rate": 0.0034225689505422295,
      "loss": 1.1131,
      "step": 72
    },
    {
      "epoch": 36.5,
      "grad_norm": 1.6234149932861328,
      "learning_rate": 0.003470104630410872,
      "loss": 1.1381,
      "step": 73
    },
    {
      "epoch": 37.0,
      "grad_norm": 2.14572811126709,
      "learning_rate": 0.003517640310279514,
      "loss": 1.0391,
      "step": 74
    },
    {
      "epoch": 37.5,
      "grad_norm": 3.131047248840332,
      "learning_rate": 0.003565175990148156,
      "loss": 1.1308,
      "step": 75
    },
    {
      "epoch": 38.0,
      "grad_norm": 3.3700780868530273,
      "learning_rate": 0.003612711670016798,
      "loss": 1.0949,
      "step": 76
    },
    {
      "epoch": 38.5,
      "grad_norm": 1.5148652791976929,
      "learning_rate": 0.0036602473498854402,
      "loss": 1.115,
      "step": 77
    },
    {
      "epoch": 39.0,
      "grad_norm": 4.782919883728027,
      "learning_rate": 0.003707783029754082,
      "loss": 1.098,
      "step": 78
    },
    {
      "epoch": 39.5,
      "grad_norm": 4.102523326873779,
      "learning_rate": 0.0037553187096227244,
      "loss": 1.1133,
      "step": 79
    },
    {
      "epoch": 40.0,
      "grad_norm": 2.5068910121917725,
      "learning_rate": 0.0038028543894913663,
      "loss": 1.079,
      "step": 80
    },
    {
      "epoch": 40.0,
      "eval_brier_0th_event": 0.18313606083393097,
      "eval_brier_0th_event_n": 247,
      "eval_brier_weighted_avg": 0.18313606083393097,
      "eval_ipcw_0th_event": 0.6176944266299944,
      "eval_ipcw_0th_event_0.25": 0.6052235960960388,
      "eval_ipcw_0th_event_0.50": 0.613961398601532,
      "eval_ipcw_0th_event_0.75": 0.6214224100112915,
      "eval_ipcw_0th_event_1.00": 0.6193963885307312,
      "eval_ipcw_0th_event_n": 473,
      "eval_ipcw_weighted_avg": 0.6176944266299945,
      "eval_loss": 0.6448389291763306,
      "eval_runtime": 0.144,
      "eval_samples_per_second": 3285.319,
      "eval_steps_per_second": 6.946,
      "step": 80
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 16348262400.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
