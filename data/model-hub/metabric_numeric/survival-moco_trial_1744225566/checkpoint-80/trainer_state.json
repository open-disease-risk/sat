{
  "best_global_step": 80,
  "best_metric": 0.6107770198515896,
  "best_model_checkpoint": "./data/model-hub/metabric_numeric/survival-moco_trial_1744225566/checkpoint-80",
  "epoch": 40.0,
  "eval_steps": 1,
  "global_step": 80,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 1.0485261678695679,
      "learning_rate": 1.528336989420565e-06,
      "loss": 1.5979,
      "step": 1
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.1892942190170288,
      "learning_rate": 3.05667397884113e-06,
      "loss": 1.6239,
      "step": 2
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.3267133235931396,
      "learning_rate": 4.585010968261695e-06,
      "loss": 1.6111,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.9273824691772461,
      "learning_rate": 6.11334795768226e-06,
      "loss": 1.6067,
      "step": 4
    },
    {
      "epoch": 2.5,
      "grad_norm": 1.103596568107605,
      "learning_rate": 7.641684947102825e-06,
      "loss": 1.6224,
      "step": 5
    },
    {
      "epoch": 3.0,
      "grad_norm": 1.1585396528244019,
      "learning_rate": 9.17002193652339e-06,
      "loss": 1.6098,
      "step": 6
    },
    {
      "epoch": 3.5,
      "grad_norm": 1.1112394332885742,
      "learning_rate": 1.0698358925943955e-05,
      "loss": 1.6158,
      "step": 7
    },
    {
      "epoch": 4.0,
      "grad_norm": 1.161146640777588,
      "learning_rate": 1.222669591536452e-05,
      "loss": 1.6178,
      "step": 8
    },
    {
      "epoch": 4.5,
      "grad_norm": 1.1955206394195557,
      "learning_rate": 1.3755032904785086e-05,
      "loss": 1.6257,
      "step": 9
    },
    {
      "epoch": 5.0,
      "grad_norm": 1.0577960014343262,
      "learning_rate": 1.528336989420565e-05,
      "loss": 1.5855,
      "step": 10
    },
    {
      "epoch": 5.5,
      "grad_norm": 1.0174657106399536,
      "learning_rate": 1.6811706883626217e-05,
      "loss": 1.5918,
      "step": 11
    },
    {
      "epoch": 6.0,
      "grad_norm": 1.1776821613311768,
      "learning_rate": 1.834004387304678e-05,
      "loss": 1.6361,
      "step": 12
    },
    {
      "epoch": 6.5,
      "grad_norm": 1.1883454322814941,
      "learning_rate": 1.9868380862467348e-05,
      "loss": 1.6038,
      "step": 13
    },
    {
      "epoch": 7.0,
      "grad_norm": 1.0157021284103394,
      "learning_rate": 2.139671785188791e-05,
      "loss": 1.6182,
      "step": 14
    },
    {
      "epoch": 7.5,
      "grad_norm": 1.1129167079925537,
      "learning_rate": 2.2925054841308478e-05,
      "loss": 1.617,
      "step": 15
    },
    {
      "epoch": 8.0,
      "grad_norm": 1.121875286102295,
      "learning_rate": 2.445339183072904e-05,
      "loss": 1.6103,
      "step": 16
    },
    {
      "epoch": 8.5,
      "grad_norm": 1.0090640783309937,
      "learning_rate": 2.5981728820149604e-05,
      "loss": 1.6424,
      "step": 17
    },
    {
      "epoch": 9.0,
      "grad_norm": 1.2823779582977295,
      "learning_rate": 2.751006580957017e-05,
      "loss": 1.5655,
      "step": 18
    },
    {
      "epoch": 9.5,
      "grad_norm": 1.1157382726669312,
      "learning_rate": 2.9038402798990734e-05,
      "loss": 1.6023,
      "step": 19
    },
    {
      "epoch": 10.0,
      "grad_norm": 1.157913327217102,
      "learning_rate": 3.05667397884113e-05,
      "loss": 1.6109,
      "step": 20
    },
    {
      "epoch": 10.5,
      "grad_norm": 0.9739911556243896,
      "learning_rate": 3.2095076777831865e-05,
      "loss": 1.6074,
      "step": 21
    },
    {
      "epoch": 11.0,
      "grad_norm": 1.3432778120040894,
      "learning_rate": 3.3623413767252435e-05,
      "loss": 1.6029,
      "step": 22
    },
    {
      "epoch": 11.5,
      "grad_norm": 1.1489171981811523,
      "learning_rate": 3.515175075667299e-05,
      "loss": 1.6183,
      "step": 23
    },
    {
      "epoch": 12.0,
      "grad_norm": 1.017773151397705,
      "learning_rate": 3.668008774609356e-05,
      "loss": 1.6097,
      "step": 24
    },
    {
      "epoch": 12.5,
      "grad_norm": 1.0679452419281006,
      "learning_rate": 3.8208424735514125e-05,
      "loss": 1.6055,
      "step": 25
    },
    {
      "epoch": 13.0,
      "grad_norm": 1.1554850339889526,
      "learning_rate": 3.9736761724934695e-05,
      "loss": 1.6014,
      "step": 26
    },
    {
      "epoch": 13.5,
      "grad_norm": 1.1275739669799805,
      "learning_rate": 4.126509871435526e-05,
      "loss": 1.608,
      "step": 27
    },
    {
      "epoch": 14.0,
      "grad_norm": 1.0972325801849365,
      "learning_rate": 4.279343570377582e-05,
      "loss": 1.5971,
      "step": 28
    },
    {
      "epoch": 14.5,
      "grad_norm": 1.1175541877746582,
      "learning_rate": 4.4321772693196385e-05,
      "loss": 1.6109,
      "step": 29
    },
    {
      "epoch": 15.0,
      "grad_norm": 1.1306495666503906,
      "learning_rate": 4.5850109682616955e-05,
      "loss": 1.5966,
      "step": 30
    },
    {
      "epoch": 15.5,
      "grad_norm": 1.2203131914138794,
      "learning_rate": 4.737844667203752e-05,
      "loss": 1.6123,
      "step": 31
    },
    {
      "epoch": 16.0,
      "grad_norm": 0.9745943546295166,
      "learning_rate": 4.890678366145808e-05,
      "loss": 1.5957,
      "step": 32
    },
    {
      "epoch": 16.5,
      "grad_norm": 1.0872526168823242,
      "learning_rate": 5.0435120650878645e-05,
      "loss": 1.6405,
      "step": 33
    },
    {
      "epoch": 17.0,
      "grad_norm": 1.1299898624420166,
      "learning_rate": 5.196345764029921e-05,
      "loss": 1.551,
      "step": 34
    },
    {
      "epoch": 17.5,
      "grad_norm": 1.1208078861236572,
      "learning_rate": 5.349179462971978e-05,
      "loss": 1.6079,
      "step": 35
    },
    {
      "epoch": 18.0,
      "grad_norm": 1.159103274345398,
      "learning_rate": 5.502013161914034e-05,
      "loss": 1.5931,
      "step": 36
    },
    {
      "epoch": 18.5,
      "grad_norm": 1.0217304229736328,
      "learning_rate": 5.654846860856091e-05,
      "loss": 1.5996,
      "step": 37
    },
    {
      "epoch": 19.0,
      "grad_norm": 1.372201681137085,
      "learning_rate": 5.807680559798147e-05,
      "loss": 1.5931,
      "step": 38
    },
    {
      "epoch": 19.5,
      "grad_norm": 1.0652309656143188,
      "learning_rate": 5.960514258740204e-05,
      "loss": 1.6122,
      "step": 39
    },
    {
      "epoch": 20.0,
      "grad_norm": 1.3609529733657837,
      "learning_rate": 6.11334795768226e-05,
      "loss": 1.5724,
      "step": 40
    },
    {
      "epoch": 20.5,
      "grad_norm": 1.3157835006713867,
      "learning_rate": 6.266181656624316e-05,
      "loss": 1.6081,
      "step": 41
    },
    {
      "epoch": 21.0,
      "grad_norm": 1.01668381690979,
      "learning_rate": 6.419015355566373e-05,
      "loss": 1.5689,
      "step": 42
    },
    {
      "epoch": 21.5,
      "grad_norm": 1.1893106698989868,
      "learning_rate": 6.57184905450843e-05,
      "loss": 1.5976,
      "step": 43
    },
    {
      "epoch": 22.0,
      "grad_norm": 1.1632200479507446,
      "learning_rate": 6.724682753450487e-05,
      "loss": 1.6068,
      "step": 44
    },
    {
      "epoch": 22.5,
      "grad_norm": 1.1932003498077393,
      "learning_rate": 6.877516452392543e-05,
      "loss": 1.5685,
      "step": 45
    },
    {
      "epoch": 23.0,
      "grad_norm": 1.231274962425232,
      "learning_rate": 7.030350151334598e-05,
      "loss": 1.6356,
      "step": 46
    },
    {
      "epoch": 23.5,
      "grad_norm": 1.3566558361053467,
      "learning_rate": 7.183183850276657e-05,
      "loss": 1.5874,
      "step": 47
    },
    {
      "epoch": 24.0,
      "grad_norm": 1.1630511283874512,
      "learning_rate": 7.336017549218712e-05,
      "loss": 1.6181,
      "step": 48
    },
    {
      "epoch": 24.5,
      "grad_norm": 1.3020659685134888,
      "learning_rate": 7.488851248160769e-05,
      "loss": 1.5681,
      "step": 49
    },
    {
      "epoch": 25.0,
      "grad_norm": 1.258052110671997,
      "learning_rate": 7.641684947102825e-05,
      "loss": 1.6234,
      "step": 50
    },
    {
      "epoch": 25.5,
      "grad_norm": 1.357408046722412,
      "learning_rate": 7.79451864604488e-05,
      "loss": 1.5802,
      "step": 51
    },
    {
      "epoch": 26.0,
      "grad_norm": 1.2650306224822998,
      "learning_rate": 7.947352344986939e-05,
      "loss": 1.6063,
      "step": 52
    },
    {
      "epoch": 26.5,
      "grad_norm": 1.3222217559814453,
      "learning_rate": 8.100186043928995e-05,
      "loss": 1.5528,
      "step": 53
    },
    {
      "epoch": 27.0,
      "grad_norm": 1.436095952987671,
      "learning_rate": 8.253019742871052e-05,
      "loss": 1.6424,
      "step": 54
    },
    {
      "epoch": 27.5,
      "grad_norm": 1.3067041635513306,
      "learning_rate": 8.405853441813107e-05,
      "loss": 1.5992,
      "step": 55
    },
    {
      "epoch": 28.0,
      "grad_norm": 1.500410795211792,
      "learning_rate": 8.558687140755164e-05,
      "loss": 1.5766,
      "step": 56
    },
    {
      "epoch": 28.5,
      "grad_norm": 1.4739453792572021,
      "learning_rate": 8.711520839697221e-05,
      "loss": 1.5994,
      "step": 57
    },
    {
      "epoch": 29.0,
      "grad_norm": 1.3522552251815796,
      "learning_rate": 8.864354538639277e-05,
      "loss": 1.5737,
      "step": 58
    },
    {
      "epoch": 29.5,
      "grad_norm": 1.433093547821045,
      "learning_rate": 9.017188237581334e-05,
      "loss": 1.5831,
      "step": 59
    },
    {
      "epoch": 30.0,
      "grad_norm": 1.5095421075820923,
      "learning_rate": 9.170021936523391e-05,
      "loss": 1.5981,
      "step": 60
    },
    {
      "epoch": 30.5,
      "grad_norm": 1.4935563802719116,
      "learning_rate": 9.322855635465447e-05,
      "loss": 1.6056,
      "step": 61
    },
    {
      "epoch": 31.0,
      "grad_norm": 1.4913945198059082,
      "learning_rate": 9.475689334407504e-05,
      "loss": 1.555,
      "step": 62
    },
    {
      "epoch": 31.5,
      "grad_norm": 1.4737454652786255,
      "learning_rate": 9.62852303334956e-05,
      "loss": 1.5735,
      "step": 63
    },
    {
      "epoch": 32.0,
      "grad_norm": 1.5739624500274658,
      "learning_rate": 9.781356732291616e-05,
      "loss": 1.5821,
      "step": 64
    },
    {
      "epoch": 32.5,
      "grad_norm": 1.5510730743408203,
      "learning_rate": 9.934190431233673e-05,
      "loss": 1.5957,
      "step": 65
    },
    {
      "epoch": 33.0,
      "grad_norm": 1.498300552368164,
      "learning_rate": 0.00010087024130175729,
      "loss": 1.5613,
      "step": 66
    },
    {
      "epoch": 33.5,
      "grad_norm": 1.5620777606964111,
      "learning_rate": 0.00010239857829117786,
      "loss": 1.5909,
      "step": 67
    },
    {
      "epoch": 34.0,
      "grad_norm": 1.6300008296966553,
      "learning_rate": 0.00010392691528059842,
      "loss": 1.5515,
      "step": 68
    },
    {
      "epoch": 34.5,
      "grad_norm": 1.8486300706863403,
      "learning_rate": 0.000105455252270019,
      "loss": 1.6113,
      "step": 69
    },
    {
      "epoch": 35.0,
      "grad_norm": 1.4098353385925293,
      "learning_rate": 0.00010698358925943956,
      "loss": 1.5325,
      "step": 70
    },
    {
      "epoch": 35.5,
      "grad_norm": 1.7296841144561768,
      "learning_rate": 0.00010851192624886011,
      "loss": 1.5771,
      "step": 71
    },
    {
      "epoch": 36.0,
      "grad_norm": 1.604677438735962,
      "learning_rate": 0.00011004026323828068,
      "loss": 1.5818,
      "step": 72
    },
    {
      "epoch": 36.5,
      "grad_norm": 1.5206693410873413,
      "learning_rate": 0.00011156860022770124,
      "loss": 1.5526,
      "step": 73
    },
    {
      "epoch": 37.0,
      "grad_norm": 1.797226905822754,
      "learning_rate": 0.00011309693721712182,
      "loss": 1.6012,
      "step": 74
    },
    {
      "epoch": 37.5,
      "grad_norm": 1.6879392862319946,
      "learning_rate": 0.00011462527420654238,
      "loss": 1.596,
      "step": 75
    },
    {
      "epoch": 38.0,
      "grad_norm": 1.5470912456512451,
      "learning_rate": 0.00011615361119596294,
      "loss": 1.5428,
      "step": 76
    },
    {
      "epoch": 38.5,
      "grad_norm": 1.6335129737854004,
      "learning_rate": 0.00011768194818538351,
      "loss": 1.5586,
      "step": 77
    },
    {
      "epoch": 39.0,
      "grad_norm": 1.6067166328430176,
      "learning_rate": 0.00011921028517480408,
      "loss": 1.5892,
      "step": 78
    },
    {
      "epoch": 39.5,
      "grad_norm": 1.5668069124221802,
      "learning_rate": 0.00012073862216422465,
      "loss": 1.5654,
      "step": 79
    },
    {
      "epoch": 40.0,
      "grad_norm": 1.6819685697555542,
      "learning_rate": 0.0001222669591536452,
      "loss": 1.5546,
      "step": 80
    },
    {
      "epoch": 40.0,
      "eval_brier_0th_event": 0.21456450816643052,
      "eval_brier_0th_event_n": 259,
      "eval_brier_avg": 0.21456450816643052,
      "eval_brier_weighted_avg": 0.21456450816643052,
      "eval_ipcw": 0.6264489495258694,
      "eval_ipcw_0th_event": 0.6264489495258694,
      "eval_ipcw_0th_event_0.25": 0.6046203311351824,
      "eval_ipcw_0th_event_0.5": 0.6060464979194291,
      "eval_ipcw_0th_event_0.75": 0.6059923008258777,
      "eval_ipcw_0th_event_1.0": 0.6264489495258694,
      "eval_ipcw_0th_event_n": 259,
      "eval_ipcw_avg": 0.6107770198515896,
      "eval_ipcw_avg_0th_event": 0.6107770198515896,
      "eval_ipcw_weighted_avg": 0.6107770198515896,
      "eval_loss": 0.7761373519897461,
      "eval_runtime": 0.0752,
      "eval_samples_per_second": 5906.777,
      "eval_steps_per_second": 13.304,
      "step": 80
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 21780864000.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
