{
  "best_global_step": 81,
  "best_metric": 0.6710656322742432,
  "best_model_checkpoint": "./data/model-hub/metabric_numeric/survival_trial_1744209205/checkpoint-81",
  "epoch": 40.5,
  "eval_steps": 1,
  "global_step": 81,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 3.2090344429016113,
      "learning_rate": 2.7400344267062478e-05,
      "loss": 1.6253,
      "step": 1
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.829589366912842,
      "learning_rate": 5.4800688534124956e-05,
      "loss": 1.6239,
      "step": 2
    },
    {
      "epoch": 1.5,
      "grad_norm": 2.1050963401794434,
      "learning_rate": 8.220103280118742e-05,
      "loss": 1.6438,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 4.345261573791504,
      "learning_rate": 0.00010960137706824991,
      "loss": 1.5795,
      "step": 4
    },
    {
      "epoch": 2.5,
      "grad_norm": 2.4663307666778564,
      "learning_rate": 0.00013700172133531238,
      "loss": 1.6139,
      "step": 5
    },
    {
      "epoch": 3.0,
      "grad_norm": 3.07224178314209,
      "learning_rate": 0.00016440206560237484,
      "loss": 1.6024,
      "step": 6
    },
    {
      "epoch": 3.5,
      "grad_norm": 3.2595157623291016,
      "learning_rate": 0.0001918024098694373,
      "loss": 1.6463,
      "step": 7
    },
    {
      "epoch": 4.0,
      "grad_norm": 3.2343146800994873,
      "learning_rate": 0.00021920275413649982,
      "loss": 1.5749,
      "step": 8
    },
    {
      "epoch": 4.5,
      "grad_norm": 2.763347625732422,
      "learning_rate": 0.0002466030984035623,
      "loss": 1.5735,
      "step": 9
    },
    {
      "epoch": 5.0,
      "grad_norm": 2.718600034713745,
      "learning_rate": 0.00027400344267062475,
      "loss": 1.6306,
      "step": 10
    },
    {
      "epoch": 5.5,
      "grad_norm": 2.6339709758758545,
      "learning_rate": 0.00030140378693768727,
      "loss": 1.541,
      "step": 11
    },
    {
      "epoch": 6.0,
      "grad_norm": 3.721281051635742,
      "learning_rate": 0.0003288041312047497,
      "loss": 1.6572,
      "step": 12
    },
    {
      "epoch": 6.5,
      "grad_norm": 3.79398512840271,
      "learning_rate": 0.0003562044754718122,
      "loss": 1.5927,
      "step": 13
    },
    {
      "epoch": 7.0,
      "grad_norm": 2.7723426818847656,
      "learning_rate": 0.0003836048197388746,
      "loss": 1.5843,
      "step": 14
    },
    {
      "epoch": 7.5,
      "grad_norm": 3.845756769180298,
      "learning_rate": 0.0004110051640059371,
      "loss": 1.5731,
      "step": 15
    },
    {
      "epoch": 8.0,
      "grad_norm": 4.486572742462158,
      "learning_rate": 0.00043840550827299964,
      "loss": 1.5789,
      "step": 16
    },
    {
      "epoch": 8.5,
      "grad_norm": 4.339843273162842,
      "learning_rate": 0.00046580585254006205,
      "loss": 1.5896,
      "step": 17
    },
    {
      "epoch": 9.0,
      "grad_norm": 4.140142917633057,
      "learning_rate": 0.0004932061968071246,
      "loss": 1.5232,
      "step": 18
    },
    {
      "epoch": 9.5,
      "grad_norm": 2.6434266567230225,
      "learning_rate": 0.000520606541074187,
      "loss": 1.5316,
      "step": 19
    },
    {
      "epoch": 10.0,
      "grad_norm": 3.0102529525756836,
      "learning_rate": 0.0005480068853412495,
      "loss": 1.5736,
      "step": 20
    },
    {
      "epoch": 10.5,
      "grad_norm": 4.4974446296691895,
      "learning_rate": 0.000575407229608312,
      "loss": 1.559,
      "step": 21
    },
    {
      "epoch": 11.0,
      "grad_norm": 2.733262538909912,
      "learning_rate": 0.0006028075738753745,
      "loss": 1.4932,
      "step": 22
    },
    {
      "epoch": 11.5,
      "grad_norm": 4.1135382652282715,
      "learning_rate": 0.0006302079181424369,
      "loss": 1.5028,
      "step": 23
    },
    {
      "epoch": 12.0,
      "grad_norm": 5.5145263671875,
      "learning_rate": 0.0006576082624094994,
      "loss": 1.5692,
      "step": 24
    },
    {
      "epoch": 12.5,
      "grad_norm": 2.9226486682891846,
      "learning_rate": 0.0006850086066765618,
      "loss": 1.5079,
      "step": 25
    },
    {
      "epoch": 13.0,
      "grad_norm": 2.433117628097534,
      "learning_rate": 0.0007124089509436244,
      "loss": 1.484,
      "step": 26
    },
    {
      "epoch": 13.5,
      "grad_norm": 4.574131011962891,
      "learning_rate": 0.0007398092952106869,
      "loss": 1.4473,
      "step": 27
    },
    {
      "epoch": 14.0,
      "grad_norm": 2.809032440185547,
      "learning_rate": 0.0007672096394777492,
      "loss": 1.5353,
      "step": 28
    },
    {
      "epoch": 14.5,
      "grad_norm": 3.666982650756836,
      "learning_rate": 0.0007946099837448118,
      "loss": 1.4931,
      "step": 29
    },
    {
      "epoch": 15.0,
      "grad_norm": 4.031002998352051,
      "learning_rate": 0.0008220103280118743,
      "loss": 1.4782,
      "step": 30
    },
    {
      "epoch": 15.5,
      "grad_norm": 2.21730375289917,
      "learning_rate": 0.0008494106722789367,
      "loss": 1.4742,
      "step": 31
    },
    {
      "epoch": 16.0,
      "grad_norm": 4.592918872833252,
      "learning_rate": 0.0008768110165459993,
      "loss": 1.4301,
      "step": 32
    },
    {
      "epoch": 16.5,
      "grad_norm": 3.905937910079956,
      "learning_rate": 0.0009042113608130616,
      "loss": 1.4569,
      "step": 33
    },
    {
      "epoch": 17.0,
      "grad_norm": 4.966923236846924,
      "learning_rate": 0.0009316117050801241,
      "loss": 1.3949,
      "step": 34
    },
    {
      "epoch": 17.5,
      "grad_norm": 2.947664737701416,
      "learning_rate": 0.0009590120493471867,
      "loss": 1.4332,
      "step": 35
    },
    {
      "epoch": 18.0,
      "grad_norm": 2.19773530960083,
      "learning_rate": 0.0009864123936142491,
      "loss": 1.4032,
      "step": 36
    },
    {
      "epoch": 18.5,
      "grad_norm": 4.517676830291748,
      "learning_rate": 0.0010138127378813116,
      "loss": 1.4129,
      "step": 37
    },
    {
      "epoch": 19.0,
      "grad_norm": 5.247594356536865,
      "learning_rate": 0.001041213082148374,
      "loss": 1.3564,
      "step": 38
    },
    {
      "epoch": 19.5,
      "grad_norm": 5.431729316711426,
      "learning_rate": 0.0010686134264154365,
      "loss": 1.3625,
      "step": 39
    },
    {
      "epoch": 20.0,
      "grad_norm": 3.7888104915618896,
      "learning_rate": 0.001096013770682499,
      "loss": 1.3951,
      "step": 40
    },
    {
      "epoch": 20.5,
      "grad_norm": 3.2151827812194824,
      "learning_rate": 0.0011234141149495615,
      "loss": 1.3924,
      "step": 41
    },
    {
      "epoch": 21.0,
      "grad_norm": 1.9028981924057007,
      "learning_rate": 0.001150814459216624,
      "loss": 1.3525,
      "step": 42
    },
    {
      "epoch": 21.5,
      "grad_norm": 2.0686087608337402,
      "learning_rate": 0.0011782148034836864,
      "loss": 1.3684,
      "step": 43
    },
    {
      "epoch": 22.0,
      "grad_norm": 2.43853759765625,
      "learning_rate": 0.001205615147750749,
      "loss": 1.319,
      "step": 44
    },
    {
      "epoch": 22.5,
      "grad_norm": 4.7009429931640625,
      "learning_rate": 0.0012330154920178113,
      "loss": 1.3366,
      "step": 45
    },
    {
      "epoch": 23.0,
      "grad_norm": 5.290717601776123,
      "learning_rate": 0.0012604158362848738,
      "loss": 1.2996,
      "step": 46
    },
    {
      "epoch": 23.5,
      "grad_norm": 3.069822311401367,
      "learning_rate": 0.0012878161805519365,
      "loss": 1.3135,
      "step": 47
    },
    {
      "epoch": 24.0,
      "grad_norm": 1.8726752996444702,
      "learning_rate": 0.0013152165248189987,
      "loss": 1.3564,
      "step": 48
    },
    {
      "epoch": 24.5,
      "grad_norm": 5.890331745147705,
      "learning_rate": 0.0013426168690860614,
      "loss": 1.3475,
      "step": 49
    },
    {
      "epoch": 25.0,
      "grad_norm": 7.712951183319092,
      "learning_rate": 0.0013700172133531236,
      "loss": 1.2979,
      "step": 50
    },
    {
      "epoch": 25.5,
      "grad_norm": 2.7896432876586914,
      "learning_rate": 0.0013974175576201861,
      "loss": 1.29,
      "step": 51
    },
    {
      "epoch": 26.0,
      "grad_norm": 4.632702827453613,
      "learning_rate": 0.0014248179018872488,
      "loss": 1.3858,
      "step": 52
    },
    {
      "epoch": 26.5,
      "grad_norm": 8.924514770507812,
      "learning_rate": 0.001452218246154311,
      "loss": 1.3238,
      "step": 53
    },
    {
      "epoch": 27.0,
      "grad_norm": 8.087801933288574,
      "learning_rate": 0.0014796185904213737,
      "loss": 1.3309,
      "step": 54
    },
    {
      "epoch": 27.5,
      "grad_norm": 2.0709683895111084,
      "learning_rate": 0.0015070189346884362,
      "loss": 1.3459,
      "step": 55
    },
    {
      "epoch": 28.0,
      "grad_norm": 5.752676486968994,
      "learning_rate": 0.0015344192789554984,
      "loss": 1.3146,
      "step": 56
    },
    {
      "epoch": 28.5,
      "grad_norm": 4.728043556213379,
      "learning_rate": 0.0015618196232225611,
      "loss": 1.3208,
      "step": 57
    },
    {
      "epoch": 29.0,
      "grad_norm": 3.3260915279388428,
      "learning_rate": 0.0015892199674896236,
      "loss": 1.3404,
      "step": 58
    },
    {
      "epoch": 29.5,
      "grad_norm": 2.4131832122802734,
      "learning_rate": 0.001616620311756686,
      "loss": 1.348,
      "step": 59
    },
    {
      "epoch": 30.0,
      "grad_norm": 15.692911148071289,
      "learning_rate": 0.0016440206560237485,
      "loss": 1.2708,
      "step": 60
    },
    {
      "epoch": 30.5,
      "grad_norm": 8.817634582519531,
      "learning_rate": 0.001671421000290811,
      "loss": 1.3221,
      "step": 61
    },
    {
      "epoch": 31.0,
      "grad_norm": 3.7990007400512695,
      "learning_rate": 0.0016988213445578734,
      "loss": 1.2918,
      "step": 62
    },
    {
      "epoch": 31.5,
      "grad_norm": 3.6429202556610107,
      "learning_rate": 0.001726221688824936,
      "loss": 1.28,
      "step": 63
    },
    {
      "epoch": 32.0,
      "grad_norm": 5.045257568359375,
      "learning_rate": 0.0017536220330919986,
      "loss": 1.3604,
      "step": 64
    },
    {
      "epoch": 32.5,
      "grad_norm": 3.5132038593292236,
      "learning_rate": 0.0017810223773590608,
      "loss": 1.3238,
      "step": 65
    },
    {
      "epoch": 33.0,
      "grad_norm": 3.4566574096679688,
      "learning_rate": 0.0018084227216261233,
      "loss": 1.278,
      "step": 66
    },
    {
      "epoch": 33.5,
      "grad_norm": 4.817307472229004,
      "learning_rate": 0.001835823065893186,
      "loss": 1.3184,
      "step": 67
    },
    {
      "epoch": 34.0,
      "grad_norm": 4.1303510665893555,
      "learning_rate": 0.0018632234101602482,
      "loss": 1.3163,
      "step": 68
    },
    {
      "epoch": 34.5,
      "grad_norm": 1.9661219120025635,
      "learning_rate": 0.001890623754427311,
      "loss": 1.3081,
      "step": 69
    },
    {
      "epoch": 35.0,
      "grad_norm": 3.562415599822998,
      "learning_rate": 0.0019180240986943734,
      "loss": 1.3056,
      "step": 70
    },
    {
      "epoch": 35.5,
      "grad_norm": 4.599595546722412,
      "learning_rate": 0.0019454244429614356,
      "loss": 1.3353,
      "step": 71
    },
    {
      "epoch": 36.0,
      "grad_norm": 8.510905265808105,
      "learning_rate": 0.0019728247872284983,
      "loss": 1.3322,
      "step": 72
    },
    {
      "epoch": 36.5,
      "grad_norm": 6.090778350830078,
      "learning_rate": 0.0020002251314955605,
      "loss": 1.3168,
      "step": 73
    },
    {
      "epoch": 37.0,
      "grad_norm": 3.657780408859253,
      "learning_rate": 0.0020276254757626232,
      "loss": 1.3327,
      "step": 74
    },
    {
      "epoch": 37.5,
      "grad_norm": 1.3423500061035156,
      "learning_rate": 0.0020550258200296855,
      "loss": 1.2899,
      "step": 75
    },
    {
      "epoch": 38.0,
      "grad_norm": 3.0502007007598877,
      "learning_rate": 0.002082426164296748,
      "loss": 1.3528,
      "step": 76
    },
    {
      "epoch": 38.5,
      "grad_norm": 3.523768186569214,
      "learning_rate": 0.002109826508563811,
      "loss": 1.2832,
      "step": 77
    },
    {
      "epoch": 39.0,
      "grad_norm": 2.768775224685669,
      "learning_rate": 0.002137226852830873,
      "loss": 1.345,
      "step": 78
    },
    {
      "epoch": 39.5,
      "grad_norm": 2.418680429458618,
      "learning_rate": 0.0021646271970979358,
      "loss": 1.2827,
      "step": 79
    },
    {
      "epoch": 40.0,
      "grad_norm": 7.01891565322876,
      "learning_rate": 0.002192027541364998,
      "loss": 1.3245,
      "step": 80
    },
    {
      "epoch": 40.0,
      "eval_brier_0th_event": 0.18511343532674396,
      "eval_brier_0th_event_n": 260,
      "eval_brier_avg": 0.18511343532674396,
      "eval_brier_weighted_avg": 0.18511343532674396,
      "eval_ipcw": 0.6366155113886071,
      "eval_ipcw_0th_event": 0.6366155113886071,
      "eval_ipcw_0th_event_0.25": 0.7110462343210909,
      "eval_ipcw_0th_event_0.5": 0.6888357399712617,
      "eval_ipcw_0th_event_0.75": 0.6477215670658456,
      "eval_ipcw_0th_event_1.0": 0.6366155113886071,
      "eval_ipcw_0th_event_n": 260,
      "eval_ipcw_avg": 0.6710547631867013,
      "eval_ipcw_avg_0th_event": 0.6710547631867013,
      "eval_ipcw_weighted_avg": 0.6710547631867013,
      "eval_loss": 0.6684551239013672,
      "eval_runtime": 0.0868,
      "eval_samples_per_second": 5116.621,
      "eval_steps_per_second": 11.524,
      "step": 80
    },
    {
      "epoch": 40.5,
      "grad_norm": 2.376185178756714,
      "learning_rate": 0.00219202115123514,
      "loss": 1.2876,
      "step": 81
    },
    {
      "epoch": 40.5,
      "eval_brier_0th_event": 0.18516016543490524,
      "eval_brier_0th_event_n": 260,
      "eval_brier_avg": 0.18516016543490524,
      "eval_brier_weighted_avg": 0.18516016543490524,
      "eval_ipcw": 0.6349245557846267,
      "eval_ipcw_0th_event": 0.6349245557846267,
      "eval_ipcw_0th_event_0.25": 0.7119018528255519,
      "eval_ipcw_0th_event_0.5": 0.6895351745355781,
      "eval_ipcw_0th_event_0.75": 0.6479009459512165,
      "eval_ipcw_0th_event_1.0": 0.6349245557846267,
      "eval_ipcw_0th_event_n": 260,
      "eval_ipcw_avg": 0.6710656322742432,
      "eval_ipcw_avg_0th_event": 0.6710656322742432,
      "eval_ipcw_weighted_avg": 0.6710656322742432,
      "eval_loss": 0.6702517867088318,
      "eval_runtime": 0.0877,
      "eval_samples_per_second": 5061.606,
      "eval_steps_per_second": 11.4,
      "step": 81
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 10558817280.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
