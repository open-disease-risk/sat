{
  "best_global_step": 80,
  "best_metric": 0.43541210413346804,
  "best_model_checkpoint": "./data/model-hub/metabric_numeric/deephit_trial_1744636411/checkpoint-80",
  "epoch": 40.0,
  "eval_steps": 1,
  "global_step": 80,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 11.35240364074707,
      "learning_rate": 2.3827205786167025e-05,
      "loss": 6.0509,
      "step": 1
    },
    {
      "epoch": 1.0,
      "grad_norm": 7.308752536773682,
      "learning_rate": 4.765441157233405e-05,
      "loss": 5.8803,
      "step": 2
    },
    {
      "epoch": 1.5,
      "grad_norm": 10.885115623474121,
      "learning_rate": 7.148161735850106e-05,
      "loss": 5.4533,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 12.345958709716797,
      "learning_rate": 9.53088231446681e-05,
      "loss": 5.2442,
      "step": 4
    },
    {
      "epoch": 2.5,
      "grad_norm": 4.4108686447143555,
      "learning_rate": 0.00011913602893083511,
      "loss": 4.956,
      "step": 5
    },
    {
      "epoch": 3.0,
      "grad_norm": 30.504657745361328,
      "learning_rate": 0.00014296323471700212,
      "loss": 5.3904,
      "step": 6
    },
    {
      "epoch": 3.5,
      "grad_norm": 15.284762382507324,
      "learning_rate": 0.00016679044050316915,
      "loss": 4.9832,
      "step": 7
    },
    {
      "epoch": 4.0,
      "grad_norm": 10.92960262298584,
      "learning_rate": 0.0001906176462893362,
      "loss": 5.1561,
      "step": 8
    },
    {
      "epoch": 4.5,
      "grad_norm": 9.304499626159668,
      "learning_rate": 0.0002144448520755032,
      "loss": 5.1049,
      "step": 9
    },
    {
      "epoch": 5.0,
      "grad_norm": 11.661426544189453,
      "learning_rate": 0.00023827205786167022,
      "loss": 5.1976,
      "step": 10
    },
    {
      "epoch": 5.5,
      "grad_norm": 11.156298637390137,
      "learning_rate": 0.00026209926364783724,
      "loss": 5.2447,
      "step": 11
    },
    {
      "epoch": 6.0,
      "grad_norm": 11.025086402893066,
      "learning_rate": 0.00028592646943400424,
      "loss": 5.4205,
      "step": 12
    },
    {
      "epoch": 6.5,
      "grad_norm": 5.687312126159668,
      "learning_rate": 0.0003097536752201713,
      "loss": 5.53,
      "step": 13
    },
    {
      "epoch": 7.0,
      "grad_norm": 9.537522315979004,
      "learning_rate": 0.0003335808810063383,
      "loss": 5.3673,
      "step": 14
    },
    {
      "epoch": 7.5,
      "grad_norm": 9.029671669006348,
      "learning_rate": 0.00035740808679250534,
      "loss": 5.5502,
      "step": 15
    },
    {
      "epoch": 8.0,
      "grad_norm": 7.438071250915527,
      "learning_rate": 0.0003812352925786724,
      "loss": 5.6992,
      "step": 16
    },
    {
      "epoch": 8.5,
      "grad_norm": 4.607845306396484,
      "learning_rate": 0.00040506249836483934,
      "loss": 5.6201,
      "step": 17
    },
    {
      "epoch": 9.0,
      "grad_norm": 8.06027603149414,
      "learning_rate": 0.0004288897041510064,
      "loss": 5.9229,
      "step": 18
    },
    {
      "epoch": 9.5,
      "grad_norm": 8.460323333740234,
      "learning_rate": 0.0004527169099371734,
      "loss": 5.7924,
      "step": 19
    },
    {
      "epoch": 10.0,
      "grad_norm": 4.71564245223999,
      "learning_rate": 0.00047654411572334044,
      "loss": 5.77,
      "step": 20
    },
    {
      "epoch": 10.5,
      "grad_norm": 4.119877815246582,
      "learning_rate": 0.0005003713215095075,
      "loss": 5.6919,
      "step": 21
    },
    {
      "epoch": 11.0,
      "grad_norm": 8.430131912231445,
      "learning_rate": 0.0005241985272956745,
      "loss": 6.0003,
      "step": 22
    },
    {
      "epoch": 11.5,
      "grad_norm": 2.6675853729248047,
      "learning_rate": 0.0005480257330818415,
      "loss": 5.908,
      "step": 23
    },
    {
      "epoch": 12.0,
      "grad_norm": 4.536012649536133,
      "learning_rate": 0.0005718529388680085,
      "loss": 5.8992,
      "step": 24
    },
    {
      "epoch": 12.5,
      "grad_norm": 2.4536561965942383,
      "learning_rate": 0.0005956801446541756,
      "loss": 5.9207,
      "step": 25
    },
    {
      "epoch": 13.0,
      "grad_norm": 2.76934552192688,
      "learning_rate": 0.0006195073504403426,
      "loss": 5.8908,
      "step": 26
    },
    {
      "epoch": 13.5,
      "grad_norm": 2.6961653232574463,
      "learning_rate": 0.0006433345562265096,
      "loss": 5.9442,
      "step": 27
    },
    {
      "epoch": 14.0,
      "grad_norm": 3.0238380432128906,
      "learning_rate": 0.0006671617620126766,
      "loss": 5.8184,
      "step": 28
    },
    {
      "epoch": 14.5,
      "grad_norm": 3.244476079940796,
      "learning_rate": 0.0006909889677988436,
      "loss": 5.8347,
      "step": 29
    },
    {
      "epoch": 15.0,
      "grad_norm": 2.7074666023254395,
      "learning_rate": 0.0007148161735850107,
      "loss": 6.1174,
      "step": 30
    },
    {
      "epoch": 15.5,
      "grad_norm": 2.978747844696045,
      "learning_rate": 0.0007386433793711777,
      "loss": 5.979,
      "step": 31
    },
    {
      "epoch": 16.0,
      "grad_norm": 3.5655784606933594,
      "learning_rate": 0.0007624705851573448,
      "loss": 5.7337,
      "step": 32
    },
    {
      "epoch": 16.5,
      "grad_norm": 3.0460081100463867,
      "learning_rate": 0.0007862977909435117,
      "loss": 6.0082,
      "step": 33
    },
    {
      "epoch": 17.0,
      "grad_norm": 3.3939273357391357,
      "learning_rate": 0.0008101249967296787,
      "loss": 5.9187,
      "step": 34
    },
    {
      "epoch": 17.5,
      "grad_norm": 3.4341773986816406,
      "learning_rate": 0.0008339522025158458,
      "loss": 5.9069,
      "step": 35
    },
    {
      "epoch": 18.0,
      "grad_norm": 2.7170252799987793,
      "learning_rate": 0.0008577794083020128,
      "loss": 5.9503,
      "step": 36
    },
    {
      "epoch": 18.5,
      "grad_norm": 2.7570371627807617,
      "learning_rate": 0.0008816066140881799,
      "loss": 5.918,
      "step": 37
    },
    {
      "epoch": 19.0,
      "grad_norm": 3.4758551120758057,
      "learning_rate": 0.0009054338198743468,
      "loss": 6.0068,
      "step": 38
    },
    {
      "epoch": 19.5,
      "grad_norm": 2.888420581817627,
      "learning_rate": 0.0009292610256605139,
      "loss": 5.9418,
      "step": 39
    },
    {
      "epoch": 20.0,
      "grad_norm": 3.5430867671966553,
      "learning_rate": 0.0009530882314466809,
      "loss": 5.7865,
      "step": 40
    },
    {
      "epoch": 20.5,
      "grad_norm": 3.316831588745117,
      "learning_rate": 0.0009769154372328479,
      "loss": 5.8251,
      "step": 41
    },
    {
      "epoch": 21.0,
      "grad_norm": 2.7504258155822754,
      "learning_rate": 0.001000742643019015,
      "loss": 5.9858,
      "step": 42
    },
    {
      "epoch": 21.5,
      "grad_norm": 3.4772019386291504,
      "learning_rate": 0.0010245698488051819,
      "loss": 5.735,
      "step": 43
    },
    {
      "epoch": 22.0,
      "grad_norm": 2.209092617034912,
      "learning_rate": 0.001048397054591349,
      "loss": 6.2463,
      "step": 44
    },
    {
      "epoch": 22.5,
      "grad_norm": 3.2138638496398926,
      "learning_rate": 0.001072224260377516,
      "loss": 5.7485,
      "step": 45
    },
    {
      "epoch": 23.0,
      "grad_norm": 2.3960049152374268,
      "learning_rate": 0.001096051466163683,
      "loss": 6.0627,
      "step": 46
    },
    {
      "epoch": 23.5,
      "grad_norm": 2.5403506755828857,
      "learning_rate": 0.00111987867194985,
      "loss": 5.9787,
      "step": 47
    },
    {
      "epoch": 24.0,
      "grad_norm": 2.7504656314849854,
      "learning_rate": 0.001143705877736017,
      "loss": 5.8682,
      "step": 48
    },
    {
      "epoch": 24.5,
      "grad_norm": 2.1833858489990234,
      "learning_rate": 0.001167533083522184,
      "loss": 5.9396,
      "step": 49
    },
    {
      "epoch": 25.0,
      "grad_norm": 2.897063732147217,
      "learning_rate": 0.0011913602893083512,
      "loss": 5.8974,
      "step": 50
    },
    {
      "epoch": 25.5,
      "grad_norm": 2.161674976348877,
      "learning_rate": 0.001215187495094518,
      "loss": 5.9083,
      "step": 51
    },
    {
      "epoch": 26.0,
      "grad_norm": 2.219085931777954,
      "learning_rate": 0.0012390147008806852,
      "loss": 5.8712,
      "step": 52
    },
    {
      "epoch": 26.5,
      "grad_norm": 1.6432212591171265,
      "learning_rate": 0.001262841906666852,
      "loss": 5.982,
      "step": 53
    },
    {
      "epoch": 27.0,
      "grad_norm": 2.3360118865966797,
      "learning_rate": 0.0012866691124530192,
      "loss": 5.8083,
      "step": 54
    },
    {
      "epoch": 27.5,
      "grad_norm": 1.6686240434646606,
      "learning_rate": 0.0013104963182391863,
      "loss": 5.997,
      "step": 55
    },
    {
      "epoch": 28.0,
      "grad_norm": 1.3692795038223267,
      "learning_rate": 0.0013343235240253532,
      "loss": 5.9606,
      "step": 56
    },
    {
      "epoch": 28.5,
      "grad_norm": 1.5066572427749634,
      "learning_rate": 0.0013581507298115203,
      "loss": 5.8961,
      "step": 57
    },
    {
      "epoch": 29.0,
      "grad_norm": 0.9268932938575745,
      "learning_rate": 0.0013819779355976872,
      "loss": 6.1182,
      "step": 58
    },
    {
      "epoch": 29.5,
      "grad_norm": 1.022972822189331,
      "learning_rate": 0.0014058051413838545,
      "loss": 5.9446,
      "step": 59
    },
    {
      "epoch": 30.0,
      "grad_norm": 0.9986575841903687,
      "learning_rate": 0.0014296323471700214,
      "loss": 5.8457,
      "step": 60
    },
    {
      "epoch": 30.5,
      "grad_norm": 0.8457155227661133,
      "learning_rate": 0.0014534595529561883,
      "loss": 5.9232,
      "step": 61
    },
    {
      "epoch": 31.0,
      "grad_norm": 0.8130726218223572,
      "learning_rate": 0.0014772867587423554,
      "loss": 5.8212,
      "step": 62
    },
    {
      "epoch": 31.5,
      "grad_norm": 0.8356086015701294,
      "learning_rate": 0.0015011139645285223,
      "loss": 5.8728,
      "step": 63
    },
    {
      "epoch": 32.0,
      "grad_norm": 0.6498993635177612,
      "learning_rate": 0.0015249411703146896,
      "loss": 5.9713,
      "step": 64
    },
    {
      "epoch": 32.5,
      "grad_norm": 0.6728513836860657,
      "learning_rate": 0.0015487683761008565,
      "loss": 5.7783,
      "step": 65
    },
    {
      "epoch": 33.0,
      "grad_norm": 0.6151248812675476,
      "learning_rate": 0.0015725955818870234,
      "loss": 6.308,
      "step": 66
    },
    {
      "epoch": 33.5,
      "grad_norm": 0.6692782044410706,
      "learning_rate": 0.0015964227876731905,
      "loss": 5.8982,
      "step": 67
    },
    {
      "epoch": 34.0,
      "grad_norm": 0.6390499472618103,
      "learning_rate": 0.0016202499934593574,
      "loss": 6.1336,
      "step": 68
    },
    {
      "epoch": 34.5,
      "grad_norm": 0.896300196647644,
      "learning_rate": 0.0016440771992455247,
      "loss": 6.1547,
      "step": 69
    },
    {
      "epoch": 35.0,
      "grad_norm": 0.5619352459907532,
      "learning_rate": 0.0016679044050316916,
      "loss": 5.6903,
      "step": 70
    },
    {
      "epoch": 35.5,
      "grad_norm": 0.6167857646942139,
      "learning_rate": 0.0016917316108178585,
      "loss": 5.8748,
      "step": 71
    },
    {
      "epoch": 36.0,
      "grad_norm": 0.3812180161476135,
      "learning_rate": 0.0017155588166040256,
      "loss": 6.0427,
      "step": 72
    },
    {
      "epoch": 36.5,
      "grad_norm": 0.3821486234664917,
      "learning_rate": 0.0017393860223901927,
      "loss": 5.9487,
      "step": 73
    },
    {
      "epoch": 37.0,
      "grad_norm": 0.44864118099212646,
      "learning_rate": 0.0017632132281763598,
      "loss": 5.8991,
      "step": 74
    },
    {
      "epoch": 37.5,
      "grad_norm": 0.3392143249511719,
      "learning_rate": 0.0017870404339625267,
      "loss": 5.947,
      "step": 75
    },
    {
      "epoch": 38.0,
      "grad_norm": 0.5220587253570557,
      "learning_rate": 0.0018108676397486935,
      "loss": 6.1262,
      "step": 76
    },
    {
      "epoch": 38.5,
      "grad_norm": 0.3023449778556824,
      "learning_rate": 0.0018346948455348607,
      "loss": 5.9067,
      "step": 77
    },
    {
      "epoch": 39.0,
      "grad_norm": 0.7616879343986511,
      "learning_rate": 0.0018585220513210278,
      "loss": 6.103,
      "step": 78
    },
    {
      "epoch": 39.5,
      "grad_norm": 0.13944533467292786,
      "learning_rate": 0.0018823492571071949,
      "loss": 6.0198,
      "step": 79
    },
    {
      "epoch": 40.0,
      "grad_norm": 0.18581444025039673,
      "learning_rate": 0.0019061764628933618,
      "loss": 5.9524,
      "step": 80
    },
    {
      "epoch": 40.0,
      "eval_brier_0th_event": 0.22020206382404975,
      "eval_brier_0th_event_n": 250,
      "eval_brier_avg": 0.22020206382404975,
      "eval_brier_weighted_avg": 0.22020206382404975,
      "eval_ipcw": 0.41538306317647633,
      "eval_ipcw_0th_event": 0.41538306317647633,
      "eval_ipcw_0th_event_0.25": 0.4180029406048574,
      "eval_ipcw_0th_event_0.5": 0.4668059893871266,
      "eval_ipcw_0th_event_0.75": 0.44145642336541197,
      "eval_ipcw_0th_event_1.0": 0.41538306317647633,
      "eval_ipcw_0th_event_n": 250,
      "eval_ipcw_avg": 0.43541210413346804,
      "eval_ipcw_avg_0th_event": 0.43541210413346804,
      "eval_ipcw_weighted_avg": 0.43541210413346804,
      "eval_loss": 3.1344566345214844,
      "eval_runtime": 0.0984,
      "eval_samples_per_second": 4514.257,
      "eval_steps_per_second": 10.167,
      "step": 80
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 12488832000.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
