{
  "best_global_step": 80,
  "best_metric": 0.6752594919734248,
  "best_model_checkpoint": "./data/model-hub/metabric_numeric/survival_trial_1744215507/checkpoint-80",
  "epoch": 40.0,
  "eval_steps": 1,
  "global_step": 80,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 2.5820939540863037,
      "learning_rate": 3.277912450673486e-05,
      "loss": 1.657,
      "step": 1
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.7771263122558594,
      "learning_rate": 6.555824901346971e-05,
      "loss": 1.639,
      "step": 2
    },
    {
      "epoch": 1.5,
      "grad_norm": 2.912301540374756,
      "learning_rate": 9.833737352020456e-05,
      "loss": 1.6356,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 2.6990554332733154,
      "learning_rate": 0.00013111649802693943,
      "loss": 1.6518,
      "step": 4
    },
    {
      "epoch": 2.5,
      "grad_norm": 2.351421356201172,
      "learning_rate": 0.00016389562253367427,
      "loss": 1.6399,
      "step": 5
    },
    {
      "epoch": 3.0,
      "grad_norm": 2.82100510597229,
      "learning_rate": 0.00019667474704040911,
      "loss": 1.6378,
      "step": 6
    },
    {
      "epoch": 3.5,
      "grad_norm": 2.0519256591796875,
      "learning_rate": 0.00022945387154714396,
      "loss": 1.6728,
      "step": 7
    },
    {
      "epoch": 4.0,
      "grad_norm": 2.229580879211426,
      "learning_rate": 0.00026223299605387885,
      "loss": 1.5505,
      "step": 8
    },
    {
      "epoch": 4.5,
      "grad_norm": 1.8462899923324585,
      "learning_rate": 0.00029501212056061367,
      "loss": 1.6307,
      "step": 9
    },
    {
      "epoch": 5.0,
      "grad_norm": 1.9155100584030151,
      "learning_rate": 0.00032779124506734854,
      "loss": 1.5764,
      "step": 10
    },
    {
      "epoch": 5.5,
      "grad_norm": 2.131103038787842,
      "learning_rate": 0.0003605703695740834,
      "loss": 1.6054,
      "step": 11
    },
    {
      "epoch": 6.0,
      "grad_norm": 2.0203521251678467,
      "learning_rate": 0.00039334949408081823,
      "loss": 1.5687,
      "step": 12
    },
    {
      "epoch": 6.5,
      "grad_norm": 2.2979819774627686,
      "learning_rate": 0.0004261286185875531,
      "loss": 1.6307,
      "step": 13
    },
    {
      "epoch": 7.0,
      "grad_norm": 2.1548891067504883,
      "learning_rate": 0.0004589077430942879,
      "loss": 1.5351,
      "step": 14
    },
    {
      "epoch": 7.5,
      "grad_norm": 2.710366725921631,
      "learning_rate": 0.0004916868676010228,
      "loss": 1.5729,
      "step": 15
    },
    {
      "epoch": 8.0,
      "grad_norm": 2.121060371398926,
      "learning_rate": 0.0005244659921077577,
      "loss": 1.6271,
      "step": 16
    },
    {
      "epoch": 8.5,
      "grad_norm": 2.554579257965088,
      "learning_rate": 0.0005572451166144925,
      "loss": 1.5814,
      "step": 17
    },
    {
      "epoch": 9.0,
      "grad_norm": 2.1667885780334473,
      "learning_rate": 0.0005900242411212273,
      "loss": 1.5729,
      "step": 18
    },
    {
      "epoch": 9.5,
      "grad_norm": 2.6944730281829834,
      "learning_rate": 0.0006228033656279622,
      "loss": 1.5671,
      "step": 19
    },
    {
      "epoch": 10.0,
      "grad_norm": 2.3995893001556396,
      "learning_rate": 0.0006555824901346971,
      "loss": 1.6072,
      "step": 20
    },
    {
      "epoch": 10.5,
      "grad_norm": 2.7277538776397705,
      "learning_rate": 0.000688361614641432,
      "loss": 1.5413,
      "step": 21
    },
    {
      "epoch": 11.0,
      "grad_norm": 2.263324022293091,
      "learning_rate": 0.0007211407391481668,
      "loss": 1.5992,
      "step": 22
    },
    {
      "epoch": 11.5,
      "grad_norm": 2.4050750732421875,
      "learning_rate": 0.0007539198636549016,
      "loss": 1.5124,
      "step": 23
    },
    {
      "epoch": 12.0,
      "grad_norm": 2.5244579315185547,
      "learning_rate": 0.0007866989881616365,
      "loss": 1.5709,
      "step": 24
    },
    {
      "epoch": 12.5,
      "grad_norm": 2.2489006519317627,
      "learning_rate": 0.0008194781126683714,
      "loss": 1.5432,
      "step": 25
    },
    {
      "epoch": 13.0,
      "grad_norm": 2.5920894145965576,
      "learning_rate": 0.0008522572371751062,
      "loss": 1.4853,
      "step": 26
    },
    {
      "epoch": 13.5,
      "grad_norm": 2.398834228515625,
      "learning_rate": 0.0008850363616818411,
      "loss": 1.4778,
      "step": 27
    },
    {
      "epoch": 14.0,
      "grad_norm": 2.4506430625915527,
      "learning_rate": 0.0009178154861885758,
      "loss": 1.5378,
      "step": 28
    },
    {
      "epoch": 14.5,
      "grad_norm": 2.289151430130005,
      "learning_rate": 0.0009505946106953108,
      "loss": 1.5533,
      "step": 29
    },
    {
      "epoch": 15.0,
      "grad_norm": 2.5775201320648193,
      "learning_rate": 0.0009833737352020456,
      "loss": 1.3985,
      "step": 30
    },
    {
      "epoch": 15.5,
      "grad_norm": 2.138617992401123,
      "learning_rate": 0.0010161528597087805,
      "loss": 1.496,
      "step": 31
    },
    {
      "epoch": 16.0,
      "grad_norm": 1.8257893323898315,
      "learning_rate": 0.0010489319842155154,
      "loss": 1.4166,
      "step": 32
    },
    {
      "epoch": 16.5,
      "grad_norm": 1.9729539155960083,
      "learning_rate": 0.0010817111087222501,
      "loss": 1.4256,
      "step": 33
    },
    {
      "epoch": 17.0,
      "grad_norm": 2.0052449703216553,
      "learning_rate": 0.001114490233228985,
      "loss": 1.4729,
      "step": 34
    },
    {
      "epoch": 17.5,
      "grad_norm": 1.1414040327072144,
      "learning_rate": 0.00114726935773572,
      "loss": 1.4198,
      "step": 35
    },
    {
      "epoch": 18.0,
      "grad_norm": 1.7893353700637817,
      "learning_rate": 0.0011800484822424547,
      "loss": 1.4361,
      "step": 36
    },
    {
      "epoch": 18.5,
      "grad_norm": 1.4705307483673096,
      "learning_rate": 0.0012128276067491896,
      "loss": 1.3924,
      "step": 37
    },
    {
      "epoch": 19.0,
      "grad_norm": 1.5162854194641113,
      "learning_rate": 0.0012456067312559243,
      "loss": 1.4136,
      "step": 38
    },
    {
      "epoch": 19.5,
      "grad_norm": 1.721813440322876,
      "learning_rate": 0.0012783858557626592,
      "loss": 1.3881,
      "step": 39
    },
    {
      "epoch": 20.0,
      "grad_norm": 2.328887939453125,
      "learning_rate": 0.0013111649802693942,
      "loss": 1.3955,
      "step": 40
    },
    {
      "epoch": 20.5,
      "grad_norm": 1.4240823984146118,
      "learning_rate": 0.0013439441047761289,
      "loss": 1.4094,
      "step": 41
    },
    {
      "epoch": 21.0,
      "grad_norm": 2.4483566284179688,
      "learning_rate": 0.001376723229282864,
      "loss": 1.356,
      "step": 42
    },
    {
      "epoch": 21.5,
      "grad_norm": 4.165386199951172,
      "learning_rate": 0.0014095023537895987,
      "loss": 1.3788,
      "step": 43
    },
    {
      "epoch": 22.0,
      "grad_norm": 2.539350986480713,
      "learning_rate": 0.0014422814782963336,
      "loss": 1.3762,
      "step": 44
    },
    {
      "epoch": 22.5,
      "grad_norm": 2.5269272327423096,
      "learning_rate": 0.0014750606028030684,
      "loss": 1.341,
      "step": 45
    },
    {
      "epoch": 23.0,
      "grad_norm": 2.8397011756896973,
      "learning_rate": 0.0015078397273098033,
      "loss": 1.3986,
      "step": 46
    },
    {
      "epoch": 23.5,
      "grad_norm": 2.747607707977295,
      "learning_rate": 0.0015406188518165382,
      "loss": 1.3505,
      "step": 47
    },
    {
      "epoch": 24.0,
      "grad_norm": 2.136983633041382,
      "learning_rate": 0.001573397976323273,
      "loss": 1.3362,
      "step": 48
    },
    {
      "epoch": 24.5,
      "grad_norm": 3.404700756072998,
      "learning_rate": 0.001606177100830008,
      "loss": 1.347,
      "step": 49
    },
    {
      "epoch": 25.0,
      "grad_norm": 2.3822340965270996,
      "learning_rate": 0.0016389562253367428,
      "loss": 1.3636,
      "step": 50
    },
    {
      "epoch": 25.5,
      "grad_norm": 1.0844390392303467,
      "learning_rate": 0.0016717353498434775,
      "loss": 1.3667,
      "step": 51
    },
    {
      "epoch": 26.0,
      "grad_norm": 2.497208595275879,
      "learning_rate": 0.0017045144743502124,
      "loss": 1.3064,
      "step": 52
    },
    {
      "epoch": 26.5,
      "grad_norm": 3.3990325927734375,
      "learning_rate": 0.0017372935988569473,
      "loss": 1.3571,
      "step": 53
    },
    {
      "epoch": 27.0,
      "grad_norm": 3.6048436164855957,
      "learning_rate": 0.0017700727233636822,
      "loss": 1.3077,
      "step": 54
    },
    {
      "epoch": 27.5,
      "grad_norm": 1.505611538887024,
      "learning_rate": 0.001802851847870417,
      "loss": 1.3212,
      "step": 55
    },
    {
      "epoch": 28.0,
      "grad_norm": 6.560492992401123,
      "learning_rate": 0.0018356309723771517,
      "loss": 1.3432,
      "step": 56
    },
    {
      "epoch": 28.5,
      "grad_norm": 5.493099689483643,
      "learning_rate": 0.0018684100968838868,
      "loss": 1.3319,
      "step": 57
    },
    {
      "epoch": 29.0,
      "grad_norm": 6.133269786834717,
      "learning_rate": 0.0019011892213906215,
      "loss": 1.3538,
      "step": 58
    },
    {
      "epoch": 29.5,
      "grad_norm": 3.546187162399292,
      "learning_rate": 0.0019339683458973564,
      "loss": 1.3528,
      "step": 59
    },
    {
      "epoch": 30.0,
      "grad_norm": 2.0330185890197754,
      "learning_rate": 0.001966747470404091,
      "loss": 1.269,
      "step": 60
    },
    {
      "epoch": 30.5,
      "grad_norm": 2.5594916343688965,
      "learning_rate": 0.001999526594910826,
      "loss": 1.289,
      "step": 61
    },
    {
      "epoch": 31.0,
      "grad_norm": 3.2702789306640625,
      "learning_rate": 0.002032305719417561,
      "loss": 1.3543,
      "step": 62
    },
    {
      "epoch": 31.5,
      "grad_norm": 3.9456517696380615,
      "learning_rate": 0.002065084843924296,
      "loss": 1.3333,
      "step": 63
    },
    {
      "epoch": 32.0,
      "grad_norm": 5.682427883148193,
      "learning_rate": 0.002097863968431031,
      "loss": 1.3241,
      "step": 64
    },
    {
      "epoch": 32.5,
      "grad_norm": 3.330502986907959,
      "learning_rate": 0.0021306430929377653,
      "loss": 1.346,
      "step": 65
    },
    {
      "epoch": 33.0,
      "grad_norm": 3.455265760421753,
      "learning_rate": 0.0021634222174445003,
      "loss": 1.2981,
      "step": 66
    },
    {
      "epoch": 33.5,
      "grad_norm": 3.8939106464385986,
      "learning_rate": 0.002196201341951235,
      "loss": 1.3629,
      "step": 67
    },
    {
      "epoch": 34.0,
      "grad_norm": 1.107869267463684,
      "learning_rate": 0.00222898046645797,
      "loss": 1.2448,
      "step": 68
    },
    {
      "epoch": 34.5,
      "grad_norm": 1.9005883932113647,
      "learning_rate": 0.002261759590964705,
      "loss": 1.2874,
      "step": 69
    },
    {
      "epoch": 35.0,
      "grad_norm": 2.627082109451294,
      "learning_rate": 0.00229453871547144,
      "loss": 1.3306,
      "step": 70
    },
    {
      "epoch": 35.5,
      "grad_norm": 1.4630988836288452,
      "learning_rate": 0.0023273178399781744,
      "loss": 1.2927,
      "step": 71
    },
    {
      "epoch": 36.0,
      "grad_norm": 4.335430145263672,
      "learning_rate": 0.0023600969644849094,
      "loss": 1.2764,
      "step": 72
    },
    {
      "epoch": 36.5,
      "grad_norm": 2.3235299587249756,
      "learning_rate": 0.0023928760889916443,
      "loss": 1.3012,
      "step": 73
    },
    {
      "epoch": 37.0,
      "grad_norm": 3.967090368270874,
      "learning_rate": 0.0024256552134983792,
      "loss": 1.3273,
      "step": 74
    },
    {
      "epoch": 37.5,
      "grad_norm": 4.405922889709473,
      "learning_rate": 0.002458434338005114,
      "loss": 1.3594,
      "step": 75
    },
    {
      "epoch": 38.0,
      "grad_norm": 3.082831621170044,
      "learning_rate": 0.0024912134625118486,
      "loss": 1.2465,
      "step": 76
    },
    {
      "epoch": 38.5,
      "grad_norm": 2.0643112659454346,
      "learning_rate": 0.002523992587018584,
      "loss": 1.2868,
      "step": 77
    },
    {
      "epoch": 39.0,
      "grad_norm": 3.5271718502044678,
      "learning_rate": 0.0025567717115253185,
      "loss": 1.2851,
      "step": 78
    },
    {
      "epoch": 39.5,
      "grad_norm": 2.309328079223633,
      "learning_rate": 0.0025895508360320534,
      "loss": 1.3209,
      "step": 79
    },
    {
      "epoch": 40.0,
      "grad_norm": 3.232962131500244,
      "learning_rate": 0.0026223299605387883,
      "loss": 1.2869,
      "step": 80
    },
    {
      "epoch": 40.0,
      "eval_brier_0th_event": 0.1866993706138096,
      "eval_brier_0th_event_n": 270,
      "eval_brier_avg": 0.1866993706138096,
      "eval_brier_weighted_avg": 0.1866993706138096,
      "eval_ipcw": 0.6201786616804025,
      "eval_ipcw_0th_event": 0.6201786616804025,
      "eval_ipcw_0th_event_0.25": 0.7483881229839104,
      "eval_ipcw_0th_event_0.5": 0.6805701759237871,
      "eval_ipcw_0th_event_0.75": 0.6519010073055993,
      "eval_ipcw_0th_event_1.0": 0.6201786616804025,
      "eval_ipcw_0th_event_n": 270,
      "eval_ipcw_avg": 0.6752594919734248,
      "eval_ipcw_avg_0th_event": 0.6752594919734248,
      "eval_ipcw_weighted_avg": 0.6752594919734248,
      "eval_loss": 0.6596888899803162,
      "eval_runtime": 0.0916,
      "eval_samples_per_second": 4849.374,
      "eval_steps_per_second": 10.922,
      "step": 80
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 63040896000.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
