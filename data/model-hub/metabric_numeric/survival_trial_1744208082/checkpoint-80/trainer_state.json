{
  "best_global_step": 80,
  "best_metric": 0.6504096146580188,
  "best_model_checkpoint": "./data/model-hub/metabric_numeric/survival_trial_1744208082/checkpoint-80",
  "epoch": 40.0,
  "eval_steps": 1,
  "global_step": 80,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 3.6995410919189453,
      "learning_rate": 2.414119984377933e-05,
      "loss": 1.6292,
      "step": 1
    },
    {
      "epoch": 1.0,
      "grad_norm": 3.141031503677368,
      "learning_rate": 4.828239968755866e-05,
      "loss": 1.6286,
      "step": 2
    },
    {
      "epoch": 1.5,
      "grad_norm": 3.195849895477295,
      "learning_rate": 7.242359953133798e-05,
      "loss": 1.639,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 3.576028347015381,
      "learning_rate": 9.656479937511732e-05,
      "loss": 1.5955,
      "step": 4
    },
    {
      "epoch": 2.5,
      "grad_norm": 3.228348970413208,
      "learning_rate": 0.00012070599921889665,
      "loss": 1.605,
      "step": 5
    },
    {
      "epoch": 3.0,
      "grad_norm": 2.136826992034912,
      "learning_rate": 0.00014484719906267596,
      "loss": 1.64,
      "step": 6
    },
    {
      "epoch": 3.5,
      "grad_norm": 2.5837111473083496,
      "learning_rate": 0.0001689883989064553,
      "loss": 1.6138,
      "step": 7
    },
    {
      "epoch": 4.0,
      "grad_norm": 1.892289638519287,
      "learning_rate": 0.00019312959875023464,
      "loss": 1.5966,
      "step": 8
    },
    {
      "epoch": 4.5,
      "grad_norm": 1.9263709783554077,
      "learning_rate": 0.00021727079859401398,
      "loss": 1.6303,
      "step": 9
    },
    {
      "epoch": 5.0,
      "grad_norm": 1.9396125078201294,
      "learning_rate": 0.0002414119984377933,
      "loss": 1.5456,
      "step": 10
    },
    {
      "epoch": 5.5,
      "grad_norm": 2.281979560852051,
      "learning_rate": 0.00026555319828157266,
      "loss": 1.628,
      "step": 11
    },
    {
      "epoch": 6.0,
      "grad_norm": 2.2278950214385986,
      "learning_rate": 0.0002896943981253519,
      "loss": 1.5669,
      "step": 12
    },
    {
      "epoch": 6.5,
      "grad_norm": 2.465648889541626,
      "learning_rate": 0.0003138355979691313,
      "loss": 1.612,
      "step": 13
    },
    {
      "epoch": 7.0,
      "grad_norm": 2.2954232692718506,
      "learning_rate": 0.0003379767978129106,
      "loss": 1.5971,
      "step": 14
    },
    {
      "epoch": 7.5,
      "grad_norm": 2.6535141468048096,
      "learning_rate": 0.0003621179976566899,
      "loss": 1.5679,
      "step": 15
    },
    {
      "epoch": 8.0,
      "grad_norm": 2.6540398597717285,
      "learning_rate": 0.0003862591975004693,
      "loss": 1.6151,
      "step": 16
    },
    {
      "epoch": 8.5,
      "grad_norm": 2.3587801456451416,
      "learning_rate": 0.0004104003973442486,
      "loss": 1.5286,
      "step": 17
    },
    {
      "epoch": 9.0,
      "grad_norm": 3.1729300022125244,
      "learning_rate": 0.00043454159718802796,
      "loss": 1.641,
      "step": 18
    },
    {
      "epoch": 9.5,
      "grad_norm": 2.502420663833618,
      "learning_rate": 0.0004586827970318072,
      "loss": 1.5321,
      "step": 19
    },
    {
      "epoch": 10.0,
      "grad_norm": 2.966585159301758,
      "learning_rate": 0.0004828239968755866,
      "loss": 1.6271,
      "step": 20
    },
    {
      "epoch": 10.5,
      "grad_norm": 2.5118563175201416,
      "learning_rate": 0.0005069651967193659,
      "loss": 1.5581,
      "step": 21
    },
    {
      "epoch": 11.0,
      "grad_norm": 2.575303077697754,
      "learning_rate": 0.0005311063965631453,
      "loss": 1.5412,
      "step": 22
    },
    {
      "epoch": 11.5,
      "grad_norm": 2.3177695274353027,
      "learning_rate": 0.0005552475964069245,
      "loss": 1.5597,
      "step": 23
    },
    {
      "epoch": 12.0,
      "grad_norm": 3.1923506259918213,
      "learning_rate": 0.0005793887962507038,
      "loss": 1.5287,
      "step": 24
    },
    {
      "epoch": 12.5,
      "grad_norm": 2.5087368488311768,
      "learning_rate": 0.0006035299960944833,
      "loss": 1.5235,
      "step": 25
    },
    {
      "epoch": 13.0,
      "grad_norm": 2.9296743869781494,
      "learning_rate": 0.0006276711959382626,
      "loss": 1.5208,
      "step": 26
    },
    {
      "epoch": 13.5,
      "grad_norm": 2.964322566986084,
      "learning_rate": 0.0006518123957820419,
      "loss": 1.508,
      "step": 27
    },
    {
      "epoch": 14.0,
      "grad_norm": 2.339920997619629,
      "learning_rate": 0.0006759535956258212,
      "loss": 1.4936,
      "step": 28
    },
    {
      "epoch": 14.5,
      "grad_norm": 2.9736013412475586,
      "learning_rate": 0.0007000947954696005,
      "loss": 1.4837,
      "step": 29
    },
    {
      "epoch": 15.0,
      "grad_norm": 2.58658504486084,
      "learning_rate": 0.0007242359953133798,
      "loss": 1.4954,
      "step": 30
    },
    {
      "epoch": 15.5,
      "grad_norm": 2.7994627952575684,
      "learning_rate": 0.0007483771951571593,
      "loss": 1.4427,
      "step": 31
    },
    {
      "epoch": 16.0,
      "grad_norm": 2.742851734161377,
      "learning_rate": 0.0007725183950009386,
      "loss": 1.4698,
      "step": 32
    },
    {
      "epoch": 16.5,
      "grad_norm": 2.8298590183258057,
      "learning_rate": 0.0007966595948447179,
      "loss": 1.4547,
      "step": 33
    },
    {
      "epoch": 17.0,
      "grad_norm": 2.349635124206543,
      "learning_rate": 0.0008208007946884972,
      "loss": 1.4065,
      "step": 34
    },
    {
      "epoch": 17.5,
      "grad_norm": 2.678791046142578,
      "learning_rate": 0.0008449419945322765,
      "loss": 1.3931,
      "step": 35
    },
    {
      "epoch": 18.0,
      "grad_norm": 2.390315532684326,
      "learning_rate": 0.0008690831943760559,
      "loss": 1.4364,
      "step": 36
    },
    {
      "epoch": 18.5,
      "grad_norm": 1.812893033027649,
      "learning_rate": 0.0008932243942198352,
      "loss": 1.4112,
      "step": 37
    },
    {
      "epoch": 19.0,
      "grad_norm": 5.654294013977051,
      "learning_rate": 0.0009173655940636144,
      "loss": 1.3564,
      "step": 38
    },
    {
      "epoch": 19.5,
      "grad_norm": 3.6880526542663574,
      "learning_rate": 0.0009415067939073939,
      "loss": 1.3729,
      "step": 39
    },
    {
      "epoch": 20.0,
      "grad_norm": 2.1079890727996826,
      "learning_rate": 0.0009656479937511732,
      "loss": 1.4275,
      "step": 40
    },
    {
      "epoch": 20.5,
      "grad_norm": 2.2966699600219727,
      "learning_rate": 0.0009897891935949524,
      "loss": 1.4075,
      "step": 41
    },
    {
      "epoch": 21.0,
      "grad_norm": 2.812729835510254,
      "learning_rate": 0.0010139303934387318,
      "loss": 1.2917,
      "step": 42
    },
    {
      "epoch": 21.5,
      "grad_norm": 1.591950535774231,
      "learning_rate": 0.0010380715932825112,
      "loss": 1.3439,
      "step": 43
    },
    {
      "epoch": 22.0,
      "grad_norm": 2.528028726577759,
      "learning_rate": 0.0010622127931262907,
      "loss": 1.3839,
      "step": 44
    },
    {
      "epoch": 22.5,
      "grad_norm": 2.5016708374023438,
      "learning_rate": 0.0010863539929700699,
      "loss": 1.3781,
      "step": 45
    },
    {
      "epoch": 23.0,
      "grad_norm": 6.51268196105957,
      "learning_rate": 0.001110495192813849,
      "loss": 1.317,
      "step": 46
    },
    {
      "epoch": 23.5,
      "grad_norm": 2.61568546295166,
      "learning_rate": 0.0011346363926576285,
      "loss": 1.3402,
      "step": 47
    },
    {
      "epoch": 24.0,
      "grad_norm": 1.8920131921768188,
      "learning_rate": 0.0011587775925014077,
      "loss": 1.3375,
      "step": 48
    },
    {
      "epoch": 24.5,
      "grad_norm": 2.682816982269287,
      "learning_rate": 0.0011829187923451873,
      "loss": 1.3136,
      "step": 49
    },
    {
      "epoch": 25.0,
      "grad_norm": 3.10359525680542,
      "learning_rate": 0.0012070599921889665,
      "loss": 1.3119,
      "step": 50
    },
    {
      "epoch": 25.5,
      "grad_norm": 1.7874900102615356,
      "learning_rate": 0.0012312011920327457,
      "loss": 1.3178,
      "step": 51
    },
    {
      "epoch": 26.0,
      "grad_norm": 1.7485278844833374,
      "learning_rate": 0.0012553423918765252,
      "loss": 1.329,
      "step": 52
    },
    {
      "epoch": 26.5,
      "grad_norm": 3.1101930141448975,
      "learning_rate": 0.0012794835917203044,
      "loss": 1.3277,
      "step": 53
    },
    {
      "epoch": 27.0,
      "grad_norm": 3.054140567779541,
      "learning_rate": 0.0013036247915640838,
      "loss": 1.3105,
      "step": 54
    },
    {
      "epoch": 27.5,
      "grad_norm": 3.641610622406006,
      "learning_rate": 0.0013277659914078632,
      "loss": 1.2786,
      "step": 55
    },
    {
      "epoch": 28.0,
      "grad_norm": 3.753352403640747,
      "learning_rate": 0.0013519071912516424,
      "loss": 1.3385,
      "step": 56
    },
    {
      "epoch": 28.5,
      "grad_norm": 2.2709543704986572,
      "learning_rate": 0.0013760483910954218,
      "loss": 1.3078,
      "step": 57
    },
    {
      "epoch": 29.0,
      "grad_norm": 3.8958840370178223,
      "learning_rate": 0.001400189590939201,
      "loss": 1.2692,
      "step": 58
    },
    {
      "epoch": 29.5,
      "grad_norm": 3.211196184158325,
      "learning_rate": 0.0014243307907829805,
      "loss": 1.3252,
      "step": 59
    },
    {
      "epoch": 30.0,
      "grad_norm": 3.8025927543640137,
      "learning_rate": 0.0014484719906267597,
      "loss": 1.255,
      "step": 60
    },
    {
      "epoch": 30.5,
      "grad_norm": 2.1541621685028076,
      "learning_rate": 0.001472613190470539,
      "loss": 1.2764,
      "step": 61
    },
    {
      "epoch": 31.0,
      "grad_norm": 4.29445743560791,
      "learning_rate": 0.0014967543903143185,
      "loss": 1.298,
      "step": 62
    },
    {
      "epoch": 31.5,
      "grad_norm": 3.4846229553222656,
      "learning_rate": 0.0015208955901580977,
      "loss": 1.3228,
      "step": 63
    },
    {
      "epoch": 32.0,
      "grad_norm": 3.0144107341766357,
      "learning_rate": 0.0015450367900018771,
      "loss": 1.2264,
      "step": 64
    },
    {
      "epoch": 32.5,
      "grad_norm": 1.542258858680725,
      "learning_rate": 0.0015691779898456563,
      "loss": 1.3078,
      "step": 65
    },
    {
      "epoch": 33.0,
      "grad_norm": 1.5270748138427734,
      "learning_rate": 0.0015933191896894358,
      "loss": 1.2666,
      "step": 66
    },
    {
      "epoch": 33.5,
      "grad_norm": 4.0644989013671875,
      "learning_rate": 0.0016174603895332152,
      "loss": 1.3331,
      "step": 67
    },
    {
      "epoch": 34.0,
      "grad_norm": 3.804591655731201,
      "learning_rate": 0.0016416015893769944,
      "loss": 1.1872,
      "step": 68
    },
    {
      "epoch": 34.5,
      "grad_norm": 2.9043190479278564,
      "learning_rate": 0.0016657427892207738,
      "loss": 1.2839,
      "step": 69
    },
    {
      "epoch": 35.0,
      "grad_norm": 3.4192326068878174,
      "learning_rate": 0.001689883989064553,
      "loss": 1.2767,
      "step": 70
    },
    {
      "epoch": 35.5,
      "grad_norm": 1.9791295528411865,
      "learning_rate": 0.0017140251889083322,
      "loss": 1.2563,
      "step": 71
    },
    {
      "epoch": 36.0,
      "grad_norm": 5.830902099609375,
      "learning_rate": 0.0017381663887521119,
      "loss": 1.3106,
      "step": 72
    },
    {
      "epoch": 36.5,
      "grad_norm": 2.126072883605957,
      "learning_rate": 0.001762307588595891,
      "loss": 1.2418,
      "step": 73
    },
    {
      "epoch": 37.0,
      "grad_norm": 2.968672275543213,
      "learning_rate": 0.0017864487884396705,
      "loss": 1.2904,
      "step": 74
    },
    {
      "epoch": 37.5,
      "grad_norm": 0.8454359769821167,
      "learning_rate": 0.0018105899882834497,
      "loss": 1.2888,
      "step": 75
    },
    {
      "epoch": 38.0,
      "grad_norm": 5.516685962677002,
      "learning_rate": 0.0018347311881272289,
      "loss": 1.2749,
      "step": 76
    },
    {
      "epoch": 38.5,
      "grad_norm": 1.3564751148223877,
      "learning_rate": 0.0018588723879710083,
      "loss": 1.2993,
      "step": 77
    },
    {
      "epoch": 39.0,
      "grad_norm": 3.1105096340179443,
      "learning_rate": 0.0018830135878147877,
      "loss": 1.2212,
      "step": 78
    },
    {
      "epoch": 39.5,
      "grad_norm": 4.087481498718262,
      "learning_rate": 0.0019071547876585672,
      "loss": 1.2401,
      "step": 79
    },
    {
      "epoch": 40.0,
      "grad_norm": 5.499205112457275,
      "learning_rate": 0.0019312959875023464,
      "loss": 1.2967,
      "step": 80
    },
    {
      "epoch": 40.0,
      "eval_brier_0th_event": 0.19003118107292,
      "eval_brier_0th_event_n": 257,
      "eval_brier_avg": 0.19003118107292,
      "eval_brier_weighted_avg": 0.19003118107292,
      "eval_ipcw": 0.6164824809626915,
      "eval_ipcw_0th_event": 0.6164824809626915,
      "eval_ipcw_0th_event_0.25": 0.6980579074149325,
      "eval_ipcw_0th_event_0.5": 0.6623619384129482,
      "eval_ipcw_0th_event_0.75": 0.6247361318415033,
      "eval_ipcw_0th_event_1.0": 0.6164824809626915,
      "eval_ipcw_0th_event_n": 257,
      "eval_ipcw_avg": 0.6504096146580188,
      "eval_ipcw_avg_0th_event": 0.6504096146580188,
      "eval_ipcw_weighted_avg": 0.6504096146580188,
      "eval_loss": 0.6621828675270081,
      "eval_runtime": 0.0759,
      "eval_samples_per_second": 5846.803,
      "eval_steps_per_second": 13.168,
      "step": 80
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 44354534400.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
