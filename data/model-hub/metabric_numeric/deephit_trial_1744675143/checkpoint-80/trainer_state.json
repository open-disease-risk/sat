{
  "best_global_step": 80,
  "best_metric": 0.6704986387745651,
  "best_model_checkpoint": "./data/model-hub/metabric_numeric/deephit_trial_1744675143/checkpoint-80",
  "epoch": 40.0,
  "eval_steps": 1,
  "global_step": 80,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 2.9656147956848145,
      "learning_rate": 3.871564531758342e-05,
      "loss": 6.6959,
      "step": 1
    },
    {
      "epoch": 1.0,
      "grad_norm": 4.592706203460693,
      "learning_rate": 7.743129063516684e-05,
      "loss": 6.0047,
      "step": 2
    },
    {
      "epoch": 1.5,
      "grad_norm": 2.1199448108673096,
      "learning_rate": 0.00011614693595275023,
      "loss": 5.6618,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 4.617472171783447,
      "learning_rate": 0.00015486258127033367,
      "loss": 5.2622,
      "step": 4
    },
    {
      "epoch": 2.5,
      "grad_norm": 4.718683242797852,
      "learning_rate": 0.00019357822658791707,
      "loss": 5.2304,
      "step": 5
    },
    {
      "epoch": 3.0,
      "grad_norm": 2.4831197261810303,
      "learning_rate": 0.00023229387190550047,
      "loss": 5.3218,
      "step": 6
    },
    {
      "epoch": 3.5,
      "grad_norm": 3.171452760696411,
      "learning_rate": 0.00027100951722308387,
      "loss": 5.2286,
      "step": 7
    },
    {
      "epoch": 4.0,
      "grad_norm": 4.5010151863098145,
      "learning_rate": 0.00030972516254066735,
      "loss": 5.1221,
      "step": 8
    },
    {
      "epoch": 4.5,
      "grad_norm": 4.40781307220459,
      "learning_rate": 0.0003484408078582507,
      "loss": 5.2009,
      "step": 9
    },
    {
      "epoch": 5.0,
      "grad_norm": 4.028475761413574,
      "learning_rate": 0.00038715645317583414,
      "loss": 5.2496,
      "step": 10
    },
    {
      "epoch": 5.5,
      "grad_norm": 3.0319902896881104,
      "learning_rate": 0.00042587209849341757,
      "loss": 5.1957,
      "step": 11
    },
    {
      "epoch": 6.0,
      "grad_norm": 2.5467469692230225,
      "learning_rate": 0.00046458774381100094,
      "loss": 5.5413,
      "step": 12
    },
    {
      "epoch": 6.5,
      "grad_norm": 2.163867473602295,
      "learning_rate": 0.0005033033891285844,
      "loss": 5.535,
      "step": 13
    },
    {
      "epoch": 7.0,
      "grad_norm": 2.3492202758789062,
      "learning_rate": 0.0005420190344461677,
      "loss": 5.3637,
      "step": 14
    },
    {
      "epoch": 7.5,
      "grad_norm": 2.456770658493042,
      "learning_rate": 0.0005807346797637512,
      "loss": 5.4711,
      "step": 15
    },
    {
      "epoch": 8.0,
      "grad_norm": 2.2340176105499268,
      "learning_rate": 0.0006194503250813347,
      "loss": 5.798,
      "step": 16
    },
    {
      "epoch": 8.5,
      "grad_norm": 3.849090337753296,
      "learning_rate": 0.0006581659703989181,
      "loss": 5.5106,
      "step": 17
    },
    {
      "epoch": 9.0,
      "grad_norm": 2.7613110542297363,
      "learning_rate": 0.0006968816157165014,
      "loss": 5.9004,
      "step": 18
    },
    {
      "epoch": 9.5,
      "grad_norm": 2.2166554927825928,
      "learning_rate": 0.0007355972610340848,
      "loss": 5.8373,
      "step": 19
    },
    {
      "epoch": 10.0,
      "grad_norm": 2.878014087677002,
      "learning_rate": 0.0007743129063516683,
      "loss": 5.592,
      "step": 20
    },
    {
      "epoch": 10.5,
      "grad_norm": 2.1991732120513916,
      "learning_rate": 0.0008130285516692518,
      "loss": 5.8645,
      "step": 21
    },
    {
      "epoch": 11.0,
      "grad_norm": 2.305860996246338,
      "learning_rate": 0.0008517441969868351,
      "loss": 5.7979,
      "step": 22
    },
    {
      "epoch": 11.5,
      "grad_norm": 2.2132785320281982,
      "learning_rate": 0.0008904598423044185,
      "loss": 5.9058,
      "step": 23
    },
    {
      "epoch": 12.0,
      "grad_norm": 3.4052822589874268,
      "learning_rate": 0.0009291754876220019,
      "loss": 5.8264,
      "step": 24
    },
    {
      "epoch": 12.5,
      "grad_norm": 2.2089431285858154,
      "learning_rate": 0.0009678911329395854,
      "loss": 5.8371,
      "step": 25
    },
    {
      "epoch": 13.0,
      "grad_norm": 2.042163372039795,
      "learning_rate": 0.0010066067782571687,
      "loss": 5.9527,
      "step": 26
    },
    {
      "epoch": 13.5,
      "grad_norm": 2.2156026363372803,
      "learning_rate": 0.0010453224235747523,
      "loss": 5.7761,
      "step": 27
    },
    {
      "epoch": 14.0,
      "grad_norm": 2.0677285194396973,
      "learning_rate": 0.0010840380688923355,
      "loss": 5.9854,
      "step": 28
    },
    {
      "epoch": 14.5,
      "grad_norm": 2.253143548965454,
      "learning_rate": 0.001122753714209919,
      "loss": 5.9422,
      "step": 29
    },
    {
      "epoch": 15.0,
      "grad_norm": 2.0121543407440186,
      "learning_rate": 0.0011614693595275024,
      "loss": 5.8783,
      "step": 30
    },
    {
      "epoch": 15.5,
      "grad_norm": 2.0838265419006348,
      "learning_rate": 0.0012001850048450858,
      "loss": 5.9903,
      "step": 31
    },
    {
      "epoch": 16.0,
      "grad_norm": 2.195394515991211,
      "learning_rate": 0.0012389006501626694,
      "loss": 5.8556,
      "step": 32
    },
    {
      "epoch": 16.5,
      "grad_norm": 2.105320453643799,
      "learning_rate": 0.0012776162954802525,
      "loss": 5.8708,
      "step": 33
    },
    {
      "epoch": 17.0,
      "grad_norm": 2.2446846961975098,
      "learning_rate": 0.0013163319407978361,
      "loss": 5.8891,
      "step": 34
    },
    {
      "epoch": 17.5,
      "grad_norm": 1.7803399562835693,
      "learning_rate": 0.0013550475861154195,
      "loss": 6.0872,
      "step": 35
    },
    {
      "epoch": 18.0,
      "grad_norm": 2.332374334335327,
      "learning_rate": 0.0013937632314330029,
      "loss": 5.6318,
      "step": 36
    },
    {
      "epoch": 18.5,
      "grad_norm": 1.8580864667892456,
      "learning_rate": 0.0014324788767505865,
      "loss": 5.8547,
      "step": 37
    },
    {
      "epoch": 19.0,
      "grad_norm": 1.718616008758545,
      "learning_rate": 0.0014711945220681696,
      "loss": 6.1048,
      "step": 38
    },
    {
      "epoch": 19.5,
      "grad_norm": 1.6050372123718262,
      "learning_rate": 0.0015099101673857532,
      "loss": 5.9384,
      "step": 39
    },
    {
      "epoch": 20.0,
      "grad_norm": 1.847751498222351,
      "learning_rate": 0.0015486258127033366,
      "loss": 5.8543,
      "step": 40
    },
    {
      "epoch": 20.5,
      "grad_norm": 1.7596030235290527,
      "learning_rate": 0.00158734145802092,
      "loss": 5.8484,
      "step": 41
    },
    {
      "epoch": 21.0,
      "grad_norm": 1.3569865226745605,
      "learning_rate": 0.0016260571033385035,
      "loss": 6.0214,
      "step": 42
    },
    {
      "epoch": 21.5,
      "grad_norm": 1.8923137187957764,
      "learning_rate": 0.0016647727486560867,
      "loss": 5.9241,
      "step": 43
    },
    {
      "epoch": 22.0,
      "grad_norm": 1.3281176090240479,
      "learning_rate": 0.0017034883939736703,
      "loss": 5.9084,
      "step": 44
    },
    {
      "epoch": 22.5,
      "grad_norm": 6.540378093719482,
      "learning_rate": 0.0017422040392912536,
      "loss": 6.1345,
      "step": 45
    },
    {
      "epoch": 23.0,
      "grad_norm": 30.81029510498047,
      "learning_rate": 0.001780919684608837,
      "loss": 5.5951,
      "step": 46
    },
    {
      "epoch": 23.5,
      "grad_norm": 71.5401840209961,
      "learning_rate": 0.0018196353299264206,
      "loss": 6.0045,
      "step": 47
    },
    {
      "epoch": 24.0,
      "grad_norm": 60.1004524230957,
      "learning_rate": 0.0018583509752440038,
      "loss": 6.1918,
      "step": 48
    },
    {
      "epoch": 24.5,
      "grad_norm": 104.74420928955078,
      "learning_rate": 0.0018970666205615873,
      "loss": 6.206,
      "step": 49
    },
    {
      "epoch": 25.0,
      "grad_norm": 62.644798278808594,
      "learning_rate": 0.0019357822658791707,
      "loss": 6.0121,
      "step": 50
    },
    {
      "epoch": 25.5,
      "grad_norm": 16.257478713989258,
      "learning_rate": 0.001974497911196754,
      "loss": 6.0166,
      "step": 51
    },
    {
      "epoch": 26.0,
      "grad_norm": 7.424127101898193,
      "learning_rate": 0.0020132135565143375,
      "loss": 5.7313,
      "step": 52
    },
    {
      "epoch": 26.5,
      "grad_norm": 2.552856683731079,
      "learning_rate": 0.002051929201831921,
      "loss": 5.7966,
      "step": 53
    },
    {
      "epoch": 27.0,
      "grad_norm": 3.6565041542053223,
      "learning_rate": 0.0020906448471495046,
      "loss": 6.1118,
      "step": 54
    },
    {
      "epoch": 27.5,
      "grad_norm": 1.5686776638031006,
      "learning_rate": 0.002129360492467088,
      "loss": 5.846,
      "step": 55
    },
    {
      "epoch": 28.0,
      "grad_norm": 3.645956039428711,
      "learning_rate": 0.002168076137784671,
      "loss": 5.9944,
      "step": 56
    },
    {
      "epoch": 28.5,
      "grad_norm": 1.484169602394104,
      "learning_rate": 0.0022067917831022545,
      "loss": 5.9344,
      "step": 57
    },
    {
      "epoch": 29.0,
      "grad_norm": 2.570319414138794,
      "learning_rate": 0.002245507428419838,
      "loss": 5.8885,
      "step": 58
    },
    {
      "epoch": 29.5,
      "grad_norm": 3.302351236343384,
      "learning_rate": 0.0022842230737374217,
      "loss": 5.9198,
      "step": 59
    },
    {
      "epoch": 30.0,
      "grad_norm": 5.939265251159668,
      "learning_rate": 0.002322938719055005,
      "loss": 5.8028,
      "step": 60
    },
    {
      "epoch": 30.5,
      "grad_norm": 6.320466995239258,
      "learning_rate": 0.002361654364372588,
      "loss": 6.0539,
      "step": 61
    },
    {
      "epoch": 31.0,
      "grad_norm": 7.600594997406006,
      "learning_rate": 0.0024003700096901716,
      "loss": 5.6981,
      "step": 62
    },
    {
      "epoch": 31.5,
      "grad_norm": 4.775447368621826,
      "learning_rate": 0.002439085655007755,
      "loss": 6.0805,
      "step": 63
    },
    {
      "epoch": 32.0,
      "grad_norm": 5.697203159332275,
      "learning_rate": 0.0024778013003253388,
      "loss": 5.8461,
      "step": 64
    },
    {
      "epoch": 32.5,
      "grad_norm": 11.477362632751465,
      "learning_rate": 0.002516516945642922,
      "loss": 6.01,
      "step": 65
    },
    {
      "epoch": 33.0,
      "grad_norm": 13.788891792297363,
      "learning_rate": 0.002555232590960505,
      "loss": 6.2254,
      "step": 66
    },
    {
      "epoch": 33.5,
      "grad_norm": 4.015852451324463,
      "learning_rate": 0.0025939482362780887,
      "loss": 5.9508,
      "step": 67
    },
    {
      "epoch": 34.0,
      "grad_norm": 5.740504264831543,
      "learning_rate": 0.0026326638815956723,
      "loss": 5.9393,
      "step": 68
    },
    {
      "epoch": 34.5,
      "grad_norm": 3.796664237976074,
      "learning_rate": 0.002671379526913256,
      "loss": 6.127,
      "step": 69
    },
    {
      "epoch": 35.0,
      "grad_norm": 2.5134105682373047,
      "learning_rate": 0.002710095172230839,
      "loss": 5.7679,
      "step": 70
    },
    {
      "epoch": 35.5,
      "grad_norm": 2.2102034091949463,
      "learning_rate": 0.002748810817548422,
      "loss": 5.9515,
      "step": 71
    },
    {
      "epoch": 36.0,
      "grad_norm": 1.9021968841552734,
      "learning_rate": 0.0027875264628660057,
      "loss": 6.0659,
      "step": 72
    },
    {
      "epoch": 36.5,
      "grad_norm": 2.061081886291504,
      "learning_rate": 0.0028262421081835893,
      "loss": 6.0158,
      "step": 73
    },
    {
      "epoch": 37.0,
      "grad_norm": 4.314722061157227,
      "learning_rate": 0.002864957753501173,
      "loss": 6.0943,
      "step": 74
    },
    {
      "epoch": 37.5,
      "grad_norm": 5.295294284820557,
      "learning_rate": 0.002903673398818756,
      "loss": 5.8686,
      "step": 75
    },
    {
      "epoch": 38.0,
      "grad_norm": 1.7118325233459473,
      "learning_rate": 0.0029423890441363392,
      "loss": 6.2029,
      "step": 76
    },
    {
      "epoch": 38.5,
      "grad_norm": 2.677407741546631,
      "learning_rate": 0.002981104689453923,
      "loss": 6.0655,
      "step": 77
    },
    {
      "epoch": 39.0,
      "grad_norm": 2.271101474761963,
      "learning_rate": 0.0030198203347715064,
      "loss": 5.7029,
      "step": 78
    },
    {
      "epoch": 39.5,
      "grad_norm": 1.7410012483596802,
      "learning_rate": 0.00305853598008909,
      "loss": 5.9942,
      "step": 79
    },
    {
      "epoch": 40.0,
      "grad_norm": 3.4668052196502686,
      "learning_rate": 0.003097251625406673,
      "loss": 5.9023,
      "step": 80
    },
    {
      "epoch": 40.0,
      "eval_brier_0th_event": 0.19446659105720138,
      "eval_brier_0th_event_n": 249,
      "eval_brier_avg": 0.19446659105720138,
      "eval_brier_weighted_avg": 0.19446659105720138,
      "eval_ipcw": 0.6443838137254084,
      "eval_ipcw_0th_event": 0.6443838137254084,
      "eval_ipcw_0th_event_0.25": 0.7232297678362031,
      "eval_ipcw_0th_event_0.5": 0.6635265206134102,
      "eval_ipcw_0th_event_0.75": 0.6508544529232386,
      "eval_ipcw_0th_event_1.0": 0.6443838137254084,
      "eval_ipcw_0th_event_n": 249,
      "eval_ipcw_avg": 0.6704986387745651,
      "eval_ipcw_avg_0th_event": 0.6704986387745651,
      "eval_ipcw_weighted_avg": 0.6704986387745651,
      "eval_loss": 2.852292776107788,
      "eval_runtime": 2.7625,
      "eval_samples_per_second": 160.723,
      "eval_steps_per_second": 0.362,
      "step": 80
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 12488832000.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
