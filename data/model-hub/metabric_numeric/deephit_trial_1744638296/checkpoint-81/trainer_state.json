{
  "best_global_step": 81,
  "best_metric": 0.6762343321032287,
  "best_model_checkpoint": "./data/model-hub/metabric_numeric/deephit_trial_1744638296/checkpoint-81",
  "epoch": 40.5,
  "eval_steps": 1,
  "global_step": 81,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 70.6699447631836,
      "learning_rate": 3.871564531758342e-05,
      "loss": 7.2576,
      "step": 1
    },
    {
      "epoch": 1.0,
      "grad_norm": 130.14390563964844,
      "learning_rate": 7.743129063516684e-05,
      "loss": 6.2261,
      "step": 2
    },
    {
      "epoch": 1.5,
      "grad_norm": 61.43074417114258,
      "learning_rate": 0.00011614693595275023,
      "loss": 6.017,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 71.07087707519531,
      "learning_rate": 0.00015486258127033367,
      "loss": 5.2938,
      "step": 4
    },
    {
      "epoch": 2.5,
      "grad_norm": 55.106475830078125,
      "learning_rate": 0.00019357822658791707,
      "loss": 5.3356,
      "step": 5
    },
    {
      "epoch": 3.0,
      "grad_norm": 33.25456619262695,
      "learning_rate": 0.00023229387190550047,
      "loss": 5.4566,
      "step": 6
    },
    {
      "epoch": 3.5,
      "grad_norm": 31.075849533081055,
      "learning_rate": 0.00027100951722308387,
      "loss": 4.9822,
      "step": 7
    },
    {
      "epoch": 4.0,
      "grad_norm": 32.54999542236328,
      "learning_rate": 0.00030972516254066735,
      "loss": 5.1409,
      "step": 8
    },
    {
      "epoch": 4.5,
      "grad_norm": 22.43073844909668,
      "learning_rate": 0.0003484408078582507,
      "loss": 4.9779,
      "step": 9
    },
    {
      "epoch": 5.0,
      "grad_norm": 13.139445304870605,
      "learning_rate": 0.00038715645317583414,
      "loss": 5.1882,
      "step": 10
    },
    {
      "epoch": 5.5,
      "grad_norm": 14.652204513549805,
      "learning_rate": 0.00042587209849341757,
      "loss": 5.1775,
      "step": 11
    },
    {
      "epoch": 6.0,
      "grad_norm": 11.584192276000977,
      "learning_rate": 0.00046458774381100094,
      "loss": 5.0431,
      "step": 12
    },
    {
      "epoch": 6.5,
      "grad_norm": 8.744097709655762,
      "learning_rate": 0.0005033033891285844,
      "loss": 5.1048,
      "step": 13
    },
    {
      "epoch": 7.0,
      "grad_norm": 8.599966049194336,
      "learning_rate": 0.0005420190344461677,
      "loss": 5.5411,
      "step": 14
    },
    {
      "epoch": 7.5,
      "grad_norm": 8.050618171691895,
      "learning_rate": 0.0005807346797637512,
      "loss": 5.3347,
      "step": 15
    },
    {
      "epoch": 8.0,
      "grad_norm": 8.335586547851562,
      "learning_rate": 0.0006194503250813347,
      "loss": 5.5222,
      "step": 16
    },
    {
      "epoch": 8.5,
      "grad_norm": 7.7157440185546875,
      "learning_rate": 0.0006581659703989181,
      "loss": 5.498,
      "step": 17
    },
    {
      "epoch": 9.0,
      "grad_norm": 6.252488136291504,
      "learning_rate": 0.0006968816157165014,
      "loss": 5.5286,
      "step": 18
    },
    {
      "epoch": 9.5,
      "grad_norm": 4.625764846801758,
      "learning_rate": 0.0007355972610340848,
      "loss": 5.6412,
      "step": 19
    },
    {
      "epoch": 10.0,
      "grad_norm": 6.41549015045166,
      "learning_rate": 0.0007743129063516683,
      "loss": 5.6279,
      "step": 20
    },
    {
      "epoch": 10.5,
      "grad_norm": 3.946511745452881,
      "learning_rate": 0.0008130285516692518,
      "loss": 5.7188,
      "step": 21
    },
    {
      "epoch": 11.0,
      "grad_norm": 4.947089672088623,
      "learning_rate": 0.0008517441969868351,
      "loss": 5.5842,
      "step": 22
    },
    {
      "epoch": 11.5,
      "grad_norm": 3.652296304702759,
      "learning_rate": 0.0008904598423044185,
      "loss": 5.7309,
      "step": 23
    },
    {
      "epoch": 12.0,
      "grad_norm": 6.107036590576172,
      "learning_rate": 0.0009291754876220019,
      "loss": 5.7777,
      "step": 24
    },
    {
      "epoch": 12.5,
      "grad_norm": 4.855000972747803,
      "learning_rate": 0.0009678911329395854,
      "loss": 5.9355,
      "step": 25
    },
    {
      "epoch": 13.0,
      "grad_norm": 3.2268903255462646,
      "learning_rate": 0.0010066067782571687,
      "loss": 5.7988,
      "step": 26
    },
    {
      "epoch": 13.5,
      "grad_norm": 3.2624876499176025,
      "learning_rate": 0.0010453224235747523,
      "loss": 5.7196,
      "step": 27
    },
    {
      "epoch": 14.0,
      "grad_norm": 4.071224212646484,
      "learning_rate": 0.0010840380688923355,
      "loss": 6.0813,
      "step": 28
    },
    {
      "epoch": 14.5,
      "grad_norm": 3.528355121612549,
      "learning_rate": 0.001122753714209919,
      "loss": 5.7591,
      "step": 29
    },
    {
      "epoch": 15.0,
      "grad_norm": 4.732854843139648,
      "learning_rate": 0.0011614693595275024,
      "loss": 6.0097,
      "step": 30
    },
    {
      "epoch": 15.5,
      "grad_norm": 2.959465742111206,
      "learning_rate": 0.0012001850048450858,
      "loss": 6.1012,
      "step": 31
    },
    {
      "epoch": 16.0,
      "grad_norm": 8.285140991210938,
      "learning_rate": 0.0012389006501626694,
      "loss": 5.5654,
      "step": 32
    },
    {
      "epoch": 16.5,
      "grad_norm": 5.214211463928223,
      "learning_rate": 0.0012776162954802525,
      "loss": 5.828,
      "step": 33
    },
    {
      "epoch": 17.0,
      "grad_norm": 5.472790718078613,
      "learning_rate": 0.0013163319407978361,
      "loss": 6.1709,
      "step": 34
    },
    {
      "epoch": 17.5,
      "grad_norm": 4.16525411605835,
      "learning_rate": 0.0013550475861154195,
      "loss": 5.9771,
      "step": 35
    },
    {
      "epoch": 18.0,
      "grad_norm": 5.6707868576049805,
      "learning_rate": 0.0013937632314330029,
      "loss": 5.8078,
      "step": 36
    },
    {
      "epoch": 18.5,
      "grad_norm": 6.732842922210693,
      "learning_rate": 0.0014324788767505865,
      "loss": 5.9318,
      "step": 37
    },
    {
      "epoch": 19.0,
      "grad_norm": 10.435927391052246,
      "learning_rate": 0.0014711945220681696,
      "loss": 5.8857,
      "step": 38
    },
    {
      "epoch": 19.5,
      "grad_norm": 7.928421974182129,
      "learning_rate": 0.0015099101673857532,
      "loss": 6.0794,
      "step": 39
    },
    {
      "epoch": 20.0,
      "grad_norm": 8.234302520751953,
      "learning_rate": 0.0015486258127033366,
      "loss": 5.6915,
      "step": 40
    },
    {
      "epoch": 20.5,
      "grad_norm": 8.9523286819458,
      "learning_rate": 0.00158734145802092,
      "loss": 6.0514,
      "step": 41
    },
    {
      "epoch": 21.0,
      "grad_norm": 10.771988868713379,
      "learning_rate": 0.0016260571033385035,
      "loss": 5.8094,
      "step": 42
    },
    {
      "epoch": 21.5,
      "grad_norm": 7.5984368324279785,
      "learning_rate": 0.0016647727486560867,
      "loss": 5.9832,
      "step": 43
    },
    {
      "epoch": 22.0,
      "grad_norm": 6.825169086456299,
      "learning_rate": 0.0017034883939736703,
      "loss": 6.1264,
      "step": 44
    },
    {
      "epoch": 22.5,
      "grad_norm": 8.407735824584961,
      "learning_rate": 0.0017422040392912536,
      "loss": 6.1669,
      "step": 45
    },
    {
      "epoch": 23.0,
      "grad_norm": 7.648579120635986,
      "learning_rate": 0.001780919684608837,
      "loss": 5.6742,
      "step": 46
    },
    {
      "epoch": 23.5,
      "grad_norm": 5.113089084625244,
      "learning_rate": 0.0018196353299264206,
      "loss": 6.108,
      "step": 47
    },
    {
      "epoch": 24.0,
      "grad_norm": 5.88223934173584,
      "learning_rate": 0.0018583509752440038,
      "loss": 5.6628,
      "step": 48
    },
    {
      "epoch": 24.5,
      "grad_norm": 6.104637145996094,
      "learning_rate": 0.0018970666205615873,
      "loss": 6.0821,
      "step": 49
    },
    {
      "epoch": 25.0,
      "grad_norm": 5.487792015075684,
      "learning_rate": 0.0019357822658791707,
      "loss": 5.9772,
      "step": 50
    },
    {
      "epoch": 25.5,
      "grad_norm": 4.907717704772949,
      "learning_rate": 0.001974497911196754,
      "loss": 5.9498,
      "step": 51
    },
    {
      "epoch": 26.0,
      "grad_norm": 5.473494052886963,
      "learning_rate": 0.0020132135565143375,
      "loss": 5.9316,
      "step": 52
    },
    {
      "epoch": 26.5,
      "grad_norm": 7.312976360321045,
      "learning_rate": 0.002051929201831921,
      "loss": 5.9735,
      "step": 53
    },
    {
      "epoch": 27.0,
      "grad_norm": 4.917716979980469,
      "learning_rate": 0.0020906448471495046,
      "loss": 6.1565,
      "step": 54
    },
    {
      "epoch": 27.5,
      "grad_norm": 5.6027326583862305,
      "learning_rate": 0.002129360492467088,
      "loss": 6.0453,
      "step": 55
    },
    {
      "epoch": 28.0,
      "grad_norm": 9.917489051818848,
      "learning_rate": 0.002168076137784671,
      "loss": 6.0052,
      "step": 56
    },
    {
      "epoch": 28.5,
      "grad_norm": 3.822031021118164,
      "learning_rate": 0.0022067917831022545,
      "loss": 5.9723,
      "step": 57
    },
    {
      "epoch": 29.0,
      "grad_norm": 4.946063995361328,
      "learning_rate": 0.002245507428419838,
      "loss": 6.1142,
      "step": 58
    },
    {
      "epoch": 29.5,
      "grad_norm": 4.424148082733154,
      "learning_rate": 0.0022842230737374217,
      "loss": 6.1259,
      "step": 59
    },
    {
      "epoch": 30.0,
      "grad_norm": 4.838014125823975,
      "learning_rate": 0.002322938719055005,
      "loss": 5.737,
      "step": 60
    },
    {
      "epoch": 30.5,
      "grad_norm": 2.8413867950439453,
      "learning_rate": 0.002361654364372588,
      "loss": 6.2049,
      "step": 61
    },
    {
      "epoch": 31.0,
      "grad_norm": 6.328024864196777,
      "learning_rate": 0.0024003700096901716,
      "loss": 5.5926,
      "step": 62
    },
    {
      "epoch": 31.5,
      "grad_norm": 4.324715614318848,
      "learning_rate": 0.002439085655007755,
      "loss": 5.9652,
      "step": 63
    },
    {
      "epoch": 32.0,
      "grad_norm": 9.367559432983398,
      "learning_rate": 0.0024778013003253388,
      "loss": 6.1133,
      "step": 64
    },
    {
      "epoch": 32.5,
      "grad_norm": 10.22609806060791,
      "learning_rate": 0.002516516945642922,
      "loss": 5.9312,
      "step": 65
    },
    {
      "epoch": 33.0,
      "grad_norm": 6.723674297332764,
      "learning_rate": 0.002555232590960505,
      "loss": 6.1573,
      "step": 66
    },
    {
      "epoch": 33.5,
      "grad_norm": 4.897307872772217,
      "learning_rate": 0.0025939482362780887,
      "loss": 5.8609,
      "step": 67
    },
    {
      "epoch": 34.0,
      "grad_norm": 8.398360252380371,
      "learning_rate": 0.0026326638815956723,
      "loss": 6.3611,
      "step": 68
    },
    {
      "epoch": 34.5,
      "grad_norm": 13.256660461425781,
      "learning_rate": 0.002671379526913256,
      "loss": 5.9821,
      "step": 69
    },
    {
      "epoch": 35.0,
      "grad_norm": 9.982965469360352,
      "learning_rate": 0.002710095172230839,
      "loss": 5.943,
      "step": 70
    },
    {
      "epoch": 35.5,
      "grad_norm": 7.571961402893066,
      "learning_rate": 0.002748810817548422,
      "loss": 5.7766,
      "step": 71
    },
    {
      "epoch": 36.0,
      "grad_norm": 2.9110965728759766,
      "learning_rate": 0.0027875264628660057,
      "loss": 6.2928,
      "step": 72
    },
    {
      "epoch": 36.5,
      "grad_norm": 6.799653053283691,
      "learning_rate": 0.0028262421081835893,
      "loss": 6.0297,
      "step": 73
    },
    {
      "epoch": 37.0,
      "grad_norm": 8.230307579040527,
      "learning_rate": 0.002864957753501173,
      "loss": 5.8537,
      "step": 74
    },
    {
      "epoch": 37.5,
      "grad_norm": 5.645284175872803,
      "learning_rate": 0.002903673398818756,
      "loss": 5.9221,
      "step": 75
    },
    {
      "epoch": 38.0,
      "grad_norm": 13.152122497558594,
      "learning_rate": 0.0029423890441363392,
      "loss": 5.9574,
      "step": 76
    },
    {
      "epoch": 38.5,
      "grad_norm": 10.921666145324707,
      "learning_rate": 0.002981104689453923,
      "loss": 6.111,
      "step": 77
    },
    {
      "epoch": 39.0,
      "grad_norm": 3.7049927711486816,
      "learning_rate": 0.0030198203347715064,
      "loss": 5.856,
      "step": 78
    },
    {
      "epoch": 39.5,
      "grad_norm": 2.8021295070648193,
      "learning_rate": 0.00305853598008909,
      "loss": 6.0371,
      "step": 79
    },
    {
      "epoch": 40.0,
      "grad_norm": 7.523502349853516,
      "learning_rate": 0.003097251625406673,
      "loss": 5.8339,
      "step": 80
    },
    {
      "epoch": 40.0,
      "eval_brier_0th_event": 0.0,
      "eval_brier_0th_event_n": 276,
      "eval_brier_avg": 0.0,
      "eval_brier_weighted_avg": 0.0,
      "eval_ipcw": 0.6178438359482598,
      "eval_ipcw_0th_event": 0.6178438359482598,
      "eval_ipcw_0th_event_0.25": 0.7301336948844473,
      "eval_ipcw_0th_event_0.5": 0.6860396023790497,
      "eval_ipcw_0th_event_0.75": 0.6622043208018709,
      "eval_ipcw_0th_event_1.0": 0.6178438359482598,
      "eval_ipcw_0th_event_n": 276,
      "eval_ipcw_avg": 0.6740553635034069,
      "eval_ipcw_avg_0th_event": 0.6740553635034069,
      "eval_ipcw_weighted_avg": 0.6740553635034069,
      "eval_loss": 2.946964740753174,
      "eval_runtime": 0.1242,
      "eval_samples_per_second": 3574.794,
      "eval_steps_per_second": 8.051,
      "step": 80
    },
    {
      "epoch": 40.5,
      "grad_norm": 5.950723648071289,
      "learning_rate": 0.00309724259639599,
      "loss": 5.8084,
      "step": 81
    },
    {
      "epoch": 40.5,
      "eval_brier_0th_event": 0.0,
      "eval_brier_0th_event_n": 276,
      "eval_brier_avg": 0.0,
      "eval_brier_weighted_avg": 0.0,
      "eval_ipcw": 0.6194966558140841,
      "eval_ipcw_0th_event": 0.6194966558140841,
      "eval_ipcw_0th_event_0.25": 0.727668771212108,
      "eval_ipcw_0th_event_0.5": 0.6923560828625973,
      "eval_ipcw_0th_event_0.75": 0.6654158185241252,
      "eval_ipcw_0th_event_1.0": 0.6194966558140841,
      "eval_ipcw_0th_event_n": 276,
      "eval_ipcw_avg": 0.6762343321032287,
      "eval_ipcw_avg_0th_event": 0.6762343321032287,
      "eval_ipcw_weighted_avg": 0.6762343321032287,
      "eval_loss": 2.9680275917053223,
      "eval_runtime": 0.1101,
      "eval_samples_per_second": 4032.696,
      "eval_steps_per_second": 9.083,
      "step": 81
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 19448632320.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
