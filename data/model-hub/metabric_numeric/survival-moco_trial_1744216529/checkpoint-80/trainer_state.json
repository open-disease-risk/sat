{
  "best_global_step": 80,
  "best_metric": 0.6506180689042712,
  "best_model_checkpoint": "./data/model-hub/metabric_numeric/survival-moco_trial_1744216529/checkpoint-80",
  "epoch": 40.0,
  "eval_steps": 1,
  "global_step": 80,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 0.424904465675354,
      "learning_rate": 1.3846278212454011e-05,
      "loss": 1.5627,
      "step": 1
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.4585990607738495,
      "learning_rate": 2.7692556424908023e-05,
      "loss": 1.6011,
      "step": 2
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.41064053773880005,
      "learning_rate": 4.153883463736203e-05,
      "loss": 1.5671,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.4684845209121704,
      "learning_rate": 5.5385112849816046e-05,
      "loss": 1.5997,
      "step": 4
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.39967629313468933,
      "learning_rate": 6.923139106227005e-05,
      "loss": 1.5705,
      "step": 5
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.44749894738197327,
      "learning_rate": 8.307766927472407e-05,
      "loss": 1.585,
      "step": 6
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.48193684220314026,
      "learning_rate": 9.692394748717806e-05,
      "loss": 1.5626,
      "step": 7
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.33260655403137207,
      "learning_rate": 0.00011077022569963209,
      "loss": 1.6037,
      "step": 8
    },
    {
      "epoch": 4.5,
      "grad_norm": 0.39595213532447815,
      "learning_rate": 0.0001246165039120861,
      "loss": 1.5644,
      "step": 9
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.45649829506874084,
      "learning_rate": 0.0001384627821245401,
      "loss": 1.5889,
      "step": 10
    },
    {
      "epoch": 5.5,
      "grad_norm": 0.38839733600616455,
      "learning_rate": 0.00015230906033699413,
      "loss": 1.5669,
      "step": 11
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.419847309589386,
      "learning_rate": 0.00016615533854944813,
      "loss": 1.5801,
      "step": 12
    },
    {
      "epoch": 6.5,
      "grad_norm": 0.4464205503463745,
      "learning_rate": 0.00018000161676190213,
      "loss": 1.592,
      "step": 13
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.3107052445411682,
      "learning_rate": 0.00019384789497435613,
      "loss": 1.5524,
      "step": 14
    },
    {
      "epoch": 7.5,
      "grad_norm": 0.3786899745464325,
      "learning_rate": 0.00020769417318681016,
      "loss": 1.5926,
      "step": 15
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.3444349765777588,
      "learning_rate": 0.00022154045139926418,
      "loss": 1.543,
      "step": 16
    },
    {
      "epoch": 8.5,
      "grad_norm": 0.3459117114543915,
      "learning_rate": 0.00023538672961171818,
      "loss": 1.5781,
      "step": 17
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.35589542984962463,
      "learning_rate": 0.0002492330078241722,
      "loss": 1.5558,
      "step": 18
    },
    {
      "epoch": 9.5,
      "grad_norm": 0.3577595055103302,
      "learning_rate": 0.0002630792860366262,
      "loss": 1.5652,
      "step": 19
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.34724345803260803,
      "learning_rate": 0.0002769255642490802,
      "loss": 1.5764,
      "step": 20
    },
    {
      "epoch": 10.5,
      "grad_norm": 0.36963534355163574,
      "learning_rate": 0.00029077184246153423,
      "loss": 1.5697,
      "step": 21
    },
    {
      "epoch": 11.0,
      "grad_norm": 0.34548425674438477,
      "learning_rate": 0.00030461812067398826,
      "loss": 1.5721,
      "step": 22
    },
    {
      "epoch": 11.5,
      "grad_norm": 0.35250380635261536,
      "learning_rate": 0.00031846439888644223,
      "loss": 1.5992,
      "step": 23
    },
    {
      "epoch": 12.0,
      "grad_norm": 0.37979304790496826,
      "learning_rate": 0.00033231067709889626,
      "loss": 1.5271,
      "step": 24
    },
    {
      "epoch": 12.5,
      "grad_norm": 0.3471028804779053,
      "learning_rate": 0.00034615695531135023,
      "loss": 1.5553,
      "step": 25
    },
    {
      "epoch": 13.0,
      "grad_norm": 0.37425515055656433,
      "learning_rate": 0.00036000323352380426,
      "loss": 1.5899,
      "step": 26
    },
    {
      "epoch": 13.5,
      "grad_norm": 0.4170801043510437,
      "learning_rate": 0.0003738495117362583,
      "loss": 1.5649,
      "step": 27
    },
    {
      "epoch": 14.0,
      "grad_norm": 0.3495880961418152,
      "learning_rate": 0.00038769578994871226,
      "loss": 1.5711,
      "step": 28
    },
    {
      "epoch": 14.5,
      "grad_norm": 0.38349929451942444,
      "learning_rate": 0.0004015420681611663,
      "loss": 1.5604,
      "step": 29
    },
    {
      "epoch": 15.0,
      "grad_norm": 0.4135175943374634,
      "learning_rate": 0.0004153883463736203,
      "loss": 1.5741,
      "step": 30
    },
    {
      "epoch": 15.5,
      "grad_norm": 0.4038693904876709,
      "learning_rate": 0.00042923462458607434,
      "loss": 1.5437,
      "step": 31
    },
    {
      "epoch": 16.0,
      "grad_norm": 0.457643061876297,
      "learning_rate": 0.00044308090279852836,
      "loss": 1.5884,
      "step": 32
    },
    {
      "epoch": 16.5,
      "grad_norm": 0.41005247831344604,
      "learning_rate": 0.00045692718101098234,
      "loss": 1.5725,
      "step": 33
    },
    {
      "epoch": 17.0,
      "grad_norm": 0.4416353404521942,
      "learning_rate": 0.00047077345922343636,
      "loss": 1.5637,
      "step": 34
    },
    {
      "epoch": 17.5,
      "grad_norm": 0.44397789239883423,
      "learning_rate": 0.0004846197374358904,
      "loss": 1.5433,
      "step": 35
    },
    {
      "epoch": 18.0,
      "grad_norm": 0.4011147916316986,
      "learning_rate": 0.0004984660156483444,
      "loss": 1.5738,
      "step": 36
    },
    {
      "epoch": 18.5,
      "grad_norm": 0.4761417806148529,
      "learning_rate": 0.0005123122938607984,
      "loss": 1.544,
      "step": 37
    },
    {
      "epoch": 19.0,
      "grad_norm": 0.43339547514915466,
      "learning_rate": 0.0005261585720732524,
      "loss": 1.5706,
      "step": 38
    },
    {
      "epoch": 19.5,
      "grad_norm": 0.44068288803100586,
      "learning_rate": 0.0005400048502857064,
      "loss": 1.5522,
      "step": 39
    },
    {
      "epoch": 20.0,
      "grad_norm": 0.5275759100914001,
      "learning_rate": 0.0005538511284981604,
      "loss": 1.548,
      "step": 40
    },
    {
      "epoch": 20.5,
      "grad_norm": 0.4582532048225403,
      "learning_rate": 0.0005676974067106143,
      "loss": 1.5587,
      "step": 41
    },
    {
      "epoch": 21.0,
      "grad_norm": 0.48552459478378296,
      "learning_rate": 0.0005815436849230685,
      "loss": 1.5383,
      "step": 42
    },
    {
      "epoch": 21.5,
      "grad_norm": 0.5115753412246704,
      "learning_rate": 0.0005953899631355224,
      "loss": 1.5464,
      "step": 43
    },
    {
      "epoch": 22.0,
      "grad_norm": 0.4202556312084198,
      "learning_rate": 0.0006092362413479765,
      "loss": 1.5442,
      "step": 44
    },
    {
      "epoch": 22.5,
      "grad_norm": 0.5607772469520569,
      "learning_rate": 0.0006230825195604304,
      "loss": 1.5599,
      "step": 45
    },
    {
      "epoch": 23.0,
      "grad_norm": 0.358010470867157,
      "learning_rate": 0.0006369287977728845,
      "loss": 1.5143,
      "step": 46
    },
    {
      "epoch": 23.5,
      "grad_norm": 0.44455766677856445,
      "learning_rate": 0.0006507750759853385,
      "loss": 1.5122,
      "step": 47
    },
    {
      "epoch": 24.0,
      "grad_norm": 0.572309136390686,
      "learning_rate": 0.0006646213541977925,
      "loss": 1.5749,
      "step": 48
    },
    {
      "epoch": 24.5,
      "grad_norm": 0.5221602916717529,
      "learning_rate": 0.0006784676324102465,
      "loss": 1.5639,
      "step": 49
    },
    {
      "epoch": 25.0,
      "grad_norm": 0.5059046745300293,
      "learning_rate": 0.0006923139106227005,
      "loss": 1.4855,
      "step": 50
    },
    {
      "epoch": 25.5,
      "grad_norm": 0.45116889476776123,
      "learning_rate": 0.0007061601888351545,
      "loss": 1.5471,
      "step": 51
    },
    {
      "epoch": 26.0,
      "grad_norm": 0.5692427754402161,
      "learning_rate": 0.0007200064670476085,
      "loss": 1.5207,
      "step": 52
    },
    {
      "epoch": 26.5,
      "grad_norm": 0.5236047506332397,
      "learning_rate": 0.0007338527452600625,
      "loss": 1.5176,
      "step": 53
    },
    {
      "epoch": 27.0,
      "grad_norm": 0.44745200872421265,
      "learning_rate": 0.0007476990234725166,
      "loss": 1.528,
      "step": 54
    },
    {
      "epoch": 27.5,
      "grad_norm": 0.49146369099617004,
      "learning_rate": 0.0007615453016849706,
      "loss": 1.5242,
      "step": 55
    },
    {
      "epoch": 28.0,
      "grad_norm": 0.5327803492546082,
      "learning_rate": 0.0007753915798974245,
      "loss": 1.5123,
      "step": 56
    },
    {
      "epoch": 28.5,
      "grad_norm": 0.49740296602249146,
      "learning_rate": 0.0007892378581098787,
      "loss": 1.5406,
      "step": 57
    },
    {
      "epoch": 29.0,
      "grad_norm": 0.49911823868751526,
      "learning_rate": 0.0008030841363223326,
      "loss": 1.4799,
      "step": 58
    },
    {
      "epoch": 29.5,
      "grad_norm": 0.4938562214374542,
      "learning_rate": 0.0008169304145347867,
      "loss": 1.5275,
      "step": 59
    },
    {
      "epoch": 30.0,
      "grad_norm": 0.44840285181999207,
      "learning_rate": 0.0008307766927472406,
      "loss": 1.4875,
      "step": 60
    },
    {
      "epoch": 30.5,
      "grad_norm": 0.5068345665931702,
      "learning_rate": 0.0008446229709596945,
      "loss": 1.4926,
      "step": 61
    },
    {
      "epoch": 31.0,
      "grad_norm": 0.44366633892059326,
      "learning_rate": 0.0008584692491721487,
      "loss": 1.5116,
      "step": 62
    },
    {
      "epoch": 31.5,
      "grad_norm": 0.4111073911190033,
      "learning_rate": 0.0008723155273846026,
      "loss": 1.4852,
      "step": 63
    },
    {
      "epoch": 32.0,
      "grad_norm": 0.6669958233833313,
      "learning_rate": 0.0008861618055970567,
      "loss": 1.523,
      "step": 64
    },
    {
      "epoch": 32.5,
      "grad_norm": 0.4101235866546631,
      "learning_rate": 0.0009000080838095106,
      "loss": 1.5153,
      "step": 65
    },
    {
      "epoch": 33.0,
      "grad_norm": 0.4649151861667633,
      "learning_rate": 0.0009138543620219647,
      "loss": 1.4725,
      "step": 66
    },
    {
      "epoch": 33.5,
      "grad_norm": 0.4468553364276886,
      "learning_rate": 0.0009277006402344187,
      "loss": 1.4898,
      "step": 67
    },
    {
      "epoch": 34.0,
      "grad_norm": 0.4258274734020233,
      "learning_rate": 0.0009415469184468727,
      "loss": 1.5005,
      "step": 68
    },
    {
      "epoch": 34.5,
      "grad_norm": 0.4757303297519684,
      "learning_rate": 0.0009553931966593268,
      "loss": 1.4932,
      "step": 69
    },
    {
      "epoch": 35.0,
      "grad_norm": 0.4212486743927002,
      "learning_rate": 0.0009692394748717808,
      "loss": 1.4876,
      "step": 70
    },
    {
      "epoch": 35.5,
      "grad_norm": 0.5166820287704468,
      "learning_rate": 0.0009830857530842346,
      "loss": 1.4988,
      "step": 71
    },
    {
      "epoch": 36.0,
      "grad_norm": 0.46738603711128235,
      "learning_rate": 0.0009969320312966888,
      "loss": 1.4534,
      "step": 72
    },
    {
      "epoch": 36.5,
      "grad_norm": 0.5206370949745178,
      "learning_rate": 0.0010107783095091426,
      "loss": 1.4919,
      "step": 73
    },
    {
      "epoch": 37.0,
      "grad_norm": 0.5842281579971313,
      "learning_rate": 0.0010246245877215969,
      "loss": 1.455,
      "step": 74
    },
    {
      "epoch": 37.5,
      "grad_norm": 0.6182060837745667,
      "learning_rate": 0.0010384708659340507,
      "loss": 1.482,
      "step": 75
    },
    {
      "epoch": 38.0,
      "grad_norm": 0.3997642695903778,
      "learning_rate": 0.0010523171441465047,
      "loss": 1.4677,
      "step": 76
    },
    {
      "epoch": 38.5,
      "grad_norm": 0.4401630759239197,
      "learning_rate": 0.0010661634223589588,
      "loss": 1.4629,
      "step": 77
    },
    {
      "epoch": 39.0,
      "grad_norm": 0.7587202787399292,
      "learning_rate": 0.0010800097005714128,
      "loss": 1.4756,
      "step": 78
    },
    {
      "epoch": 39.5,
      "grad_norm": 0.3756825625896454,
      "learning_rate": 0.0010938559787838668,
      "loss": 1.4691,
      "step": 79
    },
    {
      "epoch": 40.0,
      "grad_norm": 0.4522761106491089,
      "learning_rate": 0.0011077022569963208,
      "loss": 1.4513,
      "step": 80
    },
    {
      "epoch": 40.0,
      "eval_brier_0th_event": 0.20293677136617247,
      "eval_brier_0th_event_n": 252,
      "eval_brier_avg": 0.20293677136617247,
      "eval_brier_weighted_avg": 0.20293677136617247,
      "eval_ipcw": 0.5722232684365397,
      "eval_ipcw_0th_event": 0.5722232684365397,
      "eval_ipcw_0th_event_0.25": 0.713353401843378,
      "eval_ipcw_0th_event_0.5": 0.6735574541627412,
      "eval_ipcw_0th_event_0.75": 0.6433381511744259,
      "eval_ipcw_0th_event_1.0": 0.5722232684365397,
      "eval_ipcw_0th_event_n": 252,
      "eval_ipcw_avg": 0.6506180689042712,
      "eval_ipcw_avg_0th_event": 0.6506180689042712,
      "eval_ipcw_weighted_avg": 0.6506180689042712,
      "eval_loss": 0.7137311100959778,
      "eval_runtime": 0.0736,
      "eval_samples_per_second": 6030.494,
      "eval_steps_per_second": 13.582,
      "step": 80
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3435494400.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
