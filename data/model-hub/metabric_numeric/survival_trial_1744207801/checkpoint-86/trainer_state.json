{
  "best_global_step": 86,
  "best_metric": 0.6752733368126023,
  "best_model_checkpoint": "./data/model-hub/metabric_numeric/survival_trial_1744207801/checkpoint-86",
  "epoch": 43.0,
  "eval_steps": 1,
  "global_step": 86,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 3.5593109130859375,
      "learning_rate": 3.272143610207149e-05,
      "loss": 1.6343,
      "step": 1
    },
    {
      "epoch": 1.0,
      "grad_norm": 3.4663984775543213,
      "learning_rate": 6.544287220414298e-05,
      "loss": 1.6277,
      "step": 2
    },
    {
      "epoch": 1.5,
      "grad_norm": 3.261838674545288,
      "learning_rate": 9.816430830621447e-05,
      "loss": 1.6017,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 3.2966957092285156,
      "learning_rate": 0.00013088574440828595,
      "loss": 1.695,
      "step": 4
    },
    {
      "epoch": 2.5,
      "grad_norm": 2.779672145843506,
      "learning_rate": 0.00016360718051035744,
      "loss": 1.602,
      "step": 5
    },
    {
      "epoch": 3.0,
      "grad_norm": 3.424342155456543,
      "learning_rate": 0.00019632861661242893,
      "loss": 1.6415,
      "step": 6
    },
    {
      "epoch": 3.5,
      "grad_norm": 2.9386227130889893,
      "learning_rate": 0.0002290500527145004,
      "loss": 1.607,
      "step": 7
    },
    {
      "epoch": 4.0,
      "grad_norm": 1.7465317249298096,
      "learning_rate": 0.0002617714888165719,
      "loss": 1.6143,
      "step": 8
    },
    {
      "epoch": 4.5,
      "grad_norm": 2.2280571460723877,
      "learning_rate": 0.0002944929249186434,
      "loss": 1.5974,
      "step": 9
    },
    {
      "epoch": 5.0,
      "grad_norm": 2.290674924850464,
      "learning_rate": 0.0003272143610207149,
      "loss": 1.5849,
      "step": 10
    },
    {
      "epoch": 5.5,
      "grad_norm": 2.038386344909668,
      "learning_rate": 0.0003599357971227864,
      "loss": 1.5508,
      "step": 11
    },
    {
      "epoch": 6.0,
      "grad_norm": 2.5787525177001953,
      "learning_rate": 0.00039265723322485786,
      "loss": 1.648,
      "step": 12
    },
    {
      "epoch": 6.5,
      "grad_norm": 2.9096643924713135,
      "learning_rate": 0.00042537866932692935,
      "loss": 1.6189,
      "step": 13
    },
    {
      "epoch": 7.0,
      "grad_norm": 2.4609553813934326,
      "learning_rate": 0.0004581001054290008,
      "loss": 1.5601,
      "step": 14
    },
    {
      "epoch": 7.5,
      "grad_norm": 2.8175301551818848,
      "learning_rate": 0.0004908215415310724,
      "loss": 1.5858,
      "step": 15
    },
    {
      "epoch": 8.0,
      "grad_norm": 3.3304333686828613,
      "learning_rate": 0.0005235429776331438,
      "loss": 1.567,
      "step": 16
    },
    {
      "epoch": 8.5,
      "grad_norm": 2.942582607269287,
      "learning_rate": 0.0005562644137352152,
      "loss": 1.5438,
      "step": 17
    },
    {
      "epoch": 9.0,
      "grad_norm": 3.0294229984283447,
      "learning_rate": 0.0005889858498372868,
      "loss": 1.5537,
      "step": 18
    },
    {
      "epoch": 9.5,
      "grad_norm": 3.026418447494507,
      "learning_rate": 0.0006217072859393582,
      "loss": 1.5226,
      "step": 19
    },
    {
      "epoch": 10.0,
      "grad_norm": 3.0051121711730957,
      "learning_rate": 0.0006544287220414298,
      "loss": 1.5555,
      "step": 20
    },
    {
      "epoch": 10.5,
      "grad_norm": 3.0671064853668213,
      "learning_rate": 0.0006871501581435013,
      "loss": 1.5123,
      "step": 21
    },
    {
      "epoch": 11.0,
      "grad_norm": 3.02795672416687,
      "learning_rate": 0.0007198715942455729,
      "loss": 1.5393,
      "step": 22
    },
    {
      "epoch": 11.5,
      "grad_norm": 2.7085278034210205,
      "learning_rate": 0.0007525930303476442,
      "loss": 1.5234,
      "step": 23
    },
    {
      "epoch": 12.0,
      "grad_norm": 3.29461932182312,
      "learning_rate": 0.0007853144664497157,
      "loss": 1.4661,
      "step": 24
    },
    {
      "epoch": 12.5,
      "grad_norm": 2.6897919178009033,
      "learning_rate": 0.0008180359025517872,
      "loss": 1.5042,
      "step": 25
    },
    {
      "epoch": 13.0,
      "grad_norm": 3.049394130706787,
      "learning_rate": 0.0008507573386538587,
      "loss": 1.4651,
      "step": 26
    },
    {
      "epoch": 13.5,
      "grad_norm": 3.4459612369537354,
      "learning_rate": 0.0008834787747559302,
      "loss": 1.4033,
      "step": 27
    },
    {
      "epoch": 14.0,
      "grad_norm": 2.2707576751708984,
      "learning_rate": 0.0009162002108580016,
      "loss": 1.5272,
      "step": 28
    },
    {
      "epoch": 14.5,
      "grad_norm": 2.6838650703430176,
      "learning_rate": 0.0009489216469600731,
      "loss": 1.4261,
      "step": 29
    },
    {
      "epoch": 15.0,
      "grad_norm": 2.984452486038208,
      "learning_rate": 0.0009816430830621448,
      "loss": 1.4426,
      "step": 30
    },
    {
      "epoch": 15.5,
      "grad_norm": 2.122683525085449,
      "learning_rate": 0.0010143645191642162,
      "loss": 1.4097,
      "step": 31
    },
    {
      "epoch": 16.0,
      "grad_norm": 2.229860305786133,
      "learning_rate": 0.0010470859552662876,
      "loss": 1.4066,
      "step": 32
    },
    {
      "epoch": 16.5,
      "grad_norm": 2.048779010772705,
      "learning_rate": 0.001079807391368359,
      "loss": 1.3927,
      "step": 33
    },
    {
      "epoch": 17.0,
      "grad_norm": 2.314908981323242,
      "learning_rate": 0.0011125288274704305,
      "loss": 1.4097,
      "step": 34
    },
    {
      "epoch": 17.5,
      "grad_norm": 1.4310890436172485,
      "learning_rate": 0.0011452502635725021,
      "loss": 1.3866,
      "step": 35
    },
    {
      "epoch": 18.0,
      "grad_norm": 3.015597105026245,
      "learning_rate": 0.0011779716996745736,
      "loss": 1.3474,
      "step": 36
    },
    {
      "epoch": 18.5,
      "grad_norm": 1.7225220203399658,
      "learning_rate": 0.0012106931357766452,
      "loss": 1.3472,
      "step": 37
    },
    {
      "epoch": 19.0,
      "grad_norm": 2.052834987640381,
      "learning_rate": 0.0012434145718787165,
      "loss": 1.4277,
      "step": 38
    },
    {
      "epoch": 19.5,
      "grad_norm": 1.8625248670578003,
      "learning_rate": 0.001276136007980788,
      "loss": 1.3806,
      "step": 39
    },
    {
      "epoch": 20.0,
      "grad_norm": 1.2921086549758911,
      "learning_rate": 0.0013088574440828595,
      "loss": 1.3714,
      "step": 40
    },
    {
      "epoch": 20.5,
      "grad_norm": 1.8790931701660156,
      "learning_rate": 0.001341578880184931,
      "loss": 1.3368,
      "step": 41
    },
    {
      "epoch": 21.0,
      "grad_norm": 2.419811487197876,
      "learning_rate": 0.0013743003162870026,
      "loss": 1.3717,
      "step": 42
    },
    {
      "epoch": 21.5,
      "grad_norm": 2.133606195449829,
      "learning_rate": 0.0014070217523890738,
      "loss": 1.3521,
      "step": 43
    },
    {
      "epoch": 22.0,
      "grad_norm": 1.5984784364700317,
      "learning_rate": 0.0014397431884911457,
      "loss": 1.3298,
      "step": 44
    },
    {
      "epoch": 22.5,
      "grad_norm": 2.1250877380371094,
      "learning_rate": 0.001472464624593217,
      "loss": 1.3408,
      "step": 45
    },
    {
      "epoch": 23.0,
      "grad_norm": 1.640680193901062,
      "learning_rate": 0.0015051860606952884,
      "loss": 1.3391,
      "step": 46
    },
    {
      "epoch": 23.5,
      "grad_norm": 1.6452245712280273,
      "learning_rate": 0.00153790749679736,
      "loss": 1.3163,
      "step": 47
    },
    {
      "epoch": 24.0,
      "grad_norm": 3.7410192489624023,
      "learning_rate": 0.0015706289328994314,
      "loss": 1.3279,
      "step": 48
    },
    {
      "epoch": 24.5,
      "grad_norm": 1.1617584228515625,
      "learning_rate": 0.001603350369001503,
      "loss": 1.3048,
      "step": 49
    },
    {
      "epoch": 25.0,
      "grad_norm": 2.2750563621520996,
      "learning_rate": 0.0016360718051035743,
      "loss": 1.3505,
      "step": 50
    },
    {
      "epoch": 25.5,
      "grad_norm": 1.752347469329834,
      "learning_rate": 0.0016687932412056457,
      "loss": 1.3197,
      "step": 51
    },
    {
      "epoch": 26.0,
      "grad_norm": 3.9354424476623535,
      "learning_rate": 0.0017015146773077174,
      "loss": 1.3403,
      "step": 52
    },
    {
      "epoch": 26.5,
      "grad_norm": 1.199181079864502,
      "learning_rate": 0.0017342361134097888,
      "loss": 1.3258,
      "step": 53
    },
    {
      "epoch": 27.0,
      "grad_norm": 1.8421728610992432,
      "learning_rate": 0.0017669575495118605,
      "loss": 1.3083,
      "step": 54
    },
    {
      "epoch": 27.5,
      "grad_norm": 2.6304709911346436,
      "learning_rate": 0.001799678985613932,
      "loss": 1.2925,
      "step": 55
    },
    {
      "epoch": 28.0,
      "grad_norm": 1.2198987007141113,
      "learning_rate": 0.0018324004217160031,
      "loss": 1.3329,
      "step": 56
    },
    {
      "epoch": 28.5,
      "grad_norm": 1.3349863290786743,
      "learning_rate": 0.001865121857818075,
      "loss": 1.3194,
      "step": 57
    },
    {
      "epoch": 29.0,
      "grad_norm": 2.0802512168884277,
      "learning_rate": 0.0018978432939201462,
      "loss": 1.2591,
      "step": 58
    },
    {
      "epoch": 29.5,
      "grad_norm": 1.4248095750808716,
      "learning_rate": 0.0019305647300222179,
      "loss": 1.2999,
      "step": 59
    },
    {
      "epoch": 30.0,
      "grad_norm": 2.0731518268585205,
      "learning_rate": 0.0019632861661242895,
      "loss": 1.323,
      "step": 60
    },
    {
      "epoch": 30.5,
      "grad_norm": 1.7946771383285522,
      "learning_rate": 0.0019960076022263605,
      "loss": 1.3086,
      "step": 61
    },
    {
      "epoch": 31.0,
      "grad_norm": 1.4291406869888306,
      "learning_rate": 0.0020287290383284324,
      "loss": 1.278,
      "step": 62
    },
    {
      "epoch": 31.5,
      "grad_norm": 1.2885372638702393,
      "learning_rate": 0.002061450474430504,
      "loss": 1.3093,
      "step": 63
    },
    {
      "epoch": 32.0,
      "grad_norm": 1.2021845579147339,
      "learning_rate": 0.0020941719105325753,
      "loss": 1.275,
      "step": 64
    },
    {
      "epoch": 32.5,
      "grad_norm": 2.006993293762207,
      "learning_rate": 0.0021268933466346467,
      "loss": 1.3089,
      "step": 65
    },
    {
      "epoch": 33.0,
      "grad_norm": 2.261225938796997,
      "learning_rate": 0.002159614782736718,
      "loss": 1.2817,
      "step": 66
    },
    {
      "epoch": 33.5,
      "grad_norm": 1.7163058519363403,
      "learning_rate": 0.00219233621883879,
      "loss": 1.2994,
      "step": 67
    },
    {
      "epoch": 34.0,
      "grad_norm": 2.116412401199341,
      "learning_rate": 0.002225057654940861,
      "loss": 1.284,
      "step": 68
    },
    {
      "epoch": 34.5,
      "grad_norm": 2.3745224475860596,
      "learning_rate": 0.002257779091042933,
      "loss": 1.2971,
      "step": 69
    },
    {
      "epoch": 35.0,
      "grad_norm": 1.8806813955307007,
      "learning_rate": 0.0022905005271450043,
      "loss": 1.2887,
      "step": 70
    },
    {
      "epoch": 35.5,
      "grad_norm": 2.1365737915039062,
      "learning_rate": 0.0023232219632470757,
      "loss": 1.2705,
      "step": 71
    },
    {
      "epoch": 36.0,
      "grad_norm": 1.8461709022521973,
      "learning_rate": 0.002355943399349147,
      "loss": 1.3287,
      "step": 72
    },
    {
      "epoch": 36.5,
      "grad_norm": 2.2125234603881836,
      "learning_rate": 0.0023886648354512186,
      "loss": 1.2496,
      "step": 73
    },
    {
      "epoch": 37.0,
      "grad_norm": 3.5816478729248047,
      "learning_rate": 0.0024213862715532905,
      "loss": 1.3476,
      "step": 74
    },
    {
      "epoch": 37.5,
      "grad_norm": 1.9144233465194702,
      "learning_rate": 0.0024541077076553615,
      "loss": 1.2892,
      "step": 75
    },
    {
      "epoch": 38.0,
      "grad_norm": 2.3266706466674805,
      "learning_rate": 0.002486829143757433,
      "loss": 1.2661,
      "step": 76
    },
    {
      "epoch": 38.5,
      "grad_norm": 1.8290461301803589,
      "learning_rate": 0.0025195505798595048,
      "loss": 1.2989,
      "step": 77
    },
    {
      "epoch": 39.0,
      "grad_norm": 2.470642328262329,
      "learning_rate": 0.002552272015961576,
      "loss": 1.2595,
      "step": 78
    },
    {
      "epoch": 39.5,
      "grad_norm": 1.4582501649856567,
      "learning_rate": 0.0025849934520636476,
      "loss": 1.2615,
      "step": 79
    },
    {
      "epoch": 40.0,
      "grad_norm": 2.7956883907318115,
      "learning_rate": 0.002617714888165719,
      "loss": 1.2914,
      "step": 80
    },
    {
      "epoch": 40.0,
      "eval_brier_0th_event": 0.18229824604726272,
      "eval_brier_0th_event_n": 258,
      "eval_brier_avg": 0.18229824604726272,
      "eval_brier_weighted_avg": 0.18229824604726272,
      "eval_ipcw": 0.6218400831050972,
      "eval_ipcw_0th_event": 0.6218400831050972,
      "eval_ipcw_0th_event_0.25": 0.6954503206789858,
      "eval_ipcw_0th_event_0.5": 0.6764157711633155,
      "eval_ipcw_0th_event_0.75": 0.6774827142973348,
      "eval_ipcw_0th_event_1.0": 0.6218400831050972,
      "eval_ipcw_0th_event_n": 258,
      "eval_ipcw_avg": 0.6677972223111833,
      "eval_ipcw_avg_0th_event": 0.6677972223111833,
      "eval_ipcw_weighted_avg": 0.6677972223111833,
      "eval_loss": 0.6626560091972351,
      "eval_runtime": 0.0754,
      "eval_samples_per_second": 5884.771,
      "eval_steps_per_second": 13.254,
      "step": 80
    },
    {
      "epoch": 40.5,
      "grad_norm": 1.6877168416976929,
      "learning_rate": 0.002617707257085475,
      "loss": 1.2722,
      "step": 81
    },
    {
      "epoch": 40.5,
      "eval_brier_0th_event": 0.18122387487310632,
      "eval_brier_0th_event_n": 258,
      "eval_brier_avg": 0.18122387487310632,
      "eval_brier_weighted_avg": 0.18122387487310632,
      "eval_ipcw": 0.6179840480816896,
      "eval_ipcw_0th_event": 0.6179840480816896,
      "eval_ipcw_0th_event_0.25": 0.6931226830991648,
      "eval_ipcw_0th_event_0.5": 0.676410637013946,
      "eval_ipcw_0th_event_0.75": 0.6780643375345231,
      "eval_ipcw_0th_event_1.0": 0.6179840480816896,
      "eval_ipcw_0th_event_n": 258,
      "eval_ipcw_avg": 0.6663954264323309,
      "eval_ipcw_avg_0th_event": 0.6663954264323309,
      "eval_ipcw_weighted_avg": 0.6663954264323309,
      "eval_loss": 0.6628771424293518,
      "eval_runtime": 0.0735,
      "eval_samples_per_second": 6037.689,
      "eval_steps_per_second": 13.598,
      "step": 81
    },
    {
      "epoch": 41.0,
      "grad_norm": 1.8415031433105469,
      "learning_rate": 0.0026176843639337246,
      "loss": 1.2882,
      "step": 82
    },
    {
      "epoch": 41.0,
      "eval_brier_0th_event": 0.180875349404709,
      "eval_brier_0th_event_n": 258,
      "eval_brier_avg": 0.180875349404709,
      "eval_brier_weighted_avg": 0.180875349404709,
      "eval_ipcw": 0.6180165069140567,
      "eval_ipcw_0th_event": 0.6180165069140567,
      "eval_ipcw_0th_event_0.25": 0.6901103397085351,
      "eval_ipcw_0th_event_0.5": 0.6764431460728227,
      "eval_ipcw_0th_event_0.75": 0.6764924774131327,
      "eval_ipcw_0th_event_1.0": 0.6180165069140567,
      "eval_ipcw_0th_event_n": 258,
      "eval_ipcw_avg": 0.6652656175271369,
      "eval_ipcw_avg_0th_event": 0.6652656175271369,
      "eval_ipcw_weighted_avg": 0.6652656175271369,
      "eval_loss": 0.6630756258964539,
      "eval_runtime": 0.0726,
      "eval_samples_per_second": 6116.214,
      "eval_steps_per_second": 13.775,
      "step": 82
    },
    {
      "epoch": 41.5,
      "grad_norm": 1.8478950262069702,
      "learning_rate": 0.002617646208977419,
      "loss": 1.2957,
      "step": 83
    },
    {
      "epoch": 41.5,
      "eval_brier_0th_event": 0.1810904164156838,
      "eval_brier_0th_event_n": 258,
      "eval_brier_avg": 0.1810904164156838,
      "eval_brier_weighted_avg": 0.1810904164156838,
      "eval_ipcw": 0.6232261382775243,
      "eval_ipcw_0th_event": 0.6232261382775243,
      "eval_ipcw_0th_event_0.25": 0.6889291795864133,
      "eval_ipcw_0th_event_0.5": 0.6763413741775771,
      "eval_ipcw_0th_event_0.75": 0.6757708378476863,
      "eval_ipcw_0th_event_1.0": 0.6232261382775243,
      "eval_ipcw_0th_event_n": 258,
      "eval_ipcw_avg": 0.6660668824723003,
      "eval_ipcw_avg_0th_event": 0.6660668824723003,
      "eval_ipcw_weighted_avg": 0.6660668824723003,
      "eval_loss": 0.6621078848838806,
      "eval_runtime": 0.0734,
      "eval_samples_per_second": 6050.931,
      "eval_steps_per_second": 13.628,
      "step": 83
    },
    {
      "epoch": 42.0,
      "grad_norm": 1.8670984506607056,
      "learning_rate": 0.0026175927926614696,
      "loss": 1.2279,
      "step": 84
    },
    {
      "epoch": 42.0,
      "eval_brier_0th_event": 0.18119204201634695,
      "eval_brier_0th_event_n": 258,
      "eval_brier_avg": 0.18119204201634695,
      "eval_brier_weighted_avg": 0.18119204201634695,
      "eval_ipcw": 0.6305028243283697,
      "eval_ipcw_0th_event": 0.6305028243283697,
      "eval_ipcw_0th_event_0.25": 0.6927949528448066,
      "eval_ipcw_0th_event_0.5": 0.6786048538780844,
      "eval_ipcw_0th_event_0.75": 0.6774647469634373,
      "eval_ipcw_0th_event_1.0": 0.6305028243283697,
      "eval_ipcw_0th_event_n": 258,
      "eval_ipcw_avg": 0.6698418445036745,
      "eval_ipcw_avg_0th_event": 0.6698418445036745,
      "eval_ipcw_weighted_avg": 0.6698418445036745,
      "eval_loss": 0.6594844460487366,
      "eval_runtime": 0.0689,
      "eval_samples_per_second": 6441.504,
      "eval_steps_per_second": 14.508,
      "step": 84
    },
    {
      "epoch": 42.5,
      "grad_norm": 1.9997422695159912,
      "learning_rate": 0.0026175241156087474,
      "loss": 1.2811,
      "step": 85
    },
    {
      "epoch": 42.5,
      "eval_brier_0th_event": 0.18000293161058123,
      "eval_brier_0th_event_n": 258,
      "eval_brier_avg": 0.18000293161058123,
      "eval_brier_weighted_avg": 0.18000293161058123,
      "eval_ipcw": 0.6362888141621247,
      "eval_ipcw_0th_event": 0.6362888141621247,
      "eval_ipcw_0th_event_0.25": 0.6991198631462439,
      "eval_ipcw_0th_event_0.5": 0.6827293185079998,
      "eval_ipcw_0th_event_0.75": 0.6784077525688242,
      "eval_ipcw_0th_event_1.0": 0.6362888141621247,
      "eval_ipcw_0th_event_n": 258,
      "eval_ipcw_avg": 0.6741364370962981,
      "eval_ipcw_avg_0th_event": 0.6741364370962981,
      "eval_ipcw_weighted_avg": 0.6741364370962981,
      "eval_loss": 0.6530662775039673,
      "eval_runtime": 0.0723,
      "eval_samples_per_second": 6142.541,
      "eval_steps_per_second": 13.835,
      "step": 85
    },
    {
      "epoch": 43.0,
      "grad_norm": 2.5626652240753174,
      "learning_rate": 0.0026174401786200727,
      "loss": 1.2912,
      "step": 86
    },
    {
      "epoch": 43.0,
      "eval_brier_0th_event": 0.1794235814151485,
      "eval_brier_0th_event_n": 258,
      "eval_brier_avg": 0.1794235814151485,
      "eval_brier_weighted_avg": 0.1794235814151485,
      "eval_ipcw": 0.6384781502080721,
      "eval_ipcw_0th_event": 0.6384781502080721,
      "eval_ipcw_0th_event_0.25": 0.7003585122581838,
      "eval_ipcw_0th_event_0.5": 0.6828295194801192,
      "eval_ipcw_0th_event_0.75": 0.6794271653040337,
      "eval_ipcw_0th_event_1.0": 0.6384781502080721,
      "eval_ipcw_0th_event_n": 258,
      "eval_ipcw_avg": 0.6752733368126023,
      "eval_ipcw_avg_0th_event": 0.6752733368126023,
      "eval_ipcw_weighted_avg": 0.6752733368126023,
      "eval_loss": 0.6504210233688354,
      "eval_runtime": 0.0717,
      "eval_samples_per_second": 6192.831,
      "eval_steps_per_second": 13.948,
      "step": 86
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 14176955520.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
