{
  "best_global_step": 80,
  "best_metric": 0.5057533584575797,
  "best_model_checkpoint": "./data/model-hub/metabric_numeric/deephit_trial_1744630495/checkpoint-80",
  "epoch": 40.0,
  "eval_steps": 1,
  "global_step": 80,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 122.41507720947266,
      "learning_rate": 1.868483202224763e-07,
      "loss": 7.1272,
      "step": 1
    },
    {
      "epoch": 1.0,
      "grad_norm": 98.06600952148438,
      "learning_rate": 3.736966404449526e-07,
      "loss": 6.1341,
      "step": 2
    },
    {
      "epoch": 1.5,
      "grad_norm": 84.56609344482422,
      "learning_rate": 5.605449606674288e-07,
      "loss": 6.026,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 62.8948860168457,
      "learning_rate": 7.473932808899052e-07,
      "loss": 5.4356,
      "step": 4
    },
    {
      "epoch": 2.5,
      "grad_norm": 67.30001831054688,
      "learning_rate": 9.342416011123815e-07,
      "loss": 5.5528,
      "step": 5
    },
    {
      "epoch": 3.0,
      "grad_norm": 77.95069885253906,
      "learning_rate": 1.1210899213348577e-06,
      "loss": 5.21,
      "step": 6
    },
    {
      "epoch": 3.5,
      "grad_norm": 98.98170471191406,
      "learning_rate": 1.307938241557334e-06,
      "loss": 5.2604,
      "step": 7
    },
    {
      "epoch": 4.0,
      "grad_norm": 127.75300598144531,
      "learning_rate": 1.4947865617798104e-06,
      "loss": 5.6778,
      "step": 8
    },
    {
      "epoch": 4.5,
      "grad_norm": 51.5268669128418,
      "learning_rate": 1.6816348820022868e-06,
      "loss": 5.1408,
      "step": 9
    },
    {
      "epoch": 5.0,
      "grad_norm": 94.45172882080078,
      "learning_rate": 1.868483202224763e-06,
      "loss": 5.6541,
      "step": 10
    },
    {
      "epoch": 5.5,
      "grad_norm": 97.3287124633789,
      "learning_rate": 2.0553315224472396e-06,
      "loss": 5.4911,
      "step": 11
    },
    {
      "epoch": 6.0,
      "grad_norm": 85.1139907836914,
      "learning_rate": 2.2421798426697153e-06,
      "loss": 5.3562,
      "step": 12
    },
    {
      "epoch": 6.5,
      "grad_norm": 97.80799865722656,
      "learning_rate": 2.429028162892192e-06,
      "loss": 5.6486,
      "step": 13
    },
    {
      "epoch": 7.0,
      "grad_norm": 95.125732421875,
      "learning_rate": 2.615876483114668e-06,
      "loss": 5.5832,
      "step": 14
    },
    {
      "epoch": 7.5,
      "grad_norm": 101.36720275878906,
      "learning_rate": 2.8027248033371443e-06,
      "loss": 5.5836,
      "step": 15
    },
    {
      "epoch": 8.0,
      "grad_norm": 56.33656692504883,
      "learning_rate": 2.989573123559621e-06,
      "loss": 5.4729,
      "step": 16
    },
    {
      "epoch": 8.5,
      "grad_norm": 82.01531982421875,
      "learning_rate": 3.176421443782097e-06,
      "loss": 5.5991,
      "step": 17
    },
    {
      "epoch": 9.0,
      "grad_norm": 85.59113311767578,
      "learning_rate": 3.3632697640045736e-06,
      "loss": 5.83,
      "step": 18
    },
    {
      "epoch": 9.5,
      "grad_norm": 77.31060028076172,
      "learning_rate": 3.5501180842270494e-06,
      "loss": 5.8075,
      "step": 19
    },
    {
      "epoch": 10.0,
      "grad_norm": 83.13306427001953,
      "learning_rate": 3.736966404449526e-06,
      "loss": 5.6813,
      "step": 20
    },
    {
      "epoch": 10.5,
      "grad_norm": 90.4014892578125,
      "learning_rate": 3.923814724672002e-06,
      "loss": 5.8837,
      "step": 21
    },
    {
      "epoch": 11.0,
      "grad_norm": 101.51899719238281,
      "learning_rate": 4.110663044894479e-06,
      "loss": 5.7751,
      "step": 22
    },
    {
      "epoch": 11.5,
      "grad_norm": 82.9616928100586,
      "learning_rate": 4.2975113651169545e-06,
      "loss": 6.0259,
      "step": 23
    },
    {
      "epoch": 12.0,
      "grad_norm": 91.86846160888672,
      "learning_rate": 4.484359685339431e-06,
      "loss": 5.8919,
      "step": 24
    },
    {
      "epoch": 12.5,
      "grad_norm": 82.06666564941406,
      "learning_rate": 4.671208005561908e-06,
      "loss": 5.8594,
      "step": 25
    },
    {
      "epoch": 13.0,
      "grad_norm": 82.86518096923828,
      "learning_rate": 4.858056325784384e-06,
      "loss": 5.8841,
      "step": 26
    },
    {
      "epoch": 13.5,
      "grad_norm": 84.7275161743164,
      "learning_rate": 5.04490464600686e-06,
      "loss": 5.8509,
      "step": 27
    },
    {
      "epoch": 14.0,
      "grad_norm": 100.48237609863281,
      "learning_rate": 5.231752966229336e-06,
      "loss": 5.9886,
      "step": 28
    },
    {
      "epoch": 14.5,
      "grad_norm": 79.49826049804688,
      "learning_rate": 5.418601286451812e-06,
      "loss": 6.0136,
      "step": 29
    },
    {
      "epoch": 15.0,
      "grad_norm": 81.1080551147461,
      "learning_rate": 5.6054496066742885e-06,
      "loss": 5.8528,
      "step": 30
    },
    {
      "epoch": 15.5,
      "grad_norm": 107.53138732910156,
      "learning_rate": 5.7922979268967655e-06,
      "loss": 6.0542,
      "step": 31
    },
    {
      "epoch": 16.0,
      "grad_norm": 101.74393463134766,
      "learning_rate": 5.979146247119242e-06,
      "loss": 6.0467,
      "step": 32
    },
    {
      "epoch": 16.5,
      "grad_norm": 96.88807678222656,
      "learning_rate": 6.165994567341718e-06,
      "loss": 5.9162,
      "step": 33
    },
    {
      "epoch": 17.0,
      "grad_norm": 80.10447692871094,
      "learning_rate": 6.352842887564194e-06,
      "loss": 5.8706,
      "step": 34
    },
    {
      "epoch": 17.5,
      "grad_norm": 75.68411254882812,
      "learning_rate": 6.53969120778667e-06,
      "loss": 6.07,
      "step": 35
    },
    {
      "epoch": 18.0,
      "grad_norm": 80.09965515136719,
      "learning_rate": 6.726539528009147e-06,
      "loss": 5.9502,
      "step": 36
    },
    {
      "epoch": 18.5,
      "grad_norm": 114.97167205810547,
      "learning_rate": 6.913387848231623e-06,
      "loss": 5.8423,
      "step": 37
    },
    {
      "epoch": 19.0,
      "grad_norm": 129.12255859375,
      "learning_rate": 7.100236168454099e-06,
      "loss": 6.2384,
      "step": 38
    },
    {
      "epoch": 19.5,
      "grad_norm": 69.25753784179688,
      "learning_rate": 7.287084488676576e-06,
      "loss": 5.8498,
      "step": 39
    },
    {
      "epoch": 20.0,
      "grad_norm": 97.50758361816406,
      "learning_rate": 7.473932808899052e-06,
      "loss": 6.0719,
      "step": 40
    },
    {
      "epoch": 20.5,
      "grad_norm": 75.48242950439453,
      "learning_rate": 7.660781129121527e-06,
      "loss": 6.0863,
      "step": 41
    },
    {
      "epoch": 21.0,
      "grad_norm": 86.19259643554688,
      "learning_rate": 7.847629449344004e-06,
      "loss": 5.9612,
      "step": 42
    },
    {
      "epoch": 21.5,
      "grad_norm": 63.9190673828125,
      "learning_rate": 8.034477769566481e-06,
      "loss": 5.9766,
      "step": 43
    },
    {
      "epoch": 22.0,
      "grad_norm": 69.63201141357422,
      "learning_rate": 8.221326089788958e-06,
      "loss": 5.8207,
      "step": 44
    },
    {
      "epoch": 22.5,
      "grad_norm": 101.95506286621094,
      "learning_rate": 8.408174410011434e-06,
      "loss": 6.0975,
      "step": 45
    },
    {
      "epoch": 23.0,
      "grad_norm": 79.30431365966797,
      "learning_rate": 8.595022730233909e-06,
      "loss": 5.7616,
      "step": 46
    },
    {
      "epoch": 23.5,
      "grad_norm": 63.287010192871094,
      "learning_rate": 8.781871050456386e-06,
      "loss": 5.9507,
      "step": 47
    },
    {
      "epoch": 24.0,
      "grad_norm": 135.92733764648438,
      "learning_rate": 8.968719370678861e-06,
      "loss": 6.0728,
      "step": 48
    },
    {
      "epoch": 24.5,
      "grad_norm": 61.17143630981445,
      "learning_rate": 9.15556769090134e-06,
      "loss": 5.9167,
      "step": 49
    },
    {
      "epoch": 25.0,
      "grad_norm": 107.82673645019531,
      "learning_rate": 9.342416011123815e-06,
      "loss": 6.1637,
      "step": 50
    },
    {
      "epoch": 25.5,
      "grad_norm": 54.282596588134766,
      "learning_rate": 9.52926433134629e-06,
      "loss": 6.0209,
      "step": 51
    },
    {
      "epoch": 26.0,
      "grad_norm": 100.5879135131836,
      "learning_rate": 9.716112651568768e-06,
      "loss": 6.0524,
      "step": 52
    },
    {
      "epoch": 26.5,
      "grad_norm": 59.64080047607422,
      "learning_rate": 9.902960971791243e-06,
      "loss": 5.9749,
      "step": 53
    },
    {
      "epoch": 27.0,
      "grad_norm": 68.7076644897461,
      "learning_rate": 1.008980929201372e-05,
      "loss": 5.7731,
      "step": 54
    },
    {
      "epoch": 27.5,
      "grad_norm": 83.07166290283203,
      "learning_rate": 1.0276657612236197e-05,
      "loss": 6.0724,
      "step": 55
    },
    {
      "epoch": 28.0,
      "grad_norm": 142.2571258544922,
      "learning_rate": 1.0463505932458672e-05,
      "loss": 5.7263,
      "step": 56
    },
    {
      "epoch": 28.5,
      "grad_norm": 52.917152404785156,
      "learning_rate": 1.065035425268115e-05,
      "loss": 6.081,
      "step": 57
    },
    {
      "epoch": 29.0,
      "grad_norm": 123.76994323730469,
      "learning_rate": 1.0837202572903625e-05,
      "loss": 6.0782,
      "step": 58
    },
    {
      "epoch": 29.5,
      "grad_norm": 111.89466857910156,
      "learning_rate": 1.1024050893126102e-05,
      "loss": 5.9759,
      "step": 59
    },
    {
      "epoch": 30.0,
      "grad_norm": 91.79598236083984,
      "learning_rate": 1.1210899213348577e-05,
      "loss": 5.9824,
      "step": 60
    },
    {
      "epoch": 30.5,
      "grad_norm": 113.73978424072266,
      "learning_rate": 1.1397747533571054e-05,
      "loss": 5.9612,
      "step": 61
    },
    {
      "epoch": 31.0,
      "grad_norm": 99.95398712158203,
      "learning_rate": 1.1584595853793531e-05,
      "loss": 6.0033,
      "step": 62
    },
    {
      "epoch": 31.5,
      "grad_norm": 111.6445541381836,
      "learning_rate": 1.1771444174016006e-05,
      "loss": 6.1147,
      "step": 63
    },
    {
      "epoch": 32.0,
      "grad_norm": 64.5733871459961,
      "learning_rate": 1.1958292494238483e-05,
      "loss": 5.9385,
      "step": 64
    },
    {
      "epoch": 32.5,
      "grad_norm": 79.52931213378906,
      "learning_rate": 1.2145140814460959e-05,
      "loss": 5.996,
      "step": 65
    },
    {
      "epoch": 33.0,
      "grad_norm": 123.74555969238281,
      "learning_rate": 1.2331989134683436e-05,
      "loss": 6.0141,
      "step": 66
    },
    {
      "epoch": 33.5,
      "grad_norm": 71.7516098022461,
      "learning_rate": 1.2518837454905913e-05,
      "loss": 5.8269,
      "step": 67
    },
    {
      "epoch": 34.0,
      "grad_norm": 78.97747039794922,
      "learning_rate": 1.2705685775128388e-05,
      "loss": 6.3524,
      "step": 68
    },
    {
      "epoch": 34.5,
      "grad_norm": 82.42889404296875,
      "learning_rate": 1.2892534095350865e-05,
      "loss": 5.794,
      "step": 69
    },
    {
      "epoch": 35.0,
      "grad_norm": 62.880638122558594,
      "learning_rate": 1.307938241557334e-05,
      "loss": 6.0137,
      "step": 70
    },
    {
      "epoch": 35.5,
      "grad_norm": 85.03738403320312,
      "learning_rate": 1.3266230735795816e-05,
      "loss": 6.0303,
      "step": 71
    },
    {
      "epoch": 36.0,
      "grad_norm": 103.24420166015625,
      "learning_rate": 1.3453079056018294e-05,
      "loss": 5.9319,
      "step": 72
    },
    {
      "epoch": 36.5,
      "grad_norm": 100.99405670166016,
      "learning_rate": 1.363992737624077e-05,
      "loss": 6.1056,
      "step": 73
    },
    {
      "epoch": 37.0,
      "grad_norm": 79.40848541259766,
      "learning_rate": 1.3826775696463247e-05,
      "loss": 5.7691,
      "step": 74
    },
    {
      "epoch": 37.5,
      "grad_norm": 133.82968139648438,
      "learning_rate": 1.4013624016685722e-05,
      "loss": 5.9648,
      "step": 75
    },
    {
      "epoch": 38.0,
      "grad_norm": 85.16635131835938,
      "learning_rate": 1.4200472336908197e-05,
      "loss": 6.1238,
      "step": 76
    },
    {
      "epoch": 38.5,
      "grad_norm": 97.99787139892578,
      "learning_rate": 1.4387320657130674e-05,
      "loss": 6.1576,
      "step": 77
    },
    {
      "epoch": 39.0,
      "grad_norm": 74.49333953857422,
      "learning_rate": 1.4574168977353151e-05,
      "loss": 5.798,
      "step": 78
    },
    {
      "epoch": 39.5,
      "grad_norm": 65.39994812011719,
      "learning_rate": 1.4761017297575629e-05,
      "loss": 6.0925,
      "step": 79
    },
    {
      "epoch": 40.0,
      "grad_norm": 84.68997955322266,
      "learning_rate": 1.4947865617798104e-05,
      "loss": 5.7799,
      "step": 80
    },
    {
      "epoch": 40.0,
      "eval_brier_0th_event": 0.0,
      "eval_brier_0th_event_n": 276,
      "eval_brier_avg": 0.0,
      "eval_brier_weighted_avg": 0.0,
      "eval_ipcw": 0.5215046940530297,
      "eval_ipcw_0th_event": 0.5215046940530297,
      "eval_ipcw_0th_event_0.25": 0.499240467385067,
      "eval_ipcw_0th_event_0.5": 0.49659555324586335,
      "eval_ipcw_0th_event_0.75": 0.5056727191463587,
      "eval_ipcw_0th_event_1.0": 0.5215046940530297,
      "eval_ipcw_0th_event_n": 276,
      "eval_ipcw_avg": 0.5057533584575797,
      "eval_ipcw_avg_0th_event": 0.5057533584575797,
      "eval_ipcw_weighted_avg": 0.5057533584575797,
      "eval_loss": 2.902888059616089,
      "eval_runtime": 0.1005,
      "eval_samples_per_second": 4416.114,
      "eval_steps_per_second": 9.946,
      "step": 80
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 14534784000.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
