{
  "best_global_step": 80,
  "best_metric": 0.6485805448564266,
  "best_model_checkpoint": "./data/model-hub/metabric_numeric/deephit_trial_1744648879/checkpoint-80",
  "epoch": 40.0,
  "eval_steps": 1,
  "global_step": 80,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 11.79997730255127,
      "learning_rate": 1.390229684953251e-06,
      "loss": 6.2104,
      "step": 1
    },
    {
      "epoch": 1.0,
      "grad_norm": 11.241471290588379,
      "learning_rate": 2.780459369906502e-06,
      "loss": 6.07,
      "step": 2
    },
    {
      "epoch": 1.5,
      "grad_norm": 11.286063194274902,
      "learning_rate": 4.170689054859753e-06,
      "loss": 5.4191,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 12.190168380737305,
      "learning_rate": 5.560918739813004e-06,
      "loss": 5.3529,
      "step": 4
    },
    {
      "epoch": 2.5,
      "grad_norm": 11.83842945098877,
      "learning_rate": 6.9511484247662545e-06,
      "loss": 5.3739,
      "step": 5
    },
    {
      "epoch": 3.0,
      "grad_norm": 14.784029960632324,
      "learning_rate": 8.341378109719506e-06,
      "loss": 4.911,
      "step": 6
    },
    {
      "epoch": 3.5,
      "grad_norm": 14.286612510681152,
      "learning_rate": 9.731607794672756e-06,
      "loss": 5.1378,
      "step": 7
    },
    {
      "epoch": 4.0,
      "grad_norm": 14.470837593078613,
      "learning_rate": 1.1121837479626008e-05,
      "loss": 5.5173,
      "step": 8
    },
    {
      "epoch": 4.5,
      "grad_norm": 15.221981048583984,
      "learning_rate": 1.2512067164579259e-05,
      "loss": 5.2754,
      "step": 9
    },
    {
      "epoch": 5.0,
      "grad_norm": 17.30332374572754,
      "learning_rate": 1.3902296849532509e-05,
      "loss": 5.087,
      "step": 10
    },
    {
      "epoch": 5.5,
      "grad_norm": 16.221498489379883,
      "learning_rate": 1.5292526534485763e-05,
      "loss": 5.3651,
      "step": 11
    },
    {
      "epoch": 6.0,
      "grad_norm": 20.707284927368164,
      "learning_rate": 1.668275621943901e-05,
      "loss": 5.4866,
      "step": 12
    },
    {
      "epoch": 6.5,
      "grad_norm": 18.7624454498291,
      "learning_rate": 1.8072985904392264e-05,
      "loss": 5.375,
      "step": 13
    },
    {
      "epoch": 7.0,
      "grad_norm": 21.325584411621094,
      "learning_rate": 1.9463215589345512e-05,
      "loss": 5.5792,
      "step": 14
    },
    {
      "epoch": 7.5,
      "grad_norm": 21.250423431396484,
      "learning_rate": 2.0853445274298764e-05,
      "loss": 5.4976,
      "step": 15
    },
    {
      "epoch": 8.0,
      "grad_norm": 24.43889617919922,
      "learning_rate": 2.2243674959252017e-05,
      "loss": 5.6766,
      "step": 16
    },
    {
      "epoch": 8.5,
      "grad_norm": 23.41958236694336,
      "learning_rate": 2.3633904644205265e-05,
      "loss": 5.7153,
      "step": 17
    },
    {
      "epoch": 9.0,
      "grad_norm": 20.2670841217041,
      "learning_rate": 2.5024134329158517e-05,
      "loss": 5.7217,
      "step": 18
    },
    {
      "epoch": 9.5,
      "grad_norm": 23.020328521728516,
      "learning_rate": 2.6414364014111766e-05,
      "loss": 5.8101,
      "step": 19
    },
    {
      "epoch": 10.0,
      "grad_norm": 26.57520866394043,
      "learning_rate": 2.7804593699065018e-05,
      "loss": 5.6398,
      "step": 20
    },
    {
      "epoch": 10.5,
      "grad_norm": 22.002422332763672,
      "learning_rate": 2.919482338401827e-05,
      "loss": 5.9131,
      "step": 21
    },
    {
      "epoch": 11.0,
      "grad_norm": 27.586572647094727,
      "learning_rate": 3.0585053068971526e-05,
      "loss": 5.6975,
      "step": 22
    },
    {
      "epoch": 11.5,
      "grad_norm": 24.832962036132812,
      "learning_rate": 3.197528275392477e-05,
      "loss": 5.8378,
      "step": 23
    },
    {
      "epoch": 12.0,
      "grad_norm": 25.396543502807617,
      "learning_rate": 3.336551243887802e-05,
      "loss": 5.921,
      "step": 24
    },
    {
      "epoch": 12.5,
      "grad_norm": 26.30990219116211,
      "learning_rate": 3.4755742123831275e-05,
      "loss": 5.8078,
      "step": 25
    },
    {
      "epoch": 13.0,
      "grad_norm": 24.57514762878418,
      "learning_rate": 3.614597180878453e-05,
      "loss": 6.127,
      "step": 26
    },
    {
      "epoch": 13.5,
      "grad_norm": 22.625019073486328,
      "learning_rate": 3.753620149373778e-05,
      "loss": 5.9048,
      "step": 27
    },
    {
      "epoch": 14.0,
      "grad_norm": 25.42768669128418,
      "learning_rate": 3.8926431178691025e-05,
      "loss": 5.8254,
      "step": 28
    },
    {
      "epoch": 14.5,
      "grad_norm": 23.755258560180664,
      "learning_rate": 4.031666086364428e-05,
      "loss": 5.8007,
      "step": 29
    },
    {
      "epoch": 15.0,
      "grad_norm": 23.498769760131836,
      "learning_rate": 4.170689054859753e-05,
      "loss": 6.0978,
      "step": 30
    },
    {
      "epoch": 15.5,
      "grad_norm": 24.390153884887695,
      "learning_rate": 4.309712023355078e-05,
      "loss": 5.8207,
      "step": 31
    },
    {
      "epoch": 16.0,
      "grad_norm": 19.955760955810547,
      "learning_rate": 4.448734991850403e-05,
      "loss": 6.0926,
      "step": 32
    },
    {
      "epoch": 16.5,
      "grad_norm": 21.511680603027344,
      "learning_rate": 4.587757960345728e-05,
      "loss": 5.8345,
      "step": 33
    },
    {
      "epoch": 17.0,
      "grad_norm": 21.954669952392578,
      "learning_rate": 4.726780928841053e-05,
      "loss": 5.9627,
      "step": 34
    },
    {
      "epoch": 17.5,
      "grad_norm": 23.591217041015625,
      "learning_rate": 4.865803897336378e-05,
      "loss": 5.9302,
      "step": 35
    },
    {
      "epoch": 18.0,
      "grad_norm": 17.764404296875,
      "learning_rate": 5.0048268658317035e-05,
      "loss": 5.8333,
      "step": 36
    },
    {
      "epoch": 18.5,
      "grad_norm": 18.12293243408203,
      "learning_rate": 5.143849834327029e-05,
      "loss": 5.8405,
      "step": 37
    },
    {
      "epoch": 19.0,
      "grad_norm": 18.89577293395996,
      "learning_rate": 5.282872802822353e-05,
      "loss": 6.0786,
      "step": 38
    },
    {
      "epoch": 19.5,
      "grad_norm": 14.221951484680176,
      "learning_rate": 5.4218957713176784e-05,
      "loss": 5.8585,
      "step": 39
    },
    {
      "epoch": 20.0,
      "grad_norm": 18.47533416748047,
      "learning_rate": 5.5609187398130036e-05,
      "loss": 5.8111,
      "step": 40
    },
    {
      "epoch": 20.5,
      "grad_norm": 14.214475631713867,
      "learning_rate": 5.699941708308328e-05,
      "loss": 5.9808,
      "step": 41
    },
    {
      "epoch": 21.0,
      "grad_norm": 14.85893440246582,
      "learning_rate": 5.838964676803654e-05,
      "loss": 5.7649,
      "step": 42
    },
    {
      "epoch": 21.5,
      "grad_norm": 12.957328796386719,
      "learning_rate": 5.9779876452989786e-05,
      "loss": 5.9258,
      "step": 43
    },
    {
      "epoch": 22.0,
      "grad_norm": 14.947933197021484,
      "learning_rate": 6.117010613794305e-05,
      "loss": 5.9613,
      "step": 44
    },
    {
      "epoch": 22.5,
      "grad_norm": 12.508078575134277,
      "learning_rate": 6.256033582289629e-05,
      "loss": 5.9779,
      "step": 45
    },
    {
      "epoch": 23.0,
      "grad_norm": 13.044670104980469,
      "learning_rate": 6.395056550784954e-05,
      "loss": 5.7734,
      "step": 46
    },
    {
      "epoch": 23.5,
      "grad_norm": 12.436223030090332,
      "learning_rate": 6.53407951928028e-05,
      "loss": 6.0068,
      "step": 47
    },
    {
      "epoch": 24.0,
      "grad_norm": 13.83247184753418,
      "learning_rate": 6.673102487775605e-05,
      "loss": 5.8272,
      "step": 48
    },
    {
      "epoch": 24.5,
      "grad_norm": 11.198149681091309,
      "learning_rate": 6.81212545627093e-05,
      "loss": 6.0416,
      "step": 49
    },
    {
      "epoch": 25.0,
      "grad_norm": 13.118327140808105,
      "learning_rate": 6.951148424766255e-05,
      "loss": 5.7138,
      "step": 50
    },
    {
      "epoch": 25.5,
      "grad_norm": 10.88517951965332,
      "learning_rate": 7.090171393261579e-05,
      "loss": 5.9188,
      "step": 51
    },
    {
      "epoch": 26.0,
      "grad_norm": 13.784810066223145,
      "learning_rate": 7.229194361756905e-05,
      "loss": 5.967,
      "step": 52
    },
    {
      "epoch": 26.5,
      "grad_norm": 12.594482421875,
      "learning_rate": 7.368217330252229e-05,
      "loss": 5.7113,
      "step": 53
    },
    {
      "epoch": 27.0,
      "grad_norm": 10.806195259094238,
      "learning_rate": 7.507240298747556e-05,
      "loss": 6.2376,
      "step": 54
    },
    {
      "epoch": 27.5,
      "grad_norm": 11.472587585449219,
      "learning_rate": 7.64626326724288e-05,
      "loss": 5.8449,
      "step": 55
    },
    {
      "epoch": 28.0,
      "grad_norm": 11.355728149414062,
      "learning_rate": 7.785286235738205e-05,
      "loss": 6.0463,
      "step": 56
    },
    {
      "epoch": 28.5,
      "grad_norm": 10.903486251831055,
      "learning_rate": 7.92430920423353e-05,
      "loss": 5.9471,
      "step": 57
    },
    {
      "epoch": 29.0,
      "grad_norm": 10.359997749328613,
      "learning_rate": 8.063332172728855e-05,
      "loss": 5.9962,
      "step": 58
    },
    {
      "epoch": 29.5,
      "grad_norm": 9.1412353515625,
      "learning_rate": 8.20235514122418e-05,
      "loss": 5.9879,
      "step": 59
    },
    {
      "epoch": 30.0,
      "grad_norm": 9.40005874633789,
      "learning_rate": 8.341378109719506e-05,
      "loss": 5.9163,
      "step": 60
    },
    {
      "epoch": 30.5,
      "grad_norm": 9.7362060546875,
      "learning_rate": 8.48040107821483e-05,
      "loss": 5.7876,
      "step": 61
    },
    {
      "epoch": 31.0,
      "grad_norm": 10.882267951965332,
      "learning_rate": 8.619424046710156e-05,
      "loss": 6.0205,
      "step": 62
    },
    {
      "epoch": 31.5,
      "grad_norm": 8.542376518249512,
      "learning_rate": 8.75844701520548e-05,
      "loss": 5.8939,
      "step": 63
    },
    {
      "epoch": 32.0,
      "grad_norm": 10.451062202453613,
      "learning_rate": 8.897469983700807e-05,
      "loss": 6.0038,
      "step": 64
    },
    {
      "epoch": 32.5,
      "grad_norm": 8.138161659240723,
      "learning_rate": 9.03649295219613e-05,
      "loss": 6.0662,
      "step": 65
    },
    {
      "epoch": 33.0,
      "grad_norm": 9.674449920654297,
      "learning_rate": 9.175515920691456e-05,
      "loss": 5.6635,
      "step": 66
    },
    {
      "epoch": 33.5,
      "grad_norm": 7.493039608001709,
      "learning_rate": 9.314538889186781e-05,
      "loss": 5.8901,
      "step": 67
    },
    {
      "epoch": 34.0,
      "grad_norm": 9.925933837890625,
      "learning_rate": 9.453561857682106e-05,
      "loss": 6.1049,
      "step": 68
    },
    {
      "epoch": 34.5,
      "grad_norm": 6.920145511627197,
      "learning_rate": 9.592584826177431e-05,
      "loss": 5.918,
      "step": 69
    },
    {
      "epoch": 35.0,
      "grad_norm": 9.044740676879883,
      "learning_rate": 9.731607794672757e-05,
      "loss": 5.9753,
      "step": 70
    },
    {
      "epoch": 35.5,
      "grad_norm": 7.326313018798828,
      "learning_rate": 9.87063076316808e-05,
      "loss": 5.8353,
      "step": 71
    },
    {
      "epoch": 36.0,
      "grad_norm": 8.195850372314453,
      "learning_rate": 0.00010009653731663407,
      "loss": 6.1256,
      "step": 72
    },
    {
      "epoch": 36.5,
      "grad_norm": 6.389270305633545,
      "learning_rate": 0.00010148676700158731,
      "loss": 6.0314,
      "step": 73
    },
    {
      "epoch": 37.0,
      "grad_norm": 11.22146224975586,
      "learning_rate": 0.00010287699668654057,
      "loss": 5.79,
      "step": 74
    },
    {
      "epoch": 37.5,
      "grad_norm": 7.7307634353637695,
      "learning_rate": 0.00010426722637149381,
      "loss": 5.8151,
      "step": 75
    },
    {
      "epoch": 38.0,
      "grad_norm": 7.809751033782959,
      "learning_rate": 0.00010565745605644706,
      "loss": 6.2813,
      "step": 76
    },
    {
      "epoch": 38.5,
      "grad_norm": 6.996216297149658,
      "learning_rate": 0.00010704768574140032,
      "loss": 5.9185,
      "step": 77
    },
    {
      "epoch": 39.0,
      "grad_norm": 8.50745964050293,
      "learning_rate": 0.00010843791542635357,
      "loss": 5.8222,
      "step": 78
    },
    {
      "epoch": 39.5,
      "grad_norm": 8.134573936462402,
      "learning_rate": 0.00010982814511130682,
      "loss": 5.929,
      "step": 79
    },
    {
      "epoch": 40.0,
      "grad_norm": 7.336516380310059,
      "learning_rate": 0.00011121837479626007,
      "loss": 5.9718,
      "step": 80
    },
    {
      "epoch": 40.0,
      "eval_brier_0th_event": 0.2016362075975717,
      "eval_brier_0th_event_n": 236,
      "eval_brier_avg": 0.2016362075975717,
      "eval_brier_weighted_avg": 0.2016362075975717,
      "eval_ipcw": 0.6445399589450378,
      "eval_ipcw_0th_event": 0.6445399589450378,
      "eval_ipcw_0th_event_0.25": 0.6564335924606999,
      "eval_ipcw_0th_event_0.5": 0.6479635474613454,
      "eval_ipcw_0th_event_0.75": 0.6453850805586229,
      "eval_ipcw_0th_event_1.0": 0.6445399589450378,
      "eval_ipcw_0th_event_n": 236,
      "eval_ipcw_avg": 0.6485805448564266,
      "eval_ipcw_avg_0th_event": 0.6485805448564266,
      "eval_ipcw_weighted_avg": 0.6485805448564266,
      "eval_loss": 2.884516477584839,
      "eval_runtime": 0.3303,
      "eval_samples_per_second": 1344.046,
      "eval_steps_per_second": 3.027,
      "step": 80
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 53220326400.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
