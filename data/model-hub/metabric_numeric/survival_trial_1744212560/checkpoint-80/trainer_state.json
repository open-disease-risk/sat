{
  "best_global_step": 80,
  "best_metric": 0.6588487735412911,
  "best_model_checkpoint": "./data/model-hub/metabric_numeric/survival_trial_1744212560/checkpoint-80",
  "epoch": 40.0,
  "eval_steps": 1,
  "global_step": 80,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 9.927510261535645,
      "learning_rate": 5.485270238253604e-05,
      "loss": 1.7938,
      "step": 1
    },
    {
      "epoch": 1.0,
      "grad_norm": 10.204845428466797,
      "learning_rate": 0.00010970540476507208,
      "loss": 1.8409,
      "step": 2
    },
    {
      "epoch": 1.5,
      "grad_norm": 10.342326164245605,
      "learning_rate": 0.0001645581071476081,
      "loss": 1.8398,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 9.040948867797852,
      "learning_rate": 0.00021941080953014416,
      "loss": 1.7335,
      "step": 4
    },
    {
      "epoch": 2.5,
      "grad_norm": 9.366230010986328,
      "learning_rate": 0.0002742635119126802,
      "loss": 1.7476,
      "step": 5
    },
    {
      "epoch": 3.0,
      "grad_norm": 6.429545879364014,
      "learning_rate": 0.0003291162142952162,
      "loss": 1.7408,
      "step": 6
    },
    {
      "epoch": 3.5,
      "grad_norm": 5.735698699951172,
      "learning_rate": 0.0003839689166777522,
      "loss": 1.6877,
      "step": 7
    },
    {
      "epoch": 4.0,
      "grad_norm": 4.477992534637451,
      "learning_rate": 0.0004388216190602883,
      "loss": 1.6866,
      "step": 8
    },
    {
      "epoch": 4.5,
      "grad_norm": 3.4898931980133057,
      "learning_rate": 0.0004936743214428243,
      "loss": 1.644,
      "step": 9
    },
    {
      "epoch": 5.0,
      "grad_norm": 2.3364474773406982,
      "learning_rate": 0.0005485270238253603,
      "loss": 1.6494,
      "step": 10
    },
    {
      "epoch": 5.5,
      "grad_norm": 2.877815008163452,
      "learning_rate": 0.0006033797262078965,
      "loss": 1.6582,
      "step": 11
    },
    {
      "epoch": 6.0,
      "grad_norm": 3.095644474029541,
      "learning_rate": 0.0006582324285904324,
      "loss": 1.6028,
      "step": 12
    },
    {
      "epoch": 6.5,
      "grad_norm": 3.180375576019287,
      "learning_rate": 0.0007130851309729685,
      "loss": 1.5944,
      "step": 13
    },
    {
      "epoch": 7.0,
      "grad_norm": 3.272498607635498,
      "learning_rate": 0.0007679378333555044,
      "loss": 1.6682,
      "step": 14
    },
    {
      "epoch": 7.5,
      "grad_norm": 2.882840633392334,
      "learning_rate": 0.0008227905357380405,
      "loss": 1.593,
      "step": 15
    },
    {
      "epoch": 8.0,
      "grad_norm": 3.321521282196045,
      "learning_rate": 0.0008776432381205766,
      "loss": 1.6073,
      "step": 16
    },
    {
      "epoch": 8.5,
      "grad_norm": 3.449045181274414,
      "learning_rate": 0.0009324959405031125,
      "loss": 1.5667,
      "step": 17
    },
    {
      "epoch": 9.0,
      "grad_norm": 3.0137200355529785,
      "learning_rate": 0.0009873486428856487,
      "loss": 1.5707,
      "step": 18
    },
    {
      "epoch": 9.5,
      "grad_norm": 3.124297857284546,
      "learning_rate": 0.0010422013452681847,
      "loss": 1.5213,
      "step": 19
    },
    {
      "epoch": 10.0,
      "grad_norm": 3.2697668075561523,
      "learning_rate": 0.0010970540476507207,
      "loss": 1.548,
      "step": 20
    },
    {
      "epoch": 10.5,
      "grad_norm": 2.78290057182312,
      "learning_rate": 0.0011519067500332567,
      "loss": 1.5139,
      "step": 21
    },
    {
      "epoch": 11.0,
      "grad_norm": 3.329498767852783,
      "learning_rate": 0.001206759452415793,
      "loss": 1.4738,
      "step": 22
    },
    {
      "epoch": 11.5,
      "grad_norm": 2.6058526039123535,
      "learning_rate": 0.0012616121547983287,
      "loss": 1.4845,
      "step": 23
    },
    {
      "epoch": 12.0,
      "grad_norm": 2.623398542404175,
      "learning_rate": 0.0013164648571808647,
      "loss": 1.45,
      "step": 24
    },
    {
      "epoch": 12.5,
      "grad_norm": 2.2208311557769775,
      "learning_rate": 0.0013713175595634008,
      "loss": 1.4326,
      "step": 25
    },
    {
      "epoch": 13.0,
      "grad_norm": 1.7843080759048462,
      "learning_rate": 0.001426170261945937,
      "loss": 1.4354,
      "step": 26
    },
    {
      "epoch": 13.5,
      "grad_norm": 1.7530829906463623,
      "learning_rate": 0.001481022964328473,
      "loss": 1.3889,
      "step": 27
    },
    {
      "epoch": 14.0,
      "grad_norm": 1.4325604438781738,
      "learning_rate": 0.0015358756667110088,
      "loss": 1.4048,
      "step": 28
    },
    {
      "epoch": 14.5,
      "grad_norm": 1.6555241346359253,
      "learning_rate": 0.001590728369093545,
      "loss": 1.3698,
      "step": 29
    },
    {
      "epoch": 15.0,
      "grad_norm": 5.470559597015381,
      "learning_rate": 0.001645581071476081,
      "loss": 1.4018,
      "step": 30
    },
    {
      "epoch": 15.5,
      "grad_norm": 2.446685314178467,
      "learning_rate": 0.001700433773858617,
      "loss": 1.4072,
      "step": 31
    },
    {
      "epoch": 16.0,
      "grad_norm": 2.612222194671631,
      "learning_rate": 0.0017552864762411533,
      "loss": 1.3271,
      "step": 32
    },
    {
      "epoch": 16.5,
      "grad_norm": 3.7379512786865234,
      "learning_rate": 0.001810139178623689,
      "loss": 1.3474,
      "step": 33
    },
    {
      "epoch": 17.0,
      "grad_norm": 4.199516296386719,
      "learning_rate": 0.001864991881006225,
      "loss": 1.3909,
      "step": 34
    },
    {
      "epoch": 17.5,
      "grad_norm": 1.6450788974761963,
      "learning_rate": 0.0019198445833887613,
      "loss": 1.3226,
      "step": 35
    },
    {
      "epoch": 18.0,
      "grad_norm": 1.6581721305847168,
      "learning_rate": 0.0019746972857712973,
      "loss": 1.3356,
      "step": 36
    },
    {
      "epoch": 18.5,
      "grad_norm": 2.12819766998291,
      "learning_rate": 0.0020295499881538333,
      "loss": 1.2996,
      "step": 37
    },
    {
      "epoch": 19.0,
      "grad_norm": 1.7492955923080444,
      "learning_rate": 0.0020844026905363694,
      "loss": 1.3526,
      "step": 38
    },
    {
      "epoch": 19.5,
      "grad_norm": 3.370344877243042,
      "learning_rate": 0.0021392553929189054,
      "loss": 1.3181,
      "step": 39
    },
    {
      "epoch": 20.0,
      "grad_norm": 3.3631749153137207,
      "learning_rate": 0.0021941080953014414,
      "loss": 1.3389,
      "step": 40
    },
    {
      "epoch": 20.5,
      "grad_norm": 1.8404725790023804,
      "learning_rate": 0.0022489607976839774,
      "loss": 1.3531,
      "step": 41
    },
    {
      "epoch": 21.0,
      "grad_norm": 1.9507219791412354,
      "learning_rate": 0.0023038135000665134,
      "loss": 1.2818,
      "step": 42
    },
    {
      "epoch": 21.5,
      "grad_norm": 2.662710189819336,
      "learning_rate": 0.0023586662024490494,
      "loss": 1.3019,
      "step": 43
    },
    {
      "epoch": 22.0,
      "grad_norm": 3.7924110889434814,
      "learning_rate": 0.002413518904831586,
      "loss": 1.3177,
      "step": 44
    },
    {
      "epoch": 22.5,
      "grad_norm": 1.4989458322525024,
      "learning_rate": 0.0024683716072141215,
      "loss": 1.3113,
      "step": 45
    },
    {
      "epoch": 23.0,
      "grad_norm": 2.280367612838745,
      "learning_rate": 0.0025232243095966575,
      "loss": 1.2993,
      "step": 46
    },
    {
      "epoch": 23.5,
      "grad_norm": 2.110786199569702,
      "learning_rate": 0.002578077011979194,
      "loss": 1.2682,
      "step": 47
    },
    {
      "epoch": 24.0,
      "grad_norm": 3.3942081928253174,
      "learning_rate": 0.0026329297143617295,
      "loss": 1.3773,
      "step": 48
    },
    {
      "epoch": 24.5,
      "grad_norm": 1.3755912780761719,
      "learning_rate": 0.002687782416744266,
      "loss": 1.3416,
      "step": 49
    },
    {
      "epoch": 25.0,
      "grad_norm": 1.8106143474578857,
      "learning_rate": 0.0027426351191268015,
      "loss": 1.2818,
      "step": 50
    },
    {
      "epoch": 25.5,
      "grad_norm": 3.8576576709747314,
      "learning_rate": 0.0027974878215093375,
      "loss": 1.3196,
      "step": 51
    },
    {
      "epoch": 26.0,
      "grad_norm": 2.123894214630127,
      "learning_rate": 0.002852340523891874,
      "loss": 1.3348,
      "step": 52
    },
    {
      "epoch": 26.5,
      "grad_norm": 1.074324607849121,
      "learning_rate": 0.0029071932262744096,
      "loss": 1.2723,
      "step": 53
    },
    {
      "epoch": 27.0,
      "grad_norm": 4.20208740234375,
      "learning_rate": 0.002962045928656946,
      "loss": 1.3896,
      "step": 54
    },
    {
      "epoch": 27.5,
      "grad_norm": 3.432309150695801,
      "learning_rate": 0.003016898631039482,
      "loss": 1.3006,
      "step": 55
    },
    {
      "epoch": 28.0,
      "grad_norm": 1.6625721454620361,
      "learning_rate": 0.0030717513334220176,
      "loss": 1.3298,
      "step": 56
    },
    {
      "epoch": 28.5,
      "grad_norm": 1.3948198556900024,
      "learning_rate": 0.003126604035804554,
      "loss": 1.3344,
      "step": 57
    },
    {
      "epoch": 29.0,
      "grad_norm": 2.323176622390747,
      "learning_rate": 0.00318145673818709,
      "loss": 1.2312,
      "step": 58
    },
    {
      "epoch": 29.5,
      "grad_norm": 2.358323335647583,
      "learning_rate": 0.003236309440569626,
      "loss": 1.3212,
      "step": 59
    },
    {
      "epoch": 30.0,
      "grad_norm": 2.733680486679077,
      "learning_rate": 0.003291162142952162,
      "loss": 1.3003,
      "step": 60
    },
    {
      "epoch": 30.5,
      "grad_norm": 1.5068955421447754,
      "learning_rate": 0.003346014845334698,
      "loss": 1.2938,
      "step": 61
    },
    {
      "epoch": 31.0,
      "grad_norm": 3.983699083328247,
      "learning_rate": 0.003400867547717234,
      "loss": 1.3097,
      "step": 62
    },
    {
      "epoch": 31.5,
      "grad_norm": 4.371498107910156,
      "learning_rate": 0.00345572025009977,
      "loss": 1.2948,
      "step": 63
    },
    {
      "epoch": 32.0,
      "grad_norm": 1.6893830299377441,
      "learning_rate": 0.0035105729524823066,
      "loss": 1.3049,
      "step": 64
    },
    {
      "epoch": 32.5,
      "grad_norm": 1.6264322996139526,
      "learning_rate": 0.003565425654864842,
      "loss": 1.2788,
      "step": 65
    },
    {
      "epoch": 33.0,
      "grad_norm": 1.9020544290542603,
      "learning_rate": 0.003620278357247378,
      "loss": 1.3201,
      "step": 66
    },
    {
      "epoch": 33.5,
      "grad_norm": 1.8867014646530151,
      "learning_rate": 0.0036751310596299146,
      "loss": 1.2973,
      "step": 67
    },
    {
      "epoch": 34.0,
      "grad_norm": 2.0182418823242188,
      "learning_rate": 0.00372998376201245,
      "loss": 1.288,
      "step": 68
    },
    {
      "epoch": 34.5,
      "grad_norm": 1.3329397439956665,
      "learning_rate": 0.0037848364643949866,
      "loss": 1.3112,
      "step": 69
    },
    {
      "epoch": 35.0,
      "grad_norm": 1.4355034828186035,
      "learning_rate": 0.0038396891667775226,
      "loss": 1.2463,
      "step": 70
    },
    {
      "epoch": 35.5,
      "grad_norm": 1.6511101722717285,
      "learning_rate": 0.0038945418691600582,
      "loss": 1.2872,
      "step": 71
    },
    {
      "epoch": 36.0,
      "grad_norm": 2.169971466064453,
      "learning_rate": 0.003949394571542595,
      "loss": 1.3159,
      "step": 72
    },
    {
      "epoch": 36.5,
      "grad_norm": 1.508559226989746,
      "learning_rate": 0.004004247273925131,
      "loss": 1.2416,
      "step": 73
    },
    {
      "epoch": 37.0,
      "grad_norm": 1.2647963762283325,
      "learning_rate": 0.004059099976307667,
      "loss": 1.3125,
      "step": 74
    },
    {
      "epoch": 37.5,
      "grad_norm": 2.928171396255493,
      "learning_rate": 0.004113952678690203,
      "loss": 1.2889,
      "step": 75
    },
    {
      "epoch": 38.0,
      "grad_norm": 2.59928035736084,
      "learning_rate": 0.004168805381072739,
      "loss": 1.2996,
      "step": 76
    },
    {
      "epoch": 38.5,
      "grad_norm": 1.5106979608535767,
      "learning_rate": 0.004223658083455275,
      "loss": 1.3043,
      "step": 77
    },
    {
      "epoch": 39.0,
      "grad_norm": 2.29122257232666,
      "learning_rate": 0.004278510785837811,
      "loss": 1.2496,
      "step": 78
    },
    {
      "epoch": 39.5,
      "grad_norm": 1.7444652318954468,
      "learning_rate": 0.004333363488220347,
      "loss": 1.2862,
      "step": 79
    },
    {
      "epoch": 40.0,
      "grad_norm": 3.4597389698028564,
      "learning_rate": 0.004388216190602883,
      "loss": 1.2773,
      "step": 80
    },
    {
      "epoch": 40.0,
      "eval_brier_0th_event": 0.18405064062476767,
      "eval_brier_0th_event_n": 258,
      "eval_brier_avg": 0.18405064062476767,
      "eval_brier_weighted_avg": 0.18405064062476767,
      "eval_ipcw": 0.6461466854126336,
      "eval_ipcw_0th_event": 0.6461466854126336,
      "eval_ipcw_0th_event_0.25": 0.6786617981761413,
      "eval_ipcw_0th_event_0.5": 0.6606956172066474,
      "eval_ipcw_0th_event_0.75": 0.6498909933697421,
      "eval_ipcw_0th_event_1.0": 0.6461466854126336,
      "eval_ipcw_0th_event_n": 258,
      "eval_ipcw_avg": 0.6588487735412911,
      "eval_ipcw_avg_0th_event": 0.6588487735412911,
      "eval_ipcw_weighted_avg": 0.6588487735412911,
      "eval_loss": 0.6788400411605835,
      "eval_runtime": 0.0794,
      "eval_samples_per_second": 5595.396,
      "eval_steps_per_second": 12.602,
      "step": 80
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 53220326400.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
