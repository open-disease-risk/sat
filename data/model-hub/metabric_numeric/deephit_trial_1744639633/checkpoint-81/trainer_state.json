{
  "best_global_step": 81,
  "best_metric": 0.6475458906086491,
  "best_model_checkpoint": "./data/model-hub/metabric_numeric/deephit_trial_1744639633/checkpoint-81",
  "epoch": 40.5,
  "eval_steps": 1,
  "global_step": 81,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 3.8187406063079834,
      "learning_rate": 1.9718350707862026e-05,
      "loss": 6.5408,
      "step": 1
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.850980520248413,
      "learning_rate": 3.943670141572405e-05,
      "loss": 5.8451,
      "step": 2
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.4470107555389404,
      "learning_rate": 5.915505212358607e-05,
      "loss": 5.5257,
      "step": 3
    },
    {
      "epoch": 2.0,
      "grad_norm": 2.1406056880950928,
      "learning_rate": 7.88734028314481e-05,
      "loss": 5.3829,
      "step": 4
    },
    {
      "epoch": 2.5,
      "grad_norm": 2.399569272994995,
      "learning_rate": 9.859175353931012e-05,
      "loss": 5.2472,
      "step": 5
    },
    {
      "epoch": 3.0,
      "grad_norm": 1.746616244316101,
      "learning_rate": 0.00011831010424717214,
      "loss": 5.2179,
      "step": 6
    },
    {
      "epoch": 3.5,
      "grad_norm": 3.4164345264434814,
      "learning_rate": 0.00013802845495503418,
      "loss": 5.1752,
      "step": 7
    },
    {
      "epoch": 4.0,
      "grad_norm": 1.4820635318756104,
      "learning_rate": 0.0001577468056628962,
      "loss": 5.117,
      "step": 8
    },
    {
      "epoch": 4.5,
      "grad_norm": 5.166794776916504,
      "learning_rate": 0.00017746515637075822,
      "loss": 5.1609,
      "step": 9
    },
    {
      "epoch": 5.0,
      "grad_norm": 5.040765285491943,
      "learning_rate": 0.00019718350707862025,
      "loss": 5.3203,
      "step": 10
    },
    {
      "epoch": 5.5,
      "grad_norm": 3.636812448501587,
      "learning_rate": 0.00021690185778648228,
      "loss": 5.3508,
      "step": 11
    },
    {
      "epoch": 6.0,
      "grad_norm": 3.169301748275757,
      "learning_rate": 0.0002366202084943443,
      "loss": 5.4031,
      "step": 12
    },
    {
      "epoch": 6.5,
      "grad_norm": 2.5170671939849854,
      "learning_rate": 0.00025633855920220635,
      "loss": 5.4978,
      "step": 13
    },
    {
      "epoch": 7.0,
      "grad_norm": 2.8426451683044434,
      "learning_rate": 0.00027605690991006835,
      "loss": 5.5076,
      "step": 14
    },
    {
      "epoch": 7.5,
      "grad_norm": 2.3071372509002686,
      "learning_rate": 0.00029577526061793036,
      "loss": 5.5036,
      "step": 15
    },
    {
      "epoch": 8.0,
      "grad_norm": 2.166248083114624,
      "learning_rate": 0.0003154936113257924,
      "loss": 5.7396,
      "step": 16
    },
    {
      "epoch": 8.5,
      "grad_norm": 2.740532398223877,
      "learning_rate": 0.0003352119620336544,
      "loss": 5.5945,
      "step": 17
    },
    {
      "epoch": 9.0,
      "grad_norm": 2.668842315673828,
      "learning_rate": 0.00035493031274151643,
      "loss": 5.8322,
      "step": 18
    },
    {
      "epoch": 9.5,
      "grad_norm": 2.386915445327759,
      "learning_rate": 0.00037464866344937844,
      "loss": 5.9041,
      "step": 19
    },
    {
      "epoch": 10.0,
      "grad_norm": 2.888798236846924,
      "learning_rate": 0.0003943670141572405,
      "loss": 5.4164,
      "step": 20
    },
    {
      "epoch": 10.5,
      "grad_norm": 2.7407913208007812,
      "learning_rate": 0.00041408536486510256,
      "loss": 5.8921,
      "step": 21
    },
    {
      "epoch": 11.0,
      "grad_norm": 2.672959327697754,
      "learning_rate": 0.00043380371557296456,
      "loss": 5.7412,
      "step": 22
    },
    {
      "epoch": 11.5,
      "grad_norm": 2.7874715328216553,
      "learning_rate": 0.0004535220662808265,
      "loss": 5.9523,
      "step": 23
    },
    {
      "epoch": 12.0,
      "grad_norm": 2.880722761154175,
      "learning_rate": 0.0004732404169886886,
      "loss": 5.8369,
      "step": 24
    },
    {
      "epoch": 12.5,
      "grad_norm": 2.6567068099975586,
      "learning_rate": 0.0004929587676965506,
      "loss": 5.9229,
      "step": 25
    },
    {
      "epoch": 13.0,
      "grad_norm": 2.611818552017212,
      "learning_rate": 0.0005126771184044127,
      "loss": 5.939,
      "step": 26
    },
    {
      "epoch": 13.5,
      "grad_norm": 2.801596164703369,
      "learning_rate": 0.0005323954691122747,
      "loss": 5.8975,
      "step": 27
    },
    {
      "epoch": 14.0,
      "grad_norm": 2.5079188346862793,
      "learning_rate": 0.0005521138198201367,
      "loss": 6.0503,
      "step": 28
    },
    {
      "epoch": 14.5,
      "grad_norm": 2.5091679096221924,
      "learning_rate": 0.0005718321705279987,
      "loss": 6.0262,
      "step": 29
    },
    {
      "epoch": 15.0,
      "grad_norm": 2.9541070461273193,
      "learning_rate": 0.0005915505212358607,
      "loss": 5.8132,
      "step": 30
    },
    {
      "epoch": 15.5,
      "grad_norm": 2.855112075805664,
      "learning_rate": 0.0006112688719437228,
      "loss": 5.9272,
      "step": 31
    },
    {
      "epoch": 16.0,
      "grad_norm": 2.7269532680511475,
      "learning_rate": 0.0006309872226515848,
      "loss": 5.9455,
      "step": 32
    },
    {
      "epoch": 16.5,
      "grad_norm": 2.582836389541626,
      "learning_rate": 0.0006507055733594467,
      "loss": 6.0601,
      "step": 33
    },
    {
      "epoch": 17.0,
      "grad_norm": 2.89459490776062,
      "learning_rate": 0.0006704239240673089,
      "loss": 5.7613,
      "step": 34
    },
    {
      "epoch": 17.5,
      "grad_norm": 2.6409058570861816,
      "learning_rate": 0.0006901422747751709,
      "loss": 5.9705,
      "step": 35
    },
    {
      "epoch": 18.0,
      "grad_norm": 2.941333293914795,
      "learning_rate": 0.0007098606254830329,
      "loss": 5.8432,
      "step": 36
    },
    {
      "epoch": 18.5,
      "grad_norm": 2.906674861907959,
      "learning_rate": 0.000729578976190895,
      "loss": 5.9358,
      "step": 37
    },
    {
      "epoch": 19.0,
      "grad_norm": 2.816957712173462,
      "learning_rate": 0.0007492973268987569,
      "loss": 5.9926,
      "step": 38
    },
    {
      "epoch": 19.5,
      "grad_norm": 2.799927234649658,
      "learning_rate": 0.000769015677606619,
      "loss": 5.8615,
      "step": 39
    },
    {
      "epoch": 20.0,
      "grad_norm": 3.877671241760254,
      "learning_rate": 0.000788734028314481,
      "loss": 6.2942,
      "step": 40
    },
    {
      "epoch": 20.5,
      "grad_norm": 2.562614917755127,
      "learning_rate": 0.000808452379022343,
      "loss": 6.004,
      "step": 41
    },
    {
      "epoch": 21.0,
      "grad_norm": 4.179736137390137,
      "learning_rate": 0.0008281707297302051,
      "loss": 5.8212,
      "step": 42
    },
    {
      "epoch": 21.5,
      "grad_norm": 2.892845869064331,
      "learning_rate": 0.000847889080438067,
      "loss": 5.8937,
      "step": 43
    },
    {
      "epoch": 22.0,
      "grad_norm": 3.6220970153808594,
      "learning_rate": 0.0008676074311459291,
      "loss": 5.9059,
      "step": 44
    },
    {
      "epoch": 22.5,
      "grad_norm": 3.443106174468994,
      "learning_rate": 0.0008873257818537911,
      "loss": 5.9556,
      "step": 45
    },
    {
      "epoch": 23.0,
      "grad_norm": 4.945250988006592,
      "learning_rate": 0.000907044132561653,
      "loss": 5.9132,
      "step": 46
    },
    {
      "epoch": 23.5,
      "grad_norm": 3.1712894439697266,
      "learning_rate": 0.0009267624832695153,
      "loss": 5.8349,
      "step": 47
    },
    {
      "epoch": 24.0,
      "grad_norm": 4.05049991607666,
      "learning_rate": 0.0009464808339773772,
      "loss": 6.1689,
      "step": 48
    },
    {
      "epoch": 24.5,
      "grad_norm": 3.8407058715820312,
      "learning_rate": 0.0009661991846852393,
      "loss": 5.9688,
      "step": 49
    },
    {
      "epoch": 25.0,
      "grad_norm": 3.9895918369293213,
      "learning_rate": 0.0009859175353931012,
      "loss": 5.8217,
      "step": 50
    },
    {
      "epoch": 25.5,
      "grad_norm": 2.694084644317627,
      "learning_rate": 0.0010056358861009632,
      "loss": 5.9072,
      "step": 51
    },
    {
      "epoch": 26.0,
      "grad_norm": 9.334325790405273,
      "learning_rate": 0.0010253542368088254,
      "loss": 5.8725,
      "step": 52
    },
    {
      "epoch": 26.5,
      "grad_norm": 4.016694068908691,
      "learning_rate": 0.0010450725875166872,
      "loss": 5.9256,
      "step": 53
    },
    {
      "epoch": 27.0,
      "grad_norm": 4.51478385925293,
      "learning_rate": 0.0010647909382245494,
      "loss": 5.9031,
      "step": 54
    },
    {
      "epoch": 27.5,
      "grad_norm": 3.951694965362549,
      "learning_rate": 0.0010845092889324114,
      "loss": 5.8905,
      "step": 55
    },
    {
      "epoch": 28.0,
      "grad_norm": 4.692469120025635,
      "learning_rate": 0.0011042276396402734,
      "loss": 6.0801,
      "step": 56
    },
    {
      "epoch": 28.5,
      "grad_norm": 6.148902893066406,
      "learning_rate": 0.0011239459903481354,
      "loss": 5.9955,
      "step": 57
    },
    {
      "epoch": 29.0,
      "grad_norm": 7.244734287261963,
      "learning_rate": 0.0011436643410559974,
      "loss": 5.7038,
      "step": 58
    },
    {
      "epoch": 29.5,
      "grad_norm": 3.7196059226989746,
      "learning_rate": 0.0011633826917638594,
      "loss": 5.9638,
      "step": 59
    },
    {
      "epoch": 30.0,
      "grad_norm": 7.770925998687744,
      "learning_rate": 0.0011831010424717214,
      "loss": 5.8008,
      "step": 60
    },
    {
      "epoch": 30.5,
      "grad_norm": 3.9163310527801514,
      "learning_rate": 0.0012028193931795834,
      "loss": 5.8022,
      "step": 61
    },
    {
      "epoch": 31.0,
      "grad_norm": 9.618097305297852,
      "learning_rate": 0.0012225377438874457,
      "loss": 6.0865,
      "step": 62
    },
    {
      "epoch": 31.5,
      "grad_norm": 3.218940496444702,
      "learning_rate": 0.0012422560945953075,
      "loss": 5.9322,
      "step": 63
    },
    {
      "epoch": 32.0,
      "grad_norm": 7.743274211883545,
      "learning_rate": 0.0012619744453031697,
      "loss": 5.8936,
      "step": 64
    },
    {
      "epoch": 32.5,
      "grad_norm": 3.4645402431488037,
      "learning_rate": 0.0012816927960110317,
      "loss": 6.1048,
      "step": 65
    },
    {
      "epoch": 33.0,
      "grad_norm": 3.3414766788482666,
      "learning_rate": 0.0013014111467188935,
      "loss": 5.8801,
      "step": 66
    },
    {
      "epoch": 33.5,
      "grad_norm": 5.589675426483154,
      "learning_rate": 0.0013211294974267557,
      "loss": 5.917,
      "step": 67
    },
    {
      "epoch": 34.0,
      "grad_norm": 6.0509161949157715,
      "learning_rate": 0.0013408478481346177,
      "loss": 5.9342,
      "step": 68
    },
    {
      "epoch": 34.5,
      "grad_norm": 6.698136806488037,
      "learning_rate": 0.0013605661988424797,
      "loss": 6.0303,
      "step": 69
    },
    {
      "epoch": 35.0,
      "grad_norm": 6.672794818878174,
      "learning_rate": 0.0013802845495503417,
      "loss": 5.7901,
      "step": 70
    },
    {
      "epoch": 35.5,
      "grad_norm": 2.601656436920166,
      "learning_rate": 0.0014000029002582037,
      "loss": 6.0276,
      "step": 71
    },
    {
      "epoch": 36.0,
      "grad_norm": 4.701975345611572,
      "learning_rate": 0.0014197212509660657,
      "loss": 5.8712,
      "step": 72
    },
    {
      "epoch": 36.5,
      "grad_norm": 3.96669602394104,
      "learning_rate": 0.0014394396016739277,
      "loss": 6.0151,
      "step": 73
    },
    {
      "epoch": 37.0,
      "grad_norm": 4.124514579772949,
      "learning_rate": 0.00145915795238179,
      "loss": 5.8792,
      "step": 74
    },
    {
      "epoch": 37.5,
      "grad_norm": 4.337925434112549,
      "learning_rate": 0.001478876303089652,
      "loss": 6.0437,
      "step": 75
    },
    {
      "epoch": 38.0,
      "grad_norm": 5.77047061920166,
      "learning_rate": 0.0014985946537975138,
      "loss": 6.0211,
      "step": 76
    },
    {
      "epoch": 38.5,
      "grad_norm": 10.252970695495605,
      "learning_rate": 0.001518313004505376,
      "loss": 6.0006,
      "step": 77
    },
    {
      "epoch": 39.0,
      "grad_norm": 4.714377403259277,
      "learning_rate": 0.001538031355213238,
      "loss": 5.9953,
      "step": 78
    },
    {
      "epoch": 39.5,
      "grad_norm": 6.796043872833252,
      "learning_rate": 0.0015577497059211,
      "loss": 6.0627,
      "step": 79
    },
    {
      "epoch": 40.0,
      "grad_norm": 5.822690010070801,
      "learning_rate": 0.001577468056628962,
      "loss": 5.8182,
      "step": 80
    },
    {
      "epoch": 40.0,
      "eval_brier_0th_event": 0.20038037863214367,
      "eval_brier_0th_event_n": 253,
      "eval_brier_avg": 0.20038037863214367,
      "eval_brier_weighted_avg": 0.20038037863214367,
      "eval_ipcw": 0.6194385705788219,
      "eval_ipcw_0th_event": 0.6194385705788219,
      "eval_ipcw_0th_event_0.25": 0.6747672379999121,
      "eval_ipcw_0th_event_0.5": 0.6493108008220995,
      "eval_ipcw_0th_event_0.75": 0.6417540234591551,
      "eval_ipcw_0th_event_1.0": 0.6194385705788219,
      "eval_ipcw_0th_event_n": 253,
      "eval_ipcw_avg": 0.6463176582149972,
      "eval_ipcw_avg_0th_event": 0.6463176582149972,
      "eval_ipcw_weighted_avg": 0.6463176582149972,
      "eval_loss": 3.0168299674987793,
      "eval_runtime": 0.1163,
      "eval_samples_per_second": 3819.158,
      "eval_steps_per_second": 8.602,
      "step": 80
    },
    {
      "epoch": 40.5,
      "grad_norm": 7.439487934112549,
      "learning_rate": 0.0015774634580436166,
      "loss": 6.032,
      "step": 81
    },
    {
      "epoch": 40.5,
      "eval_brier_0th_event": 0.2014460664421586,
      "eval_brier_0th_event_n": 253,
      "eval_brier_avg": 0.2014460664421586,
      "eval_brier_weighted_avg": 0.2014460664421586,
      "eval_ipcw": 0.6190946770866126,
      "eval_ipcw_0th_event": 0.6190946770866126,
      "eval_ipcw_0th_event_0.25": 0.6777491443093576,
      "eval_ipcw_0th_event_0.5": 0.6508922440892403,
      "eval_ipcw_0th_event_0.75": 0.642447496949386,
      "eval_ipcw_0th_event_1.0": 0.6190946770866126,
      "eval_ipcw_0th_event_n": 253,
      "eval_ipcw_avg": 0.6475458906086491,
      "eval_ipcw_avg_0th_event": 0.6475458906086491,
      "eval_ipcw_weighted_avg": 0.6475458906086491,
      "eval_loss": 3.0135140419006348,
      "eval_runtime": 0.1059,
      "eval_samples_per_second": 4190.774,
      "eval_steps_per_second": 9.439,
      "step": 81
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 1,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4661099520.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
